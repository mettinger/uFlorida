{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d3475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "import scalpDeepModels as sdm\n",
    "\n",
    "import importlib\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef38d8",
   "metadata": {},
   "source": [
    "# PARAMETERS - GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f63db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "stftSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/freqRTheta.npz'\n",
    "timeDomainSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeDomain.npz'\n",
    "timeFreqSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeFreqRTheta.npz'\n",
    "\n",
    "modelPath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/'\n",
    "\n",
    "neptuneProject = 'jettinger35/predictScalp'\n",
    "api_token = os.environ.get('NEPTUNE_API_TOKEN')\n",
    "\n",
    "subsampleFreq = 128   # FINAL FREQUENCY IN HERTZ AFTER SUBSAMPLING\n",
    "secondsInWindow = 1\n",
    "nperseg = subsampleFreq * secondsInWindow\n",
    "noverlap = nperseg - 1\n",
    "window = ('tukey', .25)\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7fce9",
   "metadata": {},
   "source": [
    "# PARAMETERS - TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224077ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 1024\n",
    "learningRate = 1e-3\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "optChoice = 'adam'\n",
    "\n",
    "patience = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6db8c0",
   "metadata": {},
   "source": [
    "# UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7e2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT STFT FROM R,THETA TO COMPLEX\n",
    "# dim(z) = (# timesteps, # freq bins x 2 (2 reals = 1 complex))\n",
    "\n",
    "def rThetaToComplex(z):\n",
    "    rows, cols = z.shape\n",
    "    shortTermFourier = np.zeros((rows, cols // 2), dtype=np.csingle)\n",
    "    for i in range(rows):\n",
    "        for k in range(cols // 2):\n",
    "            r = z[i,k]\n",
    "            theta = z[i, (k + cols // 2)]\n",
    "            shortTermFourier[i,k] =  r * np.exp(complex(0, theta))\n",
    "    return shortTermFourier.transpose() # dim = (# freq bins, # timepoints)\n",
    "\n",
    "# CONVERT REAL STFT TO COMPLEX STFT, INVERT TO GET THE ISTFT (I.E. TIME SERIES), THEN PLOT\n",
    "\n",
    "def realSTFTtoTimeSeries(realSTFT):\n",
    "    shortTermFourierComplex = rThetaToComplex(realSTFT)\n",
    "    times, inverseShortFourier = istft(shortTermFourierComplex, \n",
    "                                       fs=subsampleFreq, \n",
    "                                       window=window, \n",
    "                                       nperseg=nperseg, \n",
    "                                       noverlap=noverlap)\n",
    "    return times, inverseShortFourier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbd749",
   "metadata": {},
   "source": [
    "# LOAD NUMPY DATA ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba4b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSwitch = 'time'\n",
    "\n",
    "if dataSwitch == 'freq':\n",
    "    # STFT DATA\n",
    "\n",
    "    npzfile = np.load(stftSavePath)\n",
    "    x_trainRTheta = npzfile['x_trainRTheta']\n",
    "    x_validRTheta = npzfile['x_validRTheta'] \n",
    "    y_trainRTheta = npzfile['y_trainRTheta'] \n",
    "    y_validRTheta = npzfile['y_validRTheta']\n",
    "\n",
    "    trainXTensor = torch.Tensor(x_trainRTheta)\n",
    "    trainYTensor = torch.Tensor(y_trainRTheta)\n",
    "    validXTensor = torch.Tensor(x_validRTheta)\n",
    "    validYTensor = torch.Tensor(y_validRTheta)\n",
    "\n",
    "elif dataSwitch == 'time':\n",
    "    # TIME DOMAIN DATA\n",
    "\n",
    "    npzfile = np.load(timeDomainSavePath)\n",
    "    xTrainTimeDomain = npzfile['xTrainTimeDomain']\n",
    "    xValidTimeDomain = npzfile['xValidTimeDomain'] \n",
    "    yTrainTimeDomain = npzfile['yTrainTimeDomain'] \n",
    "    yValidTimeDomain = npzfile['yValidTimeDomain']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrainTimeDomain)\n",
    "    trainYTensor = torch.Tensor(yTrainTimeDomain)\n",
    "    validXTensor = torch.Tensor(xValidTimeDomain)\n",
    "    validYTensor = torch.Tensor(yValidTimeDomain)\n",
    "    \n",
    "elif dataSwitch == 'timeFreq':\n",
    "    \n",
    "    npzfile = np.load(timeFreqSavePath)\n",
    "    xTrain = npzfile['x_trainTimeFreq']\n",
    "    xValid = npzfile['x_validTimeFreq'] \n",
    "    yTrain = npzfile['y_trainTimeFreq'] \n",
    "    yValid = npzfile['y_validTimeFreq']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrain)\n",
    "    trainYTensor = torch.Tensor(yTrain)\n",
    "    validXTensor = torch.Tensor(xValid)\n",
    "    validYTensor = torch.Tensor(yValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedd53c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 1]) torch.float32\n",
      "\n",
      "test: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# CREATE PYTORCH DATALOADERS\n",
    "\n",
    "trainDataset = TensorDataset(trainXTensor,trainYTensor)\n",
    "trainDataLoader = DataLoader(trainDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validDataset = TensorDataset(validXTensor,validYTensor)\n",
    "validDataLoader = DataLoader(validDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"train: \")\n",
    "for X, y in trainDataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "print(\"\\ntest: \")\n",
    "for X, y in validDataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243c05c",
   "metadata": {},
   "source": [
    "# DEFINE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeaad9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: 982815\n",
      "Number of parameters:  3963439\n",
      "Sequential(\n",
      "  (bn0): BatchNorm1d(5655, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l0): Linear(in_features=5655, out_features=512, bias=True)\n",
      "  (r0): ReLU()\n",
      "  (d0): Dropout(p=0.5, inplace=False)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r1): ReLU()\n",
      "  (d1): Dropout(p=0.5, inplace=False)\n",
      "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r2): ReLU()\n",
      "  (d2): Dropout(p=0.5, inplace=False)\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r3): ReLU()\n",
      "  (d3): Dropout(p=0.5, inplace=False)\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r4): ReLU()\n",
      "  (d4): Dropout(p=0.5, inplace=False)\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "importlib.reload(sdm) # reload in case we've made any architecture changes\n",
    "\n",
    "modelID = np.random.randint(0, 10**6)\n",
    "\n",
    "# DEFINE ARCHITECTURE HERE\n",
    "inputSize = trainXTensor.shape[1]\n",
    "hiddenLayerSizes = [512,512,512,512,512,512]\n",
    "\n",
    "layerDict = sdm.listToOrderedDict_1([inputSize] + hiddenLayerSizes)\n",
    "#layerDict = sdm.residualAddDict(inputSize, 512, 5)\n",
    "#layerDict = sdm.residualConcatDict(inputSize, hiddenLayerSizes)\n",
    "\n",
    "model = nn.Sequential(layerDict)\n",
    "bestTestLoss = float('inf')\n",
    "    \n",
    "print(\"Model ID: \" + str(modelID))\n",
    "print(\"Number of parameters: \", sdm.count_parameters(model))\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68e5ed",
   "metadata": {},
   "source": [
    "# TRAIN (LOG DATA TO NEPTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c6012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-66\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.829233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.679717 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.757629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.675505 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.798541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.669964 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.777038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.663156 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.698888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.656167 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.746138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.648799 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.739126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.641775 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.677994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.637637 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.718581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.638230 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.692159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.634185 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.686396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.631450 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.684408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.631075 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.689453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.625338 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.646151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.621583 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.631158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.618137 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.665125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.615213 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.653768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.613483 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.640502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.612933 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.638480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.613576 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.645236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.605314 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.621704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.595437 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.634750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.582952 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.592622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.575960 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.594341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.565944 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.618985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.554301 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.588213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.543652 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.597751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535405 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.587108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531927 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.566434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525821 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.589449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520669 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.604607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517501 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.560996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513827 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.530087  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511120 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.535027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.509348 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.542265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.506184 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.574717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.500585 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.532931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.497076 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.547938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.493331 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.555251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.492168 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.530863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.492733 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.509203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.490837 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.519150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.486567 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.560927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.484449 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.533001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.486884 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.540838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487855 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.510140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487153 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.526427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487195 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.550625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487053 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.507902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.485662 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.488638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.486823 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.501453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.488295 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.510948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487518 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.514923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.485013 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.493525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.480865 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.492582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.478007 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.527518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.473277 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.505698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.469598 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.493005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.466852 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.502857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.464033 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.478453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.463110 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.493571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.461931 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.448940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.463268 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.479353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.465395 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.464507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.465550 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.483207  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.465547 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.464357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.463298 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.477719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.461513 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.485830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.460736 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.458687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.462277 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.464907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.462778 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.460154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.459822 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.461097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.454711 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.492307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451280 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.477425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447671 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.467293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447747 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.458881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446318 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.462314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445666 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.454846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445667 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.474434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445515 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.455290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444513 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.443264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442174 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.440239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442666 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.438727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444267 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.462324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445141 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.474124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445289 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.447501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444547 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.458916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442982 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.449070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441257 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.453884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441245 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.434602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440991 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.436645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439062 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.424196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437964 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.430298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436247 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.434483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435407 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.435115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436608 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.401457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437705 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.424353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439185 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.436875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437099 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.421766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435116 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.420605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433393 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.443041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429349 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.447454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427450 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.424714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427483 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.417027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428551 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.427003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428851 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.423848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428574 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.448007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428660 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.424907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429093 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.421124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427578 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.465652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426911 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.423828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426810 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.429750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427656 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.426906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427856 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.435391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427053 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.434502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426605 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.431928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428579 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.423191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432244 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.435864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432060 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.470842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430124 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.426825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427357 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.451083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426160 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.435115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428832 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.429988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431938 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.436286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432935 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.429190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428893 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.436071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423590 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.414821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420663 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.413176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422743 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.413862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426034 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.411402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426702 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.438672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422410 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.429274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418869 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.390766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421107 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.428084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429491 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.430783  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.433386 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.435549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431005 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.453028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422959 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.442638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413788 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.393823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415867 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.421842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425170 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.414223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428151 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.442633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423561 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.409549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418465 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.440031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418245 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.421166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423392 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.410377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427972 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.408565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430341 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.396065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425981 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.410724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420051 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.407757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417112 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.409433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415923 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.404343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417862 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.416279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419283 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.412882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419014 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.413624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417288 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.412017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415201 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.443233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415622 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.411867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418229 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.413347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420835 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.402067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422263 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.424143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421848 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.423987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418812 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.435182  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416736 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.413065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413957 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.418743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412638 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.407356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412136 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.426064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411806 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.391282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411656 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.403640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410531 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.401424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410894 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.403612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411144 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.402783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411065 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.398172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411327 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.404805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411223 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.404519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412082 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.407729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412628 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.416458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411330 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.412392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409926 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.376147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409888 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.413788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410740 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.431203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411059 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.418239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409660 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.423720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406801 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.383075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406128 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.408688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409959 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.438628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412933 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.411999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411908 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.407705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410944 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.408108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415728 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.408588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421485 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.402861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423383 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.408264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420562 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.391970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416006 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.383619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412187 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.420701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409763 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.407526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409234 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.411545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408737 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.404347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407472 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.437440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407301 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.395233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409717 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.401836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410654 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.415336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409017 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.403270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407646 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.400258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406140 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.388546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405343 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.378420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404931 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.390330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404898 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.409594  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.405446 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.381952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405767 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.426137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403918 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.388333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403287 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.414971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403797 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.384628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404866 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.392816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405908 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.400754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406275 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.385122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404419 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.377778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403981 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.404784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405517 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.375736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407703 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.395417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408008 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.405307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406245 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.395472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406042 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.413943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413285 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.396912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420084 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.400878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419404 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.413329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413627 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.400753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405770 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.379701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408181 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.404413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418941 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.421418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421880 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.420778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413769 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.386307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408200 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.374785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410562 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.399317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414606 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.406012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415881 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.413400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414544 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.407958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411547 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.381397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408483 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.400551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405977 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.406262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405318 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.382881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408003 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.396544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410758 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.395781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408965 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.402237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405835 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.356926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406206 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.391436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410555 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.399652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417363 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.402686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418390 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.387021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411085 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.374229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404377 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.383477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404386 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.394993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407080 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.379053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408285 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.400912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407029 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.384700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405889 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.384948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409319 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.392332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414521 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.399072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414621 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.394210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408459 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.411893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404158 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.384416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404681 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.387943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405962 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.400988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405820 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.387170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405598 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.413797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406353 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.378650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407386 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.379657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406219 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.389153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404074 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.395091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403428 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.372906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403731 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.391661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404810 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.404132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405847 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.389375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406425 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.399497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408213 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.389508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409066 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.419641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405419 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.365803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404332 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.375445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403803 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.399701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407017 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.377946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409650 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.382374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409635 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.390661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406713 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.384676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405101 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.381008  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.407723 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.386351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410841 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.366865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410830 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.373037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407158 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.395135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401667 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.412316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398634 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.351128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399135 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.391482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399760 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.388072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399597 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.389166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398239 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.376221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398435 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.367793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399890 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.387201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401049 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.374048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401960 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.384677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402668 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.376620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403455 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.375973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403427 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.392556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402182 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.403324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399573 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.368461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397909 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.392277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398034 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.370736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397795 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.374146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396471 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.357873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396833 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.410720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397723 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.359060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395721 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.377965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394303 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.381294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395150 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.394199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398001 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.382310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400135 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.387605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400190 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.396007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401241 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.365829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404206 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.380888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404493 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.405764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400506 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.382727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398421 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.374097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402604 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.379199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407527 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.395957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406360 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.387209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399583 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.380898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401221 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.385562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406336 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.359006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409645 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.359267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409271 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.389334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404022 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.369200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399830 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.394087  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400262 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.370737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402523 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.389414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403723 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.379329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400078 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.372020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398639 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.371965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399512 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.372391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401765 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.359080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405711 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.385607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408342 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.377585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407370 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.378103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403810 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.360670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399734 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.374240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396959 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.390108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396542 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.377485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397069 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.370191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396539 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.384303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396839 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.391688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397510 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.345570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395945 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.375733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396372 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.380152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397370 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.372311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397333 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.355477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396124 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.360824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395985 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.370820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395910 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.370296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395376 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.373243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396060 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.381846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397713 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.386191  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397830 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.361890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397619 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.373946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397398 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.400412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397120 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.367069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397861 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.371758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399688 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.393206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402384 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.351129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405739 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.360768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408577 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.386500  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407172 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.381075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402616 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.366185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402410 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.366752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403960 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.364556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406075 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.369880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405014 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.369063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401466 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.365426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399234 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.368870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398219 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.371124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399266 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.362767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401460 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.348954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400930 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.370343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397904 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.359624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396316 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.372202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396978 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.382568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396376 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.359362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395135 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.366910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395860 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.389170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399394 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.364975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400693 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.365266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398949 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.366926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396089 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.375312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394451 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.363255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394306 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.371818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394811 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.373179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396961 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.358485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398795 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.339384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399904 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.368874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401925 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.372229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401753 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.380496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400877 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.388499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400462 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.356968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400090 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.355938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398261 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.363464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397625 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.348379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399275 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.364499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400554 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.362059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401202 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.355756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399830 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.393036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399636 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.375216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402627 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.362079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410423 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.379665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415290 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.378124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413202 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.369341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403456 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.373817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402060 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.348980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410241 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.373855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415383 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.384716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414573 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.380495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406706 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.380664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402351 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.350503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403937 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.375014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408595 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.364481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409851 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.373403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405513 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.397751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401543 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.361980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402395 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.348740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407216 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.381295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408449 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.388526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405216 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.367534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399870 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.374181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396909 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.359789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399340 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.376851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403570 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.377039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403563 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.363587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401761 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.351812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399832 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.367280  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400148 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.353776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400878 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.372344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401404 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.381031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400412 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.355015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400447 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.357157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401718 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.361782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401677 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.368694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400080 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.372610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398756 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.370607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398345 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.342887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399434 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.371854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400405 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.365583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400667 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.359436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400682 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.358197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400493 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.354856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399163 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.368062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398313 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.356402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396866 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.373854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395897 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.343101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396746 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.361537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397420 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.368969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396224 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.361443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397123 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.366605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397352 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.376885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397998 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.354985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397410 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.345654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395623 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.356454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393649 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.362880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394216 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.360448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395028 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.369599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397322 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.347575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397121 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.356393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396402 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.365909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400770 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.332970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406478 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.379372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406684 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.352414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404468 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.362572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400462 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.374023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399140 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.342736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400500 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.359008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402773 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.368023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402803 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.358199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400015 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.355618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396640 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.339706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397259 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.353133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402885 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.336856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406264 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.351106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403726 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.343297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399127 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.355407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395864 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.358223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396127 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.358072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397942 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.360379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398183 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.345694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400514 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.357410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402833 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.366380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404762 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.385538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406811 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.350951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404135 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.379742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400523 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.350222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397937 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.360927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397227 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.350612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398378 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.369328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398610 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.363577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396245 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.351491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393947 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.375204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394657 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.361842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397620 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.359563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399433 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.384886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398084 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.353588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396388 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.358470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397150 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.357777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398613 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.341967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399152 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.369537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398011 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.348084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396635 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.341935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395384 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.349295  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.394064 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.359295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394841 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.354126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396777 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.378165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397939 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.367201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396498 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.346504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396443 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.362808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396056 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.352599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395165 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.359943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395136 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.358221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395006 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.361664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395337 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.368364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396687 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.342974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395730 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.365160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394023 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.334300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394441 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.368015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397247 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.354137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399723 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.339930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400330 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.365067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396112 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.348478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393724 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.353796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394799 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.348278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397524 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.364812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398924 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.350913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399395 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.387610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399593 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.347259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404420 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.349067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411149 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.373205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411188 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.336172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405571 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.346263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398281 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.338203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395924 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.363157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398847 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.354780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400142 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.371918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398055 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.346959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396710 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.340163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398977 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.334545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399474 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.343919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399662 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.350757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396476 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.356321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394971 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.359101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395900 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.356040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397645 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.353556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398443 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.344574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394762 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.332333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393214 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.355068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396266 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.350770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401741 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.359761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402075 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.333255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399140 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.344996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395799 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.353120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392637 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.359047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394524 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.345339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397122 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.357314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397441 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.348563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396084 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.360298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397254 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.330536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401381 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.348550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404521 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.350863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404183 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.351796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401591 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.353681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398674 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.383225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396166 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.332439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396267 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.352261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396745 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.344706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397115 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.356904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396090 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.353220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397169 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.344115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401030 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.352555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405338 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.340793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403524 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.350196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398286 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.341754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394842 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.349472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394646 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.329324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395745 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.331294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395853 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.346336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395191 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.346557  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.396760 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.349175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398300 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.358883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398541 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.360936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398076 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.352247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396731 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.342657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395820 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.366579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395937 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.376844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395863 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.349727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396197 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.356555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396208 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.335523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396508 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.352316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397611 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.387802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395749 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.336999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394178 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.360112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393176 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.339184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394767 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.350013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399827 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.347187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403458 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.333456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403076 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.331194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400204 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.342437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396861 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.347906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392041 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.344245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.389841 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.372044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391170 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.319176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394038 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.338059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393919 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.337898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392592 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.341220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391379 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.321092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391814 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.363006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395147 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.340225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398201 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.342811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401182 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.347507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400682 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.358356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398794 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.355232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397243 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.349045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397649 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.349022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400352 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.361991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402067 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.351463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401636 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.337741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399562 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.350339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397153 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.337655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396838 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.347823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397183 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.348583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398307 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.342249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398017 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.323221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397535 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.336972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397209 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.323308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397452 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.328984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397749 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.354233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398169 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.337084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398376 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.351509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398403 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.323314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398512 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.337658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398116 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.346362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398446 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.338471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398349 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.342557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398970 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.339621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399087 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.338540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398023 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.328601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397307 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.328378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398006 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.339291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399131 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.332991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399608 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.345267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399353 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.354801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396853 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.322386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396596 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.367148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397458 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.326411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397846 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.321771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396984 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.344425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397859 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.324172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401360 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.356122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399709 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.348717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393650 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.345869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392641 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.339016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393891 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.352531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394862 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.336647  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.393927 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.342674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393299 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.348933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396377 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.347349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398484 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.344966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399020 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.349816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394265 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.313084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392480 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.327477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393710 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.352831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395634 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.340656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398114 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.355552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398367 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.353455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396502 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.332142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395920 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.355156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395430 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.341658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394740 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.328625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396599 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.329676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400849 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.332610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401302 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.330591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398018 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.361644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394423 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.330540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396323 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.329088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399966 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.340318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401530 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.348811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398637 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.346840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397003 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.337518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399283 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.333457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401180 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.352386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399151 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.350103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397685 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.331188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397616 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.334475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396741 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.335263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396193 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.336211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396367 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.331239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395255 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.325562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396583 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.339247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397142 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.350297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398793 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.351441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397870 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.327140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397024 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.342581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398901 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.310375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401465 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.346064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401708 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.333811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400180 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.339269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399020 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.339746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396748 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.339023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394321 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.336226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393987 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.333769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395472 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.336057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397276 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.329019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396807 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.337207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395237 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.342943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396084 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.323597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401618 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.317975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405120 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.332115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404178 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.328313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401403 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.339991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399597 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.344755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395645 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.318085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393444 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.329482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395418 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.342596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398841 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.361945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401948 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.345014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402609 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.335461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400074 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.334687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398093 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.339202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398634 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.348009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401227 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.344819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402291 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.303397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402612 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.347932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401161 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.346945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397848 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.339419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394688 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.309018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394331 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.329537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396331 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.357276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398151 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.329020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398737 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.348211  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.396885 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.307733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395857 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.312056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395653 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.335818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395383 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.343983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395919 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.349392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395805 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.339474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395998 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.326417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394439 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.330355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394373 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.325626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397242 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.335371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400655 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.323397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401804 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.336361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399544 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.311297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395966 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.340387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395318 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.321823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397001 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.327651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399709 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.328584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401362 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.337123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397181 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.332187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395412 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.310954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399082 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.330700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402407 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.332181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401712 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.342643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397296 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.334144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393219 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.321811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393540 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.334570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394444 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.321540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395561 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.321689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395898 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.318957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396256 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.348680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396530 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.326306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398082 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.325341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400086 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.347052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400013 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.357629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398003 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.334383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396047 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.328958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395811 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.309687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396264 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.323310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397792 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.337902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399013 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.328785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400224 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.342883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401632 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.353206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400406 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.332603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398653 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.353228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397014 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.316769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395283 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.348009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394764 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.321631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395546 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.326266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396337 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.335150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398539 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.304497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398544 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.337870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397118 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.332857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395521 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.343096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396444 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.334870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398835 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.333672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398089 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.348602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397102 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.337629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397213 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.347568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399236 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.338235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399662 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.348688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399194 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.346929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398202 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.326598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396720 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.341204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395702 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.350273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395855 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.332128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397603 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.306461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398984 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.336299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398262 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.325194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398462 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.343928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400274 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.322799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401553 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.342165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402017 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.341205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401137 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.332007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402514 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.324011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404369 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.324698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404491 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.317097  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403979 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.331001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400670 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.314259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396552 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.345943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395313 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.326063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395386 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.326341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394911 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.327994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395272 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.313428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399425 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.345818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405391 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.324392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407053 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.323733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404005 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.326566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396251 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.341492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391168 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.328502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392383 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.337259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393521 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.343939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392956 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.303699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393560 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.330054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394922 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.318580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396141 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.335543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395732 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.332338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395312 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.306790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395443 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.337517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393121 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.316346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392646 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.327899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392480 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.317392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392097 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.316879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394037 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.313043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400686 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.336829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402861 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.310094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399532 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.331247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396077 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.322807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395385 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.333688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396479 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.340654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396358 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.333541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395562 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.320202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398140 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.319489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402074 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.318072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403150 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.315125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400807 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.332117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397404 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.320638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398762 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.330543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402511 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.321427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402389 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.340312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398110 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.312209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400477 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.327261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406480 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.338152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407760 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.336181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402748 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.329875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396840 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.307159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396039 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.324464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398057 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.320720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397543 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.323492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397001 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.331256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396369 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.312611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398154 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.311770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398728 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.318268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398068 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.315725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396511 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.291142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395487 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.330093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394084 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.299349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394639 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.309543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394932 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.319383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394295 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.321404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395169 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.318922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397331 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.339166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400170 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.312915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400358 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.338300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395877 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.306541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394270 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.326427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396414 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.314721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399526 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.327126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400325 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.314024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400920 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.314965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401146 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.323247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401385 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.324459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400895 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.315347  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399724 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.326286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397868 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.322751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396737 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.307778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396443 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.309435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397019 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.311040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397032 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.330194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396901 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.324192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396512 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.338175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395928 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.329158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394696 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.314176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394637 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.319959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394376 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.321654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393695 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.316906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394442 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.319834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397112 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.304141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398546 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.322071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399343 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.326149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398594 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.316344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397906 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.296243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396018 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.332928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394728 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.302179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393630 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.309055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391863 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.333726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392566 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.316975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397777 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.336077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401983 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.335884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402633 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.337414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399537 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.314874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397628 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.313948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400054 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.315346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401192 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.346682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398538 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.323656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396287 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.309723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396168 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.321628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398728 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.319753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400233 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.318958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399714 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.308776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398838 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.315813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398022 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.311554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397932 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.312123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398179 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.324893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397444 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.336509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397525 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.330129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399896 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.309809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402555 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.312752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402489 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.314433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401790 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.324202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399841 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.324778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398928 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.324679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398708 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.323756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399390 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.331978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400884 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.308951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403792 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.333434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408789 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.316643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412972 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.306136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412064 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.347157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405444 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.318144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399391 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.320271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398171 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.316988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398092 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.326646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397424 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.312404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397203 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.321016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397603 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.324622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398728 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.309097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400375 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.328798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400899 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.325897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400565 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.317265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400636 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.310726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400650 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.329854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400583 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.298351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401031 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.318724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403904 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.308311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407810 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.320996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409738 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.313612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406357 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.313587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401077 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.305670  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.398603 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.334078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398389 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.328870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398728 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.311814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397855 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.321183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397232 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.321300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398087 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.308409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399793 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.310262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400350 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.306672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400355 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.313571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401748 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.298524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401635 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.299369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399819 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.319371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398733 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.308516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397665 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.338628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395984 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.321428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393858 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.303927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395593 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.342217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397990 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.337567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398639 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.320887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397659 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.301868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395990 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.320781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396302 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.309156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399004 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.323606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399083 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.314240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397579 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.302762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397557 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.323375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398634 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.323127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398128 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.319791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396099 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.298767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395438 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.293249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396785 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.315343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398233 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.293155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400715 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.317746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401212 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.308333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399840 \n",
      "\n",
      "Epoch 1001\n",
      "-------------------------------\n",
      "loss: 0.317856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397952 \n",
      "\n",
      "Epoch 1002\n",
      "-------------------------------\n",
      "loss: 0.322397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397521 \n",
      "\n",
      "Epoch 1003\n",
      "-------------------------------\n",
      "loss: 0.302782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397718 \n",
      "\n",
      "Epoch 1004\n",
      "-------------------------------\n",
      "loss: 0.323842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397181 \n",
      "\n",
      "Epoch 1005\n",
      "-------------------------------\n",
      "loss: 0.334721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397377 \n",
      "\n",
      "Epoch 1006\n",
      "-------------------------------\n",
      "loss: 0.300503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398841 \n",
      "\n",
      "Epoch 1007\n",
      "-------------------------------\n",
      "loss: 0.291744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401268 \n",
      "\n",
      "Epoch 1008\n",
      "-------------------------------\n",
      "loss: 0.314410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399942 \n",
      "\n",
      "Epoch 1009\n",
      "-------------------------------\n",
      "loss: 0.304719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398446 \n",
      "\n",
      "Epoch 1010\n",
      "-------------------------------\n",
      "loss: 0.327674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396792 \n",
      "\n",
      "Epoch 1011\n",
      "-------------------------------\n",
      "loss: 0.333243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396246 \n",
      "\n",
      "Epoch 1012\n",
      "-------------------------------\n",
      "loss: 0.305202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396873 \n",
      "\n",
      "Epoch 1013\n",
      "-------------------------------\n",
      "loss: 0.302215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397656 \n",
      "\n",
      "Epoch 1014\n",
      "-------------------------------\n",
      "loss: 0.295728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399254 \n",
      "\n",
      "Epoch 1015\n",
      "-------------------------------\n",
      "loss: 0.297919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402171 \n",
      "\n",
      "Epoch 1016\n",
      "-------------------------------\n",
      "loss: 0.319466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404364 \n",
      "\n",
      "Epoch 1017\n",
      "-------------------------------\n",
      "loss: 0.332220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404529 \n",
      "\n",
      "Epoch 1018\n",
      "-------------------------------\n",
      "loss: 0.326599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400785 \n",
      "\n",
      "Epoch 1019\n",
      "-------------------------------\n",
      "loss: 0.302168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397280 \n",
      "\n",
      "Epoch 1020\n",
      "-------------------------------\n",
      "loss: 0.302348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395741 \n",
      "\n",
      "Epoch 1021\n",
      "-------------------------------\n",
      "loss: 0.310899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396151 \n",
      "\n",
      "Epoch 1022\n",
      "-------------------------------\n",
      "loss: 0.310680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396338 \n",
      "\n",
      "Epoch 1023\n",
      "-------------------------------\n",
      "loss: 0.324711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396881 \n",
      "\n",
      "Epoch 1024\n",
      "-------------------------------\n",
      "loss: 0.313393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396781 \n",
      "\n",
      "Epoch 1025\n",
      "-------------------------------\n",
      "loss: 0.324029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396605 \n",
      "\n",
      "Epoch 1026\n",
      "-------------------------------\n",
      "loss: 0.317854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396377 \n",
      "\n",
      "Epoch 1027\n",
      "-------------------------------\n",
      "loss: 0.300661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395854 \n",
      "\n",
      "Epoch 1028\n",
      "-------------------------------\n",
      "loss: 0.319998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395095 \n",
      "\n",
      "Epoch 1029\n",
      "-------------------------------\n",
      "loss: 0.316606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394599 \n",
      "\n",
      "Epoch 1030\n",
      "-------------------------------\n",
      "loss: 0.317811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394725 \n",
      "\n",
      "Epoch 1031\n",
      "-------------------------------\n",
      "loss: 0.319296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395284 \n",
      "\n",
      "Epoch 1032\n",
      "-------------------------------\n",
      "loss: 0.331290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396629 \n",
      "\n",
      "Epoch 1033\n",
      "-------------------------------\n",
      "loss: 0.300998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399145 \n",
      "\n",
      "Epoch 1034\n",
      "-------------------------------\n",
      "loss: 0.295669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401094 \n",
      "\n",
      "Epoch 1035\n",
      "-------------------------------\n",
      "loss: 0.302730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402724 \n",
      "\n",
      "Epoch 1036\n",
      "-------------------------------\n",
      "loss: 0.305083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402338 \n",
      "\n",
      "Epoch 1037\n",
      "-------------------------------\n",
      "loss: 0.285547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401705 \n",
      "\n",
      "Epoch 1038\n",
      "-------------------------------\n",
      "loss: 0.305772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400578 \n",
      "\n",
      "Epoch 1039\n",
      "-------------------------------\n",
      "loss: 0.324894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401398 \n",
      "\n",
      "Epoch 1040\n",
      "-------------------------------\n",
      "loss: 0.308974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400925 \n",
      "\n",
      "Epoch 1041\n",
      "-------------------------------\n",
      "loss: 0.302273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400408 \n",
      "\n",
      "Epoch 1042\n",
      "-------------------------------\n",
      "loss: 0.310806  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.398556 \n",
      "\n",
      "Epoch 1043\n",
      "-------------------------------\n",
      "loss: 0.308288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396911 \n",
      "\n",
      "Epoch 1044\n",
      "-------------------------------\n",
      "loss: 0.299866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395000 \n",
      "\n",
      "Epoch 1045\n",
      "-------------------------------\n",
      "loss: 0.316980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394729 \n",
      "\n",
      "Epoch 1046\n",
      "-------------------------------\n",
      "loss: 0.295892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394878 \n",
      "\n",
      "Epoch 1047\n",
      "-------------------------------\n",
      "loss: 0.325225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395965 \n",
      "\n",
      "Epoch 1048\n",
      "-------------------------------\n",
      "loss: 0.310552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395237 \n",
      "\n",
      "Epoch 1049\n",
      "-------------------------------\n",
      "loss: 0.328959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394168 \n",
      "\n",
      "Epoch 1050\n",
      "-------------------------------\n",
      "loss: 0.309224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394708 \n",
      "\n",
      "Epoch 1051\n",
      "-------------------------------\n",
      "loss: 0.299633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395733 \n",
      "\n",
      "Epoch 1052\n",
      "-------------------------------\n",
      "loss: 0.311556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396251 \n",
      "\n",
      "Epoch 1053\n",
      "-------------------------------\n",
      "loss: 0.310949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394839 \n",
      "\n",
      "Epoch 1054\n",
      "-------------------------------\n",
      "loss: 0.298179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397134 \n",
      "\n",
      "Epoch 1055\n",
      "-------------------------------\n",
      "loss: 0.301823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404569 \n",
      "\n",
      "Epoch 1056\n",
      "-------------------------------\n",
      "loss: 0.295286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409947 \n",
      "\n",
      "Epoch 1057\n",
      "-------------------------------\n",
      "loss: 0.326723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407390 \n",
      "\n",
      "Epoch 1058\n",
      "-------------------------------\n",
      "loss: 0.299883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400987 \n",
      "\n",
      "Epoch 1059\n",
      "-------------------------------\n",
      "loss: 0.315041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396943 \n",
      "\n",
      "Epoch 1060\n",
      "-------------------------------\n",
      "loss: 0.295541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396661 \n",
      "\n",
      "Epoch 1061\n",
      "-------------------------------\n",
      "loss: 0.314874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400988 \n",
      "\n",
      "Epoch 1062\n",
      "-------------------------------\n",
      "loss: 0.327980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400888 \n",
      "\n",
      "Epoch 1063\n",
      "-------------------------------\n",
      "loss: 0.324339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397452 \n",
      "\n",
      "Epoch 1064\n",
      "-------------------------------\n",
      "loss: 0.311180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398545 \n",
      "\n",
      "Epoch 1065\n",
      "-------------------------------\n",
      "loss: 0.300910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403287 \n",
      "\n",
      "Epoch 1066\n",
      "-------------------------------\n",
      "loss: 0.301798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404528 \n",
      "\n",
      "Epoch 1067\n",
      "-------------------------------\n",
      "loss: 0.303624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402668 \n",
      "\n",
      "Epoch 1068\n",
      "-------------------------------\n",
      "loss: 0.292237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401169 \n",
      "\n",
      "Epoch 1069\n",
      "-------------------------------\n",
      "loss: 0.293662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401881 \n",
      "\n",
      "Epoch 1070\n",
      "-------------------------------\n",
      "loss: 0.319341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403197 \n",
      "\n",
      "Epoch 1071\n",
      "-------------------------------\n",
      "loss: 0.316838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402675 \n",
      "\n",
      "Epoch 1072\n",
      "-------------------------------\n",
      "loss: 0.300339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402350 \n",
      "\n",
      "Epoch 1073\n",
      "-------------------------------\n",
      "loss: 0.314933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402273 \n",
      "\n",
      "Epoch 1074\n",
      "-------------------------------\n",
      "loss: 0.301135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402378 \n",
      "\n",
      "Epoch 1075\n",
      "-------------------------------\n",
      "loss: 0.310504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401633 \n",
      "\n",
      "Epoch 1076\n",
      "-------------------------------\n",
      "loss: 0.315345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399519 \n",
      "\n",
      "Epoch 1077\n",
      "-------------------------------\n",
      "loss: 0.305855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398990 \n",
      "\n",
      "Epoch 1078\n",
      "-------------------------------\n",
      "loss: 0.327283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397426 \n",
      "\n",
      "Epoch 1079\n",
      "-------------------------------\n",
      "loss: 0.321850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394116 \n",
      "\n",
      "Epoch 1080\n",
      "-------------------------------\n",
      "loss: 0.306663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392999 \n",
      "\n",
      "Epoch 1081\n",
      "-------------------------------\n",
      "loss: 0.300158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395896 \n",
      "\n",
      "Epoch 1082\n",
      "-------------------------------\n",
      "loss: 0.314685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399458 \n",
      "\n",
      "Epoch 1083\n",
      "-------------------------------\n",
      "loss: 0.310094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400187 \n",
      "\n",
      "Epoch 1084\n",
      "-------------------------------\n",
      "loss: 0.310948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396315 \n",
      "\n",
      "Epoch 1085\n",
      "-------------------------------\n",
      "loss: 0.320954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392354 \n",
      "\n",
      "Epoch 1086\n",
      "-------------------------------\n",
      "loss: 0.314474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.390173 \n",
      "\n",
      "Epoch 1087\n",
      "-------------------------------\n",
      "loss: 0.292119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.389803 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 1088\n",
      "-------------------------------\n",
      "loss: 0.299423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.390882 \n",
      "\n",
      "Epoch 1089\n",
      "-------------------------------\n",
      "loss: 0.303494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393389 \n",
      "\n",
      "Epoch 1090\n",
      "-------------------------------\n",
      "loss: 0.297575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396085 \n",
      "\n",
      "Epoch 1091\n",
      "-------------------------------\n",
      "loss: 0.334006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398674 \n",
      "\n",
      "Epoch 1092\n",
      "-------------------------------\n",
      "loss: 0.305205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399420 \n",
      "\n",
      "Epoch 1093\n",
      "-------------------------------\n",
      "loss: 0.300994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401313 \n",
      "\n",
      "Epoch 1094\n",
      "-------------------------------\n",
      "loss: 0.301178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403861 \n",
      "\n",
      "Epoch 1095\n",
      "-------------------------------\n",
      "loss: 0.296419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404016 \n",
      "\n",
      "Epoch 1096\n",
      "-------------------------------\n",
      "loss: 0.302903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402324 \n",
      "\n",
      "Epoch 1097\n",
      "-------------------------------\n",
      "loss: 0.304902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400605 \n",
      "\n",
      "Epoch 1098\n",
      "-------------------------------\n",
      "loss: 0.299456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398141 \n",
      "\n",
      "Epoch 1099\n",
      "-------------------------------\n",
      "loss: 0.309312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397380 \n",
      "\n",
      "Epoch 1100\n",
      "-------------------------------\n",
      "loss: 0.311088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397892 \n",
      "\n",
      "Epoch 1101\n",
      "-------------------------------\n",
      "loss: 0.305527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398452 \n",
      "\n",
      "Epoch 1102\n",
      "-------------------------------\n",
      "loss: 0.313162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399037 \n",
      "\n",
      "Epoch 1103\n",
      "-------------------------------\n",
      "loss: 0.315007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400245 \n",
      "\n",
      "Epoch 1104\n",
      "-------------------------------\n",
      "loss: 0.330568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399939 \n",
      "\n",
      "Epoch 1105\n",
      "-------------------------------\n",
      "loss: 0.317779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398312 \n",
      "\n",
      "Epoch 1106\n",
      "-------------------------------\n",
      "loss: 0.288239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397724 \n",
      "\n",
      "Epoch 1107\n",
      "-------------------------------\n",
      "loss: 0.307704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398703 \n",
      "\n",
      "Epoch 1108\n",
      "-------------------------------\n",
      "loss: 0.292787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400281 \n",
      "\n",
      "Epoch 1109\n",
      "-------------------------------\n",
      "loss: 0.310069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401129 \n",
      "\n",
      "Epoch 1110\n",
      "-------------------------------\n",
      "loss: 0.286752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401495 \n",
      "\n",
      "Epoch 1111\n",
      "-------------------------------\n",
      "loss: 0.285281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400828 \n",
      "\n",
      "Epoch 1112\n",
      "-------------------------------\n",
      "loss: 0.315951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398900 \n",
      "\n",
      "Epoch 1113\n",
      "-------------------------------\n",
      "loss: 0.306830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396773 \n",
      "\n",
      "Epoch 1114\n",
      "-------------------------------\n",
      "loss: 0.298801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396488 \n",
      "\n",
      "Epoch 1115\n",
      "-------------------------------\n",
      "loss: 0.308320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397215 \n",
      "\n",
      "Epoch 1116\n",
      "-------------------------------\n",
      "loss: 0.291998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397393 \n",
      "\n",
      "Epoch 1117\n",
      "-------------------------------\n",
      "loss: 0.325611  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397101 \n",
      "\n",
      "Epoch 1118\n",
      "-------------------------------\n",
      "loss: 0.317491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397478 \n",
      "\n",
      "Epoch 1119\n",
      "-------------------------------\n",
      "loss: 0.290903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399797 \n",
      "\n",
      "Epoch 1120\n",
      "-------------------------------\n",
      "loss: 0.333008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398603 \n",
      "\n",
      "Epoch 1121\n",
      "-------------------------------\n",
      "loss: 0.295445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396455 \n",
      "\n",
      "Epoch 1122\n",
      "-------------------------------\n",
      "loss: 0.313927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395720 \n",
      "\n",
      "Epoch 1123\n",
      "-------------------------------\n",
      "loss: 0.317891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396304 \n",
      "\n",
      "Epoch 1124\n",
      "-------------------------------\n",
      "loss: 0.295488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396239 \n",
      "\n",
      "Epoch 1125\n",
      "-------------------------------\n",
      "loss: 0.326617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396780 \n",
      "\n",
      "Epoch 1126\n",
      "-------------------------------\n",
      "loss: 0.304679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397294 \n",
      "\n",
      "Epoch 1127\n",
      "-------------------------------\n",
      "loss: 0.314519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399471 \n",
      "\n",
      "Epoch 1128\n",
      "-------------------------------\n",
      "loss: 0.301680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401130 \n",
      "\n",
      "Epoch 1129\n",
      "-------------------------------\n",
      "loss: 0.300327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400808 \n",
      "\n",
      "Epoch 1130\n",
      "-------------------------------\n",
      "loss: 0.301758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399287 \n",
      "\n",
      "Epoch 1131\n",
      "-------------------------------\n",
      "loss: 0.304956  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397295 \n",
      "\n",
      "Epoch 1132\n",
      "-------------------------------\n",
      "loss: 0.302448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395422 \n",
      "\n",
      "Epoch 1133\n",
      "-------------------------------\n",
      "loss: 0.315352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395819 \n",
      "\n",
      "Epoch 1134\n",
      "-------------------------------\n",
      "loss: 0.310664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397420 \n",
      "\n",
      "Epoch 1135\n",
      "-------------------------------\n",
      "loss: 0.295074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399886 \n",
      "\n",
      "Epoch 1136\n",
      "-------------------------------\n",
      "loss: 0.323816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404410 \n",
      "\n",
      "Epoch 1137\n",
      "-------------------------------\n",
      "loss: 0.287030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408793 \n",
      "\n",
      "Epoch 1138\n",
      "-------------------------------\n",
      "loss: 0.309145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409732 \n",
      "\n",
      "Epoch 1139\n",
      "-------------------------------\n",
      "loss: 0.297168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408049 \n",
      "\n",
      "Epoch 1140\n",
      "-------------------------------\n",
      "loss: 0.300807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405190 \n",
      "\n",
      "Epoch 1141\n",
      "-------------------------------\n",
      "loss: 0.304926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403304 \n",
      "\n",
      "Epoch 1142\n",
      "-------------------------------\n",
      "loss: 0.290788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401193 \n",
      "\n",
      "Epoch 1143\n",
      "-------------------------------\n",
      "loss: 0.300760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399550 \n",
      "\n",
      "Epoch 1144\n",
      "-------------------------------\n",
      "loss: 0.291735  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399737 \n",
      "\n",
      "Epoch 1145\n",
      "-------------------------------\n",
      "loss: 0.305695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401419 \n",
      "\n",
      "Epoch 1146\n",
      "-------------------------------\n",
      "loss: 0.292613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403704 \n",
      "\n",
      "Epoch 1147\n",
      "-------------------------------\n",
      "loss: 0.293388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403651 \n",
      "\n",
      "Epoch 1148\n",
      "-------------------------------\n",
      "loss: 0.305873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403225 \n",
      "\n",
      "Epoch 1149\n",
      "-------------------------------\n",
      "loss: 0.304305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403449 \n",
      "\n",
      "Epoch 1150\n",
      "-------------------------------\n",
      "loss: 0.311036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403912 \n",
      "\n",
      "Epoch 1151\n",
      "-------------------------------\n",
      "loss: 0.307243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402423 \n",
      "\n",
      "Epoch 1152\n",
      "-------------------------------\n",
      "loss: 0.302251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402630 \n",
      "\n",
      "Epoch 1153\n",
      "-------------------------------\n",
      "loss: 0.304304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403805 \n",
      "\n",
      "Epoch 1154\n",
      "-------------------------------\n",
      "loss: 0.307471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407082 \n",
      "\n",
      "Epoch 1155\n",
      "-------------------------------\n",
      "loss: 0.318883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405807 \n",
      "\n",
      "Epoch 1156\n",
      "-------------------------------\n",
      "loss: 0.314056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402559 \n",
      "\n",
      "Epoch 1157\n",
      "-------------------------------\n",
      "loss: 0.296820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400705 \n",
      "\n",
      "Epoch 1158\n",
      "-------------------------------\n",
      "loss: 0.308954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399428 \n",
      "\n",
      "Epoch 1159\n",
      "-------------------------------\n",
      "loss: 0.304707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399874 \n",
      "\n",
      "Epoch 1160\n",
      "-------------------------------\n",
      "loss: 0.310889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402180 \n",
      "\n",
      "Epoch 1161\n",
      "-------------------------------\n",
      "loss: 0.312896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402819 \n",
      "\n",
      "Epoch 1162\n",
      "-------------------------------\n",
      "loss: 0.296092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402895 \n",
      "\n",
      "Epoch 1163\n",
      "-------------------------------\n",
      "loss: 0.296914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403531 \n",
      "\n",
      "Epoch 1164\n",
      "-------------------------------\n",
      "loss: 0.287701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407087 \n",
      "\n",
      "Epoch 1165\n",
      "-------------------------------\n",
      "loss: 0.297779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412288 \n",
      "\n",
      "Epoch 1166\n",
      "-------------------------------\n",
      "loss: 0.319599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412749 \n",
      "\n",
      "Epoch 1167\n",
      "-------------------------------\n",
      "loss: 0.294800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408805 \n",
      "\n",
      "Epoch 1168\n",
      "-------------------------------\n",
      "loss: 0.281428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403147 \n",
      "\n",
      "Epoch 1169\n",
      "-------------------------------\n",
      "loss: 0.307230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400835 \n",
      "\n",
      "Epoch 1170\n",
      "-------------------------------\n",
      "loss: 0.311766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400315 \n",
      "\n",
      "Epoch 1171\n",
      "-------------------------------\n",
      "loss: 0.303068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399851 \n",
      "\n",
      "Epoch 1172\n",
      "-------------------------------\n",
      "loss: 0.300306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399261 \n",
      "\n",
      "Epoch 1173\n",
      "-------------------------------\n",
      "loss: 0.301984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399853 \n",
      "\n",
      "Epoch 1174\n",
      "-------------------------------\n",
      "loss: 0.303296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401456 \n",
      "\n",
      "Epoch 1175\n",
      "-------------------------------\n",
      "loss: 0.307391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403621 \n",
      "\n",
      "Epoch 1176\n",
      "-------------------------------\n",
      "loss: 0.307683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403967 \n",
      "\n",
      "Epoch 1177\n",
      "-------------------------------\n",
      "loss: 0.315199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403026 \n",
      "\n",
      "Epoch 1178\n",
      "-------------------------------\n",
      "loss: 0.304185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400314 \n",
      "\n",
      "Epoch 1179\n",
      "-------------------------------\n",
      "loss: 0.297380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400047 \n",
      "\n",
      "Epoch 1180\n",
      "-------------------------------\n",
      "loss: 0.294070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398719 \n",
      "\n",
      "Epoch 1181\n",
      "-------------------------------\n",
      "loss: 0.287713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398042 \n",
      "\n",
      "Epoch 1182\n",
      "-------------------------------\n",
      "loss: 0.294787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397070 \n",
      "\n",
      "Epoch 1183\n",
      "-------------------------------\n",
      "loss: 0.298439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397311 \n",
      "\n",
      "Epoch 1184\n",
      "-------------------------------\n",
      "loss: 0.297185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398630 \n",
      "\n",
      "Epoch 1185\n",
      "-------------------------------\n",
      "loss: 0.311142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398564 \n",
      "\n",
      "Epoch 1186\n",
      "-------------------------------\n",
      "loss: 0.299129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399009 \n",
      "\n",
      "Epoch 1187\n",
      "-------------------------------\n",
      "loss: 0.300598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400139 \n",
      "\n",
      "Epoch 1188\n",
      "-------------------------------\n",
      "loss: 0.300201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400711 \n",
      "\n",
      "Epoch 1189\n",
      "-------------------------------\n",
      "loss: 0.292011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400873 \n",
      "\n",
      "Epoch 1190\n",
      "-------------------------------\n",
      "loss: 0.308427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401148 \n",
      "\n",
      "Epoch 1191\n",
      "-------------------------------\n",
      "loss: 0.294358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401204 \n",
      "\n",
      "Epoch 1192\n",
      "-------------------------------\n",
      "loss: 0.283669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402087 \n",
      "\n",
      "Epoch 1193\n",
      "-------------------------------\n",
      "loss: 0.308044  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.402939 \n",
      "\n",
      "Epoch 1194\n",
      "-------------------------------\n",
      "loss: 0.313576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403802 \n",
      "\n",
      "Epoch 1195\n",
      "-------------------------------\n",
      "loss: 0.287374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404185 \n",
      "\n",
      "Epoch 1196\n",
      "-------------------------------\n",
      "loss: 0.289853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404376 \n",
      "\n",
      "Epoch 1197\n",
      "-------------------------------\n",
      "loss: 0.289074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404731 \n",
      "\n",
      "Epoch 1198\n",
      "-------------------------------\n",
      "loss: 0.297691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405601 \n",
      "\n",
      "Epoch 1199\n",
      "-------------------------------\n",
      "loss: 0.294601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406387 \n",
      "\n",
      "Epoch 1200\n",
      "-------------------------------\n",
      "loss: 0.320061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406713 \n",
      "\n",
      "Epoch 1201\n",
      "-------------------------------\n",
      "loss: 0.292226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406945 \n",
      "\n",
      "Epoch 1202\n",
      "-------------------------------\n",
      "loss: 0.290666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406129 \n",
      "\n",
      "Epoch 1203\n",
      "-------------------------------\n",
      "loss: 0.279007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405585 \n",
      "\n",
      "Epoch 1204\n",
      "-------------------------------\n",
      "loss: 0.289037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405093 \n",
      "\n",
      "Epoch 1205\n",
      "-------------------------------\n",
      "loss: 0.287904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405885 \n",
      "\n",
      "Epoch 1206\n",
      "-------------------------------\n",
      "loss: 0.279433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405762 \n",
      "\n",
      "Epoch 1207\n",
      "-------------------------------\n",
      "loss: 0.283978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407364 \n",
      "\n",
      "Epoch 1208\n",
      "-------------------------------\n",
      "loss: 0.286523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410537 \n",
      "\n",
      "Epoch 1209\n",
      "-------------------------------\n",
      "loss: 0.281059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411410 \n",
      "\n",
      "Epoch 1210\n",
      "-------------------------------\n",
      "loss: 0.310650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409880 \n",
      "\n",
      "Epoch 1211\n",
      "-------------------------------\n",
      "loss: 0.307320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406653 \n",
      "\n",
      "Epoch 1212\n",
      "-------------------------------\n",
      "loss: 0.303569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403913 \n",
      "\n",
      "Epoch 1213\n",
      "-------------------------------\n",
      "loss: 0.294603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403214 \n",
      "\n",
      "Epoch 1214\n",
      "-------------------------------\n",
      "loss: 0.304950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403035 \n",
      "\n",
      "Epoch 1215\n",
      "-------------------------------\n",
      "loss: 0.320224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402538 \n",
      "\n",
      "Epoch 1216\n",
      "-------------------------------\n",
      "loss: 0.319195  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401569 \n",
      "\n",
      "Epoch 1217\n",
      "-------------------------------\n",
      "loss: 0.300683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401837 \n",
      "\n",
      "Epoch 1218\n",
      "-------------------------------\n",
      "loss: 0.299115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403264 \n",
      "\n",
      "Epoch 1219\n",
      "-------------------------------\n",
      "loss: 0.289844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405030 \n",
      "\n",
      "Epoch 1220\n",
      "-------------------------------\n",
      "loss: 0.296083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404125 \n",
      "\n",
      "Epoch 1221\n",
      "-------------------------------\n",
      "loss: 0.301169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401812 \n",
      "\n",
      "Epoch 1222\n",
      "-------------------------------\n",
      "loss: 0.314007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399879 \n",
      "\n",
      "Epoch 1223\n",
      "-------------------------------\n",
      "loss: 0.280940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399005 \n",
      "\n",
      "Epoch 1224\n",
      "-------------------------------\n",
      "loss: 0.279578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399792 \n",
      "\n",
      "Epoch 1225\n",
      "-------------------------------\n",
      "loss: 0.303384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400692 \n",
      "\n",
      "Epoch 1226\n",
      "-------------------------------\n",
      "loss: 0.294632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402105 \n",
      "\n",
      "Epoch 1227\n",
      "-------------------------------\n",
      "loss: 0.293837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404533 \n",
      "\n",
      "Epoch 1228\n",
      "-------------------------------\n",
      "loss: 0.284853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407230 \n",
      "\n",
      "Epoch 1229\n",
      "-------------------------------\n",
      "loss: 0.287620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408687 \n",
      "\n",
      "Epoch 1230\n",
      "-------------------------------\n",
      "loss: 0.277197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409111 \n",
      "\n",
      "Epoch 1231\n",
      "-------------------------------\n",
      "loss: 0.289932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407107 \n",
      "\n",
      "Epoch 1232\n",
      "-------------------------------\n",
      "loss: 0.283983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404082 \n",
      "\n",
      "Epoch 1233\n",
      "-------------------------------\n",
      "loss: 0.296356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402575 \n",
      "\n",
      "Epoch 1234\n",
      "-------------------------------\n",
      "loss: 0.291565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401774 \n",
      "\n",
      "Epoch 1235\n",
      "-------------------------------\n",
      "loss: 0.299831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401350 \n",
      "\n",
      "Epoch 1236\n",
      "-------------------------------\n",
      "loss: 0.309304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400835 \n",
      "\n",
      "Epoch 1237\n",
      "-------------------------------\n",
      "loss: 0.294655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 1238\n",
      "-------------------------------\n",
      "loss: 0.305555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401871 \n",
      "\n",
      "Epoch 1239\n",
      "-------------------------------\n",
      "loss: 0.297441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402049 \n",
      "\n",
      "Epoch 1240\n",
      "-------------------------------\n",
      "loss: 0.284268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400537 \n",
      "\n",
      "Epoch 1241\n",
      "-------------------------------\n",
      "loss: 0.282059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399170 \n",
      "\n",
      "Epoch 1242\n",
      "-------------------------------\n",
      "loss: 0.295542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396907 \n",
      "\n",
      "Epoch 1243\n",
      "-------------------------------\n",
      "loss: 0.301856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395116 \n",
      "\n",
      "Epoch 1244\n",
      "-------------------------------\n",
      "loss: 0.303378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393819 \n",
      "\n",
      "Epoch 1245\n",
      "-------------------------------\n",
      "loss: 0.286313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393059 \n",
      "\n",
      "Epoch 1246\n",
      "-------------------------------\n",
      "loss: 0.302251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393758 \n",
      "\n",
      "Epoch 1247\n",
      "-------------------------------\n",
      "loss: 0.295689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394525 \n",
      "\n",
      "Epoch 1248\n",
      "-------------------------------\n",
      "loss: 0.292974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394735 \n",
      "\n",
      "Epoch 1249\n",
      "-------------------------------\n",
      "loss: 0.286355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395828 \n",
      "\n",
      "Epoch 1250\n",
      "-------------------------------\n",
      "loss: 0.295720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397935 \n",
      "\n",
      "Epoch 1251\n",
      "-------------------------------\n",
      "loss: 0.286264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399243 \n",
      "\n",
      "Epoch 1252\n",
      "-------------------------------\n",
      "loss: 0.288323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400014 \n",
      "\n",
      "Epoch 1253\n",
      "-------------------------------\n",
      "loss: 0.307676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399000 \n",
      "\n",
      "Epoch 1254\n",
      "-------------------------------\n",
      "loss: 0.268415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398381 \n",
      "\n",
      "Epoch 1255\n",
      "-------------------------------\n",
      "loss: 0.290953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398072 \n",
      "\n",
      "Epoch 1256\n",
      "-------------------------------\n",
      "loss: 0.271623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398630 \n",
      "\n",
      "Epoch 1257\n",
      "-------------------------------\n",
      "loss: 0.298175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397969 \n",
      "\n",
      "Epoch 1258\n",
      "-------------------------------\n",
      "loss: 0.290625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397067 \n",
      "\n",
      "Epoch 1259\n",
      "-------------------------------\n",
      "loss: 0.293965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395708 \n",
      "\n",
      "Epoch 1260\n",
      "-------------------------------\n",
      "loss: 0.304745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394105 \n",
      "\n",
      "Epoch 1261\n",
      "-------------------------------\n",
      "loss: 0.304177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393784 \n",
      "\n",
      "Epoch 1262\n",
      "-------------------------------\n",
      "loss: 0.298854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393723 \n",
      "\n",
      "Epoch 1263\n",
      "-------------------------------\n",
      "loss: 0.324782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394176 \n",
      "\n",
      "Epoch 1264\n",
      "-------------------------------\n",
      "loss: 0.294219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396310 \n",
      "\n",
      "Epoch 1265\n",
      "-------------------------------\n",
      "loss: 0.296623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402221 \n",
      "\n",
      "Epoch 1266\n",
      "-------------------------------\n",
      "loss: 0.282569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409204 \n",
      "\n",
      "Epoch 1267\n",
      "-------------------------------\n",
      "loss: 0.305541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410181 \n",
      "\n",
      "Epoch 1268\n",
      "-------------------------------\n",
      "loss: 0.315104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403958 \n",
      "\n",
      "Epoch 1269\n",
      "-------------------------------\n",
      "loss: 0.301255  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397019 \n",
      "\n",
      "Epoch 1270\n",
      "-------------------------------\n",
      "loss: 0.287580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394194 \n",
      "\n",
      "Epoch 1271\n",
      "-------------------------------\n",
      "loss: 0.304047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394801 \n",
      "\n",
      "Epoch 1272\n",
      "-------------------------------\n",
      "loss: 0.300194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395960 \n",
      "\n",
      "Epoch 1273\n",
      "-------------------------------\n",
      "loss: 0.283871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397156 \n",
      "\n",
      "Epoch 1274\n",
      "-------------------------------\n",
      "loss: 0.290903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398649 \n",
      "\n",
      "Epoch 1275\n",
      "-------------------------------\n",
      "loss: 0.312232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399019 \n",
      "\n",
      "Epoch 1276\n",
      "-------------------------------\n",
      "loss: 0.297843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399298 \n",
      "\n",
      "Epoch 1277\n",
      "-------------------------------\n",
      "loss: 0.284127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398810 \n",
      "\n",
      "Epoch 1278\n",
      "-------------------------------\n",
      "loss: 0.290419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398752 \n",
      "\n",
      "Epoch 1279\n",
      "-------------------------------\n",
      "loss: 0.315416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399155 \n",
      "\n",
      "Epoch 1280\n",
      "-------------------------------\n",
      "loss: 0.305225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399831 \n",
      "\n",
      "Epoch 1281\n",
      "-------------------------------\n",
      "loss: 0.303341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400066 \n",
      "\n",
      "Epoch 1282\n",
      "-------------------------------\n",
      "loss: 0.277025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400033 \n",
      "\n",
      "Epoch 1283\n",
      "-------------------------------\n",
      "loss: 0.320133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399268 \n",
      "\n",
      "Epoch 1284\n",
      "-------------------------------\n",
      "loss: 0.298366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398301 \n",
      "\n",
      "Epoch 1285\n",
      "-------------------------------\n",
      "loss: 0.300582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396873 \n",
      "\n",
      "Epoch 1286\n",
      "-------------------------------\n",
      "loss: 0.290405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396936 \n",
      "\n",
      "Epoch 1287\n",
      "-------------------------------\n",
      "loss: 0.287331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397686 \n",
      "\n",
      "Epoch 1288\n",
      "-------------------------------\n",
      "loss: 0.293449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399580 \n",
      "\n",
      "Epoch 1289\n",
      "-------------------------------\n",
      "loss: 0.285371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399560 \n",
      "\n",
      "Epoch 1290\n",
      "-------------------------------\n",
      "loss: 0.283808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399402 \n",
      "\n",
      "Epoch 1291\n",
      "-------------------------------\n",
      "loss: 0.300631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399977 \n",
      "\n",
      "Epoch 1292\n",
      "-------------------------------\n",
      "loss: 0.296135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399472 \n",
      "\n",
      "Epoch 1293\n",
      "-------------------------------\n",
      "loss: 0.314265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399117 \n",
      "\n",
      "Epoch 1294\n",
      "-------------------------------\n",
      "loss: 0.304918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399666 \n",
      "\n",
      "Epoch 1295\n",
      "-------------------------------\n",
      "loss: 0.300059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400673 \n",
      "\n",
      "Epoch 1296\n",
      "-------------------------------\n",
      "loss: 0.292322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402914 \n",
      "\n",
      "Epoch 1297\n",
      "-------------------------------\n",
      "loss: 0.287180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404707 \n",
      "\n",
      "Epoch 1298\n",
      "-------------------------------\n",
      "loss: 0.303431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403874 \n",
      "\n",
      "Epoch 1299\n",
      "-------------------------------\n",
      "loss: 0.293033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402043 \n",
      "\n",
      "Epoch 1300\n",
      "-------------------------------\n",
      "loss: 0.303435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400178 \n",
      "\n",
      "Epoch 1301\n",
      "-------------------------------\n",
      "loss: 0.281640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398787 \n",
      "\n",
      "Epoch 1302\n",
      "-------------------------------\n",
      "loss: 0.300211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397621 \n",
      "\n",
      "Epoch 1303\n",
      "-------------------------------\n",
      "loss: 0.295091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395854 \n",
      "\n",
      "Epoch 1304\n",
      "-------------------------------\n",
      "loss: 0.280454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396001 \n",
      "\n",
      "Epoch 1305\n",
      "-------------------------------\n",
      "loss: 0.279578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396682 \n",
      "\n",
      "Epoch 1306\n",
      "-------------------------------\n",
      "loss: 0.293949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397312 \n",
      "\n",
      "Epoch 1307\n",
      "-------------------------------\n",
      "loss: 0.294574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396615 \n",
      "\n",
      "Epoch 1308\n",
      "-------------------------------\n",
      "loss: 0.278217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396610 \n",
      "\n",
      "Epoch 1309\n",
      "-------------------------------\n",
      "loss: 0.300282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396743 \n",
      "\n",
      "Epoch 1310\n",
      "-------------------------------\n",
      "loss: 0.289970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397495 \n",
      "\n",
      "Epoch 1311\n",
      "-------------------------------\n",
      "loss: 0.279446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397790 \n",
      "\n",
      "Epoch 1312\n",
      "-------------------------------\n",
      "loss: 0.303271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396837 \n",
      "\n",
      "Epoch 1313\n",
      "-------------------------------\n",
      "loss: 0.292464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397232 \n",
      "\n",
      "Epoch 1314\n",
      "-------------------------------\n",
      "loss: 0.287962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398133 \n",
      "\n",
      "Epoch 1315\n",
      "-------------------------------\n",
      "loss: 0.289036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398901 \n",
      "\n",
      "Epoch 1316\n",
      "-------------------------------\n",
      "loss: 0.306500  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399459 \n",
      "\n",
      "Epoch 1317\n",
      "-------------------------------\n",
      "loss: 0.274401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399629 \n",
      "\n",
      "Epoch 1318\n",
      "-------------------------------\n",
      "loss: 0.298519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398548 \n",
      "\n",
      "Epoch 1319\n",
      "-------------------------------\n",
      "loss: 0.302190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398167 \n",
      "\n",
      "Epoch 1320\n",
      "-------------------------------\n",
      "loss: 0.274878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398494 \n",
      "\n",
      "Epoch 1321\n",
      "-------------------------------\n",
      "loss: 0.292364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398408 \n",
      "\n",
      "Epoch 1322\n",
      "-------------------------------\n",
      "loss: 0.306396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398231 \n",
      "\n",
      "Epoch 1323\n",
      "-------------------------------\n",
      "loss: 0.294900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398466 \n",
      "\n",
      "Epoch 1324\n",
      "-------------------------------\n",
      "loss: 0.293173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400039 \n",
      "\n",
      "Epoch 1325\n",
      "-------------------------------\n",
      "loss: 0.297990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402015 \n",
      "\n",
      "Epoch 1326\n",
      "-------------------------------\n",
      "loss: 0.300276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403281 \n",
      "\n",
      "Epoch 1327\n",
      "-------------------------------\n",
      "loss: 0.292044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403624 \n",
      "\n",
      "Epoch 1328\n",
      "-------------------------------\n",
      "loss: 0.294159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403073 \n",
      "\n",
      "Epoch 1329\n",
      "-------------------------------\n",
      "loss: 0.288813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402404 \n",
      "\n",
      "Epoch 1330\n",
      "-------------------------------\n",
      "loss: 0.283470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402780 \n",
      "\n",
      "Epoch 1331\n",
      "-------------------------------\n",
      "loss: 0.279779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402701 \n",
      "\n",
      "Epoch 1332\n",
      "-------------------------------\n",
      "loss: 0.316185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400766 \n",
      "\n",
      "Epoch 1333\n",
      "-------------------------------\n",
      "loss: 0.287439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401066 \n",
      "\n",
      "Epoch 1334\n",
      "-------------------------------\n",
      "loss: 0.295405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404117 \n",
      "\n",
      "Epoch 1335\n",
      "-------------------------------\n",
      "loss: 0.287720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406140 \n",
      "\n",
      "Epoch 1336\n",
      "-------------------------------\n",
      "loss: 0.294442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407133 \n",
      "\n",
      "Epoch 1337\n",
      "-------------------------------\n",
      "loss: 0.289764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406474 \n",
      "\n",
      "Epoch 1338\n",
      "-------------------------------\n",
      "loss: 0.320944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405098 \n",
      "\n",
      "Epoch 1339\n",
      "-------------------------------\n",
      "loss: 0.315396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403091 \n",
      "\n",
      "Epoch 1340\n",
      "-------------------------------\n",
      "loss: 0.303399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403523 \n",
      "\n",
      "Epoch 1341\n",
      "-------------------------------\n",
      "loss: 0.313566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405324 \n",
      "\n",
      "Epoch 1342\n",
      "-------------------------------\n",
      "loss: 0.293046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405880 \n",
      "\n",
      "Epoch 1343\n",
      "-------------------------------\n",
      "loss: 0.307756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405114 \n",
      "\n",
      "Epoch 1344\n",
      "-------------------------------\n",
      "loss: 0.312191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402144 \n",
      "\n",
      "Epoch 1345\n",
      "-------------------------------\n",
      "loss: 0.293659  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400673 \n",
      "\n",
      "Epoch 1346\n",
      "-------------------------------\n",
      "loss: 0.290679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399934 \n",
      "\n",
      "Epoch 1347\n",
      "-------------------------------\n",
      "loss: 0.286425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399655 \n",
      "\n",
      "Epoch 1348\n",
      "-------------------------------\n",
      "loss: 0.297222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401447 \n",
      "\n",
      "Epoch 1349\n",
      "-------------------------------\n",
      "loss: 0.315863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401681 \n",
      "\n",
      "Epoch 1350\n",
      "-------------------------------\n",
      "loss: 0.312536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400112 \n",
      "\n",
      "Epoch 1351\n",
      "-------------------------------\n",
      "loss: 0.294984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400094 \n",
      "\n",
      "Epoch 1352\n",
      "-------------------------------\n",
      "loss: 0.287538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400171 \n",
      "\n",
      "Epoch 1353\n",
      "-------------------------------\n",
      "loss: 0.317969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399915 \n",
      "\n",
      "Epoch 1354\n",
      "-------------------------------\n",
      "loss: 0.291817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399604 \n",
      "\n",
      "Epoch 1355\n",
      "-------------------------------\n",
      "loss: 0.302736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400457 \n",
      "\n",
      "Epoch 1356\n",
      "-------------------------------\n",
      "loss: 0.296688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401953 \n",
      "\n",
      "Epoch 1357\n",
      "-------------------------------\n",
      "loss: 0.279565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401368 \n",
      "\n",
      "Epoch 1358\n",
      "-------------------------------\n",
      "loss: 0.294994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400981 \n",
      "\n",
      "Epoch 1359\n",
      "-------------------------------\n",
      "loss: 0.290736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400328 \n",
      "\n",
      "Epoch 1360\n",
      "-------------------------------\n",
      "loss: 0.285292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400002 \n",
      "\n",
      "Epoch 1361\n",
      "-------------------------------\n",
      "loss: 0.299001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400385 \n",
      "\n",
      "Epoch 1362\n",
      "-------------------------------\n",
      "loss: 0.293375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400003 \n",
      "\n",
      "Epoch 1363\n",
      "-------------------------------\n",
      "loss: 0.298593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399685 \n",
      "\n",
      "Epoch 1364\n",
      "-------------------------------\n",
      "loss: 0.274760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401262 \n",
      "\n",
      "Epoch 1365\n",
      "-------------------------------\n",
      "loss: 0.270202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402854 \n",
      "\n",
      "Epoch 1366\n",
      "-------------------------------\n",
      "loss: 0.301463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402226 \n",
      "\n",
      "Epoch 1367\n",
      "-------------------------------\n",
      "loss: 0.296280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399293 \n",
      "\n",
      "Epoch 1368\n",
      "-------------------------------\n",
      "loss: 0.280712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397986 \n",
      "\n",
      "Epoch 1369\n",
      "-------------------------------\n",
      "loss: 0.284215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397234 \n",
      "\n",
      "Epoch 1370\n",
      "-------------------------------\n",
      "loss: 0.288760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396837 \n",
      "\n",
      "Epoch 1371\n",
      "-------------------------------\n",
      "loss: 0.297531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396858 \n",
      "\n",
      "Epoch 1372\n",
      "-------------------------------\n",
      "loss: 0.310208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398761 \n",
      "\n",
      "Epoch 1373\n",
      "-------------------------------\n",
      "loss: 0.275837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401142 \n",
      "\n",
      "Epoch 1374\n",
      "-------------------------------\n",
      "loss: 0.302450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401261 \n",
      "\n",
      "Epoch 1375\n",
      "-------------------------------\n",
      "loss: 0.305118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398646 \n",
      "\n",
      "Epoch 1376\n",
      "-------------------------------\n",
      "loss: 0.279879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396243 \n",
      "\n",
      "Epoch 1377\n",
      "-------------------------------\n",
      "loss: 0.276482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394461 \n",
      "\n",
      "Epoch 1378\n",
      "-------------------------------\n",
      "loss: 0.289444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393377 \n",
      "\n",
      "Epoch 1379\n",
      "-------------------------------\n",
      "loss: 0.303466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393396 \n",
      "\n",
      "Epoch 1380\n",
      "-------------------------------\n",
      "loss: 0.300792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394215 \n",
      "\n",
      "Epoch 1381\n",
      "-------------------------------\n",
      "loss: 0.278434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396011 \n",
      "\n",
      "Epoch 1382\n",
      "-------------------------------\n",
      "loss: 0.291611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399119 \n",
      "\n",
      "Epoch 1383\n",
      "-------------------------------\n",
      "loss: 0.299421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401402 \n",
      "\n",
      "Epoch 1384\n",
      "-------------------------------\n",
      "loss: 0.287777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403570 \n",
      "\n",
      "Epoch 1385\n",
      "-------------------------------\n",
      "loss: 0.297662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402793 \n",
      "\n",
      "Epoch 1386\n",
      "-------------------------------\n",
      "loss: 0.287385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399597 \n",
      "\n",
      "Epoch 1387\n",
      "-------------------------------\n",
      "loss: 0.293949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396535 \n",
      "\n",
      "Epoch 1388\n",
      "-------------------------------\n",
      "loss: 0.289893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395929 \n",
      "\n",
      "Epoch 1389\n",
      "-------------------------------\n",
      "loss: 0.288680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396507 \n",
      "\n",
      "Epoch 1390\n",
      "-------------------------------\n",
      "loss: 0.301451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396894 \n",
      "\n",
      "Epoch 1391\n",
      "-------------------------------\n",
      "loss: 0.283512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396935 \n",
      "\n",
      "Epoch 1392\n",
      "-------------------------------\n",
      "loss: 0.302726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397047 \n",
      "\n",
      "Epoch 1393\n",
      "-------------------------------\n",
      "loss: 0.301645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397854 \n",
      "\n",
      "Epoch 1394\n",
      "-------------------------------\n",
      "loss: 0.291010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400166 \n",
      "\n",
      "Epoch 1395\n",
      "-------------------------------\n",
      "loss: 0.283793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401794 \n",
      "\n",
      "Epoch 1396\n",
      "-------------------------------\n",
      "loss: 0.294612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400342 \n",
      "\n",
      "Epoch 1397\n",
      "-------------------------------\n",
      "loss: 0.284557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399411 \n",
      "\n",
      "Epoch 1398\n",
      "-------------------------------\n",
      "loss: 0.304781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399335 \n",
      "\n",
      "Epoch 1399\n",
      "-------------------------------\n",
      "loss: 0.289902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399967 \n",
      "\n",
      "Epoch 1400\n",
      "-------------------------------\n",
      "loss: 0.295613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400765 \n",
      "\n",
      "Epoch 1401\n",
      "-------------------------------\n",
      "loss: 0.295356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402642 \n",
      "\n",
      "Epoch 1402\n",
      "-------------------------------\n",
      "loss: 0.305043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405366 \n",
      "\n",
      "Epoch 1403\n",
      "-------------------------------\n",
      "loss: 0.294694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409974 \n",
      "\n",
      "Epoch 1404\n",
      "-------------------------------\n",
      "loss: 0.288383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411772 \n",
      "\n",
      "Epoch 1405\n",
      "-------------------------------\n",
      "loss: 0.283534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409701 \n",
      "\n",
      "Epoch 1406\n",
      "-------------------------------\n",
      "loss: 0.294632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404446 \n",
      "\n",
      "Epoch 1407\n",
      "-------------------------------\n",
      "loss: 0.294764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400880 \n",
      "\n",
      "Epoch 1408\n",
      "-------------------------------\n",
      "loss: 0.296442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400197 \n",
      "\n",
      "Epoch 1409\n",
      "-------------------------------\n",
      "loss: 0.311803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399035 \n",
      "\n",
      "Epoch 1410\n",
      "-------------------------------\n",
      "loss: 0.300779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397310 \n",
      "\n",
      "Epoch 1411\n",
      "-------------------------------\n",
      "loss: 0.290514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396789 \n",
      "\n",
      "Epoch 1412\n",
      "-------------------------------\n",
      "loss: 0.286237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399306 \n",
      "\n",
      "Epoch 1413\n",
      "-------------------------------\n",
      "loss: 0.295226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401453 \n",
      "\n",
      "Epoch 1414\n",
      "-------------------------------\n",
      "loss: 0.304999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402571 \n",
      "\n",
      "Epoch 1415\n",
      "-------------------------------\n",
      "loss: 0.275580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401573 \n",
      "\n",
      "Epoch 1416\n",
      "-------------------------------\n",
      "loss: 0.298474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399608 \n",
      "\n",
      "Epoch 1417\n",
      "-------------------------------\n",
      "loss: 0.286040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399531 \n",
      "\n",
      "Epoch 1418\n",
      "-------------------------------\n",
      "loss: 0.293556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398832 \n",
      "\n",
      "Epoch 1419\n",
      "-------------------------------\n",
      "loss: 0.292310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398231 \n",
      "\n",
      "Epoch 1420\n",
      "-------------------------------\n",
      "loss: 0.299900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398292 \n",
      "\n",
      "Epoch 1421\n",
      "-------------------------------\n",
      "loss: 0.287552  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.398478 \n",
      "\n",
      "Epoch 1422\n",
      "-------------------------------\n",
      "loss: 0.277821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398036 \n",
      "\n",
      "Epoch 1423\n",
      "-------------------------------\n",
      "loss: 0.282954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398709 \n",
      "\n",
      "Epoch 1424\n",
      "-------------------------------\n",
      "loss: 0.294644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397256 \n",
      "\n",
      "Epoch 1425\n",
      "-------------------------------\n",
      "loss: 0.298664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394741 \n",
      "\n",
      "Epoch 1426\n",
      "-------------------------------\n",
      "loss: 0.284470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394567 \n",
      "\n",
      "Epoch 1427\n",
      "-------------------------------\n",
      "loss: 0.282378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394538 \n",
      "\n",
      "Epoch 1428\n",
      "-------------------------------\n",
      "loss: 0.271736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395014 \n",
      "\n",
      "Epoch 1429\n",
      "-------------------------------\n",
      "loss: 0.276931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395876 \n",
      "\n",
      "Epoch 1430\n",
      "-------------------------------\n",
      "loss: 0.287301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397450 \n",
      "\n",
      "Epoch 1431\n",
      "-------------------------------\n",
      "loss: 0.270973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399257 \n",
      "\n",
      "Epoch 1432\n",
      "-------------------------------\n",
      "loss: 0.306588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400263 \n",
      "\n",
      "Epoch 1433\n",
      "-------------------------------\n",
      "loss: 0.275920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399991 \n",
      "\n",
      "Epoch 1434\n",
      "-------------------------------\n",
      "loss: 0.287886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399465 \n",
      "\n",
      "Epoch 1435\n",
      "-------------------------------\n",
      "loss: 0.288856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400403 \n",
      "\n",
      "Epoch 1436\n",
      "-------------------------------\n",
      "loss: 0.290905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401416 \n",
      "\n",
      "Epoch 1437\n",
      "-------------------------------\n",
      "loss: 0.274265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403042 \n",
      "\n",
      "Epoch 1438\n",
      "-------------------------------\n",
      "loss: 0.269625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404770 \n",
      "\n",
      "Epoch 1439\n",
      "-------------------------------\n",
      "loss: 0.292297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405356 \n",
      "\n",
      "Epoch 1440\n",
      "-------------------------------\n",
      "loss: 0.273981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405410 \n",
      "\n",
      "Epoch 1441\n",
      "-------------------------------\n",
      "loss: 0.271941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406725 \n",
      "\n",
      "Epoch 1442\n",
      "-------------------------------\n",
      "loss: 0.289673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407174 \n",
      "\n",
      "Epoch 1443\n",
      "-------------------------------\n",
      "loss: 0.293505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404896 \n",
      "\n",
      "Epoch 1444\n",
      "-------------------------------\n",
      "loss: 0.302357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401532 \n",
      "\n",
      "Epoch 1445\n",
      "-------------------------------\n",
      "loss: 0.280967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401278 \n",
      "\n",
      "Epoch 1446\n",
      "-------------------------------\n",
      "loss: 0.301191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401335 \n",
      "\n",
      "Epoch 1447\n",
      "-------------------------------\n",
      "loss: 0.296047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401370 \n",
      "\n",
      "Epoch 1448\n",
      "-------------------------------\n",
      "loss: 0.287707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401752 \n",
      "\n",
      "Epoch 1449\n",
      "-------------------------------\n",
      "loss: 0.279372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402561 \n",
      "\n",
      "Epoch 1450\n",
      "-------------------------------\n",
      "loss: 0.278804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403961 \n",
      "\n",
      "Epoch 1451\n",
      "-------------------------------\n",
      "loss: 0.291298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403898 \n",
      "\n",
      "Epoch 1452\n",
      "-------------------------------\n",
      "loss: 0.277882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403207 \n",
      "\n",
      "Epoch 1453\n",
      "-------------------------------\n",
      "loss: 0.269214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403119 \n",
      "\n",
      "Epoch 1454\n",
      "-------------------------------\n",
      "loss: 0.294738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401347 \n",
      "\n",
      "Epoch 1455\n",
      "-------------------------------\n",
      "loss: 0.277591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401212 \n",
      "\n",
      "Epoch 1456\n",
      "-------------------------------\n",
      "loss: 0.291102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400386 \n",
      "\n",
      "Epoch 1457\n",
      "-------------------------------\n",
      "loss: 0.267151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400462 \n",
      "\n",
      "Epoch 1458\n",
      "-------------------------------\n",
      "loss: 0.273247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401020 \n",
      "\n",
      "Epoch 1459\n",
      "-------------------------------\n",
      "loss: 0.285801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401721 \n",
      "\n",
      "Epoch 1460\n",
      "-------------------------------\n",
      "loss: 0.295849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402491 \n",
      "\n",
      "Epoch 1461\n",
      "-------------------------------\n",
      "loss: 0.289613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403278 \n",
      "\n",
      "Epoch 1462\n",
      "-------------------------------\n",
      "loss: 0.288769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402800 \n",
      "\n",
      "Epoch 1463\n",
      "-------------------------------\n",
      "loss: 0.289887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403379 \n",
      "\n",
      "Epoch 1464\n",
      "-------------------------------\n",
      "loss: 0.289594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403126 \n",
      "\n",
      "Epoch 1465\n",
      "-------------------------------\n",
      "loss: 0.298532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401125 \n",
      "\n",
      "Epoch 1466\n",
      "-------------------------------\n",
      "loss: 0.301723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399099 \n",
      "\n",
      "Epoch 1467\n",
      "-------------------------------\n",
      "loss: 0.265317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398692 \n",
      "\n",
      "Epoch 1468\n",
      "-------------------------------\n",
      "loss: 0.292211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398640 \n",
      "\n",
      "Epoch 1469\n",
      "-------------------------------\n",
      "loss: 0.297317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399481 \n",
      "\n",
      "Epoch 1470\n",
      "-------------------------------\n",
      "loss: 0.299675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401066 \n",
      "\n",
      "Epoch 1471\n",
      "-------------------------------\n",
      "loss: 0.273239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402428 \n",
      "\n",
      "Epoch 1472\n",
      "-------------------------------\n",
      "loss: 0.290676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401519 \n",
      "\n",
      "Epoch 1473\n",
      "-------------------------------\n",
      "loss: 0.288533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400188 \n",
      "\n",
      "Epoch 1474\n",
      "-------------------------------\n",
      "loss: 0.276147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398293 \n",
      "\n",
      "Epoch 1475\n",
      "-------------------------------\n",
      "loss: 0.283258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398280 \n",
      "\n",
      "Epoch 1476\n",
      "-------------------------------\n",
      "loss: 0.291509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399784 \n",
      "\n",
      "Epoch 1477\n",
      "-------------------------------\n",
      "loss: 0.277437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402645 \n",
      "\n",
      "Epoch 1478\n",
      "-------------------------------\n",
      "loss: 0.286303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407022 \n",
      "\n",
      "Epoch 1479\n",
      "-------------------------------\n",
      "loss: 0.289443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407808 \n",
      "\n",
      "Epoch 1480\n",
      "-------------------------------\n",
      "loss: 0.275569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407705 \n",
      "\n",
      "Epoch 1481\n",
      "-------------------------------\n",
      "loss: 0.305203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406920 \n",
      "\n",
      "Epoch 1482\n",
      "-------------------------------\n",
      "loss: 0.300734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404626 \n",
      "\n",
      "Epoch 1483\n",
      "-------------------------------\n",
      "loss: 0.301601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402716 \n",
      "\n",
      "Epoch 1484\n",
      "-------------------------------\n",
      "loss: 0.270507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401504 \n",
      "\n",
      "Epoch 1485\n",
      "-------------------------------\n",
      "loss: 0.286864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400841 \n",
      "\n",
      "Epoch 1486\n",
      "-------------------------------\n",
      "loss: 0.299707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399984 \n",
      "\n",
      "Epoch 1487\n",
      "-------------------------------\n",
      "loss: 0.291412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401116 \n",
      "\n",
      "Epoch 1488\n",
      "-------------------------------\n",
      "loss: 0.278083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402748 \n",
      "\n",
      "Epoch 1489\n",
      "-------------------------------\n",
      "loss: 0.293095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404782 \n",
      "\n",
      "Epoch 1490\n",
      "-------------------------------\n",
      "loss: 0.289133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404262 \n",
      "\n",
      "Epoch 1491\n",
      "-------------------------------\n",
      "loss: 0.298976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401889 \n",
      "\n",
      "Epoch 1492\n",
      "-------------------------------\n",
      "loss: 0.275336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401676 \n",
      "\n",
      "Epoch 1493\n",
      "-------------------------------\n",
      "loss: 0.296936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401893 \n",
      "\n",
      "Epoch 1494\n",
      "-------------------------------\n",
      "loss: 0.289417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401749 \n",
      "\n",
      "Epoch 1495\n",
      "-------------------------------\n",
      "loss: 0.286076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401752 \n",
      "\n",
      "Epoch 1496\n",
      "-------------------------------\n",
      "loss: 0.288376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402804 \n",
      "\n",
      "Epoch 1497\n",
      "-------------------------------\n",
      "loss: 0.287149  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.407906 \n",
      "\n",
      "Epoch 1498\n",
      "-------------------------------\n",
      "loss: 0.285371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412973 \n",
      "\n",
      "Epoch 1499\n",
      "-------------------------------\n",
      "loss: 0.300336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410825 \n",
      "\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "loss: 0.295295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404420 \n",
      "\n",
      "Epoch 1501\n",
      "-------------------------------\n",
      "loss: 0.280581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400734 \n",
      "\n",
      "Epoch 1502\n",
      "-------------------------------\n",
      "loss: 0.278813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400689 \n",
      "\n",
      "Epoch 1503\n",
      "-------------------------------\n",
      "loss: 0.288460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403341 \n",
      "\n",
      "Epoch 1504\n",
      "-------------------------------\n",
      "loss: 0.284021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406055 \n",
      "\n",
      "Epoch 1505\n",
      "-------------------------------\n",
      "loss: 0.305380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402707 \n",
      "\n",
      "Epoch 1506\n",
      "-------------------------------\n",
      "loss: 0.291789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400400 \n",
      "\n",
      "Epoch 1507\n",
      "-------------------------------\n",
      "loss: 0.269034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404676 \n",
      "\n",
      "Epoch 1508\n",
      "-------------------------------\n",
      "loss: 0.298699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410529 \n",
      "\n",
      "Epoch 1509\n",
      "-------------------------------\n",
      "loss: 0.312580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412781 \n",
      "\n",
      "Epoch 1510\n",
      "-------------------------------\n",
      "loss: 0.278823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409447 \n",
      "\n",
      "Epoch 1511\n",
      "-------------------------------\n",
      "loss: 0.291957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405487 \n",
      "\n",
      "Epoch 1512\n",
      "-------------------------------\n",
      "loss: 0.276110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404882 \n",
      "\n",
      "Epoch 1513\n",
      "-------------------------------\n",
      "loss: 0.289834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405555 \n",
      "\n",
      "Epoch 1514\n",
      "-------------------------------\n",
      "loss: 0.284788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404979 \n",
      "\n",
      "Epoch 1515\n",
      "-------------------------------\n",
      "loss: 0.284097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402720 \n",
      "\n",
      "Epoch 1516\n",
      "-------------------------------\n",
      "loss: 0.292814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403382 \n",
      "\n",
      "Epoch 1517\n",
      "-------------------------------\n",
      "loss: 0.273507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408027 \n",
      "\n",
      "Epoch 1518\n",
      "-------------------------------\n",
      "loss: 0.279069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412179 \n",
      "\n",
      "Epoch 1519\n",
      "-------------------------------\n",
      "loss: 0.290571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410729 \n",
      "\n",
      "Epoch 1520\n",
      "-------------------------------\n",
      "loss: 0.295570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406609 \n",
      "\n",
      "Epoch 1521\n",
      "-------------------------------\n",
      "loss: 0.289510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400942 \n",
      "\n",
      "Epoch 1522\n",
      "-------------------------------\n",
      "loss: 0.291800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400064 \n",
      "\n",
      "Epoch 1523\n",
      "-------------------------------\n",
      "loss: 0.297481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401245 \n",
      "\n",
      "Epoch 1524\n",
      "-------------------------------\n",
      "loss: 0.314927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401644 \n",
      "\n",
      "Epoch 1525\n",
      "-------------------------------\n",
      "loss: 0.280607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402456 \n",
      "\n",
      "Epoch 1526\n",
      "-------------------------------\n",
      "loss: 0.281828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403744 \n",
      "\n",
      "Epoch 1527\n",
      "-------------------------------\n",
      "loss: 0.281146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404947 \n",
      "\n",
      "Epoch 1528\n",
      "-------------------------------\n",
      "loss: 0.285005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408735 \n",
      "\n",
      "Epoch 1529\n",
      "-------------------------------\n",
      "loss: 0.267947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411778 \n",
      "\n",
      "Epoch 1530\n",
      "-------------------------------\n",
      "loss: 0.274172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409579 \n",
      "\n",
      "Epoch 1531\n",
      "-------------------------------\n",
      "loss: 0.290131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406019 \n",
      "\n",
      "Epoch 1532\n",
      "-------------------------------\n",
      "loss: 0.275361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404295 \n",
      "\n",
      "Epoch 1533\n",
      "-------------------------------\n",
      "loss: 0.280567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404701 \n",
      "\n",
      "Epoch 1534\n",
      "-------------------------------\n",
      "loss: 0.291405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404702 \n",
      "\n",
      "Epoch 1535\n",
      "-------------------------------\n",
      "loss: 0.283759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402969 \n",
      "\n",
      "Epoch 1536\n",
      "-------------------------------\n",
      "loss: 0.300422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401223 \n",
      "\n",
      "Epoch 1537\n",
      "-------------------------------\n",
      "loss: 0.286953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402745 \n",
      "\n",
      "Epoch 1538\n",
      "-------------------------------\n",
      "loss: 0.285927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404797 \n",
      "\n",
      "Epoch 1539\n",
      "-------------------------------\n",
      "loss: 0.300002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402915 \n",
      "\n",
      "Epoch 1540\n",
      "-------------------------------\n",
      "loss: 0.281693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400078 \n",
      "\n",
      "Epoch 1541\n",
      "-------------------------------\n",
      "loss: 0.277167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399319 \n",
      "\n",
      "Epoch 1542\n",
      "-------------------------------\n",
      "loss: 0.275244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400258 \n",
      "\n",
      "Epoch 1543\n",
      "-------------------------------\n",
      "loss: 0.287105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400732 \n",
      "\n",
      "Epoch 1544\n",
      "-------------------------------\n",
      "loss: 0.304067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399541 \n",
      "\n",
      "Epoch 1545\n",
      "-------------------------------\n",
      "loss: 0.284151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398394 \n",
      "\n",
      "Epoch 1546\n",
      "-------------------------------\n",
      "loss: 0.275302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397913 \n",
      "\n",
      "Epoch 1547\n",
      "-------------------------------\n",
      "loss: 0.273875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397261 \n",
      "\n",
      "Epoch 1548\n",
      "-------------------------------\n",
      "loss: 0.286982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397152 \n",
      "\n",
      "Epoch 1549\n",
      "-------------------------------\n",
      "loss: 0.286839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398432 \n",
      "\n",
      "Epoch 1550\n",
      "-------------------------------\n",
      "loss: 0.281771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399665 \n",
      "\n",
      "Epoch 1551\n",
      "-------------------------------\n",
      "loss: 0.282268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400094 \n",
      "\n",
      "Epoch 1552\n",
      "-------------------------------\n",
      "loss: 0.263619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400596 \n",
      "\n",
      "Epoch 1553\n",
      "-------------------------------\n",
      "loss: 0.277227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400255 \n",
      "\n",
      "Epoch 1554\n",
      "-------------------------------\n",
      "loss: 0.276696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400005 \n",
      "\n",
      "Epoch 1555\n",
      "-------------------------------\n",
      "loss: 0.280229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400725 \n",
      "\n",
      "Epoch 1556\n",
      "-------------------------------\n",
      "loss: 0.270756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401519 \n",
      "\n",
      "Epoch 1557\n",
      "-------------------------------\n",
      "loss: 0.274516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401742 \n",
      "\n",
      "Epoch 1558\n",
      "-------------------------------\n",
      "loss: 0.280333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402949 \n",
      "\n",
      "Epoch 1559\n",
      "-------------------------------\n",
      "loss: 0.295329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406557 \n",
      "\n",
      "Epoch 1560\n",
      "-------------------------------\n",
      "loss: 0.275695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411393 \n",
      "\n",
      "Epoch 1561\n",
      "-------------------------------\n",
      "loss: 0.275428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415055 \n",
      "\n",
      "Epoch 1562\n",
      "-------------------------------\n",
      "loss: 0.268145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417353 \n",
      "\n",
      "Epoch 1563\n",
      "-------------------------------\n",
      "loss: 0.262105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415766 \n",
      "\n",
      "Epoch 1564\n",
      "-------------------------------\n",
      "loss: 0.261335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409880 \n",
      "\n",
      "Epoch 1565\n",
      "-------------------------------\n",
      "loss: 0.276575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403939 \n",
      "\n",
      "Epoch 1566\n",
      "-------------------------------\n",
      "loss: 0.277439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400507 \n",
      "\n",
      "Epoch 1567\n",
      "-------------------------------\n",
      "loss: 0.291358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399141 \n",
      "\n",
      "Epoch 1568\n",
      "-------------------------------\n",
      "loss: 0.284119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399058 \n",
      "\n",
      "Epoch 1569\n",
      "-------------------------------\n",
      "loss: 0.263792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400682 \n",
      "\n",
      "Epoch 1570\n",
      "-------------------------------\n",
      "loss: 0.286707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402094 \n",
      "\n",
      "Epoch 1571\n",
      "-------------------------------\n",
      "loss: 0.274441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402402 \n",
      "\n",
      "Epoch 1572\n",
      "-------------------------------\n",
      "loss: 0.274369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402406 \n",
      "\n",
      "Epoch 1573\n",
      "-------------------------------\n",
      "loss: 0.281144  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.401080 \n",
      "\n",
      "Epoch 1574\n",
      "-------------------------------\n",
      "loss: 0.285731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398379 \n",
      "\n",
      "Epoch 1575\n",
      "-------------------------------\n",
      "loss: 0.269653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396259 \n",
      "\n",
      "Epoch 1576\n",
      "-------------------------------\n",
      "loss: 0.285357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395493 \n",
      "\n",
      "Epoch 1577\n",
      "-------------------------------\n",
      "loss: 0.287963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396828 \n",
      "\n",
      "Epoch 1578\n",
      "-------------------------------\n",
      "loss: 0.278859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398981 \n",
      "\n",
      "Epoch 1579\n",
      "-------------------------------\n",
      "loss: 0.276842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401038 \n",
      "\n",
      "Epoch 1580\n",
      "-------------------------------\n",
      "loss: 0.272985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402603 \n",
      "\n",
      "Epoch 1581\n",
      "-------------------------------\n",
      "loss: 0.295695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404089 \n",
      "\n",
      "Epoch 1582\n",
      "-------------------------------\n",
      "loss: 0.297384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402971 \n",
      "\n",
      "Epoch 1583\n",
      "-------------------------------\n",
      "loss: 0.287922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399708 \n",
      "\n",
      "Epoch 1584\n",
      "-------------------------------\n",
      "loss: 0.291173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398154 \n",
      "\n",
      "Epoch 1585\n",
      "-------------------------------\n",
      "loss: 0.271082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398401 \n",
      "\n",
      "Epoch 1586\n",
      "-------------------------------\n",
      "loss: 0.278739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398632 \n",
      "\n",
      "Epoch 1587\n",
      "-------------------------------\n",
      "loss: 0.293529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398343 \n",
      "\n",
      "Epoch 1588\n",
      "-------------------------------\n",
      "loss: 0.306911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398773 \n",
      "\n",
      "Epoch 1589\n",
      "-------------------------------\n",
      "loss: 0.291589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402406 \n",
      "\n",
      "Epoch 1590\n",
      "-------------------------------\n",
      "loss: 0.283653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405283 \n",
      "\n",
      "Epoch 1591\n",
      "-------------------------------\n",
      "loss: 0.274021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402863 \n",
      "\n",
      "Epoch 1592\n",
      "-------------------------------\n",
      "loss: 0.282728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399224 \n",
      "\n",
      "Epoch 1593\n",
      "-------------------------------\n",
      "loss: 0.298068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396216 \n",
      "\n",
      "Epoch 1594\n",
      "-------------------------------\n",
      "loss: 0.285943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395219 \n",
      "\n",
      "Epoch 1595\n",
      "-------------------------------\n",
      "loss: 0.269117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395654 \n",
      "\n",
      "Epoch 1596\n",
      "-------------------------------\n",
      "loss: 0.284851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396569 \n",
      "\n",
      "Epoch 1597\n",
      "-------------------------------\n",
      "loss: 0.270810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397555 \n",
      "\n",
      "Epoch 1598\n",
      "-------------------------------\n",
      "loss: 0.277009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399568 \n",
      "\n",
      "Epoch 1599\n",
      "-------------------------------\n",
      "loss: 0.279328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401685 \n",
      "\n",
      "Epoch 1600\n",
      "-------------------------------\n",
      "loss: 0.296363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400576 \n",
      "\n",
      "Epoch 1601\n",
      "-------------------------------\n",
      "loss: 0.289425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400309 \n",
      "\n",
      "Epoch 1602\n",
      "-------------------------------\n",
      "loss: 0.270869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400800 \n",
      "\n",
      "Epoch 1603\n",
      "-------------------------------\n",
      "loss: 0.299781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402275 \n",
      "\n",
      "Epoch 1604\n",
      "-------------------------------\n",
      "loss: 0.268991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403880 \n",
      "\n",
      "Epoch 1605\n",
      "-------------------------------\n",
      "loss: 0.267177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406415 \n",
      "\n",
      "Epoch 1606\n",
      "-------------------------------\n",
      "loss: 0.294990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407701 \n",
      "\n",
      "Epoch 1607\n",
      "-------------------------------\n",
      "loss: 0.293885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407076 \n",
      "\n",
      "Epoch 1608\n",
      "-------------------------------\n",
      "loss: 0.268728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405408 \n",
      "\n",
      "Epoch 1609\n",
      "-------------------------------\n",
      "loss: 0.271429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404517 \n",
      "\n",
      "Epoch 1610\n",
      "-------------------------------\n",
      "loss: 0.271908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403043 \n",
      "\n",
      "Epoch 1611\n",
      "-------------------------------\n",
      "loss: 0.289813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402770 \n",
      "\n",
      "Epoch 1612\n",
      "-------------------------------\n",
      "loss: 0.284636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404575 \n",
      "\n",
      "Epoch 1613\n",
      "-------------------------------\n",
      "loss: 0.287864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405954 \n",
      "\n",
      "Epoch 1614\n",
      "-------------------------------\n",
      "loss: 0.272845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406746 \n",
      "\n",
      "Epoch 1615\n",
      "-------------------------------\n",
      "loss: 0.264397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407828 \n",
      "\n",
      "Epoch 1616\n",
      "-------------------------------\n",
      "loss: 0.269769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407790 \n",
      "\n",
      "Epoch 1617\n",
      "-------------------------------\n",
      "loss: 0.273742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404490 \n",
      "\n",
      "Epoch 1618\n",
      "-------------------------------\n",
      "loss: 0.281420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401172 \n",
      "\n",
      "Epoch 1619\n",
      "-------------------------------\n",
      "loss: 0.280068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399860 \n",
      "\n",
      "Epoch 1620\n",
      "-------------------------------\n",
      "loss: 0.278525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399471 \n",
      "\n",
      "Epoch 1621\n",
      "-------------------------------\n",
      "loss: 0.289304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398891 \n",
      "\n",
      "Epoch 1622\n",
      "-------------------------------\n",
      "loss: 0.286270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398720 \n",
      "\n",
      "Epoch 1623\n",
      "-------------------------------\n",
      "loss: 0.269282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400088 \n",
      "\n",
      "Epoch 1624\n",
      "-------------------------------\n",
      "loss: 0.282862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401844 \n",
      "\n",
      "Epoch 1625\n",
      "-------------------------------\n",
      "loss: 0.282731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404341 \n",
      "\n",
      "Epoch 1626\n",
      "-------------------------------\n",
      "loss: 0.268547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403919 \n",
      "\n",
      "Epoch 1627\n",
      "-------------------------------\n",
      "loss: 0.284894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401728 \n",
      "\n",
      "Epoch 1628\n",
      "-------------------------------\n",
      "loss: 0.258615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399634 \n",
      "\n",
      "Epoch 1629\n",
      "-------------------------------\n",
      "loss: 0.269244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397671 \n",
      "\n",
      "Epoch 1630\n",
      "-------------------------------\n",
      "loss: 0.264367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397172 \n",
      "\n",
      "Epoch 1631\n",
      "-------------------------------\n",
      "loss: 0.310952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398521 \n",
      "\n",
      "Epoch 1632\n",
      "-------------------------------\n",
      "loss: 0.300816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400020 \n",
      "\n",
      "Epoch 1633\n",
      "-------------------------------\n",
      "loss: 0.256608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401886 \n",
      "\n",
      "Epoch 1634\n",
      "-------------------------------\n",
      "loss: 0.283803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402844 \n",
      "\n",
      "Epoch 1635\n",
      "-------------------------------\n",
      "loss: 0.299891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401303 \n",
      "\n",
      "Epoch 1636\n",
      "-------------------------------\n",
      "loss: 0.275173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399757 \n",
      "\n",
      "Epoch 1637\n",
      "-------------------------------\n",
      "loss: 0.279428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399082 \n",
      "\n",
      "Epoch 1638\n",
      "-------------------------------\n",
      "loss: 0.285190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398904 \n",
      "\n",
      "Epoch 1639\n",
      "-------------------------------\n",
      "loss: 0.283697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399528 \n",
      "\n",
      "Epoch 1640\n",
      "-------------------------------\n",
      "loss: 0.281680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399699 \n",
      "\n",
      "Epoch 1641\n",
      "-------------------------------\n",
      "loss: 0.285756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399309 \n",
      "\n",
      "Epoch 1642\n",
      "-------------------------------\n",
      "loss: 0.274047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401404 \n",
      "\n",
      "Epoch 1643\n",
      "-------------------------------\n",
      "loss: 0.277078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404014 \n",
      "\n",
      "Epoch 1644\n",
      "-------------------------------\n",
      "loss: 0.272301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404458 \n",
      "\n",
      "Epoch 1645\n",
      "-------------------------------\n",
      "loss: 0.272208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401729 \n",
      "\n",
      "Epoch 1646\n",
      "-------------------------------\n",
      "loss: 0.273331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399725 \n",
      "\n",
      "Epoch 1647\n",
      "-------------------------------\n",
      "loss: 0.275372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399041 \n",
      "\n",
      "Epoch 1648\n",
      "-------------------------------\n",
      "loss: 0.293810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399313 \n",
      "\n",
      "Epoch 1649\n",
      "-------------------------------\n",
      "loss: 0.299807  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400813 \n",
      "\n",
      "Epoch 1650\n",
      "-------------------------------\n",
      "loss: 0.296040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403247 \n",
      "\n",
      "Epoch 1651\n",
      "-------------------------------\n",
      "loss: 0.270425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405675 \n",
      "\n",
      "Epoch 1652\n",
      "-------------------------------\n",
      "loss: 0.255394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405883 \n",
      "\n",
      "Epoch 1653\n",
      "-------------------------------\n",
      "loss: 0.302950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404152 \n",
      "\n",
      "Epoch 1654\n",
      "-------------------------------\n",
      "loss: 0.271542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401539 \n",
      "\n",
      "Epoch 1655\n",
      "-------------------------------\n",
      "loss: 0.274457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399359 \n",
      "\n",
      "Epoch 1656\n",
      "-------------------------------\n",
      "loss: 0.270746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398627 \n",
      "\n",
      "Epoch 1657\n",
      "-------------------------------\n",
      "loss: 0.287850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400582 \n",
      "\n",
      "Epoch 1658\n",
      "-------------------------------\n",
      "loss: 0.271369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403626 \n",
      "\n",
      "Epoch 1659\n",
      "-------------------------------\n",
      "loss: 0.261330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405490 \n",
      "\n",
      "Epoch 1660\n",
      "-------------------------------\n",
      "loss: 0.268991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405656 \n",
      "\n",
      "Epoch 1661\n",
      "-------------------------------\n",
      "loss: 0.280423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401989 \n",
      "\n",
      "Epoch 1662\n",
      "-------------------------------\n",
      "loss: 0.279462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398706 \n",
      "\n",
      "Epoch 1663\n",
      "-------------------------------\n",
      "loss: 0.256237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398188 \n",
      "\n",
      "Epoch 1664\n",
      "-------------------------------\n",
      "loss: 0.279139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399091 \n",
      "\n",
      "Epoch 1665\n",
      "-------------------------------\n",
      "loss: 0.271359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399372 \n",
      "\n",
      "Epoch 1666\n",
      "-------------------------------\n",
      "loss: 0.267787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398791 \n",
      "\n",
      "Epoch 1667\n",
      "-------------------------------\n",
      "loss: 0.278618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398371 \n",
      "\n",
      "Epoch 1668\n",
      "-------------------------------\n",
      "loss: 0.272271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398185 \n",
      "\n",
      "Epoch 1669\n",
      "-------------------------------\n",
      "loss: 0.279535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398960 \n",
      "\n",
      "Epoch 1670\n",
      "-------------------------------\n",
      "loss: 0.279255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399390 \n",
      "\n",
      "Epoch 1671\n",
      "-------------------------------\n",
      "loss: 0.283977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398731 \n",
      "\n",
      "Epoch 1672\n",
      "-------------------------------\n",
      "loss: 0.269686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397899 \n",
      "\n",
      "Epoch 1673\n",
      "-------------------------------\n",
      "loss: 0.273880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397606 \n",
      "\n",
      "Epoch 1674\n",
      "-------------------------------\n",
      "loss: 0.282856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397393 \n",
      "\n",
      "Epoch 1675\n",
      "-------------------------------\n",
      "loss: 0.293100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396769 \n",
      "\n",
      "Epoch 1676\n",
      "-------------------------------\n",
      "loss: 0.292851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396984 \n",
      "\n",
      "Epoch 1677\n",
      "-------------------------------\n",
      "loss: 0.278650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396576 \n",
      "\n",
      "Epoch 1678\n",
      "-------------------------------\n",
      "loss: 0.263533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395816 \n",
      "\n",
      "Epoch 1679\n",
      "-------------------------------\n",
      "loss: 0.276923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397474 \n",
      "\n",
      "Epoch 1680\n",
      "-------------------------------\n",
      "loss: 0.287284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402106 \n",
      "\n",
      "Epoch 1681\n",
      "-------------------------------\n",
      "loss: 0.288166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402751 \n",
      "\n",
      "Epoch 1682\n",
      "-------------------------------\n",
      "loss: 0.268408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402267 \n",
      "\n",
      "Epoch 1683\n",
      "-------------------------------\n",
      "loss: 0.280687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399455 \n",
      "\n",
      "Epoch 1684\n",
      "-------------------------------\n",
      "loss: 0.278543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399339 \n",
      "\n",
      "Epoch 1685\n",
      "-------------------------------\n",
      "loss: 0.286923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399463 \n",
      "\n",
      "Epoch 1686\n",
      "-------------------------------\n",
      "loss: 0.284468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399127 \n",
      "\n",
      "Epoch 1687\n",
      "-------------------------------\n",
      "loss: 0.273963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397874 \n",
      "\n",
      "Epoch 1688\n",
      "-------------------------------\n",
      "loss: 0.278774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398414 \n",
      "\n",
      "Epoch 1689\n",
      "-------------------------------\n",
      "loss: 0.285044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398769 \n",
      "\n",
      "Epoch 1690\n",
      "-------------------------------\n",
      "loss: 0.284278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398689 \n",
      "\n",
      "Epoch 1691\n",
      "-------------------------------\n",
      "loss: 0.275424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399268 \n",
      "\n",
      "Epoch 1692\n",
      "-------------------------------\n",
      "loss: 0.294797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398589 \n",
      "\n",
      "Epoch 1693\n",
      "-------------------------------\n",
      "loss: 0.267811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399551 \n",
      "\n",
      "Epoch 1694\n",
      "-------------------------------\n",
      "loss: 0.266077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402687 \n",
      "\n",
      "Epoch 1695\n",
      "-------------------------------\n",
      "loss: 0.286187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406251 \n",
      "\n",
      "Epoch 1696\n",
      "-------------------------------\n",
      "loss: 0.290154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405285 \n",
      "\n",
      "Epoch 1697\n",
      "-------------------------------\n",
      "loss: 0.278717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401928 \n",
      "\n",
      "Epoch 1698\n",
      "-------------------------------\n",
      "loss: 0.260037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400592 \n",
      "\n",
      "Epoch 1699\n",
      "-------------------------------\n",
      "loss: 0.267891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400748 \n",
      "\n",
      "Epoch 1700\n",
      "-------------------------------\n",
      "loss: 0.263620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402472 \n",
      "\n",
      "Epoch 1701\n",
      "-------------------------------\n",
      "loss: 0.289186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403687 \n",
      "\n",
      "Epoch 1702\n",
      "-------------------------------\n",
      "loss: 0.279795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405720 \n",
      "\n",
      "Epoch 1703\n",
      "-------------------------------\n",
      "loss: 0.279255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406748 \n",
      "\n",
      "Epoch 1704\n",
      "-------------------------------\n",
      "loss: 0.282531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405061 \n",
      "\n",
      "Epoch 1705\n",
      "-------------------------------\n",
      "loss: 0.300526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401071 \n",
      "\n",
      "Epoch 1706\n",
      "-------------------------------\n",
      "loss: 0.290368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399236 \n",
      "\n",
      "Epoch 1707\n",
      "-------------------------------\n",
      "loss: 0.285173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399835 \n",
      "\n",
      "Epoch 1708\n",
      "-------------------------------\n",
      "loss: 0.281211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399492 \n",
      "\n",
      "Epoch 1709\n",
      "-------------------------------\n",
      "loss: 0.274790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398037 \n",
      "\n",
      "Epoch 1710\n",
      "-------------------------------\n",
      "loss: 0.289944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399660 \n",
      "\n",
      "Epoch 1711\n",
      "-------------------------------\n",
      "loss: 0.294707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405328 \n",
      "\n",
      "Epoch 1712\n",
      "-------------------------------\n",
      "loss: 0.261860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408597 \n",
      "\n",
      "Epoch 1713\n",
      "-------------------------------\n",
      "loss: 0.309464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404115 \n",
      "\n",
      "Epoch 1714\n",
      "-------------------------------\n",
      "loss: 0.267756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399878 \n",
      "\n",
      "Epoch 1715\n",
      "-------------------------------\n",
      "loss: 0.279096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397941 \n",
      "\n",
      "Epoch 1716\n",
      "-------------------------------\n",
      "loss: 0.285462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398802 \n",
      "\n",
      "Epoch 1717\n",
      "-------------------------------\n",
      "loss: 0.277760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400400 \n",
      "\n",
      "Epoch 1718\n",
      "-------------------------------\n",
      "loss: 0.271659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401928 \n",
      "\n",
      "Epoch 1719\n",
      "-------------------------------\n",
      "loss: 0.272571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403688 \n",
      "\n",
      "Epoch 1720\n",
      "-------------------------------\n",
      "loss: 0.268784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407340 \n",
      "\n",
      "Epoch 1721\n",
      "-------------------------------\n",
      "loss: 0.292471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408813 \n",
      "\n",
      "Epoch 1722\n",
      "-------------------------------\n",
      "loss: 0.286379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405470 \n",
      "\n",
      "Epoch 1723\n",
      "-------------------------------\n",
      "loss: 0.249492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402763 \n",
      "\n",
      "Epoch 1724\n",
      "-------------------------------\n",
      "loss: 0.274572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400568 \n",
      "\n",
      "Epoch 1725\n",
      "-------------------------------\n",
      "loss: 0.265630  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399408 \n",
      "\n",
      "Epoch 1726\n",
      "-------------------------------\n",
      "loss: 0.280473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398674 \n",
      "\n",
      "Epoch 1727\n",
      "-------------------------------\n",
      "loss: 0.265018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398317 \n",
      "\n",
      "Epoch 1728\n",
      "-------------------------------\n",
      "loss: 0.280992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398668 \n",
      "\n",
      "Epoch 1729\n",
      "-------------------------------\n",
      "loss: 0.268669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398099 \n",
      "\n",
      "Epoch 1730\n",
      "-------------------------------\n",
      "loss: 0.271696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397271 \n",
      "\n",
      "Epoch 1731\n",
      "-------------------------------\n",
      "loss: 0.307721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396116 \n",
      "\n",
      "Epoch 1732\n",
      "-------------------------------\n",
      "loss: 0.279580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397051 \n",
      "\n",
      "Epoch 1733\n",
      "-------------------------------\n",
      "loss: 0.271620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398931 \n",
      "\n",
      "Epoch 1734\n",
      "-------------------------------\n",
      "loss: 0.253695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400750 \n",
      "\n",
      "Epoch 1735\n",
      "-------------------------------\n",
      "loss: 0.269499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400337 \n",
      "\n",
      "Epoch 1736\n",
      "-------------------------------\n",
      "loss: 0.277411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399748 \n",
      "\n",
      "Epoch 1737\n",
      "-------------------------------\n",
      "loss: 0.290677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398892 \n",
      "\n",
      "Epoch 1738\n",
      "-------------------------------\n",
      "loss: 0.278807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399203 \n",
      "\n",
      "Epoch 1739\n",
      "-------------------------------\n",
      "loss: 0.291822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399907 \n",
      "\n",
      "Epoch 1740\n",
      "-------------------------------\n",
      "loss: 0.263389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399886 \n",
      "\n",
      "Epoch 1741\n",
      "-------------------------------\n",
      "loss: 0.268079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399685 \n",
      "\n",
      "Epoch 1742\n",
      "-------------------------------\n",
      "loss: 0.251951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400482 \n",
      "\n",
      "Epoch 1743\n",
      "-------------------------------\n",
      "loss: 0.271452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401794 \n",
      "\n",
      "Epoch 1744\n",
      "-------------------------------\n",
      "loss: 0.285628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401900 \n",
      "\n",
      "Epoch 1745\n",
      "-------------------------------\n",
      "loss: 0.269142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 1746\n",
      "-------------------------------\n",
      "loss: 0.272234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400077 \n",
      "\n",
      "Epoch 1747\n",
      "-------------------------------\n",
      "loss: 0.289715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399466 \n",
      "\n",
      "Epoch 1748\n",
      "-------------------------------\n",
      "loss: 0.283794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399250 \n",
      "\n",
      "Epoch 1749\n",
      "-------------------------------\n",
      "loss: 0.274060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399857 \n",
      "\n",
      "Epoch 1750\n",
      "-------------------------------\n",
      "loss: 0.276131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400857 \n",
      "\n",
      "Epoch 1751\n",
      "-------------------------------\n",
      "loss: 0.273311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401586 \n",
      "\n",
      "Epoch 1752\n",
      "-------------------------------\n",
      "loss: 0.274449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402031 \n",
      "\n",
      "Epoch 1753\n",
      "-------------------------------\n",
      "loss: 0.263327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401033 \n",
      "\n",
      "Epoch 1754\n",
      "-------------------------------\n",
      "loss: 0.272523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399562 \n",
      "\n",
      "Epoch 1755\n",
      "-------------------------------\n",
      "loss: 0.271517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398935 \n",
      "\n",
      "Epoch 1756\n",
      "-------------------------------\n",
      "loss: 0.265705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399231 \n",
      "\n",
      "Epoch 1757\n",
      "-------------------------------\n",
      "loss: 0.269263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400213 \n",
      "\n",
      "Epoch 1758\n",
      "-------------------------------\n",
      "loss: 0.281852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401192 \n",
      "\n",
      "Epoch 1759\n",
      "-------------------------------\n",
      "loss: 0.259255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402087 \n",
      "\n",
      "Epoch 1760\n",
      "-------------------------------\n",
      "loss: 0.261736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402607 \n",
      "\n",
      "Epoch 1761\n",
      "-------------------------------\n",
      "loss: 0.286049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400830 \n",
      "\n",
      "Epoch 1762\n",
      "-------------------------------\n",
      "loss: 0.290542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399362 \n",
      "\n",
      "Epoch 1763\n",
      "-------------------------------\n",
      "loss: 0.267082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398237 \n",
      "\n",
      "Epoch 1764\n",
      "-------------------------------\n",
      "loss: 0.267569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398378 \n",
      "\n",
      "Epoch 1765\n",
      "-------------------------------\n",
      "loss: 0.278406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400026 \n",
      "\n",
      "Epoch 1766\n",
      "-------------------------------\n",
      "loss: 0.266192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402658 \n",
      "\n",
      "Epoch 1767\n",
      "-------------------------------\n",
      "loss: 0.268799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404432 \n",
      "\n",
      "Epoch 1768\n",
      "-------------------------------\n",
      "loss: 0.272020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405361 \n",
      "\n",
      "Epoch 1769\n",
      "-------------------------------\n",
      "loss: 0.279268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404996 \n",
      "\n",
      "Epoch 1770\n",
      "-------------------------------\n",
      "loss: 0.256022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406028 \n",
      "\n",
      "Epoch 1771\n",
      "-------------------------------\n",
      "loss: 0.272390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406760 \n",
      "\n",
      "Epoch 1772\n",
      "-------------------------------\n",
      "loss: 0.273981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404834 \n",
      "\n",
      "Epoch 1773\n",
      "-------------------------------\n",
      "loss: 0.288702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400816 \n",
      "\n",
      "Epoch 1774\n",
      "-------------------------------\n",
      "loss: 0.254071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398890 \n",
      "\n",
      "Epoch 1775\n",
      "-------------------------------\n",
      "loss: 0.267475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399006 \n",
      "\n",
      "Epoch 1776\n",
      "-------------------------------\n",
      "loss: 0.278380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399357 \n",
      "\n",
      "Epoch 1777\n",
      "-------------------------------\n",
      "loss: 0.287668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401051 \n",
      "\n",
      "Epoch 1778\n",
      "-------------------------------\n",
      "loss: 0.253359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405189 \n",
      "\n",
      "Epoch 1779\n",
      "-------------------------------\n",
      "loss: 0.265892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408713 \n",
      "\n",
      "Epoch 1780\n",
      "-------------------------------\n",
      "loss: 0.268126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408876 \n",
      "\n",
      "Epoch 1781\n",
      "-------------------------------\n",
      "loss: 0.291184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404506 \n",
      "\n",
      "Epoch 1782\n",
      "-------------------------------\n",
      "loss: 0.264380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399730 \n",
      "\n",
      "Epoch 1783\n",
      "-------------------------------\n",
      "loss: 0.299693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398409 \n",
      "\n",
      "Epoch 1784\n",
      "-------------------------------\n",
      "loss: 0.266244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398912 \n",
      "\n",
      "Epoch 1785\n",
      "-------------------------------\n",
      "loss: 0.290904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399942 \n",
      "\n",
      "Epoch 1786\n",
      "-------------------------------\n",
      "loss: 0.279439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400593 \n",
      "\n",
      "Epoch 1787\n",
      "-------------------------------\n",
      "loss: 0.295797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400857 \n",
      "\n",
      "Epoch 1788\n",
      "-------------------------------\n",
      "loss: 0.260458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402572 \n",
      "\n",
      "Epoch 1789\n",
      "-------------------------------\n",
      "loss: 0.279198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407282 \n",
      "\n",
      "Epoch 1790\n",
      "-------------------------------\n",
      "loss: 0.298096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409904 \n",
      "\n",
      "Epoch 1791\n",
      "-------------------------------\n",
      "loss: 0.284338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409582 \n",
      "\n",
      "Epoch 1792\n",
      "-------------------------------\n",
      "loss: 0.271581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407661 \n",
      "\n",
      "Epoch 1793\n",
      "-------------------------------\n",
      "loss: 0.271069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405484 \n",
      "\n",
      "Epoch 1794\n",
      "-------------------------------\n",
      "loss: 0.265373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401998 \n",
      "\n",
      "Epoch 1795\n",
      "-------------------------------\n",
      "loss: 0.271260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399377 \n",
      "\n",
      "Epoch 1796\n",
      "-------------------------------\n",
      "loss: 0.283614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399892 \n",
      "\n",
      "Epoch 1797\n",
      "-------------------------------\n",
      "loss: 0.265094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401850 \n",
      "\n",
      "Epoch 1798\n",
      "-------------------------------\n",
      "loss: 0.266191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403439 \n",
      "\n",
      "Epoch 1799\n",
      "-------------------------------\n",
      "loss: 0.278437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402353 \n",
      "\n",
      "Epoch 1800\n",
      "-------------------------------\n",
      "loss: 0.267709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401440 \n",
      "\n",
      "Epoch 1801\n",
      "-------------------------------\n",
      "loss: 0.274328  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400483 \n",
      "\n",
      "Epoch 1802\n",
      "-------------------------------\n",
      "loss: 0.268858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400518 \n",
      "\n",
      "Epoch 1803\n",
      "-------------------------------\n",
      "loss: 0.264516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400653 \n",
      "\n",
      "Epoch 1804\n",
      "-------------------------------\n",
      "loss: 0.273557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398984 \n",
      "\n",
      "Epoch 1805\n",
      "-------------------------------\n",
      "loss: 0.269622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398999 \n",
      "\n",
      "Epoch 1806\n",
      "-------------------------------\n",
      "loss: 0.272968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399009 \n",
      "\n",
      "Epoch 1807\n",
      "-------------------------------\n",
      "loss: 0.261299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399717 \n",
      "\n",
      "Epoch 1808\n",
      "-------------------------------\n",
      "loss: 0.265938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400966 \n",
      "\n",
      "Epoch 1809\n",
      "-------------------------------\n",
      "loss: 0.266931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403491 \n",
      "\n",
      "Epoch 1810\n",
      "-------------------------------\n",
      "loss: 0.268632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404882 \n",
      "\n",
      "Epoch 1811\n",
      "-------------------------------\n",
      "loss: 0.265637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404578 \n",
      "\n",
      "Epoch 1812\n",
      "-------------------------------\n",
      "loss: 0.277203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404719 \n",
      "\n",
      "Epoch 1813\n",
      "-------------------------------\n",
      "loss: 0.268950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404609 \n",
      "\n",
      "Epoch 1814\n",
      "-------------------------------\n",
      "loss: 0.270981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405803 \n",
      "\n",
      "Epoch 1815\n",
      "-------------------------------\n",
      "loss: 0.261450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406589 \n",
      "\n",
      "Epoch 1816\n",
      "-------------------------------\n",
      "loss: 0.281984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404972 \n",
      "\n",
      "Epoch 1817\n",
      "-------------------------------\n",
      "loss: 0.279412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401578 \n",
      "\n",
      "Epoch 1818\n",
      "-------------------------------\n",
      "loss: 0.284865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400302 \n",
      "\n",
      "Epoch 1819\n",
      "-------------------------------\n",
      "loss: 0.265960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399749 \n",
      "\n",
      "Epoch 1820\n",
      "-------------------------------\n",
      "loss: 0.266837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399370 \n",
      "\n",
      "Epoch 1821\n",
      "-------------------------------\n",
      "loss: 0.272005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399374 \n",
      "\n",
      "Epoch 1822\n",
      "-------------------------------\n",
      "loss: 0.263631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399642 \n",
      "\n",
      "Epoch 1823\n",
      "-------------------------------\n",
      "loss: 0.256715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401667 \n",
      "\n",
      "Epoch 1824\n",
      "-------------------------------\n",
      "loss: 0.268983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401660 \n",
      "\n",
      "Epoch 1825\n",
      "-------------------------------\n",
      "loss: 0.256168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399250 \n",
      "\n",
      "Epoch 1826\n",
      "-------------------------------\n",
      "loss: 0.262734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397480 \n",
      "\n",
      "Epoch 1827\n",
      "-------------------------------\n",
      "loss: 0.278300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397125 \n",
      "\n",
      "Epoch 1828\n",
      "-------------------------------\n",
      "loss: 0.266179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397049 \n",
      "\n",
      "Epoch 1829\n",
      "-------------------------------\n",
      "loss: 0.268201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396393 \n",
      "\n",
      "Epoch 1830\n",
      "-------------------------------\n",
      "loss: 0.269713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396407 \n",
      "\n",
      "Epoch 1831\n",
      "-------------------------------\n",
      "loss: 0.280502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399204 \n",
      "\n",
      "Epoch 1832\n",
      "-------------------------------\n",
      "loss: 0.251122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404727 \n",
      "\n",
      "Epoch 1833\n",
      "-------------------------------\n",
      "loss: 0.269515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407344 \n",
      "\n",
      "Epoch 1834\n",
      "-------------------------------\n",
      "loss: 0.259948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406063 \n",
      "\n",
      "Epoch 1835\n",
      "-------------------------------\n",
      "loss: 0.269408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402684 \n",
      "\n",
      "Epoch 1836\n",
      "-------------------------------\n",
      "loss: 0.260527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400176 \n",
      "\n",
      "Epoch 1837\n",
      "-------------------------------\n",
      "loss: 0.263138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398948 \n",
      "\n",
      "Epoch 1838\n",
      "-------------------------------\n",
      "loss: 0.277277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398756 \n",
      "\n",
      "Epoch 1839\n",
      "-------------------------------\n",
      "loss: 0.279598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398762 \n",
      "\n",
      "Epoch 1840\n",
      "-------------------------------\n",
      "loss: 0.252595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399892 \n",
      "\n",
      "Epoch 1841\n",
      "-------------------------------\n",
      "loss: 0.271289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401280 \n",
      "\n",
      "Epoch 1842\n",
      "-------------------------------\n",
      "loss: 0.267322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403219 \n",
      "\n",
      "Epoch 1843\n",
      "-------------------------------\n",
      "loss: 0.274597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403322 \n",
      "\n",
      "Epoch 1844\n",
      "-------------------------------\n",
      "loss: 0.289849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404075 \n",
      "\n",
      "Epoch 1845\n",
      "-------------------------------\n",
      "loss: 0.277764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403899 \n",
      "\n",
      "Epoch 1846\n",
      "-------------------------------\n",
      "loss: 0.275072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402439 \n",
      "\n",
      "Epoch 1847\n",
      "-------------------------------\n",
      "loss: 0.267992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400877 \n",
      "\n",
      "Epoch 1848\n",
      "-------------------------------\n",
      "loss: 0.271221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400320 \n",
      "\n",
      "Epoch 1849\n",
      "-------------------------------\n",
      "loss: 0.267675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400578 \n",
      "\n",
      "Epoch 1850\n",
      "-------------------------------\n",
      "loss: 0.254619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401757 \n",
      "\n",
      "Epoch 1851\n",
      "-------------------------------\n",
      "loss: 0.270157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402100 \n",
      "\n",
      "Epoch 1852\n",
      "-------------------------------\n",
      "loss: 0.288863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400092 \n",
      "\n",
      "Epoch 1853\n",
      "-------------------------------\n",
      "loss: 0.260213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399041 \n",
      "\n",
      "Epoch 1854\n",
      "-------------------------------\n",
      "loss: 0.273088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399948 \n",
      "\n",
      "Epoch 1855\n",
      "-------------------------------\n",
      "loss: 0.275132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399874 \n",
      "\n",
      "Epoch 1856\n",
      "-------------------------------\n",
      "loss: 0.266994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400564 \n",
      "\n",
      "Epoch 1857\n",
      "-------------------------------\n",
      "loss: 0.273662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401144 \n",
      "\n",
      "Epoch 1858\n",
      "-------------------------------\n",
      "loss: 0.264290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402413 \n",
      "\n",
      "Epoch 1859\n",
      "-------------------------------\n",
      "loss: 0.272501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402432 \n",
      "\n",
      "Epoch 1860\n",
      "-------------------------------\n",
      "loss: 0.274370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402652 \n",
      "\n",
      "Epoch 1861\n",
      "-------------------------------\n",
      "loss: 0.278048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400766 \n",
      "\n",
      "Epoch 1862\n",
      "-------------------------------\n",
      "loss: 0.256658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399889 \n",
      "\n",
      "Epoch 1863\n",
      "-------------------------------\n",
      "loss: 0.265376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400417 \n",
      "\n",
      "Epoch 1864\n",
      "-------------------------------\n",
      "loss: 0.260613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 1865\n",
      "-------------------------------\n",
      "loss: 0.274585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400681 \n",
      "\n",
      "Epoch 1866\n",
      "-------------------------------\n",
      "loss: 0.255939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399810 \n",
      "\n",
      "Epoch 1867\n",
      "-------------------------------\n",
      "loss: 0.260789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400477 \n",
      "\n",
      "Epoch 1868\n",
      "-------------------------------\n",
      "loss: 0.258010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402757 \n",
      "\n",
      "Epoch 1869\n",
      "-------------------------------\n",
      "loss: 0.262802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404134 \n",
      "\n",
      "Epoch 1870\n",
      "-------------------------------\n",
      "loss: 0.279065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404590 \n",
      "\n",
      "Epoch 1871\n",
      "-------------------------------\n",
      "loss: 0.277373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402544 \n",
      "\n",
      "Epoch 1872\n",
      "-------------------------------\n",
      "loss: 0.270407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399621 \n",
      "\n",
      "Epoch 1873\n",
      "-------------------------------\n",
      "loss: 0.265788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397560 \n",
      "\n",
      "Epoch 1874\n",
      "-------------------------------\n",
      "loss: 0.270924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396704 \n",
      "\n",
      "Epoch 1875\n",
      "-------------------------------\n",
      "loss: 0.279264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396889 \n",
      "\n",
      "Epoch 1876\n",
      "-------------------------------\n",
      "loss: 0.268943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397493 \n",
      "\n",
      "Epoch 1877\n",
      "-------------------------------\n",
      "loss: 0.275571  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.398257 \n",
      "\n",
      "Epoch 1878\n",
      "-------------------------------\n",
      "loss: 0.272225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397924 \n",
      "\n",
      "Epoch 1879\n",
      "-------------------------------\n",
      "loss: 0.293002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398889 \n",
      "\n",
      "Epoch 1880\n",
      "-------------------------------\n",
      "loss: 0.262206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401415 \n",
      "\n",
      "Epoch 1881\n",
      "-------------------------------\n",
      "loss: 0.278721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404738 \n",
      "\n",
      "Epoch 1882\n",
      "-------------------------------\n",
      "loss: 0.264608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405244 \n",
      "\n",
      "Epoch 1883\n",
      "-------------------------------\n",
      "loss: 0.268743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404715 \n",
      "\n",
      "Epoch 1884\n",
      "-------------------------------\n",
      "loss: 0.271201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401347 \n",
      "\n",
      "Epoch 1885\n",
      "-------------------------------\n",
      "loss: 0.253690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399040 \n",
      "\n",
      "Epoch 1886\n",
      "-------------------------------\n",
      "loss: 0.280499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397765 \n",
      "\n",
      "Epoch 1887\n",
      "-------------------------------\n",
      "loss: 0.274158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397983 \n",
      "\n",
      "Epoch 1888\n",
      "-------------------------------\n",
      "loss: 0.265949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399913 \n",
      "\n",
      "Epoch 1889\n",
      "-------------------------------\n",
      "loss: 0.277476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402786 \n",
      "\n",
      "Epoch 1890\n",
      "-------------------------------\n",
      "loss: 0.274978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405310 \n",
      "\n",
      "Epoch 1891\n",
      "-------------------------------\n",
      "loss: 0.261350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406072 \n",
      "\n",
      "Epoch 1892\n",
      "-------------------------------\n",
      "loss: 0.284119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404874 \n",
      "\n",
      "Epoch 1893\n",
      "-------------------------------\n",
      "loss: 0.276157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403094 \n",
      "\n",
      "Epoch 1894\n",
      "-------------------------------\n",
      "loss: 0.269219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403380 \n",
      "\n",
      "Epoch 1895\n",
      "-------------------------------\n",
      "loss: 0.277736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404880 \n",
      "\n",
      "Epoch 1896\n",
      "-------------------------------\n",
      "loss: 0.263346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407138 \n",
      "\n",
      "Epoch 1897\n",
      "-------------------------------\n",
      "loss: 0.306920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408833 \n",
      "\n",
      "Epoch 1898\n",
      "-------------------------------\n",
      "loss: 0.284704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409954 \n",
      "\n",
      "Epoch 1899\n",
      "-------------------------------\n",
      "loss: 0.274139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411476 \n",
      "\n",
      "Epoch 1900\n",
      "-------------------------------\n",
      "loss: 0.267292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412918 \n",
      "\n",
      "Epoch 1901\n",
      "-------------------------------\n",
      "loss: 0.300058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408939 \n",
      "\n",
      "Epoch 1902\n",
      "-------------------------------\n",
      "loss: 0.259676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405761 \n",
      "\n",
      "Epoch 1903\n",
      "-------------------------------\n",
      "loss: 0.278480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406160 \n",
      "\n",
      "Epoch 1904\n",
      "-------------------------------\n",
      "loss: 0.267426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406864 \n",
      "\n",
      "Epoch 1905\n",
      "-------------------------------\n",
      "loss: 0.265055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405817 \n",
      "\n",
      "Epoch 1906\n",
      "-------------------------------\n",
      "loss: 0.278725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403308 \n",
      "\n",
      "Epoch 1907\n",
      "-------------------------------\n",
      "loss: 0.254270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401368 \n",
      "\n",
      "Epoch 1908\n",
      "-------------------------------\n",
      "loss: 0.271992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399986 \n",
      "\n",
      "Epoch 1909\n",
      "-------------------------------\n",
      "loss: 0.261305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400092 \n",
      "\n",
      "Epoch 1910\n",
      "-------------------------------\n",
      "loss: 0.267586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402120 \n",
      "\n",
      "Epoch 1911\n",
      "-------------------------------\n",
      "loss: 0.279411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404801 \n",
      "\n",
      "Epoch 1912\n",
      "-------------------------------\n",
      "loss: 0.279905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405690 \n",
      "\n",
      "Epoch 1913\n",
      "-------------------------------\n",
      "loss: 0.284630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403919 \n",
      "\n",
      "Epoch 1914\n",
      "-------------------------------\n",
      "loss: 0.272068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401325 \n",
      "\n",
      "Epoch 1915\n",
      "-------------------------------\n",
      "loss: 0.269771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398440 \n",
      "\n",
      "Epoch 1916\n",
      "-------------------------------\n",
      "loss: 0.283876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397270 \n",
      "\n",
      "Epoch 1917\n",
      "-------------------------------\n",
      "loss: 0.264163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397766 \n",
      "\n",
      "Epoch 1918\n",
      "-------------------------------\n",
      "loss: 0.266679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399129 \n",
      "\n",
      "Epoch 1919\n",
      "-------------------------------\n",
      "loss: 0.255484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399754 \n",
      "\n",
      "Epoch 1920\n",
      "-------------------------------\n",
      "loss: 0.253070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400749 \n",
      "\n",
      "Epoch 1921\n",
      "-------------------------------\n",
      "loss: 0.266527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399577 \n",
      "\n",
      "Epoch 1922\n",
      "-------------------------------\n",
      "loss: 0.262992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398601 \n",
      "\n",
      "Epoch 1923\n",
      "-------------------------------\n",
      "loss: 0.250427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398723 \n",
      "\n",
      "Epoch 1924\n",
      "-------------------------------\n",
      "loss: 0.254370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400099 \n",
      "\n",
      "Epoch 1925\n",
      "-------------------------------\n",
      "loss: 0.267414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402406 \n",
      "\n",
      "Epoch 1926\n",
      "-------------------------------\n",
      "loss: 0.256305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404961 \n",
      "\n",
      "Epoch 1927\n",
      "-------------------------------\n",
      "loss: 0.257841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406485 \n",
      "\n",
      "Epoch 1928\n",
      "-------------------------------\n",
      "loss: 0.284682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404776 \n",
      "\n",
      "Epoch 1929\n",
      "-------------------------------\n",
      "loss: 0.280015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400733 \n",
      "\n",
      "Epoch 1930\n",
      "-------------------------------\n",
      "loss: 0.258378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399106 \n",
      "\n",
      "Epoch 1931\n",
      "-------------------------------\n",
      "loss: 0.267139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399184 \n",
      "\n",
      "Epoch 1932\n",
      "-------------------------------\n",
      "loss: 0.273666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398533 \n",
      "\n",
      "Epoch 1933\n",
      "-------------------------------\n",
      "loss: 0.265429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397487 \n",
      "\n",
      "Epoch 1934\n",
      "-------------------------------\n",
      "loss: 0.286613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396630 \n",
      "\n",
      "Epoch 1935\n",
      "-------------------------------\n",
      "loss: 0.280464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395857 \n",
      "\n",
      "Epoch 1936\n",
      "-------------------------------\n",
      "loss: 0.260679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396584 \n",
      "\n",
      "Epoch 1937\n",
      "-------------------------------\n",
      "loss: 0.269942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398865 \n",
      "\n",
      "Epoch 1938\n",
      "-------------------------------\n",
      "loss: 0.287506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400750 \n",
      "\n",
      "Epoch 1939\n",
      "-------------------------------\n",
      "loss: 0.274408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400758 \n",
      "\n",
      "Epoch 1940\n",
      "-------------------------------\n",
      "loss: 0.269055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399382 \n",
      "\n",
      "Epoch 1941\n",
      "-------------------------------\n",
      "loss: 0.278218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398873 \n",
      "\n",
      "Epoch 1942\n",
      "-------------------------------\n",
      "loss: 0.253815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399289 \n",
      "\n",
      "Epoch 1943\n",
      "-------------------------------\n",
      "loss: 0.263001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399512 \n",
      "\n",
      "Epoch 1944\n",
      "-------------------------------\n",
      "loss: 0.278051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398788 \n",
      "\n",
      "Epoch 1945\n",
      "-------------------------------\n",
      "loss: 0.256383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397082 \n",
      "\n",
      "Epoch 1946\n",
      "-------------------------------\n",
      "loss: 0.266712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396010 \n",
      "\n",
      "Epoch 1947\n",
      "-------------------------------\n",
      "loss: 0.278732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394593 \n",
      "\n",
      "Epoch 1948\n",
      "-------------------------------\n",
      "loss: 0.247013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393899 \n",
      "\n",
      "Epoch 1949\n",
      "-------------------------------\n",
      "loss: 0.264549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394171 \n",
      "\n",
      "Epoch 1950\n",
      "-------------------------------\n",
      "loss: 0.268164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396729 \n",
      "\n",
      "Epoch 1951\n",
      "-------------------------------\n",
      "loss: 0.269812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399471 \n",
      "\n",
      "Epoch 1952\n",
      "-------------------------------\n",
      "loss: 0.265341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400403 \n",
      "\n",
      "Epoch 1953\n",
      "-------------------------------\n",
      "loss: 0.261502  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400795 \n",
      "\n",
      "Epoch 1954\n",
      "-------------------------------\n",
      "loss: 0.261648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400805 \n",
      "\n",
      "Epoch 1955\n",
      "-------------------------------\n",
      "loss: 0.267266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399348 \n",
      "\n",
      "Epoch 1956\n",
      "-------------------------------\n",
      "loss: 0.261314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397281 \n",
      "\n",
      "Epoch 1957\n",
      "-------------------------------\n",
      "loss: 0.269537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395601 \n",
      "\n",
      "Epoch 1958\n",
      "-------------------------------\n",
      "loss: 0.257221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394743 \n",
      "\n",
      "Epoch 1959\n",
      "-------------------------------\n",
      "loss: 0.267678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393804 \n",
      "\n",
      "Epoch 1960\n",
      "-------------------------------\n",
      "loss: 0.275161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393094 \n",
      "\n",
      "Epoch 1961\n",
      "-------------------------------\n",
      "loss: 0.258187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393220 \n",
      "\n",
      "Epoch 1962\n",
      "-------------------------------\n",
      "loss: 0.271794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393072 \n",
      "\n",
      "Epoch 1963\n",
      "-------------------------------\n",
      "loss: 0.271008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393192 \n",
      "\n",
      "Epoch 1964\n",
      "-------------------------------\n",
      "loss: 0.262287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394206 \n",
      "\n",
      "Epoch 1965\n",
      "-------------------------------\n",
      "loss: 0.261882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395821 \n",
      "\n",
      "Epoch 1966\n",
      "-------------------------------\n",
      "loss: 0.244058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397143 \n",
      "\n",
      "Epoch 1967\n",
      "-------------------------------\n",
      "loss: 0.267536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395954 \n",
      "\n",
      "Epoch 1968\n",
      "-------------------------------\n",
      "loss: 0.272824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394157 \n",
      "\n",
      "Epoch 1969\n",
      "-------------------------------\n",
      "loss: 0.286006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394210 \n",
      "\n",
      "Epoch 1970\n",
      "-------------------------------\n",
      "loss: 0.277795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394983 \n",
      "\n",
      "Epoch 1971\n",
      "-------------------------------\n",
      "loss: 0.279923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394128 \n",
      "\n",
      "Epoch 1972\n",
      "-------------------------------\n",
      "loss: 0.262189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393490 \n",
      "\n",
      "Epoch 1973\n",
      "-------------------------------\n",
      "loss: 0.255608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396474 \n",
      "\n",
      "Epoch 1974\n",
      "-------------------------------\n",
      "loss: 0.262965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400695 \n",
      "\n",
      "Epoch 1975\n",
      "-------------------------------\n",
      "loss: 0.281296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400537 \n",
      "\n",
      "Epoch 1976\n",
      "-------------------------------\n",
      "loss: 0.269738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397060 \n",
      "\n",
      "Epoch 1977\n",
      "-------------------------------\n",
      "loss: 0.249986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394928 \n",
      "\n",
      "Epoch 1978\n",
      "-------------------------------\n",
      "loss: 0.258479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394967 \n",
      "\n",
      "Epoch 1979\n",
      "-------------------------------\n",
      "loss: 0.265981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395932 \n",
      "\n",
      "Epoch 1980\n",
      "-------------------------------\n",
      "loss: 0.280118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396664 \n",
      "\n",
      "Epoch 1981\n",
      "-------------------------------\n",
      "loss: 0.260060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397847 \n",
      "\n",
      "Epoch 1982\n",
      "-------------------------------\n",
      "loss: 0.251678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399396 \n",
      "\n",
      "Epoch 1983\n",
      "-------------------------------\n",
      "loss: 0.277470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401793 \n",
      "\n",
      "Epoch 1984\n",
      "-------------------------------\n",
      "loss: 0.278049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404422 \n",
      "\n",
      "Epoch 1985\n",
      "-------------------------------\n",
      "loss: 0.275210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405476 \n",
      "\n",
      "Epoch 1986\n",
      "-------------------------------\n",
      "loss: 0.284175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403529 \n",
      "\n",
      "Epoch 1987\n",
      "-------------------------------\n",
      "loss: 0.269776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400655 \n",
      "\n",
      "Epoch 1988\n",
      "-------------------------------\n",
      "loss: 0.271697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399146 \n",
      "\n",
      "Epoch 1989\n",
      "-------------------------------\n",
      "loss: 0.271113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398136 \n",
      "\n",
      "Epoch 1990\n",
      "-------------------------------\n",
      "loss: 0.261333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396482 \n",
      "\n",
      "Epoch 1991\n",
      "-------------------------------\n",
      "loss: 0.270266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397180 \n",
      "\n",
      "Epoch 1992\n",
      "-------------------------------\n",
      "loss: 0.250525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402817 \n",
      "\n",
      "Epoch 1993\n",
      "-------------------------------\n",
      "loss: 0.261880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408690 \n",
      "\n",
      "Epoch 1994\n",
      "-------------------------------\n",
      "loss: 0.275671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405715 \n",
      "\n",
      "Epoch 1995\n",
      "-------------------------------\n",
      "loss: 0.273141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400662 \n",
      "\n",
      "Epoch 1996\n",
      "-------------------------------\n",
      "loss: 0.281338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396013 \n",
      "\n",
      "Epoch 1997\n",
      "-------------------------------\n",
      "loss: 0.260284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396782 \n",
      "\n",
      "Epoch 1998\n",
      "-------------------------------\n",
      "loss: 0.251591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397497 \n",
      "\n",
      "Epoch 1999\n",
      "-------------------------------\n",
      "loss: 0.262484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396555 \n",
      "\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "loss: 0.272627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396873 \n",
      "\n",
      "Epoch 2001\n",
      "-------------------------------\n",
      "loss: 0.270993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400553 \n",
      "\n",
      "Epoch 2002\n",
      "-------------------------------\n",
      "loss: 0.246146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408197 \n",
      "\n",
      "Epoch 2003\n",
      "-------------------------------\n",
      "loss: 0.263041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412368 \n",
      "\n",
      "Epoch 2004\n",
      "-------------------------------\n",
      "loss: 0.265793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409665 \n",
      "\n",
      "Epoch 2005\n",
      "-------------------------------\n",
      "loss: 0.267346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403761 \n",
      "\n",
      "Epoch 2006\n",
      "-------------------------------\n",
      "loss: 0.286918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397983 \n",
      "\n",
      "Epoch 2007\n",
      "-------------------------------\n",
      "loss: 0.270960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396403 \n",
      "\n",
      "Epoch 2008\n",
      "-------------------------------\n",
      "loss: 0.279821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397390 \n",
      "\n",
      "Epoch 2009\n",
      "-------------------------------\n",
      "loss: 0.280832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396604 \n",
      "\n",
      "Epoch 2010\n",
      "-------------------------------\n",
      "loss: 0.278519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396546 \n",
      "\n",
      "Epoch 2011\n",
      "-------------------------------\n",
      "loss: 0.255503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398351 \n",
      "\n",
      "Epoch 2012\n",
      "-------------------------------\n",
      "loss: 0.258563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403246 \n",
      "\n",
      "Epoch 2013\n",
      "-------------------------------\n",
      "loss: 0.279168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406669 \n",
      "\n",
      "Epoch 2014\n",
      "-------------------------------\n",
      "loss: 0.259041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406598 \n",
      "\n",
      "Epoch 2015\n",
      "-------------------------------\n",
      "loss: 0.258413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402040 \n",
      "\n",
      "Epoch 2016\n",
      "-------------------------------\n",
      "loss: 0.255237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398504 \n",
      "\n",
      "Epoch 2017\n",
      "-------------------------------\n",
      "loss: 0.265190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397671 \n",
      "\n",
      "Epoch 2018\n",
      "-------------------------------\n",
      "loss: 0.267985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398121 \n",
      "\n",
      "Epoch 2019\n",
      "-------------------------------\n",
      "loss: 0.267561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397394 \n",
      "\n",
      "Epoch 2020\n",
      "-------------------------------\n",
      "loss: 0.267924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397841 \n",
      "\n",
      "Epoch 2021\n",
      "-------------------------------\n",
      "loss: 0.259959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400337 \n",
      "\n",
      "Epoch 2022\n",
      "-------------------------------\n",
      "loss: 0.274917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405041 \n",
      "\n",
      "Epoch 2023\n",
      "-------------------------------\n",
      "loss: 0.261337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408807 \n",
      "\n",
      "Epoch 2024\n",
      "-------------------------------\n",
      "loss: 0.263763  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407823 \n",
      "\n",
      "Epoch 2025\n",
      "-------------------------------\n",
      "loss: 0.262386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403843 \n",
      "\n",
      "Epoch 2026\n",
      "-------------------------------\n",
      "loss: 0.283534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397826 \n",
      "\n",
      "Epoch 2027\n",
      "-------------------------------\n",
      "loss: 0.250271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395175 \n",
      "\n",
      "Epoch 2028\n",
      "-------------------------------\n",
      "loss: 0.258841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394901 \n",
      "\n",
      "Epoch 2029\n",
      "-------------------------------\n",
      "loss: 0.272519  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.394526 \n",
      "\n",
      "Epoch 2030\n",
      "-------------------------------\n",
      "loss: 0.267232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394920 \n",
      "\n",
      "Epoch 2031\n",
      "-------------------------------\n",
      "loss: 0.248699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399557 \n",
      "\n",
      "Epoch 2032\n",
      "-------------------------------\n",
      "loss: 0.246406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404217 \n",
      "\n",
      "Epoch 2033\n",
      "-------------------------------\n",
      "loss: 0.262210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402867 \n",
      "\n",
      "Epoch 2034\n",
      "-------------------------------\n",
      "loss: 0.255089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397729 \n",
      "\n",
      "Epoch 2035\n",
      "-------------------------------\n",
      "loss: 0.274788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394813 \n",
      "\n",
      "Epoch 2036\n",
      "-------------------------------\n",
      "loss: 0.248432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396534 \n",
      "\n",
      "Epoch 2037\n",
      "-------------------------------\n",
      "loss: 0.278809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399808 \n",
      "\n",
      "Epoch 2038\n",
      "-------------------------------\n",
      "loss: 0.274052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401792 \n",
      "\n",
      "Epoch 2039\n",
      "-------------------------------\n",
      "loss: 0.267531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401520 \n",
      "\n",
      "Epoch 2040\n",
      "-------------------------------\n",
      "loss: 0.251959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402087 \n",
      "\n",
      "Epoch 2041\n",
      "-------------------------------\n",
      "loss: 0.263931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404804 \n",
      "\n",
      "Epoch 2042\n",
      "-------------------------------\n",
      "loss: 0.255046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406903 \n",
      "\n",
      "Epoch 2043\n",
      "-------------------------------\n",
      "loss: 0.261843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407142 \n",
      "\n",
      "Epoch 2044\n",
      "-------------------------------\n",
      "loss: 0.265604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404592 \n",
      "\n",
      "Epoch 2045\n",
      "-------------------------------\n",
      "loss: 0.281250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400110 \n",
      "\n",
      "Epoch 2046\n",
      "-------------------------------\n",
      "loss: 0.258578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397607 \n",
      "\n",
      "Epoch 2047\n",
      "-------------------------------\n",
      "loss: 0.267211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396041 \n",
      "\n",
      "Epoch 2048\n",
      "-------------------------------\n",
      "loss: 0.270289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395009 \n",
      "\n",
      "Epoch 2049\n",
      "-------------------------------\n",
      "loss: 0.275373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395674 \n",
      "\n",
      "Epoch 2050\n",
      "-------------------------------\n",
      "loss: 0.242048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399954 \n",
      "\n",
      "Epoch 2051\n",
      "-------------------------------\n",
      "loss: 0.263091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401958 \n",
      "\n",
      "Epoch 2052\n",
      "-------------------------------\n",
      "loss: 0.252172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400627 \n",
      "\n",
      "Epoch 2053\n",
      "-------------------------------\n",
      "loss: 0.265332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397843 \n",
      "\n",
      "Epoch 2054\n",
      "-------------------------------\n",
      "loss: 0.257751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395700 \n",
      "\n",
      "Epoch 2055\n",
      "-------------------------------\n",
      "loss: 0.246441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394656 \n",
      "\n",
      "Epoch 2056\n",
      "-------------------------------\n",
      "loss: 0.258729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394687 \n",
      "\n",
      "Epoch 2057\n",
      "-------------------------------\n",
      "loss: 0.282849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395353 \n",
      "\n",
      "Epoch 2058\n",
      "-------------------------------\n",
      "loss: 0.272174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396894 \n",
      "\n",
      "Epoch 2059\n",
      "-------------------------------\n",
      "loss: 0.257270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397553 \n",
      "\n",
      "Epoch 2060\n",
      "-------------------------------\n",
      "loss: 0.275238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398187 \n",
      "\n",
      "Epoch 2061\n",
      "-------------------------------\n",
      "loss: 0.260302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398719 \n",
      "\n",
      "Epoch 2062\n",
      "-------------------------------\n",
      "loss: 0.257251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399283 \n",
      "\n",
      "Epoch 2063\n",
      "-------------------------------\n",
      "loss: 0.251725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400047 \n",
      "\n",
      "Epoch 2064\n",
      "-------------------------------\n",
      "loss: 0.254295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401227 \n",
      "\n",
      "Epoch 2065\n",
      "-------------------------------\n",
      "loss: 0.255189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402098 \n",
      "\n",
      "Epoch 2066\n",
      "-------------------------------\n",
      "loss: 0.268656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402907 \n",
      "\n",
      "Epoch 2067\n",
      "-------------------------------\n",
      "loss: 0.245632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403289 \n",
      "\n",
      "Epoch 2068\n",
      "-------------------------------\n",
      "loss: 0.264396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401748 \n",
      "\n",
      "Epoch 2069\n",
      "-------------------------------\n",
      "loss: 0.254240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400348 \n",
      "\n",
      "Epoch 2070\n",
      "-------------------------------\n",
      "loss: 0.266981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397747 \n",
      "\n",
      "Epoch 2071\n",
      "-------------------------------\n",
      "loss: 0.283179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396931 \n",
      "\n",
      "Epoch 2072\n",
      "-------------------------------\n",
      "loss: 0.266429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396900 \n",
      "\n",
      "Epoch 2073\n",
      "-------------------------------\n",
      "loss: 0.264929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398052 \n",
      "\n",
      "Epoch 2074\n",
      "-------------------------------\n",
      "loss: 0.260076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400970 \n",
      "\n",
      "Epoch 2075\n",
      "-------------------------------\n",
      "loss: 0.256626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401986 \n",
      "\n",
      "Epoch 2076\n",
      "-------------------------------\n",
      "loss: 0.266295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401529 \n",
      "\n",
      "Epoch 2077\n",
      "-------------------------------\n",
      "loss: 0.268900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400220 \n",
      "\n",
      "Epoch 2078\n",
      "-------------------------------\n",
      "loss: 0.261540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399310 \n",
      "\n",
      "Epoch 2079\n",
      "-------------------------------\n",
      "loss: 0.262442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398688 \n",
      "\n",
      "Epoch 2080\n",
      "-------------------------------\n",
      "loss: 0.280156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397615 \n",
      "\n",
      "Epoch 2081\n",
      "-------------------------------\n",
      "loss: 0.269999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396030 \n",
      "\n",
      "Epoch 2082\n",
      "-------------------------------\n",
      "loss: 0.271173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396129 \n",
      "\n",
      "Epoch 2083\n",
      "-------------------------------\n",
      "loss: 0.252847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397727 \n",
      "\n",
      "Epoch 2084\n",
      "-------------------------------\n",
      "loss: 0.266336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401234 \n",
      "\n",
      "Epoch 2085\n",
      "-------------------------------\n",
      "loss: 0.260389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403476 \n",
      "\n",
      "Epoch 2086\n",
      "-------------------------------\n",
      "loss: 0.273425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402924 \n",
      "\n",
      "Epoch 2087\n",
      "-------------------------------\n",
      "loss: 0.271285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398101 \n",
      "\n",
      "Epoch 2088\n",
      "-------------------------------\n",
      "loss: 0.261705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393531 \n",
      "\n",
      "Epoch 2089\n",
      "-------------------------------\n",
      "loss: 0.274435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393204 \n",
      "\n",
      "Epoch 2090\n",
      "-------------------------------\n",
      "loss: 0.266127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393336 \n",
      "\n",
      "Epoch 2091\n",
      "-------------------------------\n",
      "loss: 0.255559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392330 \n",
      "\n",
      "Epoch 2092\n",
      "-------------------------------\n",
      "loss: 0.264119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393669 \n",
      "\n",
      "Epoch 2093\n",
      "-------------------------------\n",
      "loss: 0.258180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398543 \n",
      "\n",
      "Epoch 2094\n",
      "-------------------------------\n",
      "loss: 0.259465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405306 \n",
      "\n",
      "Epoch 2095\n",
      "-------------------------------\n",
      "loss: 0.294090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408655 \n",
      "\n",
      "Epoch 2096\n",
      "-------------------------------\n",
      "loss: 0.288942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406407 \n",
      "\n",
      "Epoch 2097\n",
      "-------------------------------\n",
      "loss: 0.270548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402060 \n",
      "\n",
      "Epoch 2098\n",
      "-------------------------------\n",
      "loss: 0.267721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400180 \n",
      "\n",
      "Epoch 2099\n",
      "-------------------------------\n",
      "loss: 0.257174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399540 \n",
      "\n",
      "Epoch 2100\n",
      "-------------------------------\n",
      "loss: 0.268583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399415 \n",
      "\n",
      "Epoch 2101\n",
      "-------------------------------\n",
      "loss: 0.269073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399066 \n",
      "\n",
      "Epoch 2102\n",
      "-------------------------------\n",
      "loss: 0.261488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399658 \n",
      "\n",
      "Epoch 2103\n",
      "-------------------------------\n",
      "loss: 0.251672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400133 \n",
      "\n",
      "Epoch 2104\n",
      "-------------------------------\n",
      "loss: 0.263561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398448 \n",
      "\n",
      "Epoch 2105\n",
      "-------------------------------\n",
      "loss: 0.259053  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.395442 \n",
      "\n",
      "Epoch 2106\n",
      "-------------------------------\n",
      "loss: 0.258478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392837 \n",
      "\n",
      "Epoch 2107\n",
      "-------------------------------\n",
      "loss: 0.260701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392997 \n",
      "\n",
      "Epoch 2108\n",
      "-------------------------------\n",
      "loss: 0.267690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394100 \n",
      "\n",
      "Epoch 2109\n",
      "-------------------------------\n",
      "loss: 0.267035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394017 \n",
      "\n",
      "Epoch 2110\n",
      "-------------------------------\n",
      "loss: 0.270616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395201 \n",
      "\n",
      "Epoch 2111\n",
      "-------------------------------\n",
      "loss: 0.260952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397738 \n",
      "\n",
      "Epoch 2112\n",
      "-------------------------------\n",
      "loss: 0.257523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400825 \n",
      "\n",
      "Epoch 2113\n",
      "-------------------------------\n",
      "loss: 0.264605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402386 \n",
      "\n",
      "Epoch 2114\n",
      "-------------------------------\n",
      "loss: 0.264486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400177 \n",
      "\n",
      "Epoch 2115\n",
      "-------------------------------\n",
      "loss: 0.263023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397199 \n",
      "\n",
      "Epoch 2116\n",
      "-------------------------------\n",
      "loss: 0.263056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395074 \n",
      "\n",
      "Epoch 2117\n",
      "-------------------------------\n",
      "loss: 0.271016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394873 \n",
      "\n",
      "Epoch 2118\n",
      "-------------------------------\n",
      "loss: 0.284672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394028 \n",
      "\n",
      "Epoch 2119\n",
      "-------------------------------\n",
      "loss: 0.277949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393733 \n",
      "\n",
      "Epoch 2120\n",
      "-------------------------------\n",
      "loss: 0.275386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395871 \n",
      "\n",
      "Epoch 2121\n",
      "-------------------------------\n",
      "loss: 0.250301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400682 \n",
      "\n",
      "Epoch 2122\n",
      "-------------------------------\n",
      "loss: 0.278657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406456 \n",
      "\n",
      "Epoch 2123\n",
      "-------------------------------\n",
      "loss: 0.287715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408411 \n",
      "\n",
      "Epoch 2124\n",
      "-------------------------------\n",
      "loss: 0.260919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406817 \n",
      "\n",
      "Epoch 2125\n",
      "-------------------------------\n",
      "loss: 0.271634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402718 \n",
      "\n",
      "Epoch 2126\n",
      "-------------------------------\n",
      "loss: 0.270714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399501 \n",
      "\n",
      "Epoch 2127\n",
      "-------------------------------\n",
      "loss: 0.250709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398308 \n",
      "\n",
      "Epoch 2128\n",
      "-------------------------------\n",
      "loss: 0.270032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399732 \n",
      "\n",
      "Epoch 2129\n",
      "-------------------------------\n",
      "loss: 0.269058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401126 \n",
      "\n",
      "Epoch 2130\n",
      "-------------------------------\n",
      "loss: 0.273896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401616 \n",
      "\n",
      "Epoch 2131\n",
      "-------------------------------\n",
      "loss: 0.274379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404170 \n",
      "\n",
      "Epoch 2132\n",
      "-------------------------------\n",
      "loss: 0.268170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406964 \n",
      "\n",
      "Epoch 2133\n",
      "-------------------------------\n",
      "loss: 0.257196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409357 \n",
      "\n",
      "Epoch 2134\n",
      "-------------------------------\n",
      "loss: 0.263269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409870 \n",
      "\n",
      "Epoch 2135\n",
      "-------------------------------\n",
      "loss: 0.252824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406673 \n",
      "\n",
      "Epoch 2136\n",
      "-------------------------------\n",
      "loss: 0.256806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403318 \n",
      "\n",
      "Epoch 2137\n",
      "-------------------------------\n",
      "loss: 0.252465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400984 \n",
      "\n",
      "Epoch 2138\n",
      "-------------------------------\n",
      "loss: 0.263039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400406 \n",
      "\n",
      "Epoch 2139\n",
      "-------------------------------\n",
      "loss: 0.256824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400203 \n",
      "\n",
      "Epoch 2140\n",
      "-------------------------------\n",
      "loss: 0.262900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400679 \n",
      "\n",
      "Epoch 2141\n",
      "-------------------------------\n",
      "loss: 0.258943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403038 \n",
      "\n",
      "Epoch 2142\n",
      "-------------------------------\n",
      "loss: 0.263850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406288 \n",
      "\n",
      "Epoch 2143\n",
      "-------------------------------\n",
      "loss: 0.287915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407334 \n",
      "\n",
      "Epoch 2144\n",
      "-------------------------------\n",
      "loss: 0.255461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405299 \n",
      "\n",
      "Epoch 2145\n",
      "-------------------------------\n",
      "loss: 0.277252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402746 \n",
      "\n",
      "Epoch 2146\n",
      "-------------------------------\n",
      "loss: 0.242386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401600 \n",
      "\n",
      "Epoch 2147\n",
      "-------------------------------\n",
      "loss: 0.254102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401219 \n",
      "\n",
      "Epoch 2148\n",
      "-------------------------------\n",
      "loss: 0.253323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401335 \n",
      "\n",
      "Epoch 2149\n",
      "-------------------------------\n",
      "loss: 0.250983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402117 \n",
      "\n",
      "Epoch 2150\n",
      "-------------------------------\n",
      "loss: 0.253365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401978 \n",
      "\n",
      "Epoch 2151\n",
      "-------------------------------\n",
      "loss: 0.272793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400961 \n",
      "\n",
      "Epoch 2152\n",
      "-------------------------------\n",
      "loss: 0.260765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400990 \n",
      "\n",
      "Epoch 2153\n",
      "-------------------------------\n",
      "loss: 0.237958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404280 \n",
      "\n",
      "Epoch 2154\n",
      "-------------------------------\n",
      "loss: 0.263148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407989 \n",
      "\n",
      "Epoch 2155\n",
      "-------------------------------\n",
      "loss: 0.278724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405398 \n",
      "\n",
      "Epoch 2156\n",
      "-------------------------------\n",
      "loss: 0.245568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400183 \n",
      "\n",
      "Epoch 2157\n",
      "-------------------------------\n",
      "loss: 0.238148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397351 \n",
      "\n",
      "Epoch 2158\n",
      "-------------------------------\n",
      "loss: 0.264219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396510 \n",
      "\n",
      "Epoch 2159\n",
      "-------------------------------\n",
      "loss: 0.269548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397127 \n",
      "\n",
      "Epoch 2160\n",
      "-------------------------------\n",
      "loss: 0.263342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398862 \n",
      "\n",
      "Epoch 2161\n",
      "-------------------------------\n",
      "loss: 0.256342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401590 \n",
      "\n",
      "Epoch 2162\n",
      "-------------------------------\n",
      "loss: 0.270116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402570 \n",
      "\n",
      "Epoch 2163\n",
      "-------------------------------\n",
      "loss: 0.258922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402325 \n",
      "\n",
      "Epoch 2164\n",
      "-------------------------------\n",
      "loss: 0.262337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401182 \n",
      "\n",
      "Epoch 2165\n",
      "-------------------------------\n",
      "loss: 0.251505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401450 \n",
      "\n",
      "Epoch 2166\n",
      "-------------------------------\n",
      "loss: 0.255328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402409 \n",
      "\n",
      "Epoch 2167\n",
      "-------------------------------\n",
      "loss: 0.253030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404422 \n",
      "\n",
      "Epoch 2168\n",
      "-------------------------------\n",
      "loss: 0.252480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407568 \n",
      "\n",
      "Epoch 2169\n",
      "-------------------------------\n",
      "loss: 0.270981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409802 \n",
      "\n",
      "Epoch 2170\n",
      "-------------------------------\n",
      "loss: 0.256708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409827 \n",
      "\n",
      "Epoch 2171\n",
      "-------------------------------\n",
      "loss: 0.271940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408712 \n",
      "\n",
      "Epoch 2172\n",
      "-------------------------------\n",
      "loss: 0.269759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405106 \n",
      "\n",
      "Epoch 2173\n",
      "-------------------------------\n",
      "loss: 0.255147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402103 \n",
      "\n",
      "Epoch 2174\n",
      "-------------------------------\n",
      "loss: 0.270008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401078 \n",
      "\n",
      "Epoch 2175\n",
      "-------------------------------\n",
      "loss: 0.256389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 2176\n",
      "-------------------------------\n",
      "loss: 0.262308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403301 \n",
      "\n",
      "Epoch 2177\n",
      "-------------------------------\n",
      "loss: 0.252892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405086 \n",
      "\n",
      "Epoch 2178\n",
      "-------------------------------\n",
      "loss: 0.257873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405323 \n",
      "\n",
      "Epoch 2179\n",
      "-------------------------------\n",
      "loss: 0.247570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404475 \n",
      "\n",
      "Epoch 2180\n",
      "-------------------------------\n",
      "loss: 0.252307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402728 \n",
      "\n",
      "Epoch 2181\n",
      "-------------------------------\n",
      "loss: 0.250147  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400987 \n",
      "\n",
      "Epoch 2182\n",
      "-------------------------------\n",
      "loss: 0.252167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399246 \n",
      "\n",
      "Epoch 2183\n",
      "-------------------------------\n",
      "loss: 0.254615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399569 \n",
      "\n",
      "Epoch 2184\n",
      "-------------------------------\n",
      "loss: 0.267163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400492 \n",
      "\n",
      "Epoch 2185\n",
      "-------------------------------\n",
      "loss: 0.261386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400235 \n",
      "\n",
      "Epoch 2186\n",
      "-------------------------------\n",
      "loss: 0.269975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400001 \n",
      "\n",
      "Epoch 2187\n",
      "-------------------------------\n",
      "loss: 0.273577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399453 \n",
      "\n",
      "Epoch 2188\n",
      "-------------------------------\n",
      "loss: 0.258904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399414 \n",
      "\n",
      "Epoch 2189\n",
      "-------------------------------\n",
      "loss: 0.259476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401493 \n",
      "\n",
      "Epoch 2190\n",
      "-------------------------------\n",
      "loss: 0.249967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402541 \n",
      "\n",
      "Epoch 2191\n",
      "-------------------------------\n",
      "loss: 0.266096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403395 \n",
      "\n",
      "Epoch 2192\n",
      "-------------------------------\n",
      "loss: 0.257519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403042 \n",
      "\n",
      "Epoch 2193\n",
      "-------------------------------\n",
      "loss: 0.247276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401821 \n",
      "\n",
      "Epoch 2194\n",
      "-------------------------------\n",
      "loss: 0.256975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400090 \n",
      "\n",
      "Epoch 2195\n",
      "-------------------------------\n",
      "loss: 0.276945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398376 \n",
      "\n",
      "Epoch 2196\n",
      "-------------------------------\n",
      "loss: 0.245825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396847 \n",
      "\n",
      "Epoch 2197\n",
      "-------------------------------\n",
      "loss: 0.253369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396677 \n",
      "\n",
      "Epoch 2198\n",
      "-------------------------------\n",
      "loss: 0.259630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397840 \n",
      "\n",
      "Epoch 2199\n",
      "-------------------------------\n",
      "loss: 0.271107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400484 \n",
      "\n",
      "Epoch 2200\n",
      "-------------------------------\n",
      "loss: 0.254039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406219 \n",
      "\n",
      "Epoch 2201\n",
      "-------------------------------\n",
      "loss: 0.271945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409568 \n",
      "\n",
      "Epoch 2202\n",
      "-------------------------------\n",
      "loss: 0.254503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406381 \n",
      "\n",
      "Epoch 2203\n",
      "-------------------------------\n",
      "loss: 0.261569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400431 \n",
      "\n",
      "Epoch 2204\n",
      "-------------------------------\n",
      "loss: 0.246253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396369 \n",
      "\n",
      "Epoch 2205\n",
      "-------------------------------\n",
      "loss: 0.263050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395173 \n",
      "\n",
      "Epoch 2206\n",
      "-------------------------------\n",
      "loss: 0.242715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395416 \n",
      "\n",
      "Epoch 2207\n",
      "-------------------------------\n",
      "loss: 0.264989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395346 \n",
      "\n",
      "Epoch 2208\n",
      "-------------------------------\n",
      "loss: 0.261086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395433 \n",
      "\n",
      "Epoch 2209\n",
      "-------------------------------\n",
      "loss: 0.259834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394725 \n",
      "\n",
      "Epoch 2210\n",
      "-------------------------------\n",
      "loss: 0.254918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395078 \n",
      "\n",
      "Epoch 2211\n",
      "-------------------------------\n",
      "loss: 0.256820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396442 \n",
      "\n",
      "Epoch 2212\n",
      "-------------------------------\n",
      "loss: 0.254714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398986 \n",
      "\n",
      "Epoch 2213\n",
      "-------------------------------\n",
      "loss: 0.257557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400205 \n",
      "\n",
      "Epoch 2214\n",
      "-------------------------------\n",
      "loss: 0.281221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399637 \n",
      "\n",
      "Epoch 2215\n",
      "-------------------------------\n",
      "loss: 0.250807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399774 \n",
      "\n",
      "Epoch 2216\n",
      "-------------------------------\n",
      "loss: 0.250048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402447 \n",
      "\n",
      "Epoch 2217\n",
      "-------------------------------\n",
      "loss: 0.255205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403074 \n",
      "\n",
      "Epoch 2218\n",
      "-------------------------------\n",
      "loss: 0.259019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402027 \n",
      "\n",
      "Epoch 2219\n",
      "-------------------------------\n",
      "loss: 0.267002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400309 \n",
      "\n",
      "Epoch 2220\n",
      "-------------------------------\n",
      "loss: 0.257011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400171 \n",
      "\n",
      "Epoch 2221\n",
      "-------------------------------\n",
      "loss: 0.255505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401345 \n",
      "\n",
      "Epoch 2222\n",
      "-------------------------------\n",
      "loss: 0.242781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402750 \n",
      "\n",
      "Epoch 2223\n",
      "-------------------------------\n",
      "loss: 0.254665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403367 \n",
      "\n",
      "Epoch 2224\n",
      "-------------------------------\n",
      "loss: 0.268250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401613 \n",
      "\n",
      "Epoch 2225\n",
      "-------------------------------\n",
      "loss: 0.262491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399939 \n",
      "\n",
      "Epoch 2226\n",
      "-------------------------------\n",
      "loss: 0.277700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398258 \n",
      "\n",
      "Epoch 2227\n",
      "-------------------------------\n",
      "loss: 0.257653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396670 \n",
      "\n",
      "Epoch 2228\n",
      "-------------------------------\n",
      "loss: 0.252063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396265 \n",
      "\n",
      "Epoch 2229\n",
      "-------------------------------\n",
      "loss: 0.275118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396302 \n",
      "\n",
      "Epoch 2230\n",
      "-------------------------------\n",
      "loss: 0.257343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398992 \n",
      "\n",
      "Epoch 2231\n",
      "-------------------------------\n",
      "loss: 0.273151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399527 \n",
      "\n",
      "Epoch 2232\n",
      "-------------------------------\n",
      "loss: 0.256953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397405 \n",
      "\n",
      "Epoch 2233\n",
      "-------------------------------\n",
      "loss: 0.264478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394965 \n",
      "\n",
      "Epoch 2234\n",
      "-------------------------------\n",
      "loss: 0.249122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394253 \n",
      "\n",
      "Epoch 2235\n",
      "-------------------------------\n",
      "loss: 0.243229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394232 \n",
      "\n",
      "Epoch 2236\n",
      "-------------------------------\n",
      "loss: 0.246663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394689 \n",
      "\n",
      "Epoch 2237\n",
      "-------------------------------\n",
      "loss: 0.252848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396346 \n",
      "\n",
      "Epoch 2238\n",
      "-------------------------------\n",
      "loss: 0.243288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399329 \n",
      "\n",
      "Epoch 2239\n",
      "-------------------------------\n",
      "loss: 0.260809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402774 \n",
      "\n",
      "Epoch 2240\n",
      "-------------------------------\n",
      "loss: 0.268221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401903 \n",
      "\n",
      "Epoch 2241\n",
      "-------------------------------\n",
      "loss: 0.266289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399349 \n",
      "\n",
      "Epoch 2242\n",
      "-------------------------------\n",
      "loss: 0.237458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396918 \n",
      "\n",
      "Epoch 2243\n",
      "-------------------------------\n",
      "loss: 0.268229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395215 \n",
      "\n",
      "Epoch 2244\n",
      "-------------------------------\n",
      "loss: 0.254586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394728 \n",
      "\n",
      "Epoch 2245\n",
      "-------------------------------\n",
      "loss: 0.262618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395036 \n",
      "\n",
      "Epoch 2246\n",
      "-------------------------------\n",
      "loss: 0.247920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396251 \n",
      "\n",
      "Epoch 2247\n",
      "-------------------------------\n",
      "loss: 0.263427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397789 \n",
      "\n",
      "Epoch 2248\n",
      "-------------------------------\n",
      "loss: 0.276488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397572 \n",
      "\n",
      "Epoch 2249\n",
      "-------------------------------\n",
      "loss: 0.283189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395762 \n",
      "\n",
      "Epoch 2250\n",
      "-------------------------------\n",
      "loss: 0.276141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393869 \n",
      "\n",
      "Epoch 2251\n",
      "-------------------------------\n",
      "loss: 0.241155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394435 \n",
      "\n",
      "Epoch 2252\n",
      "-------------------------------\n",
      "loss: 0.259835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395881 \n",
      "\n",
      "Epoch 2253\n",
      "-------------------------------\n",
      "loss: 0.269784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397562 \n",
      "\n",
      "Epoch 2254\n",
      "-------------------------------\n",
      "loss: 0.246341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399523 \n",
      "\n",
      "Epoch 2255\n",
      "-------------------------------\n",
      "loss: 0.272785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399988 \n",
      "\n",
      "Epoch 2256\n",
      "-------------------------------\n",
      "loss: 0.262711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398202 \n",
      "\n",
      "Epoch 2257\n",
      "-------------------------------\n",
      "loss: 0.253257  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397800 \n",
      "\n",
      "Epoch 2258\n",
      "-------------------------------\n",
      "loss: 0.247635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398419 \n",
      "\n",
      "Epoch 2259\n",
      "-------------------------------\n",
      "loss: 0.254776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400044 \n",
      "\n",
      "Epoch 2260\n",
      "-------------------------------\n",
      "loss: 0.256044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400025 \n",
      "\n",
      "Epoch 2261\n",
      "-------------------------------\n",
      "loss: 0.243362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399543 \n",
      "\n",
      "Epoch 2262\n",
      "-------------------------------\n",
      "loss: 0.257871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399824 \n",
      "\n",
      "Epoch 2263\n",
      "-------------------------------\n",
      "loss: 0.248104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400684 \n",
      "\n",
      "Epoch 2264\n",
      "-------------------------------\n",
      "loss: 0.255875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401918 \n",
      "\n",
      "Epoch 2265\n",
      "-------------------------------\n",
      "loss: 0.259803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403538 \n",
      "\n",
      "Epoch 2266\n",
      "-------------------------------\n",
      "loss: 0.270014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405300 \n",
      "\n",
      "Epoch 2267\n",
      "-------------------------------\n",
      "loss: 0.246306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407345 \n",
      "\n",
      "Epoch 2268\n",
      "-------------------------------\n",
      "loss: 0.272313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407419 \n",
      "\n",
      "Epoch 2269\n",
      "-------------------------------\n",
      "loss: 0.257311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406499 \n",
      "\n",
      "Epoch 2270\n",
      "-------------------------------\n",
      "loss: 0.264532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404489 \n",
      "\n",
      "Epoch 2271\n",
      "-------------------------------\n",
      "loss: 0.261588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402276 \n",
      "\n",
      "Epoch 2272\n",
      "-------------------------------\n",
      "loss: 0.253228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401127 \n",
      "\n",
      "Epoch 2273\n",
      "-------------------------------\n",
      "loss: 0.244167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401474 \n",
      "\n",
      "Epoch 2274\n",
      "-------------------------------\n",
      "loss: 0.259652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402367 \n",
      "\n",
      "Epoch 2275\n",
      "-------------------------------\n",
      "loss: 0.255601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404148 \n",
      "\n",
      "Epoch 2276\n",
      "-------------------------------\n",
      "loss: 0.254601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407697 \n",
      "\n",
      "Epoch 2277\n",
      "-------------------------------\n",
      "loss: 0.258284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409293 \n",
      "\n",
      "Epoch 2278\n",
      "-------------------------------\n",
      "loss: 0.247762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408630 \n",
      "\n",
      "Epoch 2279\n",
      "-------------------------------\n",
      "loss: 0.241535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407321 \n",
      "\n",
      "Epoch 2280\n",
      "-------------------------------\n",
      "loss: 0.245734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405891 \n",
      "\n",
      "Epoch 2281\n",
      "-------------------------------\n",
      "loss: 0.256985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403913 \n",
      "\n",
      "Epoch 2282\n",
      "-------------------------------\n",
      "loss: 0.252559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401747 \n",
      "\n",
      "Epoch 2283\n",
      "-------------------------------\n",
      "loss: 0.263796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400113 \n",
      "\n",
      "Epoch 2284\n",
      "-------------------------------\n",
      "loss: 0.260055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399387 \n",
      "\n",
      "Epoch 2285\n",
      "-------------------------------\n",
      "loss: 0.253233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399541 \n",
      "\n",
      "Epoch 2286\n",
      "-------------------------------\n",
      "loss: 0.250932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399919 \n",
      "\n",
      "Epoch 2287\n",
      "-------------------------------\n",
      "loss: 0.260293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399626 \n",
      "\n",
      "Epoch 2288\n",
      "-------------------------------\n",
      "loss: 0.258606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399369 \n",
      "\n",
      "Epoch 2289\n",
      "-------------------------------\n",
      "loss: 0.242154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398769 \n",
      "\n",
      "Epoch 2290\n",
      "-------------------------------\n",
      "loss: 0.278227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399283 \n",
      "\n",
      "Epoch 2291\n",
      "-------------------------------\n",
      "loss: 0.250732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398538 \n",
      "\n",
      "Epoch 2292\n",
      "-------------------------------\n",
      "loss: 0.263104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399672 \n",
      "\n",
      "Epoch 2293\n",
      "-------------------------------\n",
      "loss: 0.259243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403202 \n",
      "\n",
      "Epoch 2294\n",
      "-------------------------------\n",
      "loss: 0.263528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407659 \n",
      "\n",
      "Epoch 2295\n",
      "-------------------------------\n",
      "loss: 0.264801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411054 \n",
      "\n",
      "Epoch 2296\n",
      "-------------------------------\n",
      "loss: 0.252732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411071 \n",
      "\n",
      "Epoch 2297\n",
      "-------------------------------\n",
      "loss: 0.258026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409130 \n",
      "\n",
      "Epoch 2298\n",
      "-------------------------------\n",
      "loss: 0.278634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404395 \n",
      "\n",
      "Epoch 2299\n",
      "-------------------------------\n",
      "loss: 0.245389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402151 \n",
      "\n",
      "Epoch 2300\n",
      "-------------------------------\n",
      "loss: 0.267292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402201 \n",
      "\n",
      "Epoch 2301\n",
      "-------------------------------\n",
      "loss: 0.268154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402090 \n",
      "\n",
      "Epoch 2302\n",
      "-------------------------------\n",
      "loss: 0.259082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401315 \n",
      "\n",
      "Epoch 2303\n",
      "-------------------------------\n",
      "loss: 0.251529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403189 \n",
      "\n",
      "Epoch 2304\n",
      "-------------------------------\n",
      "loss: 0.250054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407419 \n",
      "\n",
      "Epoch 2305\n",
      "-------------------------------\n",
      "loss: 0.257643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410971 \n",
      "\n",
      "Epoch 2306\n",
      "-------------------------------\n",
      "loss: 0.249689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412042 \n",
      "\n",
      "Epoch 2307\n",
      "-------------------------------\n",
      "loss: 0.241480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408628 \n",
      "\n",
      "Epoch 2308\n",
      "-------------------------------\n",
      "loss: 0.246452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405287 \n",
      "\n",
      "Epoch 2309\n",
      "-------------------------------\n",
      "loss: 0.264201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402631 \n",
      "\n",
      "Epoch 2310\n",
      "-------------------------------\n",
      "loss: 0.257609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401582 \n",
      "\n",
      "Epoch 2311\n",
      "-------------------------------\n",
      "loss: 0.254930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401361 \n",
      "\n",
      "Epoch 2312\n",
      "-------------------------------\n",
      "loss: 0.273838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401289 \n",
      "\n",
      "Epoch 2313\n",
      "-------------------------------\n",
      "loss: 0.267745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401180 \n",
      "\n",
      "Epoch 2314\n",
      "-------------------------------\n",
      "loss: 0.256169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401860 \n",
      "\n",
      "Epoch 2315\n",
      "-------------------------------\n",
      "loss: 0.267990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403033 \n",
      "\n",
      "Epoch 2316\n",
      "-------------------------------\n",
      "loss: 0.271003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403389 \n",
      "\n",
      "Epoch 2317\n",
      "-------------------------------\n",
      "loss: 0.248431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404055 \n",
      "\n",
      "Epoch 2318\n",
      "-------------------------------\n",
      "loss: 0.259955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402319 \n",
      "\n",
      "Epoch 2319\n",
      "-------------------------------\n",
      "loss: 0.269506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398482 \n",
      "\n",
      "Epoch 2320\n",
      "-------------------------------\n",
      "loss: 0.250153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398050 \n",
      "\n",
      "Epoch 2321\n",
      "-------------------------------\n",
      "loss: 0.253447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399714 \n",
      "\n",
      "Epoch 2322\n",
      "-------------------------------\n",
      "loss: 0.262890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400510 \n",
      "\n",
      "Epoch 2323\n",
      "-------------------------------\n",
      "loss: 0.259778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400569 \n",
      "\n",
      "Epoch 2324\n",
      "-------------------------------\n",
      "loss: 0.253903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400660 \n",
      "\n",
      "Epoch 2325\n",
      "-------------------------------\n",
      "loss: 0.252020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400765 \n",
      "\n",
      "Epoch 2326\n",
      "-------------------------------\n",
      "loss: 0.250111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402075 \n",
      "\n",
      "Epoch 2327\n",
      "-------------------------------\n",
      "loss: 0.243008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404435 \n",
      "\n",
      "Epoch 2328\n",
      "-------------------------------\n",
      "loss: 0.258487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406861 \n",
      "\n",
      "Epoch 2329\n",
      "-------------------------------\n",
      "loss: 0.261210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407143 \n",
      "\n",
      "Epoch 2330\n",
      "-------------------------------\n",
      "loss: 0.262964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404344 \n",
      "\n",
      "Epoch 2331\n",
      "-------------------------------\n",
      "loss: 0.257424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401433 \n",
      "\n",
      "Epoch 2332\n",
      "-------------------------------\n",
      "loss: 0.252162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400900 \n",
      "\n",
      "Epoch 2333\n",
      "-------------------------------\n",
      "loss: 0.246696  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400844 \n",
      "\n",
      "Epoch 2334\n",
      "-------------------------------\n",
      "loss: 0.247566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402057 \n",
      "\n",
      "Epoch 2335\n",
      "-------------------------------\n",
      "loss: 0.255038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405318 \n",
      "\n",
      "Epoch 2336\n",
      "-------------------------------\n",
      "loss: 0.261471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408002 \n",
      "\n",
      "Epoch 2337\n",
      "-------------------------------\n",
      "loss: 0.265803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405396 \n",
      "\n",
      "Epoch 2338\n",
      "-------------------------------\n",
      "loss: 0.261696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401691 \n",
      "\n",
      "Epoch 2339\n",
      "-------------------------------\n",
      "loss: 0.249378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400497 \n",
      "\n",
      "Epoch 2340\n",
      "-------------------------------\n",
      "loss: 0.256676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400197 \n",
      "\n",
      "Epoch 2341\n",
      "-------------------------------\n",
      "loss: 0.266766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399526 \n",
      "\n",
      "Epoch 2342\n",
      "-------------------------------\n",
      "loss: 0.244024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398767 \n",
      "\n",
      "Epoch 2343\n",
      "-------------------------------\n",
      "loss: 0.260121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398492 \n",
      "\n",
      "Epoch 2344\n",
      "-------------------------------\n",
      "loss: 0.263344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398858 \n",
      "\n",
      "Epoch 2345\n",
      "-------------------------------\n",
      "loss: 0.250447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400268 \n",
      "\n",
      "Epoch 2346\n",
      "-------------------------------\n",
      "loss: 0.249516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401582 \n",
      "\n",
      "Epoch 2347\n",
      "-------------------------------\n",
      "loss: 0.247968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401852 \n",
      "\n",
      "Epoch 2348\n",
      "-------------------------------\n",
      "loss: 0.241871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400598 \n",
      "\n",
      "Epoch 2349\n",
      "-------------------------------\n",
      "loss: 0.253903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398604 \n",
      "\n",
      "Epoch 2350\n",
      "-------------------------------\n",
      "loss: 0.258176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398828 \n",
      "\n",
      "Epoch 2351\n",
      "-------------------------------\n",
      "loss: 0.257425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398475 \n",
      "\n",
      "Epoch 2352\n",
      "-------------------------------\n",
      "loss: 0.251307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397111 \n",
      "\n",
      "Epoch 2353\n",
      "-------------------------------\n",
      "loss: 0.251408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396261 \n",
      "\n",
      "Epoch 2354\n",
      "-------------------------------\n",
      "loss: 0.236633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395878 \n",
      "\n",
      "Epoch 2355\n",
      "-------------------------------\n",
      "loss: 0.243110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396257 \n",
      "\n",
      "Epoch 2356\n",
      "-------------------------------\n",
      "loss: 0.252584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395794 \n",
      "\n",
      "Epoch 2357\n",
      "-------------------------------\n",
      "loss: 0.247361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396288 \n",
      "\n",
      "Epoch 2358\n",
      "-------------------------------\n",
      "loss: 0.253140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397086 \n",
      "\n",
      "Epoch 2359\n",
      "-------------------------------\n",
      "loss: 0.264273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397871 \n",
      "\n",
      "Epoch 2360\n",
      "-------------------------------\n",
      "loss: 0.245738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399397 \n",
      "\n",
      "Epoch 2361\n",
      "-------------------------------\n",
      "loss: 0.256939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400768 \n",
      "\n",
      "Epoch 2362\n",
      "-------------------------------\n",
      "loss: 0.263402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400910 \n",
      "\n",
      "Epoch 2363\n",
      "-------------------------------\n",
      "loss: 0.242127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400546 \n",
      "\n",
      "Epoch 2364\n",
      "-------------------------------\n",
      "loss: 0.267090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400290 \n",
      "\n",
      "Epoch 2365\n",
      "-------------------------------\n",
      "loss: 0.258386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399983 \n",
      "\n",
      "Epoch 2366\n",
      "-------------------------------\n",
      "loss: 0.259555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400480 \n",
      "\n",
      "Epoch 2367\n",
      "-------------------------------\n",
      "loss: 0.268458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399835 \n",
      "\n",
      "Epoch 2368\n",
      "-------------------------------\n",
      "loss: 0.247144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398971 \n",
      "\n",
      "Epoch 2369\n",
      "-------------------------------\n",
      "loss: 0.247975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398995 \n",
      "\n",
      "Epoch 2370\n",
      "-------------------------------\n",
      "loss: 0.272226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398464 \n",
      "\n",
      "Epoch 2371\n",
      "-------------------------------\n",
      "loss: 0.249544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397460 \n",
      "\n",
      "Epoch 2372\n",
      "-------------------------------\n",
      "loss: 0.253681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395920 \n",
      "\n",
      "Epoch 2373\n",
      "-------------------------------\n",
      "loss: 0.251473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395818 \n",
      "\n",
      "Epoch 2374\n",
      "-------------------------------\n",
      "loss: 0.266286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398436 \n",
      "\n",
      "Epoch 2375\n",
      "-------------------------------\n",
      "loss: 0.263796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402183 \n",
      "\n",
      "Epoch 2376\n",
      "-------------------------------\n",
      "loss: 0.262969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403810 \n",
      "\n",
      "Epoch 2377\n",
      "-------------------------------\n",
      "loss: 0.257257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401248 \n",
      "\n",
      "Epoch 2378\n",
      "-------------------------------\n",
      "loss: 0.256561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398514 \n",
      "\n",
      "Epoch 2379\n",
      "-------------------------------\n",
      "loss: 0.264490  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397219 \n",
      "\n",
      "Epoch 2380\n",
      "-------------------------------\n",
      "loss: 0.262840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397814 \n",
      "\n",
      "Epoch 2381\n",
      "-------------------------------\n",
      "loss: 0.249166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399702 \n",
      "\n",
      "Epoch 2382\n",
      "-------------------------------\n",
      "loss: 0.274538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399284 \n",
      "\n",
      "Epoch 2383\n",
      "-------------------------------\n",
      "loss: 0.262511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399022 \n",
      "\n",
      "Epoch 2384\n",
      "-------------------------------\n",
      "loss: 0.262013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399252 \n",
      "\n",
      "Epoch 2385\n",
      "-------------------------------\n",
      "loss: 0.246882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401433 \n",
      "\n",
      "Epoch 2386\n",
      "-------------------------------\n",
      "loss: 0.260006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401960 \n",
      "\n",
      "Epoch 2387\n",
      "-------------------------------\n",
      "loss: 0.258141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401470 \n",
      "\n",
      "Epoch 2388\n",
      "-------------------------------\n",
      "loss: 0.243119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400115 \n",
      "\n",
      "Epoch 2389\n",
      "-------------------------------\n",
      "loss: 0.261412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398472 \n",
      "\n",
      "Epoch 2390\n",
      "-------------------------------\n",
      "loss: 0.254395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397380 \n",
      "\n",
      "Epoch 2391\n",
      "-------------------------------\n",
      "loss: 0.250085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396810 \n",
      "\n",
      "Epoch 2392\n",
      "-------------------------------\n",
      "loss: 0.256451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397477 \n",
      "\n",
      "Epoch 2393\n",
      "-------------------------------\n",
      "loss: 0.248895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398662 \n",
      "\n",
      "Epoch 2394\n",
      "-------------------------------\n",
      "loss: 0.245820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400355 \n",
      "\n",
      "Epoch 2395\n",
      "-------------------------------\n",
      "loss: 0.251984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401786 \n",
      "\n",
      "Epoch 2396\n",
      "-------------------------------\n",
      "loss: 0.253361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402120 \n",
      "\n",
      "Epoch 2397\n",
      "-------------------------------\n",
      "loss: 0.245584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401591 \n",
      "\n",
      "Epoch 2398\n",
      "-------------------------------\n",
      "loss: 0.261644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399693 \n",
      "\n",
      "Epoch 2399\n",
      "-------------------------------\n",
      "loss: 0.265590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396424 \n",
      "\n",
      "Epoch 2400\n",
      "-------------------------------\n",
      "loss: 0.266102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395203 \n",
      "\n",
      "Epoch 2401\n",
      "-------------------------------\n",
      "loss: 0.252529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395890 \n",
      "\n",
      "Epoch 2402\n",
      "-------------------------------\n",
      "loss: 0.259427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398352 \n",
      "\n",
      "Epoch 2403\n",
      "-------------------------------\n",
      "loss: 0.259854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401759 \n",
      "\n",
      "Epoch 2404\n",
      "-------------------------------\n",
      "loss: 0.250591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405330 \n",
      "\n",
      "Epoch 2405\n",
      "-------------------------------\n",
      "loss: 0.258475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406914 \n",
      "\n",
      "Epoch 2406\n",
      "-------------------------------\n",
      "loss: 0.267376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405625 \n",
      "\n",
      "Epoch 2407\n",
      "-------------------------------\n",
      "loss: 0.268994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401611 \n",
      "\n",
      "Epoch 2408\n",
      "-------------------------------\n",
      "loss: 0.248001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398130 \n",
      "\n",
      "Epoch 2409\n",
      "-------------------------------\n",
      "loss: 0.240412  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397223 \n",
      "\n",
      "Epoch 2410\n",
      "-------------------------------\n",
      "loss: 0.250395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398274 \n",
      "\n",
      "Epoch 2411\n",
      "-------------------------------\n",
      "loss: 0.260618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399633 \n",
      "\n",
      "Epoch 2412\n",
      "-------------------------------\n",
      "loss: 0.251715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401263 \n",
      "\n",
      "Epoch 2413\n",
      "-------------------------------\n",
      "loss: 0.250565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402462 \n",
      "\n",
      "Epoch 2414\n",
      "-------------------------------\n",
      "loss: 0.238159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403011 \n",
      "\n",
      "Epoch 2415\n",
      "-------------------------------\n",
      "loss: 0.261104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404718 \n",
      "\n",
      "Epoch 2416\n",
      "-------------------------------\n",
      "loss: 0.241596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404833 \n",
      "\n",
      "Epoch 2417\n",
      "-------------------------------\n",
      "loss: 0.260333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404053 \n",
      "\n",
      "Epoch 2418\n",
      "-------------------------------\n",
      "loss: 0.249498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402932 \n",
      "\n",
      "Epoch 2419\n",
      "-------------------------------\n",
      "loss: 0.252636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401878 \n",
      "\n",
      "Epoch 2420\n",
      "-------------------------------\n",
      "loss: 0.267317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400559 \n",
      "\n",
      "Epoch 2421\n",
      "-------------------------------\n",
      "loss: 0.262258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399968 \n",
      "\n",
      "Epoch 2422\n",
      "-------------------------------\n",
      "loss: 0.258021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401308 \n",
      "\n",
      "Epoch 2423\n",
      "-------------------------------\n",
      "loss: 0.245159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401706 \n",
      "\n",
      "Epoch 2424\n",
      "-------------------------------\n",
      "loss: 0.272628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398627 \n",
      "\n",
      "Epoch 2425\n",
      "-------------------------------\n",
      "loss: 0.262064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396803 \n",
      "\n",
      "Epoch 2426\n",
      "-------------------------------\n",
      "loss: 0.259773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397950 \n",
      "\n",
      "Epoch 2427\n",
      "-------------------------------\n",
      "loss: 0.255443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399304 \n",
      "\n",
      "Epoch 2428\n",
      "-------------------------------\n",
      "loss: 0.255964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398501 \n",
      "\n",
      "Epoch 2429\n",
      "-------------------------------\n",
      "loss: 0.266898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398061 \n",
      "\n",
      "Epoch 2430\n",
      "-------------------------------\n",
      "loss: 0.263691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402381 \n",
      "\n",
      "Epoch 2431\n",
      "-------------------------------\n",
      "loss: 0.249908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409928 \n",
      "\n",
      "Epoch 2432\n",
      "-------------------------------\n",
      "loss: 0.264140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413700 \n",
      "\n",
      "Epoch 2433\n",
      "-------------------------------\n",
      "loss: 0.251666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411134 \n",
      "\n",
      "Epoch 2434\n",
      "-------------------------------\n",
      "loss: 0.249971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405782 \n",
      "\n",
      "Epoch 2435\n",
      "-------------------------------\n",
      "loss: 0.270659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402989 \n",
      "\n",
      "Epoch 2436\n",
      "-------------------------------\n",
      "loss: 0.260146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403122 \n",
      "\n",
      "Epoch 2437\n",
      "-------------------------------\n",
      "loss: 0.254000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403203 \n",
      "\n",
      "Epoch 2438\n",
      "-------------------------------\n",
      "loss: 0.265907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403912 \n",
      "\n",
      "Epoch 2439\n",
      "-------------------------------\n",
      "loss: 0.243137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406453 \n",
      "\n",
      "Epoch 2440\n",
      "-------------------------------\n",
      "loss: 0.224755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411732 \n",
      "\n",
      "Epoch 2441\n",
      "-------------------------------\n",
      "loss: 0.258797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413567 \n",
      "\n",
      "Epoch 2442\n",
      "-------------------------------\n",
      "loss: 0.279948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409146 \n",
      "\n",
      "Epoch 2443\n",
      "-------------------------------\n",
      "loss: 0.245741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402992 \n",
      "\n",
      "Epoch 2444\n",
      "-------------------------------\n",
      "loss: 0.265693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398998 \n",
      "\n",
      "Epoch 2445\n",
      "-------------------------------\n",
      "loss: 0.268112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397791 \n",
      "\n",
      "Epoch 2446\n",
      "-------------------------------\n",
      "loss: 0.260115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397719 \n",
      "\n",
      "Epoch 2447\n",
      "-------------------------------\n",
      "loss: 0.266665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397510 \n",
      "\n",
      "Epoch 2448\n",
      "-------------------------------\n",
      "loss: 0.262496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399983 \n",
      "\n",
      "Epoch 2449\n",
      "-------------------------------\n",
      "loss: 0.243494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404748 \n",
      "\n",
      "Epoch 2450\n",
      "-------------------------------\n",
      "loss: 0.248419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406623 \n",
      "\n",
      "Epoch 2451\n",
      "-------------------------------\n",
      "loss: 0.243034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406168 \n",
      "\n",
      "Epoch 2452\n",
      "-------------------------------\n",
      "loss: 0.258430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406116 \n",
      "\n",
      "Epoch 2453\n",
      "-------------------------------\n",
      "loss: 0.241477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404340 \n",
      "\n",
      "Epoch 2454\n",
      "-------------------------------\n",
      "loss: 0.245130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402081 \n",
      "\n",
      "Epoch 2455\n",
      "-------------------------------\n",
      "loss: 0.237819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400783 \n",
      "\n",
      "Epoch 2456\n",
      "-------------------------------\n",
      "loss: 0.247488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400512 \n",
      "\n",
      "Epoch 2457\n",
      "-------------------------------\n",
      "loss: 0.256145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400620 \n",
      "\n",
      "Epoch 2458\n",
      "-------------------------------\n",
      "loss: 0.247507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401335 \n",
      "\n",
      "Epoch 2459\n",
      "-------------------------------\n",
      "loss: 0.243056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402048 \n",
      "\n",
      "Epoch 2460\n",
      "-------------------------------\n",
      "loss: 0.245924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401719 \n",
      "\n",
      "Epoch 2461\n",
      "-------------------------------\n",
      "loss: 0.268132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400764 \n",
      "\n",
      "Epoch 2462\n",
      "-------------------------------\n",
      "loss: 0.244660  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400257 \n",
      "\n",
      "Epoch 2463\n",
      "-------------------------------\n",
      "loss: 0.249349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399722 \n",
      "\n",
      "Epoch 2464\n",
      "-------------------------------\n",
      "loss: 0.261116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399704 \n",
      "\n",
      "Epoch 2465\n",
      "-------------------------------\n",
      "loss: 0.263568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399771 \n",
      "\n",
      "Epoch 2466\n",
      "-------------------------------\n",
      "loss: 0.238959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400309 \n",
      "\n",
      "Epoch 2467\n",
      "-------------------------------\n",
      "loss: 0.262928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401379 \n",
      "\n",
      "Epoch 2468\n",
      "-------------------------------\n",
      "loss: 0.245491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400988 \n",
      "\n",
      "Epoch 2469\n",
      "-------------------------------\n",
      "loss: 0.238477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400935 \n",
      "\n",
      "Epoch 2470\n",
      "-------------------------------\n",
      "loss: 0.249215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401435 \n",
      "\n",
      "Epoch 2471\n",
      "-------------------------------\n",
      "loss: 0.246792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402022 \n",
      "\n",
      "Epoch 2472\n",
      "-------------------------------\n",
      "loss: 0.256659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401734 \n",
      "\n",
      "Epoch 2473\n",
      "-------------------------------\n",
      "loss: 0.269334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399681 \n",
      "\n",
      "Epoch 2474\n",
      "-------------------------------\n",
      "loss: 0.235359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399157 \n",
      "\n",
      "Epoch 2475\n",
      "-------------------------------\n",
      "loss: 0.244474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400046 \n",
      "\n",
      "Epoch 2476\n",
      "-------------------------------\n",
      "loss: 0.253176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400817 \n",
      "\n",
      "Epoch 2477\n",
      "-------------------------------\n",
      "loss: 0.260526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400800 \n",
      "\n",
      "Epoch 2478\n",
      "-------------------------------\n",
      "loss: 0.249526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400359 \n",
      "\n",
      "Epoch 2479\n",
      "-------------------------------\n",
      "loss: 0.252957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402028 \n",
      "\n",
      "Epoch 2480\n",
      "-------------------------------\n",
      "loss: 0.245819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404795 \n",
      "\n",
      "Epoch 2481\n",
      "-------------------------------\n",
      "loss: 0.248745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405208 \n",
      "\n",
      "Epoch 2482\n",
      "-------------------------------\n",
      "loss: 0.257157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404928 \n",
      "\n",
      "Epoch 2483\n",
      "-------------------------------\n",
      "loss: 0.230382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404333 \n",
      "\n",
      "Epoch 2484\n",
      "-------------------------------\n",
      "loss: 0.244984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401493 \n",
      "\n",
      "Epoch 2485\n",
      "-------------------------------\n",
      "loss: 0.239774  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399795 \n",
      "\n",
      "Epoch 2486\n",
      "-------------------------------\n",
      "loss: 0.256813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399704 \n",
      "\n",
      "Epoch 2487\n",
      "-------------------------------\n",
      "loss: 0.245900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399786 \n",
      "\n",
      "Epoch 2488\n",
      "-------------------------------\n",
      "loss: 0.263775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399200 \n",
      "\n",
      "Epoch 2489\n",
      "-------------------------------\n",
      "loss: 0.258765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399810 \n",
      "\n",
      "Epoch 2490\n",
      "-------------------------------\n",
      "loss: 0.235445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402971 \n",
      "\n",
      "Epoch 2491\n",
      "-------------------------------\n",
      "loss: 0.256278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405656 \n",
      "\n",
      "Epoch 2492\n",
      "-------------------------------\n",
      "loss: 0.254363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405414 \n",
      "\n",
      "Epoch 2493\n",
      "-------------------------------\n",
      "loss: 0.253032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403111 \n",
      "\n",
      "Epoch 2494\n",
      "-------------------------------\n",
      "loss: 0.239039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401695 \n",
      "\n",
      "Epoch 2495\n",
      "-------------------------------\n",
      "loss: 0.241680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400650 \n",
      "\n",
      "Epoch 2496\n",
      "-------------------------------\n",
      "loss: 0.245933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400526 \n",
      "\n",
      "Epoch 2497\n",
      "-------------------------------\n",
      "loss: 0.231162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400683 \n",
      "\n",
      "Epoch 2498\n",
      "-------------------------------\n",
      "loss: 0.248911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401215 \n",
      "\n",
      "Epoch 2499\n",
      "-------------------------------\n",
      "loss: 0.249278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402884 \n",
      "\n",
      "Epoch 2500\n",
      "-------------------------------\n",
      "loss: 0.250839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403440 \n",
      "\n",
      "Epoch 2501\n",
      "-------------------------------\n",
      "loss: 0.256985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402760 \n",
      "\n",
      "Epoch 2502\n",
      "-------------------------------\n",
      "loss: 0.243525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402153 \n",
      "\n",
      "Epoch 2503\n",
      "-------------------------------\n",
      "loss: 0.243998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401963 \n",
      "\n",
      "Epoch 2504\n",
      "-------------------------------\n",
      "loss: 0.242229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402711 \n",
      "\n",
      "Epoch 2505\n",
      "-------------------------------\n",
      "loss: 0.244488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402461 \n",
      "\n",
      "Epoch 2506\n",
      "-------------------------------\n",
      "loss: 0.254960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401447 \n",
      "\n",
      "Epoch 2507\n",
      "-------------------------------\n",
      "loss: 0.269655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400717 \n",
      "\n",
      "Epoch 2508\n",
      "-------------------------------\n",
      "loss: 0.256977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400102 \n",
      "\n",
      "Epoch 2509\n",
      "-------------------------------\n",
      "loss: 0.248459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400141 \n",
      "\n",
      "Epoch 2510\n",
      "-------------------------------\n",
      "loss: 0.244417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400304 \n",
      "\n",
      "Epoch 2511\n",
      "-------------------------------\n",
      "loss: 0.240317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401380 \n",
      "\n",
      "Epoch 2512\n",
      "-------------------------------\n",
      "loss: 0.248154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401695 \n",
      "\n",
      "Epoch 2513\n",
      "-------------------------------\n",
      "loss: 0.258441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401221 \n",
      "\n",
      "Epoch 2514\n",
      "-------------------------------\n",
      "loss: 0.239451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400995 \n",
      "\n",
      "Epoch 2515\n",
      "-------------------------------\n",
      "loss: 0.271178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401208 \n",
      "\n",
      "Epoch 2516\n",
      "-------------------------------\n",
      "loss: 0.242948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401511 \n",
      "\n",
      "Epoch 2517\n",
      "-------------------------------\n",
      "loss: 0.236271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401659 \n",
      "\n",
      "Epoch 2518\n",
      "-------------------------------\n",
      "loss: 0.257973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402407 \n",
      "\n",
      "Epoch 2519\n",
      "-------------------------------\n",
      "loss: 0.258701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402821 \n",
      "\n",
      "Epoch 2520\n",
      "-------------------------------\n",
      "loss: 0.247911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403881 \n",
      "\n",
      "Epoch 2521\n",
      "-------------------------------\n",
      "loss: 0.253757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404938 \n",
      "\n",
      "Epoch 2522\n",
      "-------------------------------\n",
      "loss: 0.261230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404535 \n",
      "\n",
      "Epoch 2523\n",
      "-------------------------------\n",
      "loss: 0.250668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403456 \n",
      "\n",
      "Epoch 2524\n",
      "-------------------------------\n",
      "loss: 0.247562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402944 \n",
      "\n",
      "Epoch 2525\n",
      "-------------------------------\n",
      "loss: 0.253395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402731 \n",
      "\n",
      "Epoch 2526\n",
      "-------------------------------\n",
      "loss: 0.243667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402987 \n",
      "\n",
      "Epoch 2527\n",
      "-------------------------------\n",
      "loss: 0.246708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402942 \n",
      "\n",
      "Epoch 2528\n",
      "-------------------------------\n",
      "loss: 0.244040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403325 \n",
      "\n",
      "Epoch 2529\n",
      "-------------------------------\n",
      "loss: 0.256290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404471 \n",
      "\n",
      "Epoch 2530\n",
      "-------------------------------\n",
      "loss: 0.243904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405664 \n",
      "\n",
      "Epoch 2531\n",
      "-------------------------------\n",
      "loss: 0.255794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406260 \n",
      "\n",
      "Epoch 2532\n",
      "-------------------------------\n",
      "loss: 0.260348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405680 \n",
      "\n",
      "Epoch 2533\n",
      "-------------------------------\n",
      "loss: 0.247867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404604 \n",
      "\n",
      "Epoch 2534\n",
      "-------------------------------\n",
      "loss: 0.262277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403833 \n",
      "\n",
      "Epoch 2535\n",
      "-------------------------------\n",
      "loss: 0.253411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403881 \n",
      "\n",
      "Epoch 2536\n",
      "-------------------------------\n",
      "loss: 0.252514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405079 \n",
      "\n",
      "Epoch 2537\n",
      "-------------------------------\n",
      "loss: 0.256948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405394 \n",
      "\n",
      "Epoch 2538\n",
      "-------------------------------\n",
      "loss: 0.231251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404351 \n",
      "\n",
      "Epoch 2539\n",
      "-------------------------------\n",
      "loss: 0.248472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403697 \n",
      "\n",
      "Epoch 2540\n",
      "-------------------------------\n",
      "loss: 0.256240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403577 \n",
      "\n",
      "Epoch 2541\n",
      "-------------------------------\n",
      "loss: 0.248426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403089 \n",
      "\n",
      "Epoch 2542\n",
      "-------------------------------\n",
      "loss: 0.242157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403406 \n",
      "\n",
      "Epoch 2543\n",
      "-------------------------------\n",
      "loss: 0.261696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401379 \n",
      "\n",
      "Epoch 2544\n",
      "-------------------------------\n",
      "loss: 0.225484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400208 \n",
      "\n",
      "Epoch 2545\n",
      "-------------------------------\n",
      "loss: 0.247718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399304 \n",
      "\n",
      "Epoch 2546\n",
      "-------------------------------\n",
      "loss: 0.259431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398498 \n",
      "\n",
      "Epoch 2547\n",
      "-------------------------------\n",
      "loss: 0.251375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397968 \n",
      "\n",
      "Epoch 2548\n",
      "-------------------------------\n",
      "loss: 0.243459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397731 \n",
      "\n",
      "Epoch 2549\n",
      "-------------------------------\n",
      "loss: 0.248306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399054 \n",
      "\n",
      "Epoch 2550\n",
      "-------------------------------\n",
      "loss: 0.257357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402376 \n",
      "\n",
      "Epoch 2551\n",
      "-------------------------------\n",
      "loss: 0.254460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404588 \n",
      "\n",
      "Epoch 2552\n",
      "-------------------------------\n",
      "loss: 0.244508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403688 \n",
      "\n",
      "Epoch 2553\n",
      "-------------------------------\n",
      "loss: 0.241147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401769 \n",
      "\n",
      "Epoch 2554\n",
      "-------------------------------\n",
      "loss: 0.242837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400470 \n",
      "\n",
      "Epoch 2555\n",
      "-------------------------------\n",
      "loss: 0.239077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399288 \n",
      "\n",
      "Epoch 2556\n",
      "-------------------------------\n",
      "loss: 0.244470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398396 \n",
      "\n",
      "Epoch 2557\n",
      "-------------------------------\n",
      "loss: 0.258580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398760 \n",
      "\n",
      "Epoch 2558\n",
      "-------------------------------\n",
      "loss: 0.235962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401220 \n",
      "\n",
      "Epoch 2559\n",
      "-------------------------------\n",
      "loss: 0.237980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404967 \n",
      "\n",
      "Epoch 2560\n",
      "-------------------------------\n",
      "loss: 0.256531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406129 \n",
      "\n",
      "Epoch 2561\n",
      "-------------------------------\n",
      "loss: 0.252140  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.405371 \n",
      "\n",
      "Epoch 2562\n",
      "-------------------------------\n",
      "loss: 0.267898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402967 \n",
      "\n",
      "Epoch 2563\n",
      "-------------------------------\n",
      "loss: 0.250426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400761 \n",
      "\n",
      "Epoch 2564\n",
      "-------------------------------\n",
      "loss: 0.251370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401151 \n",
      "\n",
      "Epoch 2565\n",
      "-------------------------------\n",
      "loss: 0.247580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401773 \n",
      "\n",
      "Epoch 2566\n",
      "-------------------------------\n",
      "loss: 0.270094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402145 \n",
      "\n",
      "Epoch 2567\n",
      "-------------------------------\n",
      "loss: 0.260483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402271 \n",
      "\n",
      "Epoch 2568\n",
      "-------------------------------\n",
      "loss: 0.240601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402503 \n",
      "\n",
      "Epoch 2569\n",
      "-------------------------------\n",
      "loss: 0.249941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402063 \n",
      "\n",
      "Epoch 2570\n",
      "-------------------------------\n",
      "loss: 0.230816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403657 \n",
      "\n",
      "Epoch 2571\n",
      "-------------------------------\n",
      "loss: 0.247983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406254 \n",
      "\n",
      "Epoch 2572\n",
      "-------------------------------\n",
      "loss: 0.270578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404536 \n",
      "\n",
      "Epoch 2573\n",
      "-------------------------------\n",
      "loss: 0.229777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402701 \n",
      "\n",
      "Epoch 2574\n",
      "-------------------------------\n",
      "loss: 0.232805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401643 \n",
      "\n",
      "Epoch 2575\n",
      "-------------------------------\n",
      "loss: 0.238007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401076 \n",
      "\n",
      "Epoch 2576\n",
      "-------------------------------\n",
      "loss: 0.244706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400550 \n",
      "\n",
      "Epoch 2577\n",
      "-------------------------------\n",
      "loss: 0.241046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400758 \n",
      "\n",
      "Epoch 2578\n",
      "-------------------------------\n",
      "loss: 0.237974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401496 \n",
      "\n",
      "Epoch 2579\n",
      "-------------------------------\n",
      "loss: 0.251306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403754 \n",
      "\n",
      "Epoch 2580\n",
      "-------------------------------\n",
      "loss: 0.249905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404628 \n",
      "\n",
      "Epoch 2581\n",
      "-------------------------------\n",
      "loss: 0.257415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404925 \n",
      "\n",
      "Epoch 2582\n",
      "-------------------------------\n",
      "loss: 0.258934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403484 \n",
      "\n",
      "Epoch 2583\n",
      "-------------------------------\n",
      "loss: 0.243642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402361 \n",
      "\n",
      "Epoch 2584\n",
      "-------------------------------\n",
      "loss: 0.261809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400588 \n",
      "\n",
      "Epoch 2585\n",
      "-------------------------------\n",
      "loss: 0.249580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400505 \n",
      "\n",
      "Epoch 2586\n",
      "-------------------------------\n",
      "loss: 0.242352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401116 \n",
      "\n",
      "Epoch 2587\n",
      "-------------------------------\n",
      "loss: 0.253351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403711 \n",
      "\n",
      "Epoch 2588\n",
      "-------------------------------\n",
      "loss: 0.256505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406679 \n",
      "\n",
      "Epoch 2589\n",
      "-------------------------------\n",
      "loss: 0.246540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409027 \n",
      "\n",
      "Epoch 2590\n",
      "-------------------------------\n",
      "loss: 0.240241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409806 \n",
      "\n",
      "Epoch 2591\n",
      "-------------------------------\n",
      "loss: 0.265052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408085 \n",
      "\n",
      "Epoch 2592\n",
      "-------------------------------\n",
      "loss: 0.250458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405630 \n",
      "\n",
      "Epoch 2593\n",
      "-------------------------------\n",
      "loss: 0.245003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403757 \n",
      "\n",
      "Epoch 2594\n",
      "-------------------------------\n",
      "loss: 0.247244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402882 \n",
      "\n",
      "Epoch 2595\n",
      "-------------------------------\n",
      "loss: 0.236861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402847 \n",
      "\n",
      "Epoch 2596\n",
      "-------------------------------\n",
      "loss: 0.246941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403183 \n",
      "\n",
      "Epoch 2597\n",
      "-------------------------------\n",
      "loss: 0.242161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404904 \n",
      "\n",
      "Epoch 2598\n",
      "-------------------------------\n",
      "loss: 0.243346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405150 \n",
      "\n",
      "Epoch 2599\n",
      "-------------------------------\n",
      "loss: 0.240465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404535 \n",
      "\n",
      "Epoch 2600\n",
      "-------------------------------\n",
      "loss: 0.264505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401094 \n",
      "\n",
      "Epoch 2601\n",
      "-------------------------------\n",
      "loss: 0.244795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398359 \n",
      "\n",
      "Epoch 2602\n",
      "-------------------------------\n",
      "loss: 0.250682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398327 \n",
      "\n",
      "Epoch 2603\n",
      "-------------------------------\n",
      "loss: 0.244724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398813 \n",
      "\n",
      "Epoch 2604\n",
      "-------------------------------\n",
      "loss: 0.251166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398668 \n",
      "\n",
      "Epoch 2605\n",
      "-------------------------------\n",
      "loss: 0.258282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399237 \n",
      "\n",
      "Epoch 2606\n",
      "-------------------------------\n",
      "loss: 0.251494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400201 \n",
      "\n",
      "Epoch 2607\n",
      "-------------------------------\n",
      "loss: 0.248932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400123 \n",
      "\n",
      "Epoch 2608\n",
      "-------------------------------\n",
      "loss: 0.241324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400579 \n",
      "\n",
      "Epoch 2609\n",
      "-------------------------------\n",
      "loss: 0.242303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401156 \n",
      "\n",
      "Epoch 2610\n",
      "-------------------------------\n",
      "loss: 0.270263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 2611\n",
      "-------------------------------\n",
      "loss: 0.242995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401422 \n",
      "\n",
      "Epoch 2612\n",
      "-------------------------------\n",
      "loss: 0.243586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401378 \n",
      "\n",
      "Epoch 2613\n",
      "-------------------------------\n",
      "loss: 0.246351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401808 \n",
      "\n",
      "Epoch 2614\n",
      "-------------------------------\n",
      "loss: 0.249253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403206 \n",
      "\n",
      "Epoch 2615\n",
      "-------------------------------\n",
      "loss: 0.254512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403795 \n",
      "\n",
      "Epoch 2616\n",
      "-------------------------------\n",
      "loss: 0.255084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401906 \n",
      "\n",
      "Epoch 2617\n",
      "-------------------------------\n",
      "loss: 0.259366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400566 \n",
      "\n",
      "Epoch 2618\n",
      "-------------------------------\n",
      "loss: 0.253311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400946 \n",
      "\n",
      "Epoch 2619\n",
      "-------------------------------\n",
      "loss: 0.232852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401437 \n",
      "\n",
      "Epoch 2620\n",
      "-------------------------------\n",
      "loss: 0.257706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402377 \n",
      "\n",
      "Epoch 2621\n",
      "-------------------------------\n",
      "loss: 0.251281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403554 \n",
      "\n",
      "Epoch 2622\n",
      "-------------------------------\n",
      "loss: 0.243387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404971 \n",
      "\n",
      "Epoch 2623\n",
      "-------------------------------\n",
      "loss: 0.234451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408708 \n",
      "\n",
      "Epoch 2624\n",
      "-------------------------------\n",
      "loss: 0.244351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411327 \n",
      "\n",
      "Epoch 2625\n",
      "-------------------------------\n",
      "loss: 0.265049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410003 \n",
      "\n",
      "Epoch 2626\n",
      "-------------------------------\n",
      "loss: 0.252409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405420 \n",
      "\n",
      "Epoch 2627\n",
      "-------------------------------\n",
      "loss: 0.234726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401746 \n",
      "\n",
      "Epoch 2628\n",
      "-------------------------------\n",
      "loss: 0.251657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401375 \n",
      "\n",
      "Epoch 2629\n",
      "-------------------------------\n",
      "loss: 0.255987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401925 \n",
      "\n",
      "Epoch 2630\n",
      "-------------------------------\n",
      "loss: 0.258329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401004 \n",
      "\n",
      "Epoch 2631\n",
      "-------------------------------\n",
      "loss: 0.252166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400861 \n",
      "\n",
      "Epoch 2632\n",
      "-------------------------------\n",
      "loss: 0.252056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403949 \n",
      "\n",
      "Epoch 2633\n",
      "-------------------------------\n",
      "loss: 0.252438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411348 \n",
      "\n",
      "Epoch 2634\n",
      "-------------------------------\n",
      "loss: 0.291590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412820 \n",
      "\n",
      "Epoch 2635\n",
      "-------------------------------\n",
      "loss: 0.265398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408761 \n",
      "\n",
      "Epoch 2636\n",
      "-------------------------------\n",
      "loss: 0.256383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402693 \n",
      "\n",
      "Epoch 2637\n",
      "-------------------------------\n",
      "loss: 0.279755  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399861 \n",
      "\n",
      "Epoch 2638\n",
      "-------------------------------\n",
      "loss: 0.258027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401998 \n",
      "\n",
      "Epoch 2639\n",
      "-------------------------------\n",
      "loss: 0.249830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403517 \n",
      "\n",
      "Epoch 2640\n",
      "-------------------------------\n",
      "loss: 0.261843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403137 \n",
      "\n",
      "Epoch 2641\n",
      "-------------------------------\n",
      "loss: 0.268129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404504 \n",
      "\n",
      "Epoch 2642\n",
      "-------------------------------\n",
      "loss: 0.256121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408111 \n",
      "\n",
      "Epoch 2643\n",
      "-------------------------------\n",
      "loss: 0.267317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409974 \n",
      "\n",
      "Epoch 2644\n",
      "-------------------------------\n",
      "loss: 0.258238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407282 \n",
      "\n",
      "Epoch 2645\n",
      "-------------------------------\n",
      "loss: 0.246789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402309 \n",
      "\n",
      "Epoch 2646\n",
      "-------------------------------\n",
      "loss: 0.237938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399627 \n",
      "\n",
      "Epoch 2647\n",
      "-------------------------------\n",
      "loss: 0.246713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399455 \n",
      "\n",
      "Epoch 2648\n",
      "-------------------------------\n",
      "loss: 0.242364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399792 \n",
      "\n",
      "Epoch 2649\n",
      "-------------------------------\n",
      "loss: 0.242061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400542 \n",
      "\n",
      "Epoch 2650\n",
      "-------------------------------\n",
      "loss: 0.243912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400545 \n",
      "\n",
      "Epoch 2651\n",
      "-------------------------------\n",
      "loss: 0.236712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401493 \n",
      "\n",
      "Epoch 2652\n",
      "-------------------------------\n",
      "loss: 0.237813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403400 \n",
      "\n",
      "Epoch 2653\n",
      "-------------------------------\n",
      "loss: 0.257703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403668 \n",
      "\n",
      "Epoch 2654\n",
      "-------------------------------\n",
      "loss: 0.264476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402693 \n",
      "\n",
      "Epoch 2655\n",
      "-------------------------------\n",
      "loss: 0.242271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402578 \n",
      "\n",
      "Epoch 2656\n",
      "-------------------------------\n",
      "loss: 0.254346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402369 \n",
      "\n",
      "Epoch 2657\n",
      "-------------------------------\n",
      "loss: 0.250246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402633 \n",
      "\n",
      "Epoch 2658\n",
      "-------------------------------\n",
      "loss: 0.260781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401868 \n",
      "\n",
      "Epoch 2659\n",
      "-------------------------------\n",
      "loss: 0.239606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400689 \n",
      "\n",
      "Epoch 2660\n",
      "-------------------------------\n",
      "loss: 0.252329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401175 \n",
      "\n",
      "Epoch 2661\n",
      "-------------------------------\n",
      "loss: 0.239104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402790 \n",
      "\n",
      "Epoch 2662\n",
      "-------------------------------\n",
      "loss: 0.259070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403937 \n",
      "\n",
      "Epoch 2663\n",
      "-------------------------------\n",
      "loss: 0.250771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404440 \n",
      "\n",
      "Epoch 2664\n",
      "-------------------------------\n",
      "loss: 0.248363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403450 \n",
      "\n",
      "Epoch 2665\n",
      "-------------------------------\n",
      "loss: 0.254370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401764 \n",
      "\n",
      "Epoch 2666\n",
      "-------------------------------\n",
      "loss: 0.259723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400354 \n",
      "\n",
      "Epoch 2667\n",
      "-------------------------------\n",
      "loss: 0.244386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400032 \n",
      "\n",
      "Epoch 2668\n",
      "-------------------------------\n",
      "loss: 0.253751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400498 \n",
      "\n",
      "Epoch 2669\n",
      "-------------------------------\n",
      "loss: 0.239785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402382 \n",
      "\n",
      "Epoch 2670\n",
      "-------------------------------\n",
      "loss: 0.255988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404511 \n",
      "\n",
      "Epoch 2671\n",
      "-------------------------------\n",
      "loss: 0.248242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403752 \n",
      "\n",
      "Epoch 2672\n",
      "-------------------------------\n",
      "loss: 0.270541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400904 \n",
      "\n",
      "Epoch 2673\n",
      "-------------------------------\n",
      "loss: 0.248761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401725 \n",
      "\n",
      "Epoch 2674\n",
      "-------------------------------\n",
      "loss: 0.263302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404313 \n",
      "\n",
      "Epoch 2675\n",
      "-------------------------------\n",
      "loss: 0.265043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404919 \n",
      "\n",
      "Epoch 2676\n",
      "-------------------------------\n",
      "loss: 0.253054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404112 \n",
      "\n",
      "Epoch 2677\n",
      "-------------------------------\n",
      "loss: 0.235384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406407 \n",
      "\n",
      "Epoch 2678\n",
      "-------------------------------\n",
      "loss: 0.247568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409616 \n",
      "\n",
      "Epoch 2679\n",
      "-------------------------------\n",
      "loss: 0.235502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411950 \n",
      "\n",
      "Epoch 2680\n",
      "-------------------------------\n",
      "loss: 0.240773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413275 \n",
      "\n",
      "Epoch 2681\n",
      "-------------------------------\n",
      "loss: 0.244947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412231 \n",
      "\n",
      "Epoch 2682\n",
      "-------------------------------\n",
      "loss: 0.253492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409386 \n",
      "\n",
      "Epoch 2683\n",
      "-------------------------------\n",
      "loss: 0.243980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406529 \n",
      "\n",
      "Epoch 2684\n",
      "-------------------------------\n",
      "loss: 0.240412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404722 \n",
      "\n",
      "Epoch 2685\n",
      "-------------------------------\n",
      "loss: 0.247742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404056 \n",
      "\n",
      "Epoch 2686\n",
      "-------------------------------\n",
      "loss: 0.245555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402524 \n",
      "\n",
      "Epoch 2687\n",
      "-------------------------------\n",
      "loss: 0.246244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400933 \n",
      "\n",
      "Epoch 2688\n",
      "-------------------------------\n",
      "loss: 0.254800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399369 \n",
      "\n",
      "Epoch 2689\n",
      "-------------------------------\n",
      "loss: 0.255326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399269 \n",
      "\n",
      "Epoch 2690\n",
      "-------------------------------\n",
      "loss: 0.247281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400949 \n",
      "\n",
      "Epoch 2691\n",
      "-------------------------------\n",
      "loss: 0.240359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404410 \n",
      "\n",
      "Epoch 2692\n",
      "-------------------------------\n",
      "loss: 0.266461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405355 \n",
      "\n",
      "Epoch 2693\n",
      "-------------------------------\n",
      "loss: 0.245231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404135 \n",
      "\n",
      "Epoch 2694\n",
      "-------------------------------\n",
      "loss: 0.242922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402715 \n",
      "\n",
      "Epoch 2695\n",
      "-------------------------------\n",
      "loss: 0.250929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401835 \n",
      "\n",
      "Epoch 2696\n",
      "-------------------------------\n",
      "loss: 0.240585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401417 \n",
      "\n",
      "Epoch 2697\n",
      "-------------------------------\n",
      "loss: 0.250748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401807 \n",
      "\n",
      "Epoch 2698\n",
      "-------------------------------\n",
      "loss: 0.234342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402613 \n",
      "\n",
      "Epoch 2699\n",
      "-------------------------------\n",
      "loss: 0.248267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404459 \n",
      "\n",
      "Epoch 2700\n",
      "-------------------------------\n",
      "loss: 0.251164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406563 \n",
      "\n",
      "Epoch 2701\n",
      "-------------------------------\n",
      "loss: 0.237599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407754 \n",
      "\n",
      "Epoch 2702\n",
      "-------------------------------\n",
      "loss: 0.238178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407656 \n",
      "\n",
      "Epoch 2703\n",
      "-------------------------------\n",
      "loss: 0.238775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408241 \n",
      "\n",
      "Epoch 2704\n",
      "-------------------------------\n",
      "loss: 0.242527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406758 \n",
      "\n",
      "Epoch 2705\n",
      "-------------------------------\n",
      "loss: 0.246774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406294 \n",
      "\n",
      "Epoch 2706\n",
      "-------------------------------\n",
      "loss: 0.247972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405351 \n",
      "\n",
      "Epoch 2707\n",
      "-------------------------------\n",
      "loss: 0.229639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405910 \n",
      "\n",
      "Epoch 2708\n",
      "-------------------------------\n",
      "loss: 0.242206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406019 \n",
      "\n",
      "Epoch 2709\n",
      "-------------------------------\n",
      "loss: 0.243482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405020 \n",
      "\n",
      "Epoch 2710\n",
      "-------------------------------\n",
      "loss: 0.242162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403639 \n",
      "\n",
      "Epoch 2711\n",
      "-------------------------------\n",
      "loss: 0.241250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403080 \n",
      "\n",
      "Epoch 2712\n",
      "-------------------------------\n",
      "loss: 0.239691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403530 \n",
      "\n",
      "Epoch 2713\n",
      "-------------------------------\n",
      "loss: 0.244021  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.404041 \n",
      "\n",
      "Epoch 2714\n",
      "-------------------------------\n",
      "loss: 0.241721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404943 \n",
      "\n",
      "Epoch 2715\n",
      "-------------------------------\n",
      "loss: 0.238207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406756 \n",
      "\n",
      "Epoch 2716\n",
      "-------------------------------\n",
      "loss: 0.237397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408126 \n",
      "\n",
      "Epoch 2717\n",
      "-------------------------------\n",
      "loss: 0.230841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407614 \n",
      "\n",
      "Epoch 2718\n",
      "-------------------------------\n",
      "loss: 0.235327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406983 \n",
      "\n",
      "Epoch 2719\n",
      "-------------------------------\n",
      "loss: 0.275514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405106 \n",
      "\n",
      "Epoch 2720\n",
      "-------------------------------\n",
      "loss: 0.236252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404124 \n",
      "\n",
      "Epoch 2721\n",
      "-------------------------------\n",
      "loss: 0.246234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404575 \n",
      "\n",
      "Epoch 2722\n",
      "-------------------------------\n",
      "loss: 0.259253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404417 \n",
      "\n",
      "Epoch 2723\n",
      "-------------------------------\n",
      "loss: 0.231551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404528 \n",
      "\n",
      "Epoch 2724\n",
      "-------------------------------\n",
      "loss: 0.245886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404215 \n",
      "\n",
      "Epoch 2725\n",
      "-------------------------------\n",
      "loss: 0.234093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403516 \n",
      "\n",
      "Epoch 2726\n",
      "-------------------------------\n",
      "loss: 0.251275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402331 \n",
      "\n",
      "Epoch 2727\n",
      "-------------------------------\n",
      "loss: 0.236274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402373 \n",
      "\n",
      "Epoch 2728\n",
      "-------------------------------\n",
      "loss: 0.247696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402211 \n",
      "\n",
      "Epoch 2729\n",
      "-------------------------------\n",
      "loss: 0.242056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402525 \n",
      "\n",
      "Epoch 2730\n",
      "-------------------------------\n",
      "loss: 0.228094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403075 \n",
      "\n",
      "Epoch 2731\n",
      "-------------------------------\n",
      "loss: 0.233405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403831 \n",
      "\n",
      "Epoch 2732\n",
      "-------------------------------\n",
      "loss: 0.241135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404724 \n",
      "\n",
      "Epoch 2733\n",
      "-------------------------------\n",
      "loss: 0.254172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404524 \n",
      "\n",
      "Epoch 2734\n",
      "-------------------------------\n",
      "loss: 0.243506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404497 \n",
      "\n",
      "Epoch 2735\n",
      "-------------------------------\n",
      "loss: 0.242405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403595 \n",
      "\n",
      "Epoch 2736\n",
      "-------------------------------\n",
      "loss: 0.247225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402757 \n",
      "\n",
      "Epoch 2737\n",
      "-------------------------------\n",
      "loss: 0.247941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400974 \n",
      "\n",
      "Epoch 2738\n",
      "-------------------------------\n",
      "loss: 0.237109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399827 \n",
      "\n",
      "Epoch 2739\n",
      "-------------------------------\n",
      "loss: 0.229740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399620 \n",
      "\n",
      "Epoch 2740\n",
      "-------------------------------\n",
      "loss: 0.254432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399627 \n",
      "\n",
      "Epoch 2741\n",
      "-------------------------------\n",
      "loss: 0.242089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400820 \n",
      "\n",
      "Epoch 2742\n",
      "-------------------------------\n",
      "loss: 0.261926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402393 \n",
      "\n",
      "Epoch 2743\n",
      "-------------------------------\n",
      "loss: 0.243704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403530 \n",
      "\n",
      "Epoch 2744\n",
      "-------------------------------\n",
      "loss: 0.225431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404742 \n",
      "\n",
      "Epoch 2745\n",
      "-------------------------------\n",
      "loss: 0.252170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405596 \n",
      "\n",
      "Epoch 2746\n",
      "-------------------------------\n",
      "loss: 0.249717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404930 \n",
      "\n",
      "Epoch 2747\n",
      "-------------------------------\n",
      "loss: 0.243945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403668 \n",
      "\n",
      "Epoch 2748\n",
      "-------------------------------\n",
      "loss: 0.248961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402914 \n",
      "\n",
      "Epoch 2749\n",
      "-------------------------------\n",
      "loss: 0.251487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402940 \n",
      "\n",
      "Epoch 2750\n",
      "-------------------------------\n",
      "loss: 0.245701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403275 \n",
      "\n",
      "Epoch 2751\n",
      "-------------------------------\n",
      "loss: 0.232455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404030 \n",
      "\n",
      "Epoch 2752\n",
      "-------------------------------\n",
      "loss: 0.237384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404419 \n",
      "\n",
      "Epoch 2753\n",
      "-------------------------------\n",
      "loss: 0.245044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403644 \n",
      "\n",
      "Epoch 2754\n",
      "-------------------------------\n",
      "loss: 0.229525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402722 \n",
      "\n",
      "Epoch 2755\n",
      "-------------------------------\n",
      "loss: 0.247096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402197 \n",
      "\n",
      "Epoch 2756\n",
      "-------------------------------\n",
      "loss: 0.248413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401691 \n",
      "\n",
      "Epoch 2757\n",
      "-------------------------------\n",
      "loss: 0.241241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401491 \n",
      "\n",
      "Epoch 2758\n",
      "-------------------------------\n",
      "loss: 0.243896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400251 \n",
      "\n",
      "Epoch 2759\n",
      "-------------------------------\n",
      "loss: 0.262535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399603 \n",
      "\n",
      "Epoch 2760\n",
      "-------------------------------\n",
      "loss: 0.251329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399395 \n",
      "\n",
      "Epoch 2761\n",
      "-------------------------------\n",
      "loss: 0.246209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400073 \n",
      "\n",
      "Epoch 2762\n",
      "-------------------------------\n",
      "loss: 0.248839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402457 \n",
      "\n",
      "Epoch 2763\n",
      "-------------------------------\n",
      "loss: 0.266746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405922 \n",
      "\n",
      "Epoch 2764\n",
      "-------------------------------\n",
      "loss: 0.263237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407176 \n",
      "\n",
      "Epoch 2765\n",
      "-------------------------------\n",
      "loss: 0.253893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405766 \n",
      "\n",
      "Epoch 2766\n",
      "-------------------------------\n",
      "loss: 0.226652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403042 \n",
      "\n",
      "Epoch 2767\n",
      "-------------------------------\n",
      "loss: 0.250132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401688 \n",
      "\n",
      "Epoch 2768\n",
      "-------------------------------\n",
      "loss: 0.239664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401156 \n",
      "\n",
      "Epoch 2769\n",
      "-------------------------------\n",
      "loss: 0.250682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401337 \n",
      "\n",
      "Epoch 2770\n",
      "-------------------------------\n",
      "loss: 0.242811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403320 \n",
      "\n",
      "Epoch 2771\n",
      "-------------------------------\n",
      "loss: 0.250640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404250 \n",
      "\n",
      "Epoch 2772\n",
      "-------------------------------\n",
      "loss: 0.254086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403859 \n",
      "\n",
      "Epoch 2773\n",
      "-------------------------------\n",
      "loss: 0.257030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402568 \n",
      "\n",
      "Epoch 2774\n",
      "-------------------------------\n",
      "loss: 0.238664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401128 \n",
      "\n",
      "Epoch 2775\n",
      "-------------------------------\n",
      "loss: 0.250776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401011 \n",
      "\n",
      "Epoch 2776\n",
      "-------------------------------\n",
      "loss: 0.229843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401646 \n",
      "\n",
      "Epoch 2777\n",
      "-------------------------------\n",
      "loss: 0.246995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402409 \n",
      "\n",
      "Epoch 2778\n",
      "-------------------------------\n",
      "loss: 0.238343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403556 \n",
      "\n",
      "Epoch 2779\n",
      "-------------------------------\n",
      "loss: 0.228132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404610 \n",
      "\n",
      "Epoch 2780\n",
      "-------------------------------\n",
      "loss: 0.248175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406190 \n",
      "\n",
      "Epoch 2781\n",
      "-------------------------------\n",
      "loss: 0.235969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407878 \n",
      "\n",
      "Epoch 2782\n",
      "-------------------------------\n",
      "loss: 0.252016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407549 \n",
      "\n",
      "Epoch 2783\n",
      "-------------------------------\n",
      "loss: 0.245121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406174 \n",
      "\n",
      "Epoch 2784\n",
      "-------------------------------\n",
      "loss: 0.245883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404538 \n",
      "\n",
      "Epoch 2785\n",
      "-------------------------------\n",
      "loss: 0.243946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403729 \n",
      "\n",
      "Epoch 2786\n",
      "-------------------------------\n",
      "loss: 0.248155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403798 \n",
      "\n",
      "Epoch 2787\n",
      "-------------------------------\n",
      "loss: 0.258513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403475 \n",
      "\n",
      "Epoch 2788\n",
      "-------------------------------\n",
      "loss: 0.234990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403981 \n",
      "\n",
      "Epoch 2789\n",
      "-------------------------------\n",
      "loss: 0.235480  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.405327 \n",
      "\n",
      "Epoch 2790\n",
      "-------------------------------\n",
      "loss: 0.258063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404845 \n",
      "\n",
      "Epoch 2791\n",
      "-------------------------------\n",
      "loss: 0.248387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403783 \n",
      "\n",
      "Epoch 2792\n",
      "-------------------------------\n",
      "loss: 0.252901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402378 \n",
      "\n",
      "Epoch 2793\n",
      "-------------------------------\n",
      "loss: 0.239653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401782 \n",
      "\n",
      "Epoch 2794\n",
      "-------------------------------\n",
      "loss: 0.254534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401990 \n",
      "\n",
      "Epoch 2795\n",
      "-------------------------------\n",
      "loss: 0.247028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402842 \n",
      "\n",
      "Epoch 2796\n",
      "-------------------------------\n",
      "loss: 0.276354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403345 \n",
      "\n",
      "Epoch 2797\n",
      "-------------------------------\n",
      "loss: 0.247685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403187 \n",
      "\n",
      "Epoch 2798\n",
      "-------------------------------\n",
      "loss: 0.268736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402497 \n",
      "\n",
      "Epoch 2799\n",
      "-------------------------------\n",
      "loss: 0.255249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402753 \n",
      "\n",
      "Epoch 2800\n",
      "-------------------------------\n",
      "loss: 0.254005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402671 \n",
      "\n",
      "Epoch 2801\n",
      "-------------------------------\n",
      "loss: 0.254824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402942 \n",
      "\n",
      "Epoch 2802\n",
      "-------------------------------\n",
      "loss: 0.261880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404076 \n",
      "\n",
      "Epoch 2803\n",
      "-------------------------------\n",
      "loss: 0.256883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404255 \n",
      "\n",
      "Epoch 2804\n",
      "-------------------------------\n",
      "loss: 0.247344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404620 \n",
      "\n",
      "Epoch 2805\n",
      "-------------------------------\n",
      "loss: 0.235498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404497 \n",
      "\n",
      "Epoch 2806\n",
      "-------------------------------\n",
      "loss: 0.253805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403022 \n",
      "\n",
      "Epoch 2807\n",
      "-------------------------------\n",
      "loss: 0.238506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401643 \n",
      "\n",
      "Epoch 2808\n",
      "-------------------------------\n",
      "loss: 0.234445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401696 \n",
      "\n",
      "Epoch 2809\n",
      "-------------------------------\n",
      "loss: 0.245752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402109 \n",
      "\n",
      "Epoch 2810\n",
      "-------------------------------\n",
      "loss: 0.236779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402458 \n",
      "\n",
      "Epoch 2811\n",
      "-------------------------------\n",
      "loss: 0.248257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402608 \n",
      "\n",
      "Epoch 2812\n",
      "-------------------------------\n",
      "loss: 0.254865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400792 \n",
      "\n",
      "Epoch 2813\n",
      "-------------------------------\n",
      "loss: 0.257070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397796 \n",
      "\n",
      "Epoch 2814\n",
      "-------------------------------\n",
      "loss: 0.244399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397579 \n",
      "\n",
      "Epoch 2815\n",
      "-------------------------------\n",
      "loss: 0.261457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397824 \n",
      "\n",
      "Epoch 2816\n",
      "-------------------------------\n",
      "loss: 0.251313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397512 \n",
      "\n",
      "Epoch 2817\n",
      "-------------------------------\n",
      "loss: 0.250782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398080 \n",
      "\n",
      "Epoch 2818\n",
      "-------------------------------\n",
      "loss: 0.245796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400861 \n",
      "\n",
      "Epoch 2819\n",
      "-------------------------------\n",
      "loss: 0.230357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408054 \n",
      "\n",
      "Epoch 2820\n",
      "-------------------------------\n",
      "loss: 0.246760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414109 \n",
      "\n",
      "Epoch 2821\n",
      "-------------------------------\n",
      "loss: 0.250272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414145 \n",
      "\n",
      "Epoch 2822\n",
      "-------------------------------\n",
      "loss: 0.285465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408213 \n",
      "\n",
      "Epoch 2823\n",
      "-------------------------------\n",
      "loss: 0.237844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402886 \n",
      "\n",
      "Epoch 2824\n",
      "-------------------------------\n",
      "loss: 0.245495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403070 \n",
      "\n",
      "Epoch 2825\n",
      "-------------------------------\n",
      "loss: 0.265859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404774 \n",
      "\n",
      "Epoch 2826\n",
      "-------------------------------\n",
      "loss: 0.248127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405139 \n",
      "\n",
      "Epoch 2827\n",
      "-------------------------------\n",
      "loss: 0.256479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404179 \n",
      "\n",
      "Epoch 2828\n",
      "-------------------------------\n",
      "loss: 0.240394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405412 \n",
      "\n",
      "Epoch 2829\n",
      "-------------------------------\n",
      "loss: 0.242181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409859 \n",
      "\n",
      "Epoch 2830\n",
      "-------------------------------\n",
      "loss: 0.256259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413220 \n",
      "\n",
      "Epoch 2831\n",
      "-------------------------------\n",
      "loss: 0.251203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411309 \n",
      "\n",
      "Epoch 2832\n",
      "-------------------------------\n",
      "loss: 0.255230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406968 \n",
      "\n",
      "Epoch 2833\n",
      "-------------------------------\n",
      "loss: 0.255517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404039 \n",
      "\n",
      "Epoch 2834\n",
      "-------------------------------\n",
      "loss: 0.249447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403852 \n",
      "\n",
      "Epoch 2835\n",
      "-------------------------------\n",
      "loss: 0.247907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403327 \n",
      "\n",
      "Epoch 2836\n",
      "-------------------------------\n",
      "loss: 0.242093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402521 \n",
      "\n",
      "Epoch 2837\n",
      "-------------------------------\n",
      "loss: 0.243900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402745 \n",
      "\n",
      "Epoch 2838\n",
      "-------------------------------\n",
      "loss: 0.241649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404043 \n",
      "\n",
      "Epoch 2839\n",
      "-------------------------------\n",
      "loss: 0.244050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406182 \n",
      "\n",
      "Epoch 2840\n",
      "-------------------------------\n",
      "loss: 0.235565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406599 \n",
      "\n",
      "Epoch 2841\n",
      "-------------------------------\n",
      "loss: 0.257666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402595 \n",
      "\n",
      "Epoch 2842\n",
      "-------------------------------\n",
      "loss: 0.249348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398713 \n",
      "\n",
      "Epoch 2843\n",
      "-------------------------------\n",
      "loss: 0.248166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397773 \n",
      "\n",
      "Epoch 2844\n",
      "-------------------------------\n",
      "loss: 0.262242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398542 \n",
      "\n",
      "Epoch 2845\n",
      "-------------------------------\n",
      "loss: 0.253999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398842 \n",
      "\n",
      "Epoch 2846\n",
      "-------------------------------\n",
      "loss: 0.239313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399461 \n",
      "\n",
      "Epoch 2847\n",
      "-------------------------------\n",
      "loss: 0.255478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399979 \n",
      "\n",
      "Epoch 2848\n",
      "-------------------------------\n",
      "loss: 0.256053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400399 \n",
      "\n",
      "Epoch 2849\n",
      "-------------------------------\n",
      "loss: 0.251395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400431 \n",
      "\n",
      "Epoch 2850\n",
      "-------------------------------\n",
      "loss: 0.237088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400338 \n",
      "\n",
      "Epoch 2851\n",
      "-------------------------------\n",
      "loss: 0.239802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400157 \n",
      "\n",
      "Epoch 2852\n",
      "-------------------------------\n",
      "loss: 0.254474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400215 \n",
      "\n",
      "Epoch 2853\n",
      "-------------------------------\n",
      "loss: 0.244095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400771 \n",
      "\n",
      "Epoch 2854\n",
      "-------------------------------\n",
      "loss: 0.235358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401357 \n",
      "\n",
      "Epoch 2855\n",
      "-------------------------------\n",
      "loss: 0.255707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401091 \n",
      "\n",
      "Epoch 2856\n",
      "-------------------------------\n",
      "loss: 0.242692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399623 \n",
      "\n",
      "Epoch 2857\n",
      "-------------------------------\n",
      "loss: 0.255168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398549 \n",
      "\n",
      "Epoch 2858\n",
      "-------------------------------\n",
      "loss: 0.252808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397303 \n",
      "\n",
      "Epoch 2859\n",
      "-------------------------------\n",
      "loss: 0.239886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396001 \n",
      "\n",
      "Epoch 2860\n",
      "-------------------------------\n",
      "loss: 0.256250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395503 \n",
      "\n",
      "Epoch 2861\n",
      "-------------------------------\n",
      "loss: 0.241801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395757 \n",
      "\n",
      "Epoch 2862\n",
      "-------------------------------\n",
      "loss: 0.234559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397298 \n",
      "\n",
      "Epoch 2863\n",
      "-------------------------------\n",
      "loss: 0.246381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398348 \n",
      "\n",
      "Epoch 2864\n",
      "-------------------------------\n",
      "loss: 0.249246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397732 \n",
      "\n",
      "Epoch 2865\n",
      "-------------------------------\n",
      "loss: 0.238358  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397189 \n",
      "\n",
      "Epoch 2866\n",
      "-------------------------------\n",
      "loss: 0.242658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397303 \n",
      "\n",
      "Epoch 2867\n",
      "-------------------------------\n",
      "loss: 0.250730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396554 \n",
      "\n",
      "Epoch 2868\n",
      "-------------------------------\n",
      "loss: 0.242609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396342 \n",
      "\n",
      "Epoch 2869\n",
      "-------------------------------\n",
      "loss: 0.244056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397247 \n",
      "\n",
      "Epoch 2870\n",
      "-------------------------------\n",
      "loss: 0.233179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399778 \n",
      "\n",
      "Epoch 2871\n",
      "-------------------------------\n",
      "loss: 0.235899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402396 \n",
      "\n",
      "Epoch 2872\n",
      "-------------------------------\n",
      "loss: 0.251813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402273 \n",
      "\n",
      "Epoch 2873\n",
      "-------------------------------\n",
      "loss: 0.255770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400039 \n",
      "\n",
      "Epoch 2874\n",
      "-------------------------------\n",
      "loss: 0.247732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398715 \n",
      "\n",
      "Epoch 2875\n",
      "-------------------------------\n",
      "loss: 0.239462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398689 \n",
      "\n",
      "Epoch 2876\n",
      "-------------------------------\n",
      "loss: 0.252097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400268 \n",
      "\n",
      "Epoch 2877\n",
      "-------------------------------\n",
      "loss: 0.247594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401519 \n",
      "\n",
      "Epoch 2878\n",
      "-------------------------------\n",
      "loss: 0.228199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401855 \n",
      "\n",
      "Epoch 2879\n",
      "-------------------------------\n",
      "loss: 0.254801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401541 \n",
      "\n",
      "Epoch 2880\n",
      "-------------------------------\n",
      "loss: 0.244365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402071 \n",
      "\n",
      "Epoch 2881\n",
      "-------------------------------\n",
      "loss: 0.246740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401034 \n",
      "\n",
      "Epoch 2882\n",
      "-------------------------------\n",
      "loss: 0.248997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401227 \n",
      "\n",
      "Epoch 2883\n",
      "-------------------------------\n",
      "loss: 0.248211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402424 \n",
      "\n",
      "Epoch 2884\n",
      "-------------------------------\n",
      "loss: 0.257495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404886 \n",
      "\n",
      "Epoch 2885\n",
      "-------------------------------\n",
      "loss: 0.252073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408720 \n",
      "\n",
      "Epoch 2886\n",
      "-------------------------------\n",
      "loss: 0.237191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411051 \n",
      "\n",
      "Epoch 2887\n",
      "-------------------------------\n",
      "loss: 0.257079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410050 \n",
      "\n",
      "Epoch 2888\n",
      "-------------------------------\n",
      "loss: 0.245471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406176 \n",
      "\n",
      "Epoch 2889\n",
      "-------------------------------\n",
      "loss: 0.246074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403153 \n",
      "\n",
      "Epoch 2890\n",
      "-------------------------------\n",
      "loss: 0.249176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401190 \n",
      "\n",
      "Epoch 2891\n",
      "-------------------------------\n",
      "loss: 0.241282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400802 \n",
      "\n",
      "Epoch 2892\n",
      "-------------------------------\n",
      "loss: 0.230592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401369 \n",
      "\n",
      "Epoch 2893\n",
      "-------------------------------\n",
      "loss: 0.242676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401829 \n",
      "\n",
      "Epoch 2894\n",
      "-------------------------------\n",
      "loss: 0.242662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402120 \n",
      "\n",
      "Epoch 2895\n",
      "-------------------------------\n",
      "loss: 0.237809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402883 \n",
      "\n",
      "Epoch 2896\n",
      "-------------------------------\n",
      "loss: 0.230475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403846 \n",
      "\n",
      "Epoch 2897\n",
      "-------------------------------\n",
      "loss: 0.246137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404076 \n",
      "\n",
      "Epoch 2898\n",
      "-------------------------------\n",
      "loss: 0.250527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403219 \n",
      "\n",
      "Epoch 2899\n",
      "-------------------------------\n",
      "loss: 0.257553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401469 \n",
      "\n",
      "Epoch 2900\n",
      "-------------------------------\n",
      "loss: 0.235398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400919 \n",
      "\n",
      "Epoch 2901\n",
      "-------------------------------\n",
      "loss: 0.251473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400314 \n",
      "\n",
      "Epoch 2902\n",
      "-------------------------------\n",
      "loss: 0.258278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399485 \n",
      "\n",
      "Epoch 2903\n",
      "-------------------------------\n",
      "loss: 0.249936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399810 \n",
      "\n",
      "Epoch 2904\n",
      "-------------------------------\n",
      "loss: 0.230492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403030 \n",
      "\n",
      "Epoch 2905\n",
      "-------------------------------\n",
      "loss: 0.240532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406677 \n",
      "\n",
      "Epoch 2906\n",
      "-------------------------------\n",
      "loss: 0.250778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406904 \n",
      "\n",
      "Epoch 2907\n",
      "-------------------------------\n",
      "loss: 0.250270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403793 \n",
      "\n",
      "Epoch 2908\n",
      "-------------------------------\n",
      "loss: 0.230903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400028 \n",
      "\n",
      "Epoch 2909\n",
      "-------------------------------\n",
      "loss: 0.231669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398502 \n",
      "\n",
      "Epoch 2910\n",
      "-------------------------------\n",
      "loss: 0.231470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398719 \n",
      "\n",
      "Epoch 2911\n",
      "-------------------------------\n",
      "loss: 0.251581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398835 \n",
      "\n",
      "Epoch 2912\n",
      "-------------------------------\n",
      "loss: 0.255759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398878 \n",
      "\n",
      "Epoch 2913\n",
      "-------------------------------\n",
      "loss: 0.254756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399782 \n",
      "\n",
      "Epoch 2914\n",
      "-------------------------------\n",
      "loss: 0.231903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401098 \n",
      "\n",
      "Epoch 2915\n",
      "-------------------------------\n",
      "loss: 0.250514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402596 \n",
      "\n",
      "Epoch 2916\n",
      "-------------------------------\n",
      "loss: 0.232475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404473 \n",
      "\n",
      "Epoch 2917\n",
      "-------------------------------\n",
      "loss: 0.226390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404267 \n",
      "\n",
      "Epoch 2918\n",
      "-------------------------------\n",
      "loss: 0.262949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400122 \n",
      "\n",
      "Epoch 2919\n",
      "-------------------------------\n",
      "loss: 0.250696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398183 \n",
      "\n",
      "Epoch 2920\n",
      "-------------------------------\n",
      "loss: 0.251943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399229 \n",
      "\n",
      "Epoch 2921\n",
      "-------------------------------\n",
      "loss: 0.251995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400566 \n",
      "\n",
      "Epoch 2922\n",
      "-------------------------------\n",
      "loss: 0.246948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401891 \n",
      "\n",
      "Epoch 2923\n",
      "-------------------------------\n",
      "loss: 0.256011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404416 \n",
      "\n",
      "Epoch 2924\n",
      "-------------------------------\n",
      "loss: 0.236904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409827 \n",
      "\n",
      "Epoch 2925\n",
      "-------------------------------\n",
      "loss: 0.258946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415371 \n",
      "\n",
      "Epoch 2926\n",
      "-------------------------------\n",
      "loss: 0.256300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416249 \n",
      "\n",
      "Epoch 2927\n",
      "-------------------------------\n",
      "loss: 0.237568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412175 \n",
      "\n",
      "Epoch 2928\n",
      "-------------------------------\n",
      "loss: 0.236694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408540 \n",
      "\n",
      "Epoch 2929\n",
      "-------------------------------\n",
      "loss: 0.230206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406176 \n",
      "\n",
      "Epoch 2930\n",
      "-------------------------------\n",
      "loss: 0.230813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404962 \n",
      "\n",
      "Epoch 2931\n",
      "-------------------------------\n",
      "loss: 0.252158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404179 \n",
      "\n",
      "Epoch 2932\n",
      "-------------------------------\n",
      "loss: 0.243761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403576 \n",
      "\n",
      "Epoch 2933\n",
      "-------------------------------\n",
      "loss: 0.274285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401903 \n",
      "\n",
      "Epoch 2934\n",
      "-------------------------------\n",
      "loss: 0.245734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402557 \n",
      "\n",
      "Epoch 2935\n",
      "-------------------------------\n",
      "loss: 0.232610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405542 \n",
      "\n",
      "Epoch 2936\n",
      "-------------------------------\n",
      "loss: 0.260754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405270 \n",
      "\n",
      "Epoch 2937\n",
      "-------------------------------\n",
      "loss: 0.234597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402705 \n",
      "\n",
      "Epoch 2938\n",
      "-------------------------------\n",
      "loss: 0.250203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399125 \n",
      "\n",
      "Epoch 2939\n",
      "-------------------------------\n",
      "loss: 0.238366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398544 \n",
      "\n",
      "Epoch 2940\n",
      "-------------------------------\n",
      "loss: 0.246554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400504 \n",
      "\n",
      "Epoch 2941\n",
      "-------------------------------\n",
      "loss: 0.263977  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.401347 \n",
      "\n",
      "Epoch 2942\n",
      "-------------------------------\n",
      "loss: 0.255271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398691 \n",
      "\n",
      "Epoch 2943\n",
      "-------------------------------\n",
      "loss: 0.253354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397552 \n",
      "\n",
      "Epoch 2944\n",
      "-------------------------------\n",
      "loss: 0.238850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402711 \n",
      "\n",
      "Epoch 2945\n",
      "-------------------------------\n",
      "loss: 0.257329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406128 \n",
      "\n",
      "Epoch 2946\n",
      "-------------------------------\n",
      "loss: 0.257034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405494 \n",
      "\n",
      "Epoch 2947\n",
      "-------------------------------\n",
      "loss: 0.239935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402630 \n",
      "\n",
      "Epoch 2948\n",
      "-------------------------------\n",
      "loss: 0.237000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398459 \n",
      "\n",
      "Epoch 2949\n",
      "-------------------------------\n",
      "loss: 0.248372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395649 \n",
      "\n",
      "Epoch 2950\n",
      "-------------------------------\n",
      "loss: 0.238653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394567 \n",
      "\n",
      "Epoch 2951\n",
      "-------------------------------\n",
      "loss: 0.243220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394072 \n",
      "\n",
      "Epoch 2952\n",
      "-------------------------------\n",
      "loss: 0.233480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394039 \n",
      "\n",
      "Epoch 2953\n",
      "-------------------------------\n",
      "loss: 0.263067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393794 \n",
      "\n",
      "Epoch 2954\n",
      "-------------------------------\n",
      "loss: 0.250827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395822 \n",
      "\n",
      "Epoch 2955\n",
      "-------------------------------\n",
      "loss: 0.228614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400002 \n",
      "\n",
      "Epoch 2956\n",
      "-------------------------------\n",
      "loss: 0.238524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402634 \n",
      "\n",
      "Epoch 2957\n",
      "-------------------------------\n",
      "loss: 0.251030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401753 \n",
      "\n",
      "Epoch 2958\n",
      "-------------------------------\n",
      "loss: 0.252690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400171 \n",
      "\n",
      "Epoch 2959\n",
      "-------------------------------\n",
      "loss: 0.260783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398457 \n",
      "\n",
      "Epoch 2960\n",
      "-------------------------------\n",
      "loss: 0.246049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398149 \n",
      "\n",
      "Epoch 2961\n",
      "-------------------------------\n",
      "loss: 0.242158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398151 \n",
      "\n",
      "Epoch 2962\n",
      "-------------------------------\n",
      "loss: 0.247640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398193 \n",
      "\n",
      "Epoch 2963\n",
      "-------------------------------\n",
      "loss: 0.236740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399243 \n",
      "\n",
      "Epoch 2964\n",
      "-------------------------------\n",
      "loss: 0.231124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402580 \n",
      "\n",
      "Epoch 2965\n",
      "-------------------------------\n",
      "loss: 0.241868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404725 \n",
      "\n",
      "Epoch 2966\n",
      "-------------------------------\n",
      "loss: 0.261863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403734 \n",
      "\n",
      "Epoch 2967\n",
      "-------------------------------\n",
      "loss: 0.248794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399696 \n",
      "\n",
      "Epoch 2968\n",
      "-------------------------------\n",
      "loss: 0.235545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398021 \n",
      "\n",
      "Epoch 2969\n",
      "-------------------------------\n",
      "loss: 0.232054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399174 \n",
      "\n",
      "Epoch 2970\n",
      "-------------------------------\n",
      "loss: 0.254013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400234 \n",
      "\n",
      "Epoch 2971\n",
      "-------------------------------\n",
      "loss: 0.254026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400092 \n",
      "\n",
      "Epoch 2972\n",
      "-------------------------------\n",
      "loss: 0.236729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399957 \n",
      "\n",
      "Epoch 2973\n",
      "-------------------------------\n",
      "loss: 0.242088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401799 \n",
      "\n",
      "Epoch 2974\n",
      "-------------------------------\n",
      "loss: 0.228750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405158 \n",
      "\n",
      "Epoch 2975\n",
      "-------------------------------\n",
      "loss: 0.246237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406731 \n",
      "\n",
      "Epoch 2976\n",
      "-------------------------------\n",
      "loss: 0.256812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404705 \n",
      "\n",
      "Epoch 2977\n",
      "-------------------------------\n",
      "loss: 0.232213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401699 \n",
      "\n",
      "Epoch 2978\n",
      "-------------------------------\n",
      "loss: 0.243261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399930 \n",
      "\n",
      "Epoch 2979\n",
      "-------------------------------\n",
      "loss: 0.239138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399316 \n",
      "\n",
      "Epoch 2980\n",
      "-------------------------------\n",
      "loss: 0.245321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398915 \n",
      "\n",
      "Epoch 2981\n",
      "-------------------------------\n",
      "loss: 0.250823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398808 \n",
      "\n",
      "Epoch 2982\n",
      "-------------------------------\n",
      "loss: 0.237784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399798 \n",
      "\n",
      "Epoch 2983\n",
      "-------------------------------\n",
      "loss: 0.244229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401287 \n",
      "\n",
      "Epoch 2984\n",
      "-------------------------------\n",
      "loss: 0.231986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403360 \n",
      "\n",
      "Epoch 2985\n",
      "-------------------------------\n",
      "loss: 0.233423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403514 \n",
      "\n",
      "Epoch 2986\n",
      "-------------------------------\n",
      "loss: 0.238520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403052 \n",
      "\n",
      "Epoch 2987\n",
      "-------------------------------\n",
      "loss: 0.238092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401363 \n",
      "\n",
      "Epoch 2988\n",
      "-------------------------------\n",
      "loss: 0.241213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400517 \n",
      "\n",
      "Epoch 2989\n",
      "-------------------------------\n",
      "loss: 0.237644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400487 \n",
      "\n",
      "Epoch 2990\n",
      "-------------------------------\n",
      "loss: 0.249489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400694 \n",
      "\n",
      "Epoch 2991\n",
      "-------------------------------\n",
      "loss: 0.244928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400314 \n",
      "\n",
      "Epoch 2992\n",
      "-------------------------------\n",
      "loss: 0.241511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399952 \n",
      "\n",
      "Epoch 2993\n",
      "-------------------------------\n",
      "loss: 0.227830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400026 \n",
      "\n",
      "Epoch 2994\n",
      "-------------------------------\n",
      "loss: 0.236694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401953 \n",
      "\n",
      "Epoch 2995\n",
      "-------------------------------\n",
      "loss: 0.239451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405003 \n",
      "\n",
      "Epoch 2996\n",
      "-------------------------------\n",
      "loss: 0.240672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405864 \n",
      "\n",
      "Epoch 2997\n",
      "-------------------------------\n",
      "loss: 0.244781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403839 \n",
      "\n",
      "Epoch 2998\n",
      "-------------------------------\n",
      "loss: 0.254634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400980 \n",
      "\n",
      "Epoch 2999\n",
      "-------------------------------\n",
      "loss: 0.240129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399584 \n",
      "\n",
      "Epoch 3000\n",
      "-------------------------------\n",
      "loss: 0.251755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397504 \n",
      "\n",
      "Epoch 3001\n",
      "-------------------------------\n",
      "loss: 0.244879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395754 \n",
      "\n",
      "Epoch 3002\n",
      "-------------------------------\n",
      "loss: 0.248572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395675 \n",
      "\n",
      "Epoch 3003\n",
      "-------------------------------\n",
      "loss: 0.238640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398190 \n",
      "\n",
      "Epoch 3004\n",
      "-------------------------------\n",
      "loss: 0.237986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403660 \n",
      "\n",
      "Epoch 3005\n",
      "-------------------------------\n",
      "loss: 0.247140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405467 \n",
      "\n",
      "Epoch 3006\n",
      "-------------------------------\n",
      "loss: 0.273445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402909 \n",
      "\n",
      "Epoch 3007\n",
      "-------------------------------\n",
      "loss: 0.250126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398821 \n",
      "\n",
      "Epoch 3008\n",
      "-------------------------------\n",
      "loss: 0.244291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397481 \n",
      "\n",
      "Epoch 3009\n",
      "-------------------------------\n",
      "loss: 0.250406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399269 \n",
      "\n",
      "Epoch 3010\n",
      "-------------------------------\n",
      "loss: 0.248639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 3011\n",
      "-------------------------------\n",
      "loss: 0.264478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399729 \n",
      "\n",
      "Epoch 3012\n",
      "-------------------------------\n",
      "loss: 0.232960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398347 \n",
      "\n",
      "Epoch 3013\n",
      "-------------------------------\n",
      "loss: 0.252358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399276 \n",
      "\n",
      "Epoch 3014\n",
      "-------------------------------\n",
      "loss: 0.226584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402915 \n",
      "\n",
      "Epoch 3015\n",
      "-------------------------------\n",
      "loss: 0.233465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409168 \n",
      "\n",
      "Epoch 3016\n",
      "-------------------------------\n",
      "loss: 0.243659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413526 \n",
      "\n",
      "Epoch 3017\n",
      "-------------------------------\n",
      "loss: 0.256951  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.411264 \n",
      "\n",
      "Epoch 3018\n",
      "-------------------------------\n",
      "loss: 0.261635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405541 \n",
      "\n",
      "Epoch 3019\n",
      "-------------------------------\n",
      "loss: 0.236980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402264 \n",
      "\n",
      "Epoch 3020\n",
      "-------------------------------\n",
      "loss: 0.234803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403245 \n",
      "\n",
      "Epoch 3021\n",
      "-------------------------------\n",
      "loss: 0.241446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405119 \n",
      "\n",
      "Epoch 3022\n",
      "-------------------------------\n",
      "loss: 0.245600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404082 \n",
      "\n",
      "Epoch 3023\n",
      "-------------------------------\n",
      "loss: 0.253620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402571 \n",
      "\n",
      "Epoch 3024\n",
      "-------------------------------\n",
      "loss: 0.237071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402911 \n",
      "\n",
      "Epoch 3025\n",
      "-------------------------------\n",
      "loss: 0.251227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404352 \n",
      "\n",
      "Epoch 3026\n",
      "-------------------------------\n",
      "loss: 0.246373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404951 \n",
      "\n",
      "Epoch 3027\n",
      "-------------------------------\n",
      "loss: 0.250616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403784 \n",
      "\n",
      "Epoch 3028\n",
      "-------------------------------\n",
      "loss: 0.237229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400994 \n",
      "\n",
      "Epoch 3029\n",
      "-------------------------------\n",
      "loss: 0.247989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399900 \n",
      "\n",
      "Epoch 3030\n",
      "-------------------------------\n",
      "loss: 0.241315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400326 \n",
      "\n",
      "Epoch 3031\n",
      "-------------------------------\n",
      "loss: 0.240830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401598 \n",
      "\n",
      "Epoch 3032\n",
      "-------------------------------\n",
      "loss: 0.241764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402980 \n",
      "\n",
      "Epoch 3033\n",
      "-------------------------------\n",
      "loss: 0.234234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403192 \n",
      "\n",
      "Epoch 3034\n",
      "-------------------------------\n",
      "loss: 0.229848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404975 \n",
      "\n",
      "Epoch 3035\n",
      "-------------------------------\n",
      "loss: 0.228258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404863 \n",
      "\n",
      "Epoch 3036\n",
      "-------------------------------\n",
      "loss: 0.242137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403830 \n",
      "\n",
      "Epoch 3037\n",
      "-------------------------------\n",
      "loss: 0.232014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403862 \n",
      "\n",
      "Epoch 3038\n",
      "-------------------------------\n",
      "loss: 0.242698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404456 \n",
      "\n",
      "Epoch 3039\n",
      "-------------------------------\n",
      "loss: 0.246469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404376 \n",
      "\n",
      "Epoch 3040\n",
      "-------------------------------\n",
      "loss: 0.243753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403552 \n",
      "\n",
      "Epoch 3041\n",
      "-------------------------------\n",
      "loss: 0.243832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403753 \n",
      "\n",
      "Epoch 3042\n",
      "-------------------------------\n",
      "loss: 0.248203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403457 \n",
      "\n",
      "Epoch 3043\n",
      "-------------------------------\n",
      "loss: 0.239661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402518 \n",
      "\n",
      "Epoch 3044\n",
      "-------------------------------\n",
      "loss: 0.249672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401555 \n",
      "\n",
      "Epoch 3045\n",
      "-------------------------------\n",
      "loss: 0.225097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401993 \n",
      "\n",
      "Epoch 3046\n",
      "-------------------------------\n",
      "loss: 0.248291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402186 \n",
      "\n",
      "Epoch 3047\n",
      "-------------------------------\n",
      "loss: 0.233532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400627 \n",
      "\n",
      "Epoch 3048\n",
      "-------------------------------\n",
      "loss: 0.229800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399196 \n",
      "\n",
      "Epoch 3049\n",
      "-------------------------------\n",
      "loss: 0.243260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398050 \n",
      "\n",
      "Epoch 3050\n",
      "-------------------------------\n",
      "loss: 0.236517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398268 \n",
      "\n",
      "Epoch 3051\n",
      "-------------------------------\n",
      "loss: 0.246220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399019 \n",
      "\n",
      "Epoch 3052\n",
      "-------------------------------\n",
      "loss: 0.238469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400475 \n",
      "\n",
      "Epoch 3053\n",
      "-------------------------------\n",
      "loss: 0.234489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402409 \n",
      "\n",
      "Epoch 3054\n",
      "-------------------------------\n",
      "loss: 0.239642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405452 \n",
      "\n",
      "Epoch 3055\n",
      "-------------------------------\n",
      "loss: 0.238776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406756 \n",
      "\n",
      "Epoch 3056\n",
      "-------------------------------\n",
      "loss: 0.229563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406830 \n",
      "\n",
      "Epoch 3057\n",
      "-------------------------------\n",
      "loss: 0.236857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406846 \n",
      "\n",
      "Epoch 3058\n",
      "-------------------------------\n",
      "loss: 0.236113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406231 \n",
      "\n",
      "Epoch 3059\n",
      "-------------------------------\n",
      "loss: 0.231740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406079 \n",
      "\n",
      "Epoch 3060\n",
      "-------------------------------\n",
      "loss: 0.249345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405952 \n",
      "\n",
      "Epoch 3061\n",
      "-------------------------------\n",
      "loss: 0.228141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406139 \n",
      "\n",
      "Epoch 3062\n",
      "-------------------------------\n",
      "loss: 0.239433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406185 \n",
      "\n",
      "Epoch 3063\n",
      "-------------------------------\n",
      "loss: 0.234873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405338 \n",
      "\n",
      "Epoch 3064\n",
      "-------------------------------\n",
      "loss: 0.241596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404521 \n",
      "\n",
      "Epoch 3065\n",
      "-------------------------------\n",
      "loss: 0.238811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403213 \n",
      "\n",
      "Epoch 3066\n",
      "-------------------------------\n",
      "loss: 0.241568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401620 \n",
      "\n",
      "Epoch 3067\n",
      "-------------------------------\n",
      "loss: 0.229824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400293 \n",
      "\n",
      "Epoch 3068\n",
      "-------------------------------\n",
      "loss: 0.249701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399601 \n",
      "\n",
      "Epoch 3069\n",
      "-------------------------------\n",
      "loss: 0.240925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399270 \n",
      "\n",
      "Epoch 3070\n",
      "-------------------------------\n",
      "loss: 0.237558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398995 \n",
      "\n",
      "Epoch 3071\n",
      "-------------------------------\n",
      "loss: 0.247284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398413 \n",
      "\n",
      "Epoch 3072\n",
      "-------------------------------\n",
      "loss: 0.230127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398389 \n",
      "\n",
      "Epoch 3073\n",
      "-------------------------------\n",
      "loss: 0.233493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398406 \n",
      "\n",
      "Epoch 3074\n",
      "-------------------------------\n",
      "loss: 0.249031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397948 \n",
      "\n",
      "Epoch 3075\n",
      "-------------------------------\n",
      "loss: 0.243132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398006 \n",
      "\n",
      "Epoch 3076\n",
      "-------------------------------\n",
      "loss: 0.240241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398156 \n",
      "\n",
      "Epoch 3077\n",
      "-------------------------------\n",
      "loss: 0.238505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398759 \n",
      "\n",
      "Epoch 3078\n",
      "-------------------------------\n",
      "loss: 0.249777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399872 \n",
      "\n",
      "Epoch 3079\n",
      "-------------------------------\n",
      "loss: 0.224871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400253 \n",
      "\n",
      "Epoch 3080\n",
      "-------------------------------\n",
      "loss: 0.250389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401289 \n",
      "\n",
      "Epoch 3081\n",
      "-------------------------------\n",
      "loss: 0.233699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403979 \n",
      "\n",
      "Epoch 3082\n",
      "-------------------------------\n",
      "loss: 0.234393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407140 \n",
      "\n",
      "Epoch 3083\n",
      "-------------------------------\n",
      "loss: 0.249211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409606 \n",
      "\n",
      "Epoch 3084\n",
      "-------------------------------\n",
      "loss: 0.232538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409816 \n",
      "\n",
      "Epoch 3085\n",
      "-------------------------------\n",
      "loss: 0.264190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406555 \n",
      "\n",
      "Epoch 3086\n",
      "-------------------------------\n",
      "loss: 0.246235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403705 \n",
      "\n",
      "Epoch 3087\n",
      "-------------------------------\n",
      "loss: 0.229390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404485 \n",
      "\n",
      "Epoch 3088\n",
      "-------------------------------\n",
      "loss: 0.223221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405751 \n",
      "\n",
      "Epoch 3089\n",
      "-------------------------------\n",
      "loss: 0.246130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406726 \n",
      "\n",
      "Epoch 3090\n",
      "-------------------------------\n",
      "loss: 0.243969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406346 \n",
      "\n",
      "Epoch 3091\n",
      "-------------------------------\n",
      "loss: 0.255287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406586 \n",
      "\n",
      "Epoch 3092\n",
      "-------------------------------\n",
      "loss: 0.230716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407206 \n",
      "\n",
      "Epoch 3093\n",
      "-------------------------------\n",
      "loss: 0.253518  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.406723 \n",
      "\n",
      "Epoch 3094\n",
      "-------------------------------\n",
      "loss: 0.231900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406270 \n",
      "\n",
      "Epoch 3095\n",
      "-------------------------------\n",
      "loss: 0.236034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404825 \n",
      "\n",
      "Epoch 3096\n",
      "-------------------------------\n",
      "loss: 0.238917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403248 \n",
      "\n",
      "Epoch 3097\n",
      "-------------------------------\n",
      "loss: 0.240534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402377 \n",
      "\n",
      "Epoch 3098\n",
      "-------------------------------\n",
      "loss: 0.233202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400705 \n",
      "\n",
      "Epoch 3099\n",
      "-------------------------------\n",
      "loss: 0.244903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398707 \n",
      "\n",
      "Epoch 3100\n",
      "-------------------------------\n",
      "loss: 0.241014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397830 \n",
      "\n",
      "Epoch 3101\n",
      "-------------------------------\n",
      "loss: 0.241862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399887 \n",
      "\n",
      "Epoch 3102\n",
      "-------------------------------\n",
      "loss: 0.235786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404091 \n",
      "\n",
      "Epoch 3103\n",
      "-------------------------------\n",
      "loss: 0.232457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406206 \n",
      "\n",
      "Epoch 3104\n",
      "-------------------------------\n",
      "loss: 0.267880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402890 \n",
      "\n",
      "Epoch 3105\n",
      "-------------------------------\n",
      "loss: 0.230257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398819 \n",
      "\n",
      "Epoch 3106\n",
      "-------------------------------\n",
      "loss: 0.232834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396375 \n",
      "\n",
      "Epoch 3107\n",
      "-------------------------------\n",
      "loss: 0.233553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394497 \n",
      "\n",
      "Epoch 3108\n",
      "-------------------------------\n",
      "loss: 0.235905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393380 \n",
      "\n",
      "Epoch 3109\n",
      "-------------------------------\n",
      "loss: 0.233615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393711 \n",
      "\n",
      "Epoch 3110\n",
      "-------------------------------\n",
      "loss: 0.236380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396395 \n",
      "\n",
      "Epoch 3111\n",
      "-------------------------------\n",
      "loss: 0.242031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402197 \n",
      "\n",
      "Epoch 3112\n",
      "-------------------------------\n",
      "loss: 0.242597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405049 \n",
      "\n",
      "Epoch 3113\n",
      "-------------------------------\n",
      "loss: 0.257039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403954 \n",
      "\n",
      "Epoch 3114\n",
      "-------------------------------\n",
      "loss: 0.250316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400120 \n",
      "\n",
      "Epoch 3115\n",
      "-------------------------------\n",
      "loss: 0.240795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397379 \n",
      "\n",
      "Epoch 3116\n",
      "-------------------------------\n",
      "loss: 0.231870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397017 \n",
      "\n",
      "Epoch 3117\n",
      "-------------------------------\n",
      "loss: 0.246362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400095 \n",
      "\n",
      "Epoch 3118\n",
      "-------------------------------\n",
      "loss: 0.251994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402949 \n",
      "\n",
      "Epoch 3119\n",
      "-------------------------------\n",
      "loss: 0.249048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403059 \n",
      "\n",
      "Epoch 3120\n",
      "-------------------------------\n",
      "loss: 0.259205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401298 \n",
      "\n",
      "Epoch 3121\n",
      "-------------------------------\n",
      "loss: 0.242718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400460 \n",
      "\n",
      "Epoch 3122\n",
      "-------------------------------\n",
      "loss: 0.242718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405293 \n",
      "\n",
      "Epoch 3123\n",
      "-------------------------------\n",
      "loss: 0.250215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408555 \n",
      "\n",
      "Epoch 3124\n",
      "-------------------------------\n",
      "loss: 0.251272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405378 \n",
      "\n",
      "Epoch 3125\n",
      "-------------------------------\n",
      "loss: 0.250476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399715 \n",
      "\n",
      "Epoch 3126\n",
      "-------------------------------\n",
      "loss: 0.246150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397869 \n",
      "\n",
      "Epoch 3127\n",
      "-------------------------------\n",
      "loss: 0.240357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397464 \n",
      "\n",
      "Epoch 3128\n",
      "-------------------------------\n",
      "loss: 0.238119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396739 \n",
      "\n",
      "Epoch 3129\n",
      "-------------------------------\n",
      "loss: 0.243681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396710 \n",
      "\n",
      "Epoch 3130\n",
      "-------------------------------\n",
      "loss: 0.241307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398975 \n",
      "\n",
      "Epoch 3131\n",
      "-------------------------------\n",
      "loss: 0.233381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401993 \n",
      "\n",
      "Epoch 3132\n",
      "-------------------------------\n",
      "loss: 0.241721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403826 \n",
      "\n",
      "Epoch 3133\n",
      "-------------------------------\n",
      "loss: 0.222903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403107 \n",
      "\n",
      "Epoch 3134\n",
      "-------------------------------\n",
      "loss: 0.232715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400907 \n",
      "\n",
      "Epoch 3135\n",
      "-------------------------------\n",
      "loss: 0.252775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398542 \n",
      "\n",
      "Epoch 3136\n",
      "-------------------------------\n",
      "loss: 0.235344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397224 \n",
      "\n",
      "Epoch 3137\n",
      "-------------------------------\n",
      "loss: 0.231224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396341 \n",
      "\n",
      "Epoch 3138\n",
      "-------------------------------\n",
      "loss: 0.230372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396678 \n",
      "\n",
      "Epoch 3139\n",
      "-------------------------------\n",
      "loss: 0.238227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397294 \n",
      "\n",
      "Epoch 3140\n",
      "-------------------------------\n",
      "loss: 0.243668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398822 \n",
      "\n",
      "Epoch 3141\n",
      "-------------------------------\n",
      "loss: 0.230846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400197 \n",
      "\n",
      "Epoch 3142\n",
      "-------------------------------\n",
      "loss: 0.233040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401190 \n",
      "\n",
      "Epoch 3143\n",
      "-------------------------------\n",
      "loss: 0.237711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400764 \n",
      "\n",
      "Epoch 3144\n",
      "-------------------------------\n",
      "loss: 0.243945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398630 \n",
      "\n",
      "Epoch 3145\n",
      "-------------------------------\n",
      "loss: 0.231090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396819 \n",
      "\n",
      "Epoch 3146\n",
      "-------------------------------\n",
      "loss: 0.245261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396336 \n",
      "\n",
      "Epoch 3147\n",
      "-------------------------------\n",
      "loss: 0.240305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397724 \n",
      "\n",
      "Epoch 3148\n",
      "-------------------------------\n",
      "loss: 0.244262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398545 \n",
      "\n",
      "Epoch 3149\n",
      "-------------------------------\n",
      "loss: 0.233311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398489 \n",
      "\n",
      "Epoch 3150\n",
      "-------------------------------\n",
      "loss: 0.237839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399285 \n",
      "\n",
      "Epoch 3151\n",
      "-------------------------------\n",
      "loss: 0.228494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402005 \n",
      "\n",
      "Epoch 3152\n",
      "-------------------------------\n",
      "loss: 0.238819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406207 \n",
      "\n",
      "Epoch 3153\n",
      "-------------------------------\n",
      "loss: 0.253319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408818 \n",
      "\n",
      "Epoch 3154\n",
      "-------------------------------\n",
      "loss: 0.238456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406411 \n",
      "\n",
      "Epoch 3155\n",
      "-------------------------------\n",
      "loss: 0.240030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401543 \n",
      "\n",
      "Epoch 3156\n",
      "-------------------------------\n",
      "loss: 0.235275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399844 \n",
      "\n",
      "Epoch 3157\n",
      "-------------------------------\n",
      "loss: 0.236275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399550 \n",
      "\n",
      "Epoch 3158\n",
      "-------------------------------\n",
      "loss: 0.236266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400127 \n",
      "\n",
      "Epoch 3159\n",
      "-------------------------------\n",
      "loss: 0.238875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399768 \n",
      "\n",
      "Epoch 3160\n",
      "-------------------------------\n",
      "loss: 0.256464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399880 \n",
      "\n",
      "Epoch 3161\n",
      "-------------------------------\n",
      "loss: 0.231420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402103 \n",
      "\n",
      "Epoch 3162\n",
      "-------------------------------\n",
      "loss: 0.244622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404994 \n",
      "\n",
      "Epoch 3163\n",
      "-------------------------------\n",
      "loss: 0.236298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405256 \n",
      "\n",
      "Epoch 3164\n",
      "-------------------------------\n",
      "loss: 0.233328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404212 \n",
      "\n",
      "Epoch 3165\n",
      "-------------------------------\n",
      "loss: 0.239145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403542 \n",
      "\n",
      "Epoch 3166\n",
      "-------------------------------\n",
      "loss: 0.232190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403961 \n",
      "\n",
      "Epoch 3167\n",
      "-------------------------------\n",
      "loss: 0.241491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403977 \n",
      "\n",
      "Epoch 3168\n",
      "-------------------------------\n",
      "loss: 0.236453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403825 \n",
      "\n",
      "Epoch 3169\n",
      "-------------------------------\n",
      "loss: 0.237125  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403705 \n",
      "\n",
      "Epoch 3170\n",
      "-------------------------------\n",
      "loss: 0.238983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404624 \n",
      "\n",
      "Epoch 3171\n",
      "-------------------------------\n",
      "loss: 0.238505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405818 \n",
      "\n",
      "Epoch 3172\n",
      "-------------------------------\n",
      "loss: 0.228884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406853 \n",
      "\n",
      "Epoch 3173\n",
      "-------------------------------\n",
      "loss: 0.257075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406353 \n",
      "\n",
      "Epoch 3174\n",
      "-------------------------------\n",
      "loss: 0.242170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404907 \n",
      "\n",
      "Epoch 3175\n",
      "-------------------------------\n",
      "loss: 0.239417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402961 \n",
      "\n",
      "Epoch 3176\n",
      "-------------------------------\n",
      "loss: 0.233357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402087 \n",
      "\n",
      "Epoch 3177\n",
      "-------------------------------\n",
      "loss: 0.240856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402325 \n",
      "\n",
      "Epoch 3178\n",
      "-------------------------------\n",
      "loss: 0.235741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403021 \n",
      "\n",
      "Epoch 3179\n",
      "-------------------------------\n",
      "loss: 0.245928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402856 \n",
      "\n",
      "Epoch 3180\n",
      "-------------------------------\n",
      "loss: 0.239781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402684 \n",
      "\n",
      "Epoch 3181\n",
      "-------------------------------\n",
      "loss: 0.254845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401956 \n",
      "\n",
      "Epoch 3182\n",
      "-------------------------------\n",
      "loss: 0.226429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401609 \n",
      "\n",
      "Epoch 3183\n",
      "-------------------------------\n",
      "loss: 0.241398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401223 \n",
      "\n",
      "Epoch 3184\n",
      "-------------------------------\n",
      "loss: 0.232952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401325 \n",
      "\n",
      "Epoch 3185\n",
      "-------------------------------\n",
      "loss: 0.246473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400722 \n",
      "\n",
      "Epoch 3186\n",
      "-------------------------------\n",
      "loss: 0.238423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399538 \n",
      "\n",
      "Epoch 3187\n",
      "-------------------------------\n",
      "loss: 0.233588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397723 \n",
      "\n",
      "Epoch 3188\n",
      "-------------------------------\n",
      "loss: 0.250239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396108 \n",
      "\n",
      "Epoch 3189\n",
      "-------------------------------\n",
      "loss: 0.232508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395849 \n",
      "\n",
      "Epoch 3190\n",
      "-------------------------------\n",
      "loss: 0.238799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396326 \n",
      "\n",
      "Epoch 3191\n",
      "-------------------------------\n",
      "loss: 0.235645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396776 \n",
      "\n",
      "Epoch 3192\n",
      "-------------------------------\n",
      "loss: 0.240948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398092 \n",
      "\n",
      "Epoch 3193\n",
      "-------------------------------\n",
      "loss: 0.259800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400902 \n",
      "\n",
      "Epoch 3194\n",
      "-------------------------------\n",
      "loss: 0.231405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402873 \n",
      "\n",
      "Epoch 3195\n",
      "-------------------------------\n",
      "loss: 0.233548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404892 \n",
      "\n",
      "Epoch 3196\n",
      "-------------------------------\n",
      "loss: 0.230073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405723 \n",
      "\n",
      "Epoch 3197\n",
      "-------------------------------\n",
      "loss: 0.247675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406081 \n",
      "\n",
      "Epoch 3198\n",
      "-------------------------------\n",
      "loss: 0.242342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405349 \n",
      "\n",
      "Epoch 3199\n",
      "-------------------------------\n",
      "loss: 0.237075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402993 \n",
      "\n",
      "Epoch 3200\n",
      "-------------------------------\n",
      "loss: 0.241754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401052 \n",
      "\n",
      "Epoch 3201\n",
      "-------------------------------\n",
      "loss: 0.229719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400676 \n",
      "\n",
      "Epoch 3202\n",
      "-------------------------------\n",
      "loss: 0.243527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401107 \n",
      "\n",
      "Epoch 3203\n",
      "-------------------------------\n",
      "loss: 0.243923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400528 \n",
      "\n",
      "Epoch 3204\n",
      "-------------------------------\n",
      "loss: 0.237695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401250 \n",
      "\n",
      "Epoch 3205\n",
      "-------------------------------\n",
      "loss: 0.243212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402626 \n",
      "\n",
      "Epoch 3206\n",
      "-------------------------------\n",
      "loss: 0.241667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404426 \n",
      "\n",
      "Epoch 3207\n",
      "-------------------------------\n",
      "loss: 0.233232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406496 \n",
      "\n",
      "Epoch 3208\n",
      "-------------------------------\n",
      "loss: 0.246214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407122 \n",
      "\n",
      "Epoch 3209\n",
      "-------------------------------\n",
      "loss: 0.238719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406070 \n",
      "\n",
      "Epoch 3210\n",
      "-------------------------------\n",
      "loss: 0.241294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405306 \n",
      "\n",
      "Epoch 3211\n",
      "-------------------------------\n",
      "loss: 0.237140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404965 \n",
      "\n",
      "Epoch 3212\n",
      "-------------------------------\n",
      "loss: 0.238077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403655 \n",
      "\n",
      "Epoch 3213\n",
      "-------------------------------\n",
      "loss: 0.239117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402939 \n",
      "\n",
      "Epoch 3214\n",
      "-------------------------------\n",
      "loss: 0.247523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403379 \n",
      "\n",
      "Epoch 3215\n",
      "-------------------------------\n",
      "loss: 0.237088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404476 \n",
      "\n",
      "Epoch 3216\n",
      "-------------------------------\n",
      "loss: 0.237020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405085 \n",
      "\n",
      "Epoch 3217\n",
      "-------------------------------\n",
      "loss: 0.245530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405277 \n",
      "\n",
      "Epoch 3218\n",
      "-------------------------------\n",
      "loss: 0.244115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403154 \n",
      "\n",
      "Epoch 3219\n",
      "-------------------------------\n",
      "loss: 0.248700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401076 \n",
      "\n",
      "Epoch 3220\n",
      "-------------------------------\n",
      "loss: 0.250754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400457 \n",
      "\n",
      "Epoch 3221\n",
      "-------------------------------\n",
      "loss: 0.224423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400536 \n",
      "\n",
      "Epoch 3222\n",
      "-------------------------------\n",
      "loss: 0.244600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400855 \n",
      "\n",
      "Epoch 3223\n",
      "-------------------------------\n",
      "loss: 0.243608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400672 \n",
      "\n",
      "Epoch 3224\n",
      "-------------------------------\n",
      "loss: 0.229162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400265 \n",
      "\n",
      "Epoch 3225\n",
      "-------------------------------\n",
      "loss: 0.232005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400685 \n",
      "\n",
      "Epoch 3226\n",
      "-------------------------------\n",
      "loss: 0.248330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400453 \n",
      "\n",
      "Epoch 3227\n",
      "-------------------------------\n",
      "loss: 0.247521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399586 \n",
      "\n",
      "Epoch 3228\n",
      "-------------------------------\n",
      "loss: 0.232811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399468 \n",
      "\n",
      "Epoch 3229\n",
      "-------------------------------\n",
      "loss: 0.228059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400002 \n",
      "\n",
      "Epoch 3230\n",
      "-------------------------------\n",
      "loss: 0.235865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401076 \n",
      "\n",
      "Epoch 3231\n",
      "-------------------------------\n",
      "loss: 0.238294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401257 \n",
      "\n",
      "Epoch 3232\n",
      "-------------------------------\n",
      "loss: 0.243915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403128 \n",
      "\n",
      "Epoch 3233\n",
      "-------------------------------\n",
      "loss: 0.239649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405939 \n",
      "\n",
      "Epoch 3234\n",
      "-------------------------------\n",
      "loss: 0.239485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406170 \n",
      "\n",
      "Epoch 3235\n",
      "-------------------------------\n",
      "loss: 0.245701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404339 \n",
      "\n",
      "Epoch 3236\n",
      "-------------------------------\n",
      "loss: 0.247818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402363 \n",
      "\n",
      "Epoch 3237\n",
      "-------------------------------\n",
      "loss: 0.238942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400510 \n",
      "\n",
      "Epoch 3238\n",
      "-------------------------------\n",
      "loss: 0.227617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399232 \n",
      "\n",
      "Epoch 3239\n",
      "-------------------------------\n",
      "loss: 0.240275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397445 \n",
      "\n",
      "Epoch 3240\n",
      "-------------------------------\n",
      "loss: 0.247578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396604 \n",
      "\n",
      "Epoch 3241\n",
      "-------------------------------\n",
      "loss: 0.234720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397318 \n",
      "\n",
      "Epoch 3242\n",
      "-------------------------------\n",
      "loss: 0.222409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400449 \n",
      "\n",
      "Epoch 3243\n",
      "-------------------------------\n",
      "loss: 0.246996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404435 \n",
      "\n",
      "Epoch 3244\n",
      "-------------------------------\n",
      "loss: 0.231350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406026 \n",
      "\n",
      "Epoch 3245\n",
      "-------------------------------\n",
      "loss: 0.242640  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.406529 \n",
      "\n",
      "Epoch 3246\n",
      "-------------------------------\n",
      "loss: 0.257320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405061 \n",
      "\n",
      "Epoch 3247\n",
      "-------------------------------\n",
      "loss: 0.236777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402173 \n",
      "\n",
      "Epoch 3248\n",
      "-------------------------------\n",
      "loss: 0.228898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400137 \n",
      "\n",
      "Epoch 3249\n",
      "-------------------------------\n",
      "loss: 0.232626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399634 \n",
      "\n",
      "Epoch 3250\n",
      "-------------------------------\n",
      "loss: 0.242676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399885 \n",
      "\n",
      "Epoch 3251\n",
      "-------------------------------\n",
      "loss: 0.257332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399610 \n",
      "\n",
      "Epoch 3252\n",
      "-------------------------------\n",
      "loss: 0.240571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400595 \n",
      "\n",
      "Epoch 3253\n",
      "-------------------------------\n",
      "loss: 0.223755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403179 \n",
      "\n",
      "Epoch 3254\n",
      "-------------------------------\n",
      "loss: 0.244787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405701 \n",
      "\n",
      "Epoch 3255\n",
      "-------------------------------\n",
      "loss: 0.236237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409126 \n",
      "\n",
      "Epoch 3256\n",
      "-------------------------------\n",
      "loss: 0.247612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410192 \n",
      "\n",
      "Epoch 3257\n",
      "-------------------------------\n",
      "loss: 0.255743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407676 \n",
      "\n",
      "Epoch 3258\n",
      "-------------------------------\n",
      "loss: 0.239296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404855 \n",
      "\n",
      "Epoch 3259\n",
      "-------------------------------\n",
      "loss: 0.215928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403233 \n",
      "\n",
      "Epoch 3260\n",
      "-------------------------------\n",
      "loss: 0.238115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403100 \n",
      "\n",
      "Epoch 3261\n",
      "-------------------------------\n",
      "loss: 0.239580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402430 \n",
      "\n",
      "Epoch 3262\n",
      "-------------------------------\n",
      "loss: 0.243038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401621 \n",
      "\n",
      "Epoch 3263\n",
      "-------------------------------\n",
      "loss: 0.227761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400672 \n",
      "\n",
      "Epoch 3264\n",
      "-------------------------------\n",
      "loss: 0.235419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401018 \n",
      "\n",
      "Epoch 3265\n",
      "-------------------------------\n",
      "loss: 0.231755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402809 \n",
      "\n",
      "Epoch 3266\n",
      "-------------------------------\n",
      "loss: 0.242616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404091 \n",
      "\n",
      "Epoch 3267\n",
      "-------------------------------\n",
      "loss: 0.229635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405573 \n",
      "\n",
      "Epoch 3268\n",
      "-------------------------------\n",
      "loss: 0.228402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406057 \n",
      "\n",
      "Epoch 3269\n",
      "-------------------------------\n",
      "loss: 0.237737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404005 \n",
      "\n",
      "Epoch 3270\n",
      "-------------------------------\n",
      "loss: 0.246591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401090 \n",
      "\n",
      "Epoch 3271\n",
      "-------------------------------\n",
      "loss: 0.241833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399450 \n",
      "\n",
      "Epoch 3272\n",
      "-------------------------------\n",
      "loss: 0.232255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399996 \n",
      "\n",
      "Epoch 3273\n",
      "-------------------------------\n",
      "loss: 0.221760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401040 \n",
      "\n",
      "Epoch 3274\n",
      "-------------------------------\n",
      "loss: 0.235575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401715 \n",
      "\n",
      "Epoch 3275\n",
      "-------------------------------\n",
      "loss: 0.239955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402598 \n",
      "\n",
      "Epoch 3276\n",
      "-------------------------------\n",
      "loss: 0.227197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403556 \n",
      "\n",
      "Epoch 3277\n",
      "-------------------------------\n",
      "loss: 0.224260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405223 \n",
      "\n",
      "Epoch 3278\n",
      "-------------------------------\n",
      "loss: 0.252051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404489 \n",
      "\n",
      "Epoch 3279\n",
      "-------------------------------\n",
      "loss: 0.247263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402739 \n",
      "\n",
      "Epoch 3280\n",
      "-------------------------------\n",
      "loss: 0.228680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401994 \n",
      "\n",
      "Epoch 3281\n",
      "-------------------------------\n",
      "loss: 0.243027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401166 \n",
      "\n",
      "Epoch 3282\n",
      "-------------------------------\n",
      "loss: 0.239352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 3283\n",
      "-------------------------------\n",
      "loss: 0.234039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400118 \n",
      "\n",
      "Epoch 3284\n",
      "-------------------------------\n",
      "loss: 0.258306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400705 \n",
      "\n",
      "Epoch 3285\n",
      "-------------------------------\n",
      "loss: 0.226985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402015 \n",
      "\n",
      "Epoch 3286\n",
      "-------------------------------\n",
      "loss: 0.233190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402419 \n",
      "\n",
      "Epoch 3287\n",
      "-------------------------------\n",
      "loss: 0.234249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402217 \n",
      "\n",
      "Epoch 3288\n",
      "-------------------------------\n",
      "loss: 0.242438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401092 \n",
      "\n",
      "Epoch 3289\n",
      "-------------------------------\n",
      "loss: 0.247692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399409 \n",
      "\n",
      "Epoch 3290\n",
      "-------------------------------\n",
      "loss: 0.233192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398785 \n",
      "\n",
      "Epoch 3291\n",
      "-------------------------------\n",
      "loss: 0.246989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397683 \n",
      "\n",
      "Epoch 3292\n",
      "-------------------------------\n",
      "loss: 0.239183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397536 \n",
      "\n",
      "Epoch 3293\n",
      "-------------------------------\n",
      "loss: 0.237734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398927 \n",
      "\n",
      "Epoch 3294\n",
      "-------------------------------\n",
      "loss: 0.229594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401743 \n",
      "\n",
      "Epoch 3295\n",
      "-------------------------------\n",
      "loss: 0.245651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402696 \n",
      "\n",
      "Epoch 3296\n",
      "-------------------------------\n",
      "loss: 0.238508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402810 \n",
      "\n",
      "Epoch 3297\n",
      "-------------------------------\n",
      "loss: 0.249909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402306 \n",
      "\n",
      "Epoch 3298\n",
      "-------------------------------\n",
      "loss: 0.244322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404033 \n",
      "\n",
      "Epoch 3299\n",
      "-------------------------------\n",
      "loss: 0.230407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405422 \n",
      "\n",
      "Epoch 3300\n",
      "-------------------------------\n",
      "loss: 0.235767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406530 \n",
      "\n",
      "Epoch 3301\n",
      "-------------------------------\n",
      "loss: 0.228510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404759 \n",
      "\n",
      "Epoch 3302\n",
      "-------------------------------\n",
      "loss: 0.235437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403138 \n",
      "\n",
      "Epoch 3303\n",
      "-------------------------------\n",
      "loss: 0.241596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401535 \n",
      "\n",
      "Epoch 3304\n",
      "-------------------------------\n",
      "loss: 0.233662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400530 \n",
      "\n",
      "Epoch 3305\n",
      "-------------------------------\n",
      "loss: 0.251053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400120 \n",
      "\n",
      "Epoch 3306\n",
      "-------------------------------\n",
      "loss: 0.220434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399811 \n",
      "\n",
      "Epoch 3307\n",
      "-------------------------------\n",
      "loss: 0.247737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399782 \n",
      "\n",
      "Epoch 3308\n",
      "-------------------------------\n",
      "loss: 0.243301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400897 \n",
      "\n",
      "Epoch 3309\n",
      "-------------------------------\n",
      "loss: 0.225022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402036 \n",
      "\n",
      "Epoch 3310\n",
      "-------------------------------\n",
      "loss: 0.244381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400809 \n",
      "\n",
      "Epoch 3311\n",
      "-------------------------------\n",
      "loss: 0.232323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399471 \n",
      "\n",
      "Epoch 3312\n",
      "-------------------------------\n",
      "loss: 0.231749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398569 \n",
      "\n",
      "Epoch 3313\n",
      "-------------------------------\n",
      "loss: 0.229042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397971 \n",
      "\n",
      "Epoch 3314\n",
      "-------------------------------\n",
      "loss: 0.229962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397630 \n",
      "\n",
      "Epoch 3315\n",
      "-------------------------------\n",
      "loss: 0.241429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398017 \n",
      "\n",
      "Epoch 3316\n",
      "-------------------------------\n",
      "loss: 0.234859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399132 \n",
      "\n",
      "Epoch 3317\n",
      "-------------------------------\n",
      "loss: 0.242980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401031 \n",
      "\n",
      "Epoch 3318\n",
      "-------------------------------\n",
      "loss: 0.238902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401453 \n",
      "\n",
      "Epoch 3319\n",
      "-------------------------------\n",
      "loss: 0.238028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401241 \n",
      "\n",
      "Epoch 3320\n",
      "-------------------------------\n",
      "loss: 0.220118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400451 \n",
      "\n",
      "Epoch 3321\n",
      "-------------------------------\n",
      "loss: 0.234002  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399835 \n",
      "\n",
      "Epoch 3322\n",
      "-------------------------------\n",
      "loss: 0.237813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399713 \n",
      "\n",
      "Epoch 3323\n",
      "-------------------------------\n",
      "loss: 0.241894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400582 \n",
      "\n",
      "Epoch 3324\n",
      "-------------------------------\n",
      "loss: 0.245357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401659 \n",
      "\n",
      "Epoch 3325\n",
      "-------------------------------\n",
      "loss: 0.238879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402474 \n",
      "\n",
      "Epoch 3326\n",
      "-------------------------------\n",
      "loss: 0.226446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402664 \n",
      "\n",
      "Epoch 3327\n",
      "-------------------------------\n",
      "loss: 0.235054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402080 \n",
      "\n",
      "Epoch 3328\n",
      "-------------------------------\n",
      "loss: 0.222693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402261 \n",
      "\n",
      "Epoch 3329\n",
      "-------------------------------\n",
      "loss: 0.239060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402500 \n",
      "\n",
      "Epoch 3330\n",
      "-------------------------------\n",
      "loss: 0.233663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402734 \n",
      "\n",
      "Epoch 3331\n",
      "-------------------------------\n",
      "loss: 0.245376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402639 \n",
      "\n",
      "Epoch 3332\n",
      "-------------------------------\n",
      "loss: 0.226862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402416 \n",
      "\n",
      "Epoch 3333\n",
      "-------------------------------\n",
      "loss: 0.245995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401863 \n",
      "\n",
      "Epoch 3334\n",
      "-------------------------------\n",
      "loss: 0.239713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401066 \n",
      "\n",
      "Epoch 3335\n",
      "-------------------------------\n",
      "loss: 0.225089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 3336\n",
      "-------------------------------\n",
      "loss: 0.232787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400965 \n",
      "\n",
      "Epoch 3337\n",
      "-------------------------------\n",
      "loss: 0.227344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401414 \n",
      "\n",
      "Epoch 3338\n",
      "-------------------------------\n",
      "loss: 0.239386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401820 \n",
      "\n",
      "Epoch 3339\n",
      "-------------------------------\n",
      "loss: 0.248832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401687 \n",
      "\n",
      "Epoch 3340\n",
      "-------------------------------\n",
      "loss: 0.237896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400699 \n",
      "\n",
      "Epoch 3341\n",
      "-------------------------------\n",
      "loss: 0.226905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399122 \n",
      "\n",
      "Epoch 3342\n",
      "-------------------------------\n",
      "loss: 0.221139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398467 \n",
      "\n",
      "Epoch 3343\n",
      "-------------------------------\n",
      "loss: 0.231589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398132 \n",
      "\n",
      "Epoch 3344\n",
      "-------------------------------\n",
      "loss: 0.248349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397499 \n",
      "\n",
      "Epoch 3345\n",
      "-------------------------------\n",
      "loss: 0.243376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396631 \n",
      "\n",
      "Epoch 3346\n",
      "-------------------------------\n",
      "loss: 0.232662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396978 \n",
      "\n",
      "Epoch 3347\n",
      "-------------------------------\n",
      "loss: 0.217078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397036 \n",
      "\n",
      "Epoch 3348\n",
      "-------------------------------\n",
      "loss: 0.233923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397530 \n",
      "\n",
      "Epoch 3349\n",
      "-------------------------------\n",
      "loss: 0.245882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398152 \n",
      "\n",
      "Epoch 3350\n",
      "-------------------------------\n",
      "loss: 0.222719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398733 \n",
      "\n",
      "Epoch 3351\n",
      "-------------------------------\n",
      "loss: 0.231498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399390 \n",
      "\n",
      "Epoch 3352\n",
      "-------------------------------\n",
      "loss: 0.234543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400266 \n",
      "\n",
      "Epoch 3353\n",
      "-------------------------------\n",
      "loss: 0.235157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399445 \n",
      "\n",
      "Epoch 3354\n",
      "-------------------------------\n",
      "loss: 0.238147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399116 \n",
      "\n",
      "Epoch 3355\n",
      "-------------------------------\n",
      "loss: 0.246602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398783 \n",
      "\n",
      "Epoch 3356\n",
      "-------------------------------\n",
      "loss: 0.226095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399150 \n",
      "\n",
      "Epoch 3357\n",
      "-------------------------------\n",
      "loss: 0.226064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400020 \n",
      "\n",
      "Epoch 3358\n",
      "-------------------------------\n",
      "loss: 0.229107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400361 \n",
      "\n",
      "Epoch 3359\n",
      "-------------------------------\n",
      "loss: 0.232145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401957 \n",
      "\n",
      "Epoch 3360\n",
      "-------------------------------\n",
      "loss: 0.228024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404362 \n",
      "\n",
      "Epoch 3361\n",
      "-------------------------------\n",
      "loss: 0.240427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405452 \n",
      "\n",
      "Epoch 3362\n",
      "-------------------------------\n",
      "loss: 0.254035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402097 \n",
      "\n",
      "Epoch 3363\n",
      "-------------------------------\n",
      "loss: 0.233398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398444 \n",
      "\n",
      "Epoch 3364\n",
      "-------------------------------\n",
      "loss: 0.233060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397851 \n",
      "\n",
      "Epoch 3365\n",
      "-------------------------------\n",
      "loss: 0.238964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399456 \n",
      "\n",
      "Epoch 3366\n",
      "-------------------------------\n",
      "loss: 0.253851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399818 \n",
      "\n",
      "Epoch 3367\n",
      "-------------------------------\n",
      "loss: 0.239939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398706 \n",
      "\n",
      "Epoch 3368\n",
      "-------------------------------\n",
      "loss: 0.220412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399485 \n",
      "\n",
      "Epoch 3369\n",
      "-------------------------------\n",
      "loss: 0.237820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401657 \n",
      "\n",
      "Epoch 3370\n",
      "-------------------------------\n",
      "loss: 0.244649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403233 \n",
      "\n",
      "Epoch 3371\n",
      "-------------------------------\n",
      "loss: 0.247415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403733 \n",
      "\n",
      "Epoch 3372\n",
      "-------------------------------\n",
      "loss: 0.220318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403571 \n",
      "\n",
      "Epoch 3373\n",
      "-------------------------------\n",
      "loss: 0.240478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401887 \n",
      "\n",
      "Epoch 3374\n",
      "-------------------------------\n",
      "loss: 0.240561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401742 \n",
      "\n",
      "Epoch 3375\n",
      "-------------------------------\n",
      "loss: 0.250250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402906 \n",
      "\n",
      "Epoch 3376\n",
      "-------------------------------\n",
      "loss: 0.233561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403317 \n",
      "\n",
      "Epoch 3377\n",
      "-------------------------------\n",
      "loss: 0.240496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402946 \n",
      "\n",
      "Epoch 3378\n",
      "-------------------------------\n",
      "loss: 0.233826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402338 \n",
      "\n",
      "Epoch 3379\n",
      "-------------------------------\n",
      "loss: 0.234186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401502 \n",
      "\n",
      "Epoch 3380\n",
      "-------------------------------\n",
      "loss: 0.235092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402301 \n",
      "\n",
      "Epoch 3381\n",
      "-------------------------------\n",
      "loss: 0.237733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403087 \n",
      "\n",
      "Epoch 3382\n",
      "-------------------------------\n",
      "loss: 0.228298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403005 \n",
      "\n",
      "Epoch 3383\n",
      "-------------------------------\n",
      "loss: 0.245842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401765 \n",
      "\n",
      "Epoch 3384\n",
      "-------------------------------\n",
      "loss: 0.220235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399914 \n",
      "\n",
      "Epoch 3385\n",
      "-------------------------------\n",
      "loss: 0.234700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399175 \n",
      "\n",
      "Epoch 3386\n",
      "-------------------------------\n",
      "loss: 0.243420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398430 \n",
      "\n",
      "Epoch 3387\n",
      "-------------------------------\n",
      "loss: 0.232418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398340 \n",
      "\n",
      "Epoch 3388\n",
      "-------------------------------\n",
      "loss: 0.237690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397247 \n",
      "\n",
      "Epoch 3389\n",
      "-------------------------------\n",
      "loss: 0.235445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396243 \n",
      "\n",
      "Epoch 3390\n",
      "-------------------------------\n",
      "loss: 0.238249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396137 \n",
      "\n",
      "Epoch 3391\n",
      "-------------------------------\n",
      "loss: 0.226008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396608 \n",
      "\n",
      "Epoch 3392\n",
      "-------------------------------\n",
      "loss: 0.231055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398656 \n",
      "\n",
      "Epoch 3393\n",
      "-------------------------------\n",
      "loss: 0.244954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401280 \n",
      "\n",
      "Epoch 3394\n",
      "-------------------------------\n",
      "loss: 0.232838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403527 \n",
      "\n",
      "Epoch 3395\n",
      "-------------------------------\n",
      "loss: 0.238710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402951 \n",
      "\n",
      "Epoch 3396\n",
      "-------------------------------\n",
      "loss: 0.235378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400531 \n",
      "\n",
      "Epoch 3397\n",
      "-------------------------------\n",
      "loss: 0.222569  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399984 \n",
      "\n",
      "Epoch 3398\n",
      "-------------------------------\n",
      "loss: 0.226816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400679 \n",
      "\n",
      "Epoch 3399\n",
      "-------------------------------\n",
      "loss: 0.226625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401333 \n",
      "\n",
      "Epoch 3400\n",
      "-------------------------------\n",
      "loss: 0.240969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401613 \n",
      "\n",
      "Epoch 3401\n",
      "-------------------------------\n",
      "loss: 0.245920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401637 \n",
      "\n",
      "Epoch 3402\n",
      "-------------------------------\n",
      "loss: 0.240320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402249 \n",
      "\n",
      "Epoch 3403\n",
      "-------------------------------\n",
      "loss: 0.222836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403007 \n",
      "\n",
      "Epoch 3404\n",
      "-------------------------------\n",
      "loss: 0.244199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403550 \n",
      "\n",
      "Epoch 3405\n",
      "-------------------------------\n",
      "loss: 0.226722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403986 \n",
      "\n",
      "Epoch 3406\n",
      "-------------------------------\n",
      "loss: 0.244951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404360 \n",
      "\n",
      "Epoch 3407\n",
      "-------------------------------\n",
      "loss: 0.234498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404806 \n",
      "\n",
      "Epoch 3408\n",
      "-------------------------------\n",
      "loss: 0.231149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405865 \n",
      "\n",
      "Epoch 3409\n",
      "-------------------------------\n",
      "loss: 0.241586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406611 \n",
      "\n",
      "Epoch 3410\n",
      "-------------------------------\n",
      "loss: 0.218055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406991 \n",
      "\n",
      "Epoch 3411\n",
      "-------------------------------\n",
      "loss: 0.229341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406157 \n",
      "\n",
      "Epoch 3412\n",
      "-------------------------------\n",
      "loss: 0.232754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405547 \n",
      "\n",
      "Epoch 3413\n",
      "-------------------------------\n",
      "loss: 0.222322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405478 \n",
      "\n",
      "Epoch 3414\n",
      "-------------------------------\n",
      "loss: 0.240848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405853 \n",
      "\n",
      "Epoch 3415\n",
      "-------------------------------\n",
      "loss: 0.220431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406164 \n",
      "\n",
      "Epoch 3416\n",
      "-------------------------------\n",
      "loss: 0.240786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406240 \n",
      "\n",
      "Epoch 3417\n",
      "-------------------------------\n",
      "loss: 0.254906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406991 \n",
      "\n",
      "Epoch 3418\n",
      "-------------------------------\n",
      "loss: 0.249001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408445 \n",
      "\n",
      "Epoch 3419\n",
      "-------------------------------\n",
      "loss: 0.236367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409495 \n",
      "\n",
      "Epoch 3420\n",
      "-------------------------------\n",
      "loss: 0.247829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408247 \n",
      "\n",
      "Epoch 3421\n",
      "-------------------------------\n",
      "loss: 0.224681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406299 \n",
      "\n",
      "Epoch 3422\n",
      "-------------------------------\n",
      "loss: 0.231743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405899 \n",
      "\n",
      "Epoch 3423\n",
      "-------------------------------\n",
      "loss: 0.220571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405799 \n",
      "\n",
      "Epoch 3424\n",
      "-------------------------------\n",
      "loss: 0.228699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405826 \n",
      "\n",
      "Epoch 3425\n",
      "-------------------------------\n",
      "loss: 0.241262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405739 \n",
      "\n",
      "Epoch 3426\n",
      "-------------------------------\n",
      "loss: 0.235341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405872 \n",
      "\n",
      "Epoch 3427\n",
      "-------------------------------\n",
      "loss: 0.240680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405479 \n",
      "\n",
      "Epoch 3428\n",
      "-------------------------------\n",
      "loss: 0.235964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404088 \n",
      "\n",
      "Epoch 3429\n",
      "-------------------------------\n",
      "loss: 0.234165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402444 \n",
      "\n",
      "Epoch 3430\n",
      "-------------------------------\n",
      "loss: 0.219342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401643 \n",
      "\n",
      "Epoch 3431\n",
      "-------------------------------\n",
      "loss: 0.221740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401669 \n",
      "\n",
      "Epoch 3432\n",
      "-------------------------------\n",
      "loss: 0.241607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403153 \n",
      "\n",
      "Epoch 3433\n",
      "-------------------------------\n",
      "loss: 0.217137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403990 \n",
      "\n",
      "Epoch 3434\n",
      "-------------------------------\n",
      "loss: 0.225205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403438 \n",
      "\n",
      "Epoch 3435\n",
      "-------------------------------\n",
      "loss: 0.229742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402615 \n",
      "\n",
      "Epoch 3436\n",
      "-------------------------------\n",
      "loss: 0.231474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402121 \n",
      "\n",
      "Epoch 3437\n",
      "-------------------------------\n",
      "loss: 0.241812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401388 \n",
      "\n",
      "Epoch 3438\n",
      "-------------------------------\n",
      "loss: 0.226553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401302 \n",
      "\n",
      "Epoch 3439\n",
      "-------------------------------\n",
      "loss: 0.228797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401852 \n",
      "\n",
      "Epoch 3440\n",
      "-------------------------------\n",
      "loss: 0.229567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403152 \n",
      "\n",
      "Epoch 3441\n",
      "-------------------------------\n",
      "loss: 0.229263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406075 \n",
      "\n",
      "Epoch 3442\n",
      "-------------------------------\n",
      "loss: 0.214172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409315 \n",
      "\n",
      "Epoch 3443\n",
      "-------------------------------\n",
      "loss: 0.263491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408196 \n",
      "\n",
      "Epoch 3444\n",
      "-------------------------------\n",
      "loss: 0.223984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404383 \n",
      "\n",
      "Epoch 3445\n",
      "-------------------------------\n",
      "loss: 0.240802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400196 \n",
      "\n",
      "Epoch 3446\n",
      "-------------------------------\n",
      "loss: 0.235681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398767 \n",
      "\n",
      "Epoch 3447\n",
      "-------------------------------\n",
      "loss: 0.225941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398585 \n",
      "\n",
      "Epoch 3448\n",
      "-------------------------------\n",
      "loss: 0.240100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398004 \n",
      "\n",
      "Epoch 3449\n",
      "-------------------------------\n",
      "loss: 0.227522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397080 \n",
      "\n",
      "Epoch 3450\n",
      "-------------------------------\n",
      "loss: 0.217032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397305 \n",
      "\n",
      "Epoch 3451\n",
      "-------------------------------\n",
      "loss: 0.229178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401205 \n",
      "\n",
      "Epoch 3452\n",
      "-------------------------------\n",
      "loss: 0.224387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406630 \n",
      "\n",
      "Epoch 3453\n",
      "-------------------------------\n",
      "loss: 0.249163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407205 \n",
      "\n",
      "Epoch 3454\n",
      "-------------------------------\n",
      "loss: 0.232882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403950 \n",
      "\n",
      "Epoch 3455\n",
      "-------------------------------\n",
      "loss: 0.247405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399574 \n",
      "\n",
      "Epoch 3456\n",
      "-------------------------------\n",
      "loss: 0.239965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397724 \n",
      "\n",
      "Epoch 3457\n",
      "-------------------------------\n",
      "loss: 0.242248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398465 \n",
      "\n",
      "Epoch 3458\n",
      "-------------------------------\n",
      "loss: 0.241760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399099 \n",
      "\n",
      "Epoch 3459\n",
      "-------------------------------\n",
      "loss: 0.222688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398385 \n",
      "\n",
      "Epoch 3460\n",
      "-------------------------------\n",
      "loss: 0.232515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399203 \n",
      "\n",
      "Epoch 3461\n",
      "-------------------------------\n",
      "loss: 0.245161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402245 \n",
      "\n",
      "Epoch 3462\n",
      "-------------------------------\n",
      "loss: 0.230560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405770 \n",
      "\n",
      "Epoch 3463\n",
      "-------------------------------\n",
      "loss: 0.230893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407115 \n",
      "\n",
      "Epoch 3464\n",
      "-------------------------------\n",
      "loss: 0.234541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407039 \n",
      "\n",
      "Epoch 3465\n",
      "-------------------------------\n",
      "loss: 0.219779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404780 \n",
      "\n",
      "Epoch 3466\n",
      "-------------------------------\n",
      "loss: 0.236113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402937 \n",
      "\n",
      "Epoch 3467\n",
      "-------------------------------\n",
      "loss: 0.236422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402103 \n",
      "\n",
      "Epoch 3468\n",
      "-------------------------------\n",
      "loss: 0.238143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401581 \n",
      "\n",
      "Epoch 3469\n",
      "-------------------------------\n",
      "loss: 0.230766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401353 \n",
      "\n",
      "Epoch 3470\n",
      "-------------------------------\n",
      "loss: 0.220458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401774 \n",
      "\n",
      "Epoch 3471\n",
      "-------------------------------\n",
      "loss: 0.225661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403345 \n",
      "\n",
      "Epoch 3472\n",
      "-------------------------------\n",
      "loss: 0.234783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406466 \n",
      "\n",
      "Epoch 3473\n",
      "-------------------------------\n",
      "loss: 0.239348  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.407948 \n",
      "\n",
      "Epoch 3474\n",
      "-------------------------------\n",
      "loss: 0.246902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405168 \n",
      "\n",
      "Epoch 3475\n",
      "-------------------------------\n",
      "loss: 0.232920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400922 \n",
      "\n",
      "Epoch 3476\n",
      "-------------------------------\n",
      "loss: 0.238717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398977 \n",
      "\n",
      "Epoch 3477\n",
      "-------------------------------\n",
      "loss: 0.245931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398646 \n",
      "\n",
      "Epoch 3478\n",
      "-------------------------------\n",
      "loss: 0.228542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398901 \n",
      "\n",
      "Epoch 3479\n",
      "-------------------------------\n",
      "loss: 0.237257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399130 \n",
      "\n",
      "Epoch 3480\n",
      "-------------------------------\n",
      "loss: 0.225931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400474 \n",
      "\n",
      "Epoch 3481\n",
      "-------------------------------\n",
      "loss: 0.231975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402691 \n",
      "\n",
      "Epoch 3482\n",
      "-------------------------------\n",
      "loss: 0.232332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403834 \n",
      "\n",
      "Epoch 3483\n",
      "-------------------------------\n",
      "loss: 0.233924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403921 \n",
      "\n",
      "Epoch 3484\n",
      "-------------------------------\n",
      "loss: 0.239940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402368 \n",
      "\n",
      "Epoch 3485\n",
      "-------------------------------\n",
      "loss: 0.242834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400915 \n",
      "\n",
      "Epoch 3486\n",
      "-------------------------------\n",
      "loss: 0.232586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401151 \n",
      "\n",
      "Epoch 3487\n",
      "-------------------------------\n",
      "loss: 0.252678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401559 \n",
      "\n",
      "Epoch 3488\n",
      "-------------------------------\n",
      "loss: 0.239714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401624 \n",
      "\n",
      "Epoch 3489\n",
      "-------------------------------\n",
      "loss: 0.254726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401111 \n",
      "\n",
      "Epoch 3490\n",
      "-------------------------------\n",
      "loss: 0.236481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400742 \n",
      "\n",
      "Epoch 3491\n",
      "-------------------------------\n",
      "loss: 0.217684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402156 \n",
      "\n",
      "Epoch 3492\n",
      "-------------------------------\n",
      "loss: 0.232122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403499 \n",
      "\n",
      "Epoch 3493\n",
      "-------------------------------\n",
      "loss: 0.224301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403548 \n",
      "\n",
      "Epoch 3494\n",
      "-------------------------------\n",
      "loss: 0.236986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404263 \n",
      "\n",
      "Epoch 3495\n",
      "-------------------------------\n",
      "loss: 0.235550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404507 \n",
      "\n",
      "Epoch 3496\n",
      "-------------------------------\n",
      "loss: 0.230332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403559 \n",
      "\n",
      "Epoch 3497\n",
      "-------------------------------\n",
      "loss: 0.222025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403592 \n",
      "\n",
      "Epoch 3498\n",
      "-------------------------------\n",
      "loss: 0.252656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403085 \n",
      "\n",
      "Epoch 3499\n",
      "-------------------------------\n",
      "loss: 0.241176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402333 \n",
      "\n",
      "Epoch 3500\n",
      "-------------------------------\n",
      "loss: 0.230613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401716 \n",
      "\n",
      "Epoch 3501\n",
      "-------------------------------\n",
      "loss: 0.242304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401357 \n",
      "\n",
      "Epoch 3502\n",
      "-------------------------------\n",
      "loss: 0.222498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401168 \n",
      "\n",
      "Epoch 3503\n",
      "-------------------------------\n",
      "loss: 0.224868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401874 \n",
      "\n",
      "Epoch 3504\n",
      "-------------------------------\n",
      "loss: 0.229577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402804 \n",
      "\n",
      "Epoch 3505\n",
      "-------------------------------\n",
      "loss: 0.239198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403221 \n",
      "\n",
      "Epoch 3506\n",
      "-------------------------------\n",
      "loss: 0.239977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403020 \n",
      "\n",
      "Epoch 3507\n",
      "-------------------------------\n",
      "loss: 0.231029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401585 \n",
      "\n",
      "Epoch 3508\n",
      "-------------------------------\n",
      "loss: 0.226343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401005 \n",
      "\n",
      "Epoch 3509\n",
      "-------------------------------\n",
      "loss: 0.234306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400747 \n",
      "\n",
      "Epoch 3510\n",
      "-------------------------------\n",
      "loss: 0.230494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400890 \n",
      "\n",
      "Epoch 3511\n",
      "-------------------------------\n",
      "loss: 0.239861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401607 \n",
      "\n",
      "Epoch 3512\n",
      "-------------------------------\n",
      "loss: 0.227766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402775 \n",
      "\n",
      "Epoch 3513\n",
      "-------------------------------\n",
      "loss: 0.238146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404863 \n",
      "\n",
      "Epoch 3514\n",
      "-------------------------------\n",
      "loss: 0.228912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404968 \n",
      "\n",
      "Epoch 3515\n",
      "-------------------------------\n",
      "loss: 0.229979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403143 \n",
      "\n",
      "Epoch 3516\n",
      "-------------------------------\n",
      "loss: 0.236685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402573 \n",
      "\n",
      "Epoch 3517\n",
      "-------------------------------\n",
      "loss: 0.237010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402582 \n",
      "\n",
      "Epoch 3518\n",
      "-------------------------------\n",
      "loss: 0.250315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402433 \n",
      "\n",
      "Epoch 3519\n",
      "-------------------------------\n",
      "loss: 0.219163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402564 \n",
      "\n",
      "Epoch 3520\n",
      "-------------------------------\n",
      "loss: 0.247622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402568 \n",
      "\n",
      "Epoch 3521\n",
      "-------------------------------\n",
      "loss: 0.223454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402187 \n",
      "\n",
      "Epoch 3522\n",
      "-------------------------------\n",
      "loss: 0.233509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401454 \n",
      "\n",
      "Epoch 3523\n",
      "-------------------------------\n",
      "loss: 0.222822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400447 \n",
      "\n",
      "Epoch 3524\n",
      "-------------------------------\n",
      "loss: 0.237733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399445 \n",
      "\n",
      "Epoch 3525\n",
      "-------------------------------\n",
      "loss: 0.234330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399166 \n",
      "\n",
      "Epoch 3526\n",
      "-------------------------------\n",
      "loss: 0.240492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398564 \n",
      "\n",
      "Epoch 3527\n",
      "-------------------------------\n",
      "loss: 0.229024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398095 \n",
      "\n",
      "Epoch 3528\n",
      "-------------------------------\n",
      "loss: 0.228699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400768 \n",
      "\n",
      "Epoch 3529\n",
      "-------------------------------\n",
      "loss: 0.235079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405551 \n",
      "\n",
      "Epoch 3530\n",
      "-------------------------------\n",
      "loss: 0.241856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407570 \n",
      "\n",
      "Epoch 3531\n",
      "-------------------------------\n",
      "loss: 0.230325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406280 \n",
      "\n",
      "Epoch 3532\n",
      "-------------------------------\n",
      "loss: 0.214039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403437 \n",
      "\n",
      "Epoch 3533\n",
      "-------------------------------\n",
      "loss: 0.226194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401276 \n",
      "\n",
      "Epoch 3534\n",
      "-------------------------------\n",
      "loss: 0.218249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399397 \n",
      "\n",
      "Epoch 3535\n",
      "-------------------------------\n",
      "loss: 0.240312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397606 \n",
      "\n",
      "Epoch 3536\n",
      "-------------------------------\n",
      "loss: 0.231164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396579 \n",
      "\n",
      "Epoch 3537\n",
      "-------------------------------\n",
      "loss: 0.222663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396375 \n",
      "\n",
      "Epoch 3538\n",
      "-------------------------------\n",
      "loss: 0.219855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398010 \n",
      "\n",
      "Epoch 3539\n",
      "-------------------------------\n",
      "loss: 0.233671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398473 \n",
      "\n",
      "Epoch 3540\n",
      "-------------------------------\n",
      "loss: 0.239823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397413 \n",
      "\n",
      "Epoch 3541\n",
      "-------------------------------\n",
      "loss: 0.223245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397366 \n",
      "\n",
      "Epoch 3542\n",
      "-------------------------------\n",
      "loss: 0.224629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397430 \n",
      "\n",
      "Epoch 3543\n",
      "-------------------------------\n",
      "loss: 0.234708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397454 \n",
      "\n",
      "Epoch 3544\n",
      "-------------------------------\n",
      "loss: 0.231508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398068 \n",
      "\n",
      "Epoch 3545\n",
      "-------------------------------\n",
      "loss: 0.236374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399199 \n",
      "\n",
      "Epoch 3546\n",
      "-------------------------------\n",
      "loss: 0.236693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400546 \n",
      "\n",
      "Epoch 3547\n",
      "-------------------------------\n",
      "loss: 0.251557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403817 \n",
      "\n",
      "Epoch 3548\n",
      "-------------------------------\n",
      "loss: 0.233838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407537 \n",
      "\n",
      "Epoch 3549\n",
      "-------------------------------\n",
      "loss: 0.247058  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.408861 \n",
      "\n",
      "Epoch 3550\n",
      "-------------------------------\n",
      "loss: 0.253685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407220 \n",
      "\n",
      "Epoch 3551\n",
      "-------------------------------\n",
      "loss: 0.226467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405845 \n",
      "\n",
      "Epoch 3552\n",
      "-------------------------------\n",
      "loss: 0.227051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403588 \n",
      "\n",
      "Epoch 3553\n",
      "-------------------------------\n",
      "loss: 0.232510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402115 \n",
      "\n",
      "Epoch 3554\n",
      "-------------------------------\n",
      "loss: 0.217316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402105 \n",
      "\n",
      "Epoch 3555\n",
      "-------------------------------\n",
      "loss: 0.238139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402108 \n",
      "\n",
      "Epoch 3556\n",
      "-------------------------------\n",
      "loss: 0.223488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402002 \n",
      "\n",
      "Epoch 3557\n",
      "-------------------------------\n",
      "loss: 0.225780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402721 \n",
      "\n",
      "Epoch 3558\n",
      "-------------------------------\n",
      "loss: 0.232006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404075 \n",
      "\n",
      "Epoch 3559\n",
      "-------------------------------\n",
      "loss: 0.234546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404072 \n",
      "\n",
      "Epoch 3560\n",
      "-------------------------------\n",
      "loss: 0.236398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403439 \n",
      "\n",
      "Epoch 3561\n",
      "-------------------------------\n",
      "loss: 0.233685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401641 \n",
      "\n",
      "Epoch 3562\n",
      "-------------------------------\n",
      "loss: 0.240034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400612 \n",
      "\n",
      "Epoch 3563\n",
      "-------------------------------\n",
      "loss: 0.229211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400653 \n",
      "\n",
      "Epoch 3564\n",
      "-------------------------------\n",
      "loss: 0.223755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401190 \n",
      "\n",
      "Epoch 3565\n",
      "-------------------------------\n",
      "loss: 0.232316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401629 \n",
      "\n",
      "Epoch 3566\n",
      "-------------------------------\n",
      "loss: 0.236044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401610 \n",
      "\n",
      "Epoch 3567\n",
      "-------------------------------\n",
      "loss: 0.230121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402199 \n",
      "\n",
      "Epoch 3568\n",
      "-------------------------------\n",
      "loss: 0.241104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402620 \n",
      "\n",
      "Epoch 3569\n",
      "-------------------------------\n",
      "loss: 0.244641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402178 \n",
      "\n",
      "Epoch 3570\n",
      "-------------------------------\n",
      "loss: 0.232956  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402270 \n",
      "\n",
      "Epoch 3571\n",
      "-------------------------------\n",
      "loss: 0.224064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402774 \n",
      "\n",
      "Epoch 3572\n",
      "-------------------------------\n",
      "loss: 0.240833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403069 \n",
      "\n",
      "Epoch 3573\n",
      "-------------------------------\n",
      "loss: 0.243473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401636 \n",
      "\n",
      "Epoch 3574\n",
      "-------------------------------\n",
      "loss: 0.229413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399173 \n",
      "\n",
      "Epoch 3575\n",
      "-------------------------------\n",
      "loss: 0.237697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398140 \n",
      "\n",
      "Epoch 3576\n",
      "-------------------------------\n",
      "loss: 0.240015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401313 \n",
      "\n",
      "Epoch 3577\n",
      "-------------------------------\n",
      "loss: 0.237188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406570 \n",
      "\n",
      "Epoch 3578\n",
      "-------------------------------\n",
      "loss: 0.243983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410590 \n",
      "\n",
      "Epoch 3579\n",
      "-------------------------------\n",
      "loss: 0.244491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410005 \n",
      "\n",
      "Epoch 3580\n",
      "-------------------------------\n",
      "loss: 0.251249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407275 \n",
      "\n",
      "Epoch 3581\n",
      "-------------------------------\n",
      "loss: 0.255560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404831 \n",
      "\n",
      "Epoch 3582\n",
      "-------------------------------\n",
      "loss: 0.238074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403655 \n",
      "\n",
      "Epoch 3583\n",
      "-------------------------------\n",
      "loss: 0.229534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403383 \n",
      "\n",
      "Epoch 3584\n",
      "-------------------------------\n",
      "loss: 0.230294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403308 \n",
      "\n",
      "Epoch 3585\n",
      "-------------------------------\n",
      "loss: 0.243627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404312 \n",
      "\n",
      "Epoch 3586\n",
      "-------------------------------\n",
      "loss: 0.232908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408518 \n",
      "\n",
      "Epoch 3587\n",
      "-------------------------------\n",
      "loss: 0.224392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413187 \n",
      "\n",
      "Epoch 3588\n",
      "-------------------------------\n",
      "loss: 0.240704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415982 \n",
      "\n",
      "Epoch 3589\n",
      "-------------------------------\n",
      "loss: 0.244220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416345 \n",
      "\n",
      "Epoch 3590\n",
      "-------------------------------\n",
      "loss: 0.241487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412097 \n",
      "\n",
      "Epoch 3591\n",
      "-------------------------------\n",
      "loss: 0.228230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408674 \n",
      "\n",
      "Epoch 3592\n",
      "-------------------------------\n",
      "loss: 0.225109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406858 \n",
      "\n",
      "Epoch 3593\n",
      "-------------------------------\n",
      "loss: 0.225438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405563 \n",
      "\n",
      "Epoch 3594\n",
      "-------------------------------\n",
      "loss: 0.242973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405555 \n",
      "\n",
      "Epoch 3595\n",
      "-------------------------------\n",
      "loss: 0.233480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406151 \n",
      "\n",
      "Epoch 3596\n",
      "-------------------------------\n",
      "loss: 0.236555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406804 \n",
      "\n",
      "Epoch 3597\n",
      "-------------------------------\n",
      "loss: 0.238517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404616 \n",
      "\n",
      "Epoch 3598\n",
      "-------------------------------\n",
      "loss: 0.230577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402463 \n",
      "\n",
      "Epoch 3599\n",
      "-------------------------------\n",
      "loss: 0.235833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401257 \n",
      "\n",
      "Epoch 3600\n",
      "-------------------------------\n",
      "loss: 0.232157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400796 \n",
      "\n",
      "Epoch 3601\n",
      "-------------------------------\n",
      "loss: 0.239080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400685 \n",
      "\n",
      "Epoch 3602\n",
      "-------------------------------\n",
      "loss: 0.235329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400805 \n",
      "\n",
      "Epoch 3603\n",
      "-------------------------------\n",
      "loss: 0.227586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400806 \n",
      "\n",
      "Epoch 3604\n",
      "-------------------------------\n",
      "loss: 0.236992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400237 \n",
      "\n",
      "Epoch 3605\n",
      "-------------------------------\n",
      "loss: 0.220795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400293 \n",
      "\n",
      "Epoch 3606\n",
      "-------------------------------\n",
      "loss: 0.229482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399657 \n",
      "\n",
      "Epoch 3607\n",
      "-------------------------------\n",
      "loss: 0.215421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398862 \n",
      "\n",
      "Epoch 3608\n",
      "-------------------------------\n",
      "loss: 0.216315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398237 \n",
      "\n",
      "Epoch 3609\n",
      "-------------------------------\n",
      "loss: 0.227314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397879 \n",
      "\n",
      "Epoch 3610\n",
      "-------------------------------\n",
      "loss: 0.232366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397997 \n",
      "\n",
      "Epoch 3611\n",
      "-------------------------------\n",
      "loss: 0.233932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397574 \n",
      "\n",
      "Epoch 3612\n",
      "-------------------------------\n",
      "loss: 0.231221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398030 \n",
      "\n",
      "Epoch 3613\n",
      "-------------------------------\n",
      "loss: 0.232601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398245 \n",
      "\n",
      "Epoch 3614\n",
      "-------------------------------\n",
      "loss: 0.223458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399603 \n",
      "\n",
      "Epoch 3615\n",
      "-------------------------------\n",
      "loss: 0.240143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400360 \n",
      "\n",
      "Epoch 3616\n",
      "-------------------------------\n",
      "loss: 0.224668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401668 \n",
      "\n",
      "Epoch 3617\n",
      "-------------------------------\n",
      "loss: 0.231222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402290 \n",
      "\n",
      "Epoch 3618\n",
      "-------------------------------\n",
      "loss: 0.222290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403554 \n",
      "\n",
      "Epoch 3619\n",
      "-------------------------------\n",
      "loss: 0.229473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402989 \n",
      "\n",
      "Epoch 3620\n",
      "-------------------------------\n",
      "loss: 0.232874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400316 \n",
      "\n",
      "Epoch 3621\n",
      "-------------------------------\n",
      "loss: 0.225470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399682 \n",
      "\n",
      "Epoch 3622\n",
      "-------------------------------\n",
      "loss: 0.227910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400241 \n",
      "\n",
      "Epoch 3623\n",
      "-------------------------------\n",
      "loss: 0.232907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400672 \n",
      "\n",
      "Epoch 3624\n",
      "-------------------------------\n",
      "loss: 0.233224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402620 \n",
      "\n",
      "Epoch 3625\n",
      "-------------------------------\n",
      "loss: 0.246203  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403756 \n",
      "\n",
      "Epoch 3626\n",
      "-------------------------------\n",
      "loss: 0.223328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403413 \n",
      "\n",
      "Epoch 3627\n",
      "-------------------------------\n",
      "loss: 0.241880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401989 \n",
      "\n",
      "Epoch 3628\n",
      "-------------------------------\n",
      "loss: 0.244068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401562 \n",
      "\n",
      "Epoch 3629\n",
      "-------------------------------\n",
      "loss: 0.232405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402133 \n",
      "\n",
      "Epoch 3630\n",
      "-------------------------------\n",
      "loss: 0.241095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402299 \n",
      "\n",
      "Epoch 3631\n",
      "-------------------------------\n",
      "loss: 0.233855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402196 \n",
      "\n",
      "Epoch 3632\n",
      "-------------------------------\n",
      "loss: 0.224674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402091 \n",
      "\n",
      "Epoch 3633\n",
      "-------------------------------\n",
      "loss: 0.240678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401381 \n",
      "\n",
      "Epoch 3634\n",
      "-------------------------------\n",
      "loss: 0.226840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401846 \n",
      "\n",
      "Epoch 3635\n",
      "-------------------------------\n",
      "loss: 0.228715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402983 \n",
      "\n",
      "Epoch 3636\n",
      "-------------------------------\n",
      "loss: 0.235135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402663 \n",
      "\n",
      "Epoch 3637\n",
      "-------------------------------\n",
      "loss: 0.235146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401342 \n",
      "\n",
      "Epoch 3638\n",
      "-------------------------------\n",
      "loss: 0.220573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400812 \n",
      "\n",
      "Epoch 3639\n",
      "-------------------------------\n",
      "loss: 0.230416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400528 \n",
      "\n",
      "Epoch 3640\n",
      "-------------------------------\n",
      "loss: 0.228687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400146 \n",
      "\n",
      "Epoch 3641\n",
      "-------------------------------\n",
      "loss: 0.236017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400217 \n",
      "\n",
      "Epoch 3642\n",
      "-------------------------------\n",
      "loss: 0.232936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401146 \n",
      "\n",
      "Epoch 3643\n",
      "-------------------------------\n",
      "loss: 0.236327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404282 \n",
      "\n",
      "Epoch 3644\n",
      "-------------------------------\n",
      "loss: 0.222816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408258 \n",
      "\n",
      "Epoch 3645\n",
      "-------------------------------\n",
      "loss: 0.237657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409012 \n",
      "\n",
      "Epoch 3646\n",
      "-------------------------------\n",
      "loss: 0.237900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406255 \n",
      "\n",
      "Epoch 3647\n",
      "-------------------------------\n",
      "loss: 0.255971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401116 \n",
      "\n",
      "Epoch 3648\n",
      "-------------------------------\n",
      "loss: 0.234401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400188 \n",
      "\n",
      "Epoch 3649\n",
      "-------------------------------\n",
      "loss: 0.236352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402437 \n",
      "\n",
      "Epoch 3650\n",
      "-------------------------------\n",
      "loss: 0.229663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403232 \n",
      "\n",
      "Epoch 3651\n",
      "-------------------------------\n",
      "loss: 0.251258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400494 \n",
      "\n",
      "Epoch 3652\n",
      "-------------------------------\n",
      "loss: 0.248138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399038 \n",
      "\n",
      "Epoch 3653\n",
      "-------------------------------\n",
      "loss: 0.238861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402496 \n",
      "\n",
      "Epoch 3654\n",
      "-------------------------------\n",
      "loss: 0.217258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407764 \n",
      "\n",
      "Epoch 3655\n",
      "-------------------------------\n",
      "loss: 0.250783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407672 \n",
      "\n",
      "Epoch 3656\n",
      "-------------------------------\n",
      "loss: 0.255906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402759 \n",
      "\n",
      "Epoch 3657\n",
      "-------------------------------\n",
      "loss: 0.235129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397915 \n",
      "\n",
      "Epoch 3658\n",
      "-------------------------------\n",
      "loss: 0.229225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396162 \n",
      "\n",
      "Epoch 3659\n",
      "-------------------------------\n",
      "loss: 0.241861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396525 \n",
      "\n",
      "Epoch 3660\n",
      "-------------------------------\n",
      "loss: 0.244085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396298 \n",
      "\n",
      "Epoch 3661\n",
      "-------------------------------\n",
      "loss: 0.242967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394569 \n",
      "\n",
      "Epoch 3662\n",
      "-------------------------------\n",
      "loss: 0.229056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394298 \n",
      "\n",
      "Epoch 3663\n",
      "-------------------------------\n",
      "loss: 0.225466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396643 \n",
      "\n",
      "Epoch 3664\n",
      "-------------------------------\n",
      "loss: 0.244580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400125 \n",
      "\n",
      "Epoch 3665\n",
      "-------------------------------\n",
      "loss: 0.218991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402804 \n",
      "\n",
      "Epoch 3666\n",
      "-------------------------------\n",
      "loss: 0.240949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402190 \n",
      "\n",
      "Epoch 3667\n",
      "-------------------------------\n",
      "loss: 0.226553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398908 \n",
      "\n",
      "Epoch 3668\n",
      "-------------------------------\n",
      "loss: 0.230550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397429 \n",
      "\n",
      "Epoch 3669\n",
      "-------------------------------\n",
      "loss: 0.230892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399297 \n",
      "\n",
      "Epoch 3670\n",
      "-------------------------------\n",
      "loss: 0.236280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401428 \n",
      "\n",
      "Epoch 3671\n",
      "-------------------------------\n",
      "loss: 0.250341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399918 \n",
      "\n",
      "Epoch 3672\n",
      "-------------------------------\n",
      "loss: 0.239838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399259 \n",
      "\n",
      "Epoch 3673\n",
      "-------------------------------\n",
      "loss: 0.227379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402179 \n",
      "\n",
      "Epoch 3674\n",
      "-------------------------------\n",
      "loss: 0.233704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406198 \n",
      "\n",
      "Epoch 3675\n",
      "-------------------------------\n",
      "loss: 0.226833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408487 \n",
      "\n",
      "Epoch 3676\n",
      "-------------------------------\n",
      "loss: 0.238027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407861 \n",
      "\n",
      "Epoch 3677\n",
      "-------------------------------\n",
      "loss: 0.237118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404414 \n",
      "\n",
      "Epoch 3678\n",
      "-------------------------------\n",
      "loss: 0.222321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401396 \n",
      "\n",
      "Epoch 3679\n",
      "-------------------------------\n",
      "loss: 0.233553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400138 \n",
      "\n",
      "Epoch 3680\n",
      "-------------------------------\n",
      "loss: 0.233895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399220 \n",
      "\n",
      "Epoch 3681\n",
      "-------------------------------\n",
      "loss: 0.224794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398452 \n",
      "\n",
      "Epoch 3682\n",
      "-------------------------------\n",
      "loss: 0.228376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399456 \n",
      "\n",
      "Epoch 3683\n",
      "-------------------------------\n",
      "loss: 0.233815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402231 \n",
      "\n",
      "Epoch 3684\n",
      "-------------------------------\n",
      "loss: 0.229254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403316 \n",
      "\n",
      "Epoch 3685\n",
      "-------------------------------\n",
      "loss: 0.228828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402416 \n",
      "\n",
      "Epoch 3686\n",
      "-------------------------------\n",
      "loss: 0.232470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400550 \n",
      "\n",
      "Epoch 3687\n",
      "-------------------------------\n",
      "loss: 0.228819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398707 \n",
      "\n",
      "Epoch 3688\n",
      "-------------------------------\n",
      "loss: 0.224253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398402 \n",
      "\n",
      "Epoch 3689\n",
      "-------------------------------\n",
      "loss: 0.237104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399156 \n",
      "\n",
      "Epoch 3690\n",
      "-------------------------------\n",
      "loss: 0.236644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400086 \n",
      "\n",
      "Epoch 3691\n",
      "-------------------------------\n",
      "loss: 0.233941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401774 \n",
      "\n",
      "Epoch 3692\n",
      "-------------------------------\n",
      "loss: 0.235314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403532 \n",
      "\n",
      "Epoch 3693\n",
      "-------------------------------\n",
      "loss: 0.237896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405380 \n",
      "\n",
      "Epoch 3694\n",
      "-------------------------------\n",
      "loss: 0.236277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405388 \n",
      "\n",
      "Epoch 3695\n",
      "-------------------------------\n",
      "loss: 0.248023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403428 \n",
      "\n",
      "Epoch 3696\n",
      "-------------------------------\n",
      "loss: 0.229186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402197 \n",
      "\n",
      "Epoch 3697\n",
      "-------------------------------\n",
      "loss: 0.240841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402228 \n",
      "\n",
      "Epoch 3698\n",
      "-------------------------------\n",
      "loss: 0.227181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402046 \n",
      "\n",
      "Epoch 3699\n",
      "-------------------------------\n",
      "loss: 0.227089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402036 \n",
      "\n",
      "Epoch 3700\n",
      "-------------------------------\n",
      "loss: 0.240869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402660 \n",
      "\n",
      "Epoch 3701\n",
      "-------------------------------\n",
      "loss: 0.234615  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.404176 \n",
      "\n",
      "Epoch 3702\n",
      "-------------------------------\n",
      "loss: 0.229844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406692 \n",
      "\n",
      "Epoch 3703\n",
      "-------------------------------\n",
      "loss: 0.230537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408411 \n",
      "\n",
      "Epoch 3704\n",
      "-------------------------------\n",
      "loss: 0.237734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406736 \n",
      "\n",
      "Epoch 3705\n",
      "-------------------------------\n",
      "loss: 0.230045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405517 \n",
      "\n",
      "Epoch 3706\n",
      "-------------------------------\n",
      "loss: 0.227340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405696 \n",
      "\n",
      "Epoch 3707\n",
      "-------------------------------\n",
      "loss: 0.237615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405875 \n",
      "\n",
      "Epoch 3708\n",
      "-------------------------------\n",
      "loss: 0.232576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405836 \n",
      "\n",
      "Epoch 3709\n",
      "-------------------------------\n",
      "loss: 0.248262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405734 \n",
      "\n",
      "Epoch 3710\n",
      "-------------------------------\n",
      "loss: 0.249560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405434 \n",
      "\n",
      "Epoch 3711\n",
      "-------------------------------\n",
      "loss: 0.235163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408748 \n",
      "\n",
      "Epoch 3712\n",
      "-------------------------------\n",
      "loss: 0.232104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414645 \n",
      "\n",
      "Epoch 3713\n",
      "-------------------------------\n",
      "loss: 0.231428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418573 \n",
      "\n",
      "Epoch 3714\n",
      "-------------------------------\n",
      "loss: 0.260908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416673 \n",
      "\n",
      "Epoch 3715\n",
      "-------------------------------\n",
      "loss: 0.257478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410584 \n",
      "\n",
      "Epoch 3716\n",
      "-------------------------------\n",
      "loss: 0.208862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405962 \n",
      "\n",
      "Epoch 3717\n",
      "-------------------------------\n",
      "loss: 0.216533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403261 \n",
      "\n",
      "Epoch 3718\n",
      "-------------------------------\n",
      "loss: 0.233792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403126 \n",
      "\n",
      "Epoch 3719\n",
      "-------------------------------\n",
      "loss: 0.241936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403082 \n",
      "\n",
      "Epoch 3720\n",
      "-------------------------------\n",
      "loss: 0.231662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402470 \n",
      "\n",
      "Epoch 3721\n",
      "-------------------------------\n",
      "loss: 0.230655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401746 \n",
      "\n",
      "Epoch 3722\n",
      "-------------------------------\n",
      "loss: 0.228069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403286 \n",
      "\n",
      "Epoch 3723\n",
      "-------------------------------\n",
      "loss: 0.229096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406396 \n",
      "\n",
      "Epoch 3724\n",
      "-------------------------------\n",
      "loss: 0.224037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407898 \n",
      "\n",
      "Epoch 3725\n",
      "-------------------------------\n",
      "loss: 0.250411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406739 \n",
      "\n",
      "Epoch 3726\n",
      "-------------------------------\n",
      "loss: 0.222265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405104 \n",
      "\n",
      "Epoch 3727\n",
      "-------------------------------\n",
      "loss: 0.218064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404770 \n",
      "\n",
      "Epoch 3728\n",
      "-------------------------------\n",
      "loss: 0.226558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404301 \n",
      "\n",
      "Epoch 3729\n",
      "-------------------------------\n",
      "loss: 0.230440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403602 \n",
      "\n",
      "Epoch 3730\n",
      "-------------------------------\n",
      "loss: 0.231095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403150 \n",
      "\n",
      "Epoch 3731\n",
      "-------------------------------\n",
      "loss: 0.232253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402621 \n",
      "\n",
      "Epoch 3732\n",
      "-------------------------------\n",
      "loss: 0.236511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401192 \n",
      "\n",
      "Epoch 3733\n",
      "-------------------------------\n",
      "loss: 0.220170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400483 \n",
      "\n",
      "Epoch 3734\n",
      "-------------------------------\n",
      "loss: 0.224487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400180 \n",
      "\n",
      "Epoch 3735\n",
      "-------------------------------\n",
      "loss: 0.232587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399574 \n",
      "\n",
      "Epoch 3736\n",
      "-------------------------------\n",
      "loss: 0.230698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399089 \n",
      "\n",
      "Epoch 3737\n",
      "-------------------------------\n",
      "loss: 0.227695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398913 \n",
      "\n",
      "Epoch 3738\n",
      "-------------------------------\n",
      "loss: 0.252751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398313 \n",
      "\n",
      "Epoch 3739\n",
      "-------------------------------\n",
      "loss: 0.229653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397705 \n",
      "\n",
      "Epoch 3740\n",
      "-------------------------------\n",
      "loss: 0.222208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397913 \n",
      "\n",
      "Epoch 3741\n",
      "-------------------------------\n",
      "loss: 0.234668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397917 \n",
      "\n",
      "Epoch 3742\n",
      "-------------------------------\n",
      "loss: 0.242365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397842 \n",
      "\n",
      "Epoch 3743\n",
      "-------------------------------\n",
      "loss: 0.231631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398119 \n",
      "\n",
      "Epoch 3744\n",
      "-------------------------------\n",
      "loss: 0.231392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399371 \n",
      "\n",
      "Epoch 3745\n",
      "-------------------------------\n",
      "loss: 0.217382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401384 \n",
      "\n",
      "Epoch 3746\n",
      "-------------------------------\n",
      "loss: 0.233302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403743 \n",
      "\n",
      "Epoch 3747\n",
      "-------------------------------\n",
      "loss: 0.230015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405921 \n",
      "\n",
      "Epoch 3748\n",
      "-------------------------------\n",
      "loss: 0.248636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406635 \n",
      "\n",
      "Epoch 3749\n",
      "-------------------------------\n",
      "loss: 0.230990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404828 \n",
      "\n",
      "Epoch 3750\n",
      "-------------------------------\n",
      "loss: 0.236795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402604 \n",
      "\n",
      "Epoch 3751\n",
      "-------------------------------\n",
      "loss: 0.226855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401232 \n",
      "\n",
      "Epoch 3752\n",
      "-------------------------------\n",
      "loss: 0.224107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400386 \n",
      "\n",
      "Epoch 3753\n",
      "-------------------------------\n",
      "loss: 0.224337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400912 \n",
      "\n",
      "Epoch 3754\n",
      "-------------------------------\n",
      "loss: 0.218835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401804 \n",
      "\n",
      "Epoch 3755\n",
      "-------------------------------\n",
      "loss: 0.237645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401792 \n",
      "\n",
      "Epoch 3756\n",
      "-------------------------------\n",
      "loss: 0.239816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402439 \n",
      "\n",
      "Epoch 3757\n",
      "-------------------------------\n",
      "loss: 0.217906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403107 \n",
      "\n",
      "Epoch 3758\n",
      "-------------------------------\n",
      "loss: 0.247532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401930 \n",
      "\n",
      "Epoch 3759\n",
      "-------------------------------\n",
      "loss: 0.245252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399577 \n",
      "\n",
      "Epoch 3760\n",
      "-------------------------------\n",
      "loss: 0.234023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399771 \n",
      "\n",
      "Epoch 3761\n",
      "-------------------------------\n",
      "loss: 0.235069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400595 \n",
      "\n",
      "Epoch 3762\n",
      "-------------------------------\n",
      "loss: 0.226537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400648 \n",
      "\n",
      "Epoch 3763\n",
      "-------------------------------\n",
      "loss: 0.228825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399992 \n",
      "\n",
      "Epoch 3764\n",
      "-------------------------------\n",
      "loss: 0.234706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400013 \n",
      "\n",
      "Epoch 3765\n",
      "-------------------------------\n",
      "loss: 0.230402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401127 \n",
      "\n",
      "Epoch 3766\n",
      "-------------------------------\n",
      "loss: 0.222626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403195 \n",
      "\n",
      "Epoch 3767\n",
      "-------------------------------\n",
      "loss: 0.228737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404789 \n",
      "\n",
      "Epoch 3768\n",
      "-------------------------------\n",
      "loss: 0.236650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403027 \n",
      "\n",
      "Epoch 3769\n",
      "-------------------------------\n",
      "loss: 0.254988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400235 \n",
      "\n",
      "Epoch 3770\n",
      "-------------------------------\n",
      "loss: 0.218007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400127 \n",
      "\n",
      "Epoch 3771\n",
      "-------------------------------\n",
      "loss: 0.238534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400347 \n",
      "\n",
      "Epoch 3772\n",
      "-------------------------------\n",
      "loss: 0.236277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399569 \n",
      "\n",
      "Epoch 3773\n",
      "-------------------------------\n",
      "loss: 0.229570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399440 \n",
      "\n",
      "Epoch 3774\n",
      "-------------------------------\n",
      "loss: 0.227292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401219 \n",
      "\n",
      "Epoch 3775\n",
      "-------------------------------\n",
      "loss: 0.231869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402938 \n",
      "\n",
      "Epoch 3776\n",
      "-------------------------------\n",
      "loss: 0.230354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402383 \n",
      "\n",
      "Epoch 3777\n",
      "-------------------------------\n",
      "loss: 0.217263  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400701 \n",
      "\n",
      "Epoch 3778\n",
      "-------------------------------\n",
      "loss: 0.217576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398304 \n",
      "\n",
      "Epoch 3779\n",
      "-------------------------------\n",
      "loss: 0.230251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398111 \n",
      "\n",
      "Epoch 3780\n",
      "-------------------------------\n",
      "loss: 0.238570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398438 \n",
      "\n",
      "Epoch 3781\n",
      "-------------------------------\n",
      "loss: 0.225345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398263 \n",
      "\n",
      "Epoch 3782\n",
      "-------------------------------\n",
      "loss: 0.223937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398053 \n",
      "\n",
      "Epoch 3783\n",
      "-------------------------------\n",
      "loss: 0.218596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398496 \n",
      "\n",
      "Epoch 3784\n",
      "-------------------------------\n",
      "loss: 0.250867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398264 \n",
      "\n",
      "Epoch 3785\n",
      "-------------------------------\n",
      "loss: 0.221606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398431 \n",
      "\n",
      "Epoch 3786\n",
      "-------------------------------\n",
      "loss: 0.222889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398313 \n",
      "\n",
      "Epoch 3787\n",
      "-------------------------------\n",
      "loss: 0.230503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398466 \n",
      "\n",
      "Epoch 3788\n",
      "-------------------------------\n",
      "loss: 0.238028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397728 \n",
      "\n",
      "Epoch 3789\n",
      "-------------------------------\n",
      "loss: 0.231574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397425 \n",
      "\n",
      "Epoch 3790\n",
      "-------------------------------\n",
      "loss: 0.232220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397197 \n",
      "\n",
      "Epoch 3791\n",
      "-------------------------------\n",
      "loss: 0.237856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397945 \n",
      "\n",
      "Epoch 3792\n",
      "-------------------------------\n",
      "loss: 0.227300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399079 \n",
      "\n",
      "Epoch 3793\n",
      "-------------------------------\n",
      "loss: 0.225427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 3794\n",
      "-------------------------------\n",
      "loss: 0.228912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403939 \n",
      "\n",
      "Epoch 3795\n",
      "-------------------------------\n",
      "loss: 0.234131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406602 \n",
      "\n",
      "Epoch 3796\n",
      "-------------------------------\n",
      "loss: 0.233776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406669 \n",
      "\n",
      "Epoch 3797\n",
      "-------------------------------\n",
      "loss: 0.227390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405827 \n",
      "\n",
      "Epoch 3798\n",
      "-------------------------------\n",
      "loss: 0.223312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405133 \n",
      "\n",
      "Epoch 3799\n",
      "-------------------------------\n",
      "loss: 0.213742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404966 \n",
      "\n",
      "Epoch 3800\n",
      "-------------------------------\n",
      "loss: 0.221325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404505 \n",
      "\n",
      "Epoch 3801\n",
      "-------------------------------\n",
      "loss: 0.227156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404365 \n",
      "\n",
      "Epoch 3802\n",
      "-------------------------------\n",
      "loss: 0.234143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404812 \n",
      "\n",
      "Epoch 3803\n",
      "-------------------------------\n",
      "loss: 0.227864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405543 \n",
      "\n",
      "Epoch 3804\n",
      "-------------------------------\n",
      "loss: 0.239593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407119 \n",
      "\n",
      "Epoch 3805\n",
      "-------------------------------\n",
      "loss: 0.248120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407108 \n",
      "\n",
      "Epoch 3806\n",
      "-------------------------------\n",
      "loss: 0.239709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405878 \n",
      "\n",
      "Epoch 3807\n",
      "-------------------------------\n",
      "loss: 0.221556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404056 \n",
      "\n",
      "Epoch 3808\n",
      "-------------------------------\n",
      "loss: 0.214407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403146 \n",
      "\n",
      "Epoch 3809\n",
      "-------------------------------\n",
      "loss: 0.225841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402467 \n",
      "\n",
      "Epoch 3810\n",
      "-------------------------------\n",
      "loss: 0.240787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401443 \n",
      "\n",
      "Epoch 3811\n",
      "-------------------------------\n",
      "loss: 0.228873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401373 \n",
      "\n",
      "Epoch 3812\n",
      "-------------------------------\n",
      "loss: 0.225477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402419 \n",
      "\n",
      "Epoch 3813\n",
      "-------------------------------\n",
      "loss: 0.235385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403205 \n",
      "\n",
      "Epoch 3814\n",
      "-------------------------------\n",
      "loss: 0.225211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403430 \n",
      "\n",
      "Epoch 3815\n",
      "-------------------------------\n",
      "loss: 0.244060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402667 \n",
      "\n",
      "Epoch 3816\n",
      "-------------------------------\n",
      "loss: 0.243332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401519 \n",
      "\n",
      "Epoch 3817\n",
      "-------------------------------\n",
      "loss: 0.221770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400929 \n",
      "\n",
      "Epoch 3818\n",
      "-------------------------------\n",
      "loss: 0.234057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400088 \n",
      "\n",
      "Epoch 3819\n",
      "-------------------------------\n",
      "loss: 0.235289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400438 \n",
      "\n",
      "Epoch 3820\n",
      "-------------------------------\n",
      "loss: 0.221192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402710 \n",
      "\n",
      "Epoch 3821\n",
      "-------------------------------\n",
      "loss: 0.225758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405554 \n",
      "\n",
      "Epoch 3822\n",
      "-------------------------------\n",
      "loss: 0.239430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406045 \n",
      "\n",
      "Epoch 3823\n",
      "-------------------------------\n",
      "loss: 0.220789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402721 \n",
      "\n",
      "Epoch 3824\n",
      "-------------------------------\n",
      "loss: 0.238051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399316 \n",
      "\n",
      "Epoch 3825\n",
      "-------------------------------\n",
      "loss: 0.227211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398309 \n",
      "\n",
      "Epoch 3826\n",
      "-------------------------------\n",
      "loss: 0.232755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398419 \n",
      "\n",
      "Epoch 3827\n",
      "-------------------------------\n",
      "loss: 0.227905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398462 \n",
      "\n",
      "Epoch 3828\n",
      "-------------------------------\n",
      "loss: 0.240387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398192 \n",
      "\n",
      "Epoch 3829\n",
      "-------------------------------\n",
      "loss: 0.232543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398617 \n",
      "\n",
      "Epoch 3830\n",
      "-------------------------------\n",
      "loss: 0.215783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399535 \n",
      "\n",
      "Epoch 3831\n",
      "-------------------------------\n",
      "loss: 0.222747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399777 \n",
      "\n",
      "Epoch 3832\n",
      "-------------------------------\n",
      "loss: 0.225747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399822 \n",
      "\n",
      "Epoch 3833\n",
      "-------------------------------\n",
      "loss: 0.212435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399647 \n",
      "\n",
      "Epoch 3834\n",
      "-------------------------------\n",
      "loss: 0.247350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399540 \n",
      "\n",
      "Epoch 3835\n",
      "-------------------------------\n",
      "loss: 0.221890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398816 \n",
      "\n",
      "Epoch 3836\n",
      "-------------------------------\n",
      "loss: 0.220107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398370 \n",
      "\n",
      "Epoch 3837\n",
      "-------------------------------\n",
      "loss: 0.231020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398226 \n",
      "\n",
      "Epoch 3838\n",
      "-------------------------------\n",
      "loss: 0.240925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398701 \n",
      "\n",
      "Epoch 3839\n",
      "-------------------------------\n",
      "loss: 0.224248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399452 \n",
      "\n",
      "Epoch 3840\n",
      "-------------------------------\n",
      "loss: 0.219000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400662 \n",
      "\n",
      "Epoch 3841\n",
      "-------------------------------\n",
      "loss: 0.219461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401501 \n",
      "\n",
      "Epoch 3842\n",
      "-------------------------------\n",
      "loss: 0.223208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401616 \n",
      "\n",
      "Epoch 3843\n",
      "-------------------------------\n",
      "loss: 0.225335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401417 \n",
      "\n",
      "Epoch 3844\n",
      "-------------------------------\n",
      "loss: 0.226035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401268 \n",
      "\n",
      "Epoch 3845\n",
      "-------------------------------\n",
      "loss: 0.214070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401406 \n",
      "\n",
      "Epoch 3846\n",
      "-------------------------------\n",
      "loss: 0.226666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401942 \n",
      "\n",
      "Epoch 3847\n",
      "-------------------------------\n",
      "loss: 0.221666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402255 \n",
      "\n",
      "Epoch 3848\n",
      "-------------------------------\n",
      "loss: 0.224039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403269 \n",
      "\n",
      "Epoch 3849\n",
      "-------------------------------\n",
      "loss: 0.221883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403159 \n",
      "\n",
      "Epoch 3850\n",
      "-------------------------------\n",
      "loss: 0.236277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402095 \n",
      "\n",
      "Epoch 3851\n",
      "-------------------------------\n",
      "loss: 0.234941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401688 \n",
      "\n",
      "Epoch 3852\n",
      "-------------------------------\n",
      "loss: 0.219462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401078 \n",
      "\n",
      "Epoch 3853\n",
      "-------------------------------\n",
      "loss: 0.225097  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400617 \n",
      "\n",
      "Epoch 3854\n",
      "-------------------------------\n",
      "loss: 0.230978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401231 \n",
      "\n",
      "Epoch 3855\n",
      "-------------------------------\n",
      "loss: 0.236606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401874 \n",
      "\n",
      "Epoch 3856\n",
      "-------------------------------\n",
      "loss: 0.221847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401812 \n",
      "\n",
      "Epoch 3857\n",
      "-------------------------------\n",
      "loss: 0.238424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401724 \n",
      "\n",
      "Epoch 3858\n",
      "-------------------------------\n",
      "loss: 0.238827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401760 \n",
      "\n",
      "Epoch 3859\n",
      "-------------------------------\n",
      "loss: 0.230166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402059 \n",
      "\n",
      "Epoch 3860\n",
      "-------------------------------\n",
      "loss: 0.228009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403067 \n",
      "\n",
      "Epoch 3861\n",
      "-------------------------------\n",
      "loss: 0.226952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404280 \n",
      "\n",
      "Epoch 3862\n",
      "-------------------------------\n",
      "loss: 0.218776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405016 \n",
      "\n",
      "Epoch 3863\n",
      "-------------------------------\n",
      "loss: 0.238924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405054 \n",
      "\n",
      "Epoch 3864\n",
      "-------------------------------\n",
      "loss: 0.225531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404905 \n",
      "\n",
      "Epoch 3865\n",
      "-------------------------------\n",
      "loss: 0.227465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404531 \n",
      "\n",
      "Epoch 3866\n",
      "-------------------------------\n",
      "loss: 0.240481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403701 \n",
      "\n",
      "Epoch 3867\n",
      "-------------------------------\n",
      "loss: 0.223429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403068 \n",
      "\n",
      "Epoch 3868\n",
      "-------------------------------\n",
      "loss: 0.228188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402968 \n",
      "\n",
      "Epoch 3869\n",
      "-------------------------------\n",
      "loss: 0.217259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403533 \n",
      "\n",
      "Epoch 3870\n",
      "-------------------------------\n",
      "loss: 0.226884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404744 \n",
      "\n",
      "Epoch 3871\n",
      "-------------------------------\n",
      "loss: 0.226806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405943 \n",
      "\n",
      "Epoch 3872\n",
      "-------------------------------\n",
      "loss: 0.256673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406627 \n",
      "\n",
      "Epoch 3873\n",
      "-------------------------------\n",
      "loss: 0.226867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406713 \n",
      "\n",
      "Epoch 3874\n",
      "-------------------------------\n",
      "loss: 0.233191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406023 \n",
      "\n",
      "Epoch 3875\n",
      "-------------------------------\n",
      "loss: 0.228517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405607 \n",
      "\n",
      "Epoch 3876\n",
      "-------------------------------\n",
      "loss: 0.218279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405127 \n",
      "\n",
      "Epoch 3877\n",
      "-------------------------------\n",
      "loss: 0.232893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404353 \n",
      "\n",
      "Epoch 3878\n",
      "-------------------------------\n",
      "loss: 0.237774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403906 \n",
      "\n",
      "Epoch 3879\n",
      "-------------------------------\n",
      "loss: 0.237999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403334 \n",
      "\n",
      "Epoch 3880\n",
      "-------------------------------\n",
      "loss: 0.223492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402584 \n",
      "\n",
      "Epoch 3881\n",
      "-------------------------------\n",
      "loss: 0.221703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402682 \n",
      "\n",
      "Epoch 3882\n",
      "-------------------------------\n",
      "loss: 0.223907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404029 \n",
      "\n",
      "Epoch 3883\n",
      "-------------------------------\n",
      "loss: 0.210053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407492 \n",
      "\n",
      "Epoch 3884\n",
      "-------------------------------\n",
      "loss: 0.224603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409885 \n",
      "\n",
      "Epoch 3885\n",
      "-------------------------------\n",
      "loss: 0.222027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410547 \n",
      "\n",
      "Epoch 3886\n",
      "-------------------------------\n",
      "loss: 0.219864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409138 \n",
      "\n",
      "Epoch 3887\n",
      "-------------------------------\n",
      "loss: 0.232628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405787 \n",
      "\n",
      "Epoch 3888\n",
      "-------------------------------\n",
      "loss: 0.234115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403314 \n",
      "\n",
      "Epoch 3889\n",
      "-------------------------------\n",
      "loss: 0.227907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401461 \n",
      "\n",
      "Epoch 3890\n",
      "-------------------------------\n",
      "loss: 0.225507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401203 \n",
      "\n",
      "Epoch 3891\n",
      "-------------------------------\n",
      "loss: 0.224510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402277 \n",
      "\n",
      "Epoch 3892\n",
      "-------------------------------\n",
      "loss: 0.222742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403345 \n",
      "\n",
      "Epoch 3893\n",
      "-------------------------------\n",
      "loss: 0.241773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403517 \n",
      "\n",
      "Epoch 3894\n",
      "-------------------------------\n",
      "loss: 0.237019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404241 \n",
      "\n",
      "Epoch 3895\n",
      "-------------------------------\n",
      "loss: 0.244333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403378 \n",
      "\n",
      "Epoch 3896\n",
      "-------------------------------\n",
      "loss: 0.222586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402533 \n",
      "\n",
      "Epoch 3897\n",
      "-------------------------------\n",
      "loss: 0.223754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403038 \n",
      "\n",
      "Epoch 3898\n",
      "-------------------------------\n",
      "loss: 0.211828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403398 \n",
      "\n",
      "Epoch 3899\n",
      "-------------------------------\n",
      "loss: 0.237968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403759 \n",
      "\n",
      "Epoch 3900\n",
      "-------------------------------\n",
      "loss: 0.221878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403609 \n",
      "\n",
      "Epoch 3901\n",
      "-------------------------------\n",
      "loss: 0.242589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403014 \n",
      "\n",
      "Epoch 3902\n",
      "-------------------------------\n",
      "loss: 0.239237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402302 \n",
      "\n",
      "Epoch 3903\n",
      "-------------------------------\n",
      "loss: 0.231939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402412 \n",
      "\n",
      "Epoch 3904\n",
      "-------------------------------\n",
      "loss: 0.231730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403735 \n",
      "\n",
      "Epoch 3905\n",
      "-------------------------------\n",
      "loss: 0.240563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404034 \n",
      "\n",
      "Epoch 3906\n",
      "-------------------------------\n",
      "loss: 0.225197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404585 \n",
      "\n",
      "Epoch 3907\n",
      "-------------------------------\n",
      "loss: 0.234321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404607 \n",
      "\n",
      "Epoch 3908\n",
      "-------------------------------\n",
      "loss: 0.228614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404153 \n",
      "\n",
      "Epoch 3909\n",
      "-------------------------------\n",
      "loss: 0.227871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402626 \n",
      "\n",
      "Epoch 3910\n",
      "-------------------------------\n",
      "loss: 0.220757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401848 \n",
      "\n",
      "Epoch 3911\n",
      "-------------------------------\n",
      "loss: 0.228459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401470 \n",
      "\n",
      "Epoch 3912\n",
      "-------------------------------\n",
      "loss: 0.237437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401027 \n",
      "\n",
      "Epoch 3913\n",
      "-------------------------------\n",
      "loss: 0.229253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401035 \n",
      "\n",
      "Epoch 3914\n",
      "-------------------------------\n",
      "loss: 0.236529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401341 \n",
      "\n",
      "Epoch 3915\n",
      "-------------------------------\n",
      "loss: 0.215022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403073 \n",
      "\n",
      "Epoch 3916\n",
      "-------------------------------\n",
      "loss: 0.226833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405847 \n",
      "\n",
      "Epoch 3917\n",
      "-------------------------------\n",
      "loss: 0.215235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408794 \n",
      "\n",
      "Epoch 3918\n",
      "-------------------------------\n",
      "loss: 0.242063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408583 \n",
      "\n",
      "Epoch 3919\n",
      "-------------------------------\n",
      "loss: 0.221889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407402 \n",
      "\n",
      "Epoch 3920\n",
      "-------------------------------\n",
      "loss: 0.240067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403545 \n",
      "\n",
      "Epoch 3921\n",
      "-------------------------------\n",
      "loss: 0.224055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400077 \n",
      "\n",
      "Epoch 3922\n",
      "-------------------------------\n",
      "loss: 0.235773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399156 \n",
      "\n",
      "Epoch 3923\n",
      "-------------------------------\n",
      "loss: 0.243018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399300 \n",
      "\n",
      "Epoch 3924\n",
      "-------------------------------\n",
      "loss: 0.223772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399290 \n",
      "\n",
      "Epoch 3925\n",
      "-------------------------------\n",
      "loss: 0.234365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398996 \n",
      "\n",
      "Epoch 3926\n",
      "-------------------------------\n",
      "loss: 0.225914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401318 \n",
      "\n",
      "Epoch 3927\n",
      "-------------------------------\n",
      "loss: 0.232113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404487 \n",
      "\n",
      "Epoch 3928\n",
      "-------------------------------\n",
      "loss: 0.229492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404838 \n",
      "\n",
      "Epoch 3929\n",
      "-------------------------------\n",
      "loss: 0.232547  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.402698 \n",
      "\n",
      "Epoch 3930\n",
      "-------------------------------\n",
      "loss: 0.240002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398809 \n",
      "\n",
      "Epoch 3931\n",
      "-------------------------------\n",
      "loss: 0.225731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396503 \n",
      "\n",
      "Epoch 3932\n",
      "-------------------------------\n",
      "loss: 0.235840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396766 \n",
      "\n",
      "Epoch 3933\n",
      "-------------------------------\n",
      "loss: 0.233688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396961 \n",
      "\n",
      "Epoch 3934\n",
      "-------------------------------\n",
      "loss: 0.264883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396661 \n",
      "\n",
      "Epoch 3935\n",
      "-------------------------------\n",
      "loss: 0.224021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398341 \n",
      "\n",
      "Epoch 3936\n",
      "-------------------------------\n",
      "loss: 0.235772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403183 \n",
      "\n",
      "Epoch 3937\n",
      "-------------------------------\n",
      "loss: 0.253042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406865 \n",
      "\n",
      "Epoch 3938\n",
      "-------------------------------\n",
      "loss: 0.225903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405927 \n",
      "\n",
      "Epoch 3939\n",
      "-------------------------------\n",
      "loss: 0.260476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401318 \n",
      "\n",
      "Epoch 3940\n",
      "-------------------------------\n",
      "loss: 0.232217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397136 \n",
      "\n",
      "Epoch 3941\n",
      "-------------------------------\n",
      "loss: 0.216411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395661 \n",
      "\n",
      "Epoch 3942\n",
      "-------------------------------\n",
      "loss: 0.223992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395286 \n",
      "\n",
      "Epoch 3943\n",
      "-------------------------------\n",
      "loss: 0.221092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395689 \n",
      "\n",
      "Epoch 3944\n",
      "-------------------------------\n",
      "loss: 0.241794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396566 \n",
      "\n",
      "Epoch 3945\n",
      "-------------------------------\n",
      "loss: 0.217459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397768 \n",
      "\n",
      "Epoch 3946\n",
      "-------------------------------\n",
      "loss: 0.218096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400222 \n",
      "\n",
      "Epoch 3947\n",
      "-------------------------------\n",
      "loss: 0.236584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400623 \n",
      "\n",
      "Epoch 3948\n",
      "-------------------------------\n",
      "loss: 0.222421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399035 \n",
      "\n",
      "Epoch 3949\n",
      "-------------------------------\n",
      "loss: 0.222733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396697 \n",
      "\n",
      "Epoch 3950\n",
      "-------------------------------\n",
      "loss: 0.213262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395202 \n",
      "\n",
      "Epoch 3951\n",
      "-------------------------------\n",
      "loss: 0.219570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394496 \n",
      "\n",
      "Epoch 3952\n",
      "-------------------------------\n",
      "loss: 0.225824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394502 \n",
      "\n",
      "Epoch 3953\n",
      "-------------------------------\n",
      "loss: 0.222676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395164 \n",
      "\n",
      "Epoch 3954\n",
      "-------------------------------\n",
      "loss: 0.242970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397439 \n",
      "\n",
      "Epoch 3955\n",
      "-------------------------------\n",
      "loss: 0.227883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398658 \n",
      "\n",
      "Epoch 3956\n",
      "-------------------------------\n",
      "loss: 0.230817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399248 \n",
      "\n",
      "Epoch 3957\n",
      "-------------------------------\n",
      "loss: 0.225226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399234 \n",
      "\n",
      "Epoch 3958\n",
      "-------------------------------\n",
      "loss: 0.218109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399785 \n",
      "\n",
      "Epoch 3959\n",
      "-------------------------------\n",
      "loss: 0.229193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399530 \n",
      "\n",
      "Epoch 3960\n",
      "-------------------------------\n",
      "loss: 0.226652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399128 \n",
      "\n",
      "Epoch 3961\n",
      "-------------------------------\n",
      "loss: 0.242757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398684 \n",
      "\n",
      "Epoch 3962\n",
      "-------------------------------\n",
      "loss: 0.230470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399118 \n",
      "\n",
      "Epoch 3963\n",
      "-------------------------------\n",
      "loss: 0.220616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399547 \n",
      "\n",
      "Epoch 3964\n",
      "-------------------------------\n",
      "loss: 0.224685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400245 \n",
      "\n",
      "Epoch 3965\n",
      "-------------------------------\n",
      "loss: 0.224280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401082 \n",
      "\n",
      "Epoch 3966\n",
      "-------------------------------\n",
      "loss: 0.245388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399569 \n",
      "\n",
      "Epoch 3967\n",
      "-------------------------------\n",
      "loss: 0.211470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397288 \n",
      "\n",
      "Epoch 3968\n",
      "-------------------------------\n",
      "loss: 0.223403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397180 \n",
      "\n",
      "Epoch 3969\n",
      "-------------------------------\n",
      "loss: 0.230426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396800 \n",
      "\n",
      "Epoch 3970\n",
      "-------------------------------\n",
      "loss: 0.233636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396103 \n",
      "\n",
      "Epoch 3971\n",
      "-------------------------------\n",
      "loss: 0.235321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396792 \n",
      "\n",
      "Epoch 3972\n",
      "-------------------------------\n",
      "loss: 0.228449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398331 \n",
      "\n",
      "Epoch 3973\n",
      "-------------------------------\n",
      "loss: 0.215496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400516 \n",
      "\n",
      "Epoch 3974\n",
      "-------------------------------\n",
      "loss: 0.234236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401803 \n",
      "\n",
      "Epoch 3975\n",
      "-------------------------------\n",
      "loss: 0.225057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401762 \n",
      "\n",
      "Epoch 3976\n",
      "-------------------------------\n",
      "loss: 0.231152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400402 \n",
      "\n",
      "Epoch 3977\n",
      "-------------------------------\n",
      "loss: 0.228960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398465 \n",
      "\n",
      "Epoch 3978\n",
      "-------------------------------\n",
      "loss: 0.217489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398416 \n",
      "\n",
      "Epoch 3979\n",
      "-------------------------------\n",
      "loss: 0.222626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399640 \n",
      "\n",
      "Epoch 3980\n",
      "-------------------------------\n",
      "loss: 0.228576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400170 \n",
      "\n",
      "Epoch 3981\n",
      "-------------------------------\n",
      "loss: 0.226359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399822 \n",
      "\n",
      "Epoch 3982\n",
      "-------------------------------\n",
      "loss: 0.226731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400827 \n",
      "\n",
      "Epoch 3983\n",
      "-------------------------------\n",
      "loss: 0.217670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402625 \n",
      "\n",
      "Epoch 3984\n",
      "-------------------------------\n",
      "loss: 0.217940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404354 \n",
      "\n",
      "Epoch 3985\n",
      "-------------------------------\n",
      "loss: 0.222945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406895 \n",
      "\n",
      "Epoch 3986\n",
      "-------------------------------\n",
      "loss: 0.207639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408638 \n",
      "\n",
      "Epoch 3987\n",
      "-------------------------------\n",
      "loss: 0.240519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408889 \n",
      "\n",
      "Epoch 3988\n",
      "-------------------------------\n",
      "loss: 0.236201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408898 \n",
      "\n",
      "Epoch 3989\n",
      "-------------------------------\n",
      "loss: 0.230854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407071 \n",
      "\n",
      "Epoch 3990\n",
      "-------------------------------\n",
      "loss: 0.225293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404884 \n",
      "\n",
      "Epoch 3991\n",
      "-------------------------------\n",
      "loss: 0.226166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403994 \n",
      "\n",
      "Epoch 3992\n",
      "-------------------------------\n",
      "loss: 0.238796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403986 \n",
      "\n",
      "Epoch 3993\n",
      "-------------------------------\n",
      "loss: 0.234389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404255 \n",
      "\n",
      "Epoch 3994\n",
      "-------------------------------\n",
      "loss: 0.219913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404174 \n",
      "\n",
      "Epoch 3995\n",
      "-------------------------------\n",
      "loss: 0.224553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404535 \n",
      "\n",
      "Epoch 3996\n",
      "-------------------------------\n",
      "loss: 0.232909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405122 \n",
      "\n",
      "Epoch 3997\n",
      "-------------------------------\n",
      "loss: 0.228743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404788 \n",
      "\n",
      "Epoch 3998\n",
      "-------------------------------\n",
      "loss: 0.227331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403683 \n",
      "\n",
      "Epoch 3999\n",
      "-------------------------------\n",
      "loss: 0.242980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402290 \n",
      "\n",
      "Epoch 4000\n",
      "-------------------------------\n",
      "loss: 0.212162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401512 \n",
      "\n",
      "Epoch 4001\n",
      "-------------------------------\n",
      "loss: 0.221230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400863 \n",
      "\n",
      "Epoch 4002\n",
      "-------------------------------\n",
      "loss: 0.224781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400183 \n",
      "\n",
      "Epoch 4003\n",
      "-------------------------------\n",
      "loss: 0.223199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400100 \n",
      "\n",
      "Epoch 4004\n",
      "-------------------------------\n",
      "loss: 0.233259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400098 \n",
      "\n",
      "Epoch 4005\n",
      "-------------------------------\n",
      "loss: 0.229386  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400067 \n",
      "\n",
      "Epoch 4006\n",
      "-------------------------------\n",
      "loss: 0.209786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400689 \n",
      "\n",
      "Epoch 4007\n",
      "-------------------------------\n",
      "loss: 0.225446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401352 \n",
      "\n",
      "Epoch 4008\n",
      "-------------------------------\n",
      "loss: 0.231983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401521 \n",
      "\n",
      "Epoch 4009\n",
      "-------------------------------\n",
      "loss: 0.227772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402101 \n",
      "\n",
      "Epoch 4010\n",
      "-------------------------------\n",
      "loss: 0.202247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402458 \n",
      "\n",
      "Epoch 4011\n",
      "-------------------------------\n",
      "loss: 0.213060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403058 \n",
      "\n",
      "Epoch 4012\n",
      "-------------------------------\n",
      "loss: 0.225112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403438 \n",
      "\n",
      "Epoch 4013\n",
      "-------------------------------\n",
      "loss: 0.238760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403009 \n",
      "\n",
      "Epoch 4014\n",
      "-------------------------------\n",
      "loss: 0.225952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402162 \n",
      "\n",
      "Epoch 4015\n",
      "-------------------------------\n",
      "loss: 0.226983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401878 \n",
      "\n",
      "Epoch 4016\n",
      "-------------------------------\n",
      "loss: 0.225471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401676 \n",
      "\n",
      "Epoch 4017\n",
      "-------------------------------\n",
      "loss: 0.224750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402358 \n",
      "\n",
      "Epoch 4018\n",
      "-------------------------------\n",
      "loss: 0.233952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402441 \n",
      "\n",
      "Epoch 4019\n",
      "-------------------------------\n",
      "loss: 0.232168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402309 \n",
      "\n",
      "Epoch 4020\n",
      "-------------------------------\n",
      "loss: 0.212631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403175 \n",
      "\n",
      "Epoch 4021\n",
      "-------------------------------\n",
      "loss: 0.221499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404679 \n",
      "\n",
      "Epoch 4022\n",
      "-------------------------------\n",
      "loss: 0.235579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404459 \n",
      "\n",
      "Epoch 4023\n",
      "-------------------------------\n",
      "loss: 0.214541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402991 \n",
      "\n",
      "Epoch 4024\n",
      "-------------------------------\n",
      "loss: 0.230073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399737 \n",
      "\n",
      "Epoch 4025\n",
      "-------------------------------\n",
      "loss: 0.242367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398283 \n",
      "\n",
      "Epoch 4026\n",
      "-------------------------------\n",
      "loss: 0.216749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397627 \n",
      "\n",
      "Epoch 4027\n",
      "-------------------------------\n",
      "loss: 0.222949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397666 \n",
      "\n",
      "Epoch 4028\n",
      "-------------------------------\n",
      "loss: 0.228761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397992 \n",
      "\n",
      "Epoch 4029\n",
      "-------------------------------\n",
      "loss: 0.218331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398567 \n",
      "\n",
      "Epoch 4030\n",
      "-------------------------------\n",
      "loss: 0.214527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398553 \n",
      "\n",
      "Epoch 4031\n",
      "-------------------------------\n",
      "loss: 0.228043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398470 \n",
      "\n",
      "Epoch 4032\n",
      "-------------------------------\n",
      "loss: 0.214997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397518 \n",
      "\n",
      "Epoch 4033\n",
      "-------------------------------\n",
      "loss: 0.219535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397316 \n",
      "\n",
      "Epoch 4034\n",
      "-------------------------------\n",
      "loss: 0.220814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397636 \n",
      "\n",
      "Epoch 4035\n",
      "-------------------------------\n",
      "loss: 0.225276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397653 \n",
      "\n",
      "Epoch 4036\n",
      "-------------------------------\n",
      "loss: 0.236915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397793 \n",
      "\n",
      "Epoch 4037\n",
      "-------------------------------\n",
      "loss: 0.222402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398454 \n",
      "\n",
      "Epoch 4038\n",
      "-------------------------------\n",
      "loss: 0.232740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399779 \n",
      "\n",
      "Epoch 4039\n",
      "-------------------------------\n",
      "loss: 0.228544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402054 \n",
      "\n",
      "Epoch 4040\n",
      "-------------------------------\n",
      "loss: 0.218959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404024 \n",
      "\n",
      "Epoch 4041\n",
      "-------------------------------\n",
      "loss: 0.255957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402607 \n",
      "\n",
      "Epoch 4042\n",
      "-------------------------------\n",
      "loss: 0.204269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401093 \n",
      "\n",
      "Epoch 4043\n",
      "-------------------------------\n",
      "loss: 0.218219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400685 \n",
      "\n",
      "Epoch 4044\n",
      "-------------------------------\n",
      "loss: 0.226375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401155 \n",
      "\n",
      "Epoch 4045\n",
      "-------------------------------\n",
      "loss: 0.238225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401004 \n",
      "\n",
      "Epoch 4046\n",
      "-------------------------------\n",
      "loss: 0.241108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403067 \n",
      "\n",
      "Epoch 4047\n",
      "-------------------------------\n",
      "loss: 0.228191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407309 \n",
      "\n",
      "Epoch 4048\n",
      "-------------------------------\n",
      "loss: 0.231681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409830 \n",
      "\n",
      "Epoch 4049\n",
      "-------------------------------\n",
      "loss: 0.218805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410172 \n",
      "\n",
      "Epoch 4050\n",
      "-------------------------------\n",
      "loss: 0.227615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406665 \n",
      "\n",
      "Epoch 4051\n",
      "-------------------------------\n",
      "loss: 0.228753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402443 \n",
      "\n",
      "Epoch 4052\n",
      "-------------------------------\n",
      "loss: 0.223031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399555 \n",
      "\n",
      "Epoch 4053\n",
      "-------------------------------\n",
      "loss: 0.229447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398530 \n",
      "\n",
      "Epoch 4054\n",
      "-------------------------------\n",
      "loss: 0.213728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398547 \n",
      "\n",
      "Epoch 4055\n",
      "-------------------------------\n",
      "loss: 0.224746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399067 \n",
      "\n",
      "Epoch 4056\n",
      "-------------------------------\n",
      "loss: 0.220976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400368 \n",
      "\n",
      "Epoch 4057\n",
      "-------------------------------\n",
      "loss: 0.215199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402688 \n",
      "\n",
      "Epoch 4058\n",
      "-------------------------------\n",
      "loss: 0.225135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405295 \n",
      "\n",
      "Epoch 4059\n",
      "-------------------------------\n",
      "loss: 0.239801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403026 \n",
      "\n",
      "Epoch 4060\n",
      "-------------------------------\n",
      "loss: 0.233374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399254 \n",
      "\n",
      "Epoch 4061\n",
      "-------------------------------\n",
      "loss: 0.217933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397521 \n",
      "\n",
      "Epoch 4062\n",
      "-------------------------------\n",
      "loss: 0.222524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397680 \n",
      "\n",
      "Epoch 4063\n",
      "-------------------------------\n",
      "loss: 0.220227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398057 \n",
      "\n",
      "Epoch 4064\n",
      "-------------------------------\n",
      "loss: 0.225751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397648 \n",
      "\n",
      "Epoch 4065\n",
      "-------------------------------\n",
      "loss: 0.218294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397607 \n",
      "\n",
      "Epoch 4066\n",
      "-------------------------------\n",
      "loss: 0.235245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398785 \n",
      "\n",
      "Epoch 4067\n",
      "-------------------------------\n",
      "loss: 0.236901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399762 \n",
      "\n",
      "Epoch 4068\n",
      "-------------------------------\n",
      "loss: 0.222233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400436 \n",
      "\n",
      "Epoch 4069\n",
      "-------------------------------\n",
      "loss: 0.229677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399323 \n",
      "\n",
      "Epoch 4070\n",
      "-------------------------------\n",
      "loss: 0.236418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397962 \n",
      "\n",
      "Epoch 4071\n",
      "-------------------------------\n",
      "loss: 0.202532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398668 \n",
      "\n",
      "Epoch 4072\n",
      "-------------------------------\n",
      "loss: 0.238474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399735 \n",
      "\n",
      "Epoch 4073\n",
      "-------------------------------\n",
      "loss: 0.215803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399742 \n",
      "\n",
      "Epoch 4074\n",
      "-------------------------------\n",
      "loss: 0.233275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399427 \n",
      "\n",
      "Epoch 4075\n",
      "-------------------------------\n",
      "loss: 0.225559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402711 \n",
      "\n",
      "Epoch 4076\n",
      "-------------------------------\n",
      "loss: 0.227933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408670 \n",
      "\n",
      "Epoch 4077\n",
      "-------------------------------\n",
      "loss: 0.244772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409457 \n",
      "\n",
      "Epoch 4078\n",
      "-------------------------------\n",
      "loss: 0.231785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405833 \n",
      "\n",
      "Epoch 4079\n",
      "-------------------------------\n",
      "loss: 0.213393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402915 \n",
      "\n",
      "Epoch 4080\n",
      "-------------------------------\n",
      "loss: 0.237411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401051 \n",
      "\n",
      "Epoch 4081\n",
      "-------------------------------\n",
      "loss: 0.235381  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.401192 \n",
      "\n",
      "Epoch 4082\n",
      "-------------------------------\n",
      "loss: 0.224538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401310 \n",
      "\n",
      "Epoch 4083\n",
      "-------------------------------\n",
      "loss: 0.226847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401321 \n",
      "\n",
      "Epoch 4084\n",
      "-------------------------------\n",
      "loss: 0.221783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401930 \n",
      "\n",
      "Epoch 4085\n",
      "-------------------------------\n",
      "loss: 0.221920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403511 \n",
      "\n",
      "Epoch 4086\n",
      "-------------------------------\n",
      "loss: 0.207571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407570 \n",
      "\n",
      "Epoch 4087\n",
      "-------------------------------\n",
      "loss: 0.226260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410212 \n",
      "\n",
      "Epoch 4088\n",
      "-------------------------------\n",
      "loss: 0.214628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410357 \n",
      "\n",
      "Epoch 4089\n",
      "-------------------------------\n",
      "loss: 0.239991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407212 \n",
      "\n",
      "Epoch 4090\n",
      "-------------------------------\n",
      "loss: 0.237249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403698 \n",
      "\n",
      "Epoch 4091\n",
      "-------------------------------\n",
      "loss: 0.219754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403713 \n",
      "\n",
      "Epoch 4092\n",
      "-------------------------------\n",
      "loss: 0.228530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403553 \n",
      "\n",
      "Epoch 4093\n",
      "-------------------------------\n",
      "loss: 0.240797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402766 \n",
      "\n",
      "Epoch 4094\n",
      "-------------------------------\n",
      "loss: 0.227283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401713 \n",
      "\n",
      "Epoch 4095\n",
      "-------------------------------\n",
      "loss: 0.223117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402225 \n",
      "\n",
      "Epoch 4096\n",
      "-------------------------------\n",
      "loss: 0.223038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403714 \n",
      "\n",
      "Epoch 4097\n",
      "-------------------------------\n",
      "loss: 0.220019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404241 \n",
      "\n",
      "Epoch 4098\n",
      "-------------------------------\n",
      "loss: 0.236773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402802 \n",
      "\n",
      "Epoch 4099\n",
      "-------------------------------\n",
      "loss: 0.230976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400508 \n",
      "\n",
      "Epoch 4100\n",
      "-------------------------------\n",
      "loss: 0.231405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399604 \n",
      "\n",
      "Epoch 4101\n",
      "-------------------------------\n",
      "loss: 0.231861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398935 \n",
      "\n",
      "Epoch 4102\n",
      "-------------------------------\n",
      "loss: 0.219058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399556 \n",
      "\n",
      "Epoch 4103\n",
      "-------------------------------\n",
      "loss: 0.232473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 4104\n",
      "-------------------------------\n",
      "loss: 0.230800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401749 \n",
      "\n",
      "Epoch 4105\n",
      "-------------------------------\n",
      "loss: 0.221096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401967 \n",
      "\n",
      "Epoch 4106\n",
      "-------------------------------\n",
      "loss: 0.244425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401223 \n",
      "\n",
      "Epoch 4107\n",
      "-------------------------------\n",
      "loss: 0.203674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400905 \n",
      "\n",
      "Epoch 4108\n",
      "-------------------------------\n",
      "loss: 0.222797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400532 \n",
      "\n",
      "Epoch 4109\n",
      "-------------------------------\n",
      "loss: 0.221638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399871 \n",
      "\n",
      "Epoch 4110\n",
      "-------------------------------\n",
      "loss: 0.217818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400081 \n",
      "\n",
      "Epoch 4111\n",
      "-------------------------------\n",
      "loss: 0.238726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399578 \n",
      "\n",
      "Epoch 4112\n",
      "-------------------------------\n",
      "loss: 0.225308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399596 \n",
      "\n",
      "Epoch 4113\n",
      "-------------------------------\n",
      "loss: 0.227718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400127 \n",
      "\n",
      "Epoch 4114\n",
      "-------------------------------\n",
      "loss: 0.229685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400885 \n",
      "\n",
      "Epoch 4115\n",
      "-------------------------------\n",
      "loss: 0.218570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402038 \n",
      "\n",
      "Epoch 4116\n",
      "-------------------------------\n",
      "loss: 0.208628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403406 \n",
      "\n",
      "Epoch 4117\n",
      "-------------------------------\n",
      "loss: 0.235635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403769 \n",
      "\n",
      "Epoch 4118\n",
      "-------------------------------\n",
      "loss: 0.210593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403646 \n",
      "\n",
      "Epoch 4119\n",
      "-------------------------------\n",
      "loss: 0.224632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402748 \n",
      "\n",
      "Epoch 4120\n",
      "-------------------------------\n",
      "loss: 0.224469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401505 \n",
      "\n",
      "Epoch 4121\n",
      "-------------------------------\n",
      "loss: 0.228082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400617 \n",
      "\n",
      "Epoch 4122\n",
      "-------------------------------\n",
      "loss: 0.219173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400626 \n",
      "\n",
      "Epoch 4123\n",
      "-------------------------------\n",
      "loss: 0.229360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400227 \n",
      "\n",
      "Epoch 4124\n",
      "-------------------------------\n",
      "loss: 0.235099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401227 \n",
      "\n",
      "Epoch 4125\n",
      "-------------------------------\n",
      "loss: 0.222619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402413 \n",
      "\n",
      "Epoch 4126\n",
      "-------------------------------\n",
      "loss: 0.213348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404738 \n",
      "\n",
      "Epoch 4127\n",
      "-------------------------------\n",
      "loss: 0.230199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405169 \n",
      "\n",
      "Epoch 4128\n",
      "-------------------------------\n",
      "loss: 0.222176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404387 \n",
      "\n",
      "Epoch 4129\n",
      "-------------------------------\n",
      "loss: 0.226973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403300 \n",
      "\n",
      "Epoch 4130\n",
      "-------------------------------\n",
      "loss: 0.231785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402892 \n",
      "\n",
      "Epoch 4131\n",
      "-------------------------------\n",
      "loss: 0.243344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402860 \n",
      "\n",
      "Epoch 4132\n",
      "-------------------------------\n",
      "loss: 0.212991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402966 \n",
      "\n",
      "Epoch 4133\n",
      "-------------------------------\n",
      "loss: 0.240099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403189 \n",
      "\n",
      "Epoch 4134\n",
      "-------------------------------\n",
      "loss: 0.229033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404469 \n",
      "\n",
      "Epoch 4135\n",
      "-------------------------------\n",
      "loss: 0.229387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405223 \n",
      "\n",
      "Epoch 4136\n",
      "-------------------------------\n",
      "loss: 0.228567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404698 \n",
      "\n",
      "Epoch 4137\n",
      "-------------------------------\n",
      "loss: 0.238971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402964 \n",
      "\n",
      "Epoch 4138\n",
      "-------------------------------\n",
      "loss: 0.213216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401841 \n",
      "\n",
      "Epoch 4139\n",
      "-------------------------------\n",
      "loss: 0.219923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400109 \n",
      "\n",
      "Epoch 4140\n",
      "-------------------------------\n",
      "loss: 0.244848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398465 \n",
      "\n",
      "Epoch 4141\n",
      "-------------------------------\n",
      "loss: 0.220619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398381 \n",
      "\n",
      "Epoch 4142\n",
      "-------------------------------\n",
      "loss: 0.229111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399321 \n",
      "\n",
      "Epoch 4143\n",
      "-------------------------------\n",
      "loss: 0.215808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404394 \n",
      "\n",
      "Epoch 4144\n",
      "-------------------------------\n",
      "loss: 0.223208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409018 \n",
      "\n",
      "Epoch 4145\n",
      "-------------------------------\n",
      "loss: 0.226581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408817 \n",
      "\n",
      "Epoch 4146\n",
      "-------------------------------\n",
      "loss: 0.245608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402878 \n",
      "\n",
      "Epoch 4147\n",
      "-------------------------------\n",
      "loss: 0.214018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398430 \n",
      "\n",
      "Epoch 4148\n",
      "-------------------------------\n",
      "loss: 0.228992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397684 \n",
      "\n",
      "Epoch 4149\n",
      "-------------------------------\n",
      "loss: 0.219833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398273 \n",
      "\n",
      "Epoch 4150\n",
      "-------------------------------\n",
      "loss: 0.246724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398666 \n",
      "\n",
      "Epoch 4151\n",
      "-------------------------------\n",
      "loss: 0.219395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398898 \n",
      "\n",
      "Epoch 4152\n",
      "-------------------------------\n",
      "loss: 0.227853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399120 \n",
      "\n",
      "Epoch 4153\n",
      "-------------------------------\n",
      "loss: 0.214822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399914 \n",
      "\n",
      "Epoch 4154\n",
      "-------------------------------\n",
      "loss: 0.224291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401163 \n",
      "\n",
      "Epoch 4155\n",
      "-------------------------------\n",
      "loss: 0.219602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401273 \n",
      "\n",
      "Epoch 4156\n",
      "-------------------------------\n",
      "loss: 0.229972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400378 \n",
      "\n",
      "Epoch 4157\n",
      "-------------------------------\n",
      "loss: 0.220197  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399164 \n",
      "\n",
      "Epoch 4158\n",
      "-------------------------------\n",
      "loss: 0.228984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398289 \n",
      "\n",
      "Epoch 4159\n",
      "-------------------------------\n",
      "loss: 0.239593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397903 \n",
      "\n",
      "Epoch 4160\n",
      "-------------------------------\n",
      "loss: 0.230661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397234 \n",
      "\n",
      "Epoch 4161\n",
      "-------------------------------\n",
      "loss: 0.240866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396673 \n",
      "\n",
      "Epoch 4162\n",
      "-------------------------------\n",
      "loss: 0.214130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396507 \n",
      "\n",
      "Epoch 4163\n",
      "-------------------------------\n",
      "loss: 0.238815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395961 \n",
      "\n",
      "Epoch 4164\n",
      "-------------------------------\n",
      "loss: 0.228522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395593 \n",
      "\n",
      "Epoch 4165\n",
      "-------------------------------\n",
      "loss: 0.219299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395609 \n",
      "\n",
      "Epoch 4166\n",
      "-------------------------------\n",
      "loss: 0.236856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395566 \n",
      "\n",
      "Epoch 4167\n",
      "-------------------------------\n",
      "loss: 0.230090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396450 \n",
      "\n",
      "Epoch 4168\n",
      "-------------------------------\n",
      "loss: 0.218344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398347 \n",
      "\n",
      "Epoch 4169\n",
      "-------------------------------\n",
      "loss: 0.216640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400933 \n",
      "\n",
      "Epoch 4170\n",
      "-------------------------------\n",
      "loss: 0.213019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402453 \n",
      "\n",
      "Epoch 4171\n",
      "-------------------------------\n",
      "loss: 0.233883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401003 \n",
      "\n",
      "Epoch 4172\n",
      "-------------------------------\n",
      "loss: 0.211890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400726 \n",
      "\n",
      "Epoch 4173\n",
      "-------------------------------\n",
      "loss: 0.218584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399691 \n",
      "\n",
      "Epoch 4174\n",
      "-------------------------------\n",
      "loss: 0.224784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399101 \n",
      "\n",
      "Epoch 4175\n",
      "-------------------------------\n",
      "loss: 0.231474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399696 \n",
      "\n",
      "Epoch 4176\n",
      "-------------------------------\n",
      "loss: 0.225127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399809 \n",
      "\n",
      "Epoch 4177\n",
      "-------------------------------\n",
      "loss: 0.229164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400068 \n",
      "\n",
      "Epoch 4178\n",
      "-------------------------------\n",
      "loss: 0.221829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401267 \n",
      "\n",
      "Epoch 4179\n",
      "-------------------------------\n",
      "loss: 0.217228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401955 \n",
      "\n",
      "Epoch 4180\n",
      "-------------------------------\n",
      "loss: 0.222161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401810 \n",
      "\n",
      "Epoch 4181\n",
      "-------------------------------\n",
      "loss: 0.230884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400890 \n",
      "\n",
      "Epoch 4182\n",
      "-------------------------------\n",
      "loss: 0.217106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399324 \n",
      "\n",
      "Epoch 4183\n",
      "-------------------------------\n",
      "loss: 0.226085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399434 \n",
      "\n",
      "Epoch 4184\n",
      "-------------------------------\n",
      "loss: 0.218302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400781 \n",
      "\n",
      "Epoch 4185\n",
      "-------------------------------\n",
      "loss: 0.219952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402511 \n",
      "\n",
      "Epoch 4186\n",
      "-------------------------------\n",
      "loss: 0.240551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401039 \n",
      "\n",
      "Epoch 4187\n",
      "-------------------------------\n",
      "loss: 0.241104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397458 \n",
      "\n",
      "Epoch 4188\n",
      "-------------------------------\n",
      "loss: 0.226160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394954 \n",
      "\n",
      "Epoch 4189\n",
      "-------------------------------\n",
      "loss: 0.216155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393615 \n",
      "\n",
      "Epoch 4190\n",
      "-------------------------------\n",
      "loss: 0.217104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394009 \n",
      "\n",
      "Epoch 4191\n",
      "-------------------------------\n",
      "loss: 0.221495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394949 \n",
      "\n",
      "Epoch 4192\n",
      "-------------------------------\n",
      "loss: 0.229446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396720 \n",
      "\n",
      "Epoch 4193\n",
      "-------------------------------\n",
      "loss: 0.225267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398498 \n",
      "\n",
      "Epoch 4194\n",
      "-------------------------------\n",
      "loss: 0.221734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399812 \n",
      "\n",
      "Epoch 4195\n",
      "-------------------------------\n",
      "loss: 0.241452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398729 \n",
      "\n",
      "Epoch 4196\n",
      "-------------------------------\n",
      "loss: 0.222319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398080 \n",
      "\n",
      "Epoch 4197\n",
      "-------------------------------\n",
      "loss: 0.228838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398151 \n",
      "\n",
      "Epoch 4198\n",
      "-------------------------------\n",
      "loss: 0.229157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397854 \n",
      "\n",
      "Epoch 4199\n",
      "-------------------------------\n",
      "loss: 0.230954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398032 \n",
      "\n",
      "Epoch 4200\n",
      "-------------------------------\n",
      "loss: 0.217634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398934 \n",
      "\n",
      "Epoch 4201\n",
      "-------------------------------\n",
      "loss: 0.227218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400199 \n",
      "\n",
      "Epoch 4202\n",
      "-------------------------------\n",
      "loss: 0.243349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400065 \n",
      "\n",
      "Epoch 4203\n",
      "-------------------------------\n",
      "loss: 0.223015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400042 \n",
      "\n",
      "Epoch 4204\n",
      "-------------------------------\n",
      "loss: 0.233749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399888 \n",
      "\n",
      "Epoch 4205\n",
      "-------------------------------\n",
      "loss: 0.220669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399848 \n",
      "\n",
      "Epoch 4206\n",
      "-------------------------------\n",
      "loss: 0.237225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398963 \n",
      "\n",
      "Epoch 4207\n",
      "-------------------------------\n",
      "loss: 0.215894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398514 \n",
      "\n",
      "Epoch 4208\n",
      "-------------------------------\n",
      "loss: 0.234386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398400 \n",
      "\n",
      "Epoch 4209\n",
      "-------------------------------\n",
      "loss: 0.233693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398607 \n",
      "\n",
      "Epoch 4210\n",
      "-------------------------------\n",
      "loss: 0.231691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398868 \n",
      "\n",
      "Epoch 4211\n",
      "-------------------------------\n",
      "loss: 0.215100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399231 \n",
      "\n",
      "Epoch 4212\n",
      "-------------------------------\n",
      "loss: 0.229328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399756 \n",
      "\n",
      "Epoch 4213\n",
      "-------------------------------\n",
      "loss: 0.220151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401413 \n",
      "\n",
      "Epoch 4214\n",
      "-------------------------------\n",
      "loss: 0.244878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403637 \n",
      "\n",
      "Epoch 4215\n",
      "-------------------------------\n",
      "loss: 0.217641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404689 \n",
      "\n",
      "Epoch 4216\n",
      "-------------------------------\n",
      "loss: 0.227139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404677 \n",
      "\n",
      "Epoch 4217\n",
      "-------------------------------\n",
      "loss: 0.223097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404334 \n",
      "\n",
      "Epoch 4218\n",
      "-------------------------------\n",
      "loss: 0.223010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404333 \n",
      "\n",
      "Epoch 4219\n",
      "-------------------------------\n",
      "loss: 0.216831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403377 \n",
      "\n",
      "Epoch 4220\n",
      "-------------------------------\n",
      "loss: 0.215636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402084 \n",
      "\n",
      "Epoch 4221\n",
      "-------------------------------\n",
      "loss: 0.230184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400598 \n",
      "\n",
      "Epoch 4222\n",
      "-------------------------------\n",
      "loss: 0.227444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400222 \n",
      "\n",
      "Epoch 4223\n",
      "-------------------------------\n",
      "loss: 0.215169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400922 \n",
      "\n",
      "Epoch 4224\n",
      "-------------------------------\n",
      "loss: 0.229405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401342 \n",
      "\n",
      "Epoch 4225\n",
      "-------------------------------\n",
      "loss: 0.227686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401662 \n",
      "\n",
      "Epoch 4226\n",
      "-------------------------------\n",
      "loss: 0.221632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403178 \n",
      "\n",
      "Epoch 4227\n",
      "-------------------------------\n",
      "loss: 0.219252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404872 \n",
      "\n",
      "Epoch 4228\n",
      "-------------------------------\n",
      "loss: 0.217238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405129 \n",
      "\n",
      "Epoch 4229\n",
      "-------------------------------\n",
      "loss: 0.219113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405476 \n",
      "\n",
      "Epoch 4230\n",
      "-------------------------------\n",
      "loss: 0.222543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405370 \n",
      "\n",
      "Epoch 4231\n",
      "-------------------------------\n",
      "loss: 0.224053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404539 \n",
      "\n",
      "Epoch 4232\n",
      "-------------------------------\n",
      "loss: 0.228368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403517 \n",
      "\n",
      "Epoch 4233\n",
      "-------------------------------\n",
      "loss: 0.227507  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.404317 \n",
      "\n",
      "Epoch 4234\n",
      "-------------------------------\n",
      "loss: 0.224251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404618 \n",
      "\n",
      "Epoch 4235\n",
      "-------------------------------\n",
      "loss: 0.230342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404509 \n",
      "\n",
      "Epoch 4236\n",
      "-------------------------------\n",
      "loss: 0.226055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404986 \n",
      "\n",
      "Epoch 4237\n",
      "-------------------------------\n",
      "loss: 0.219189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406418 \n",
      "\n",
      "Epoch 4238\n",
      "-------------------------------\n",
      "loss: 0.234591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406218 \n",
      "\n",
      "Epoch 4239\n",
      "-------------------------------\n",
      "loss: 0.223509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404637 \n",
      "\n",
      "Epoch 4240\n",
      "-------------------------------\n",
      "loss: 0.211966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402927 \n",
      "\n",
      "Epoch 4241\n",
      "-------------------------------\n",
      "loss: 0.222184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401668 \n",
      "\n",
      "Epoch 4242\n",
      "-------------------------------\n",
      "loss: 0.227185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401080 \n",
      "\n",
      "Epoch 4243\n",
      "-------------------------------\n",
      "loss: 0.221778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401184 \n",
      "\n",
      "Epoch 4244\n",
      "-------------------------------\n",
      "loss: 0.228951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400914 \n",
      "\n",
      "Epoch 4245\n",
      "-------------------------------\n",
      "loss: 0.239793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400370 \n",
      "\n",
      "Epoch 4246\n",
      "-------------------------------\n",
      "loss: 0.228003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399966 \n",
      "\n",
      "Epoch 4247\n",
      "-------------------------------\n",
      "loss: 0.234365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398879 \n",
      "\n",
      "Epoch 4248\n",
      "-------------------------------\n",
      "loss: 0.229156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397685 \n",
      "\n",
      "Epoch 4249\n",
      "-------------------------------\n",
      "loss: 0.228237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397617 \n",
      "\n",
      "Epoch 4250\n",
      "-------------------------------\n",
      "loss: 0.223840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398279 \n",
      "\n",
      "Epoch 4251\n",
      "-------------------------------\n",
      "loss: 0.214140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399573 \n",
      "\n",
      "Epoch 4252\n",
      "-------------------------------\n",
      "loss: 0.239271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400723 \n",
      "\n",
      "Epoch 4253\n",
      "-------------------------------\n",
      "loss: 0.237167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401748 \n",
      "\n",
      "Epoch 4254\n",
      "-------------------------------\n",
      "loss: 0.221183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402092 \n",
      "\n",
      "Epoch 4255\n",
      "-------------------------------\n",
      "loss: 0.218710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403622 \n",
      "\n",
      "Epoch 4256\n",
      "-------------------------------\n",
      "loss: 0.235913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404213 \n",
      "\n",
      "Epoch 4257\n",
      "-------------------------------\n",
      "loss: 0.214559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403849 \n",
      "\n",
      "Epoch 4258\n",
      "-------------------------------\n",
      "loss: 0.221896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403349 \n",
      "\n",
      "Epoch 4259\n",
      "-------------------------------\n",
      "loss: 0.236090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402934 \n",
      "\n",
      "Epoch 4260\n",
      "-------------------------------\n",
      "loss: 0.232772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402318 \n",
      "\n",
      "Epoch 4261\n",
      "-------------------------------\n",
      "loss: 0.223290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401445 \n",
      "\n",
      "Epoch 4262\n",
      "-------------------------------\n",
      "loss: 0.211435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401458 \n",
      "\n",
      "Epoch 4263\n",
      "-------------------------------\n",
      "loss: 0.230183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402020 \n",
      "\n",
      "Epoch 4264\n",
      "-------------------------------\n",
      "loss: 0.223362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402143 \n",
      "\n",
      "Epoch 4265\n",
      "-------------------------------\n",
      "loss: 0.221539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402771 \n",
      "\n",
      "Epoch 4266\n",
      "-------------------------------\n",
      "loss: 0.228498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403493 \n",
      "\n",
      "Epoch 4267\n",
      "-------------------------------\n",
      "loss: 0.218018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403828 \n",
      "\n",
      "Epoch 4268\n",
      "-------------------------------\n",
      "loss: 0.222058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402901 \n",
      "\n",
      "Epoch 4269\n",
      "-------------------------------\n",
      "loss: 0.236295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402013 \n",
      "\n",
      "Epoch 4270\n",
      "-------------------------------\n",
      "loss: 0.230910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401029 \n",
      "\n",
      "Epoch 4271\n",
      "-------------------------------\n",
      "loss: 0.227975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400576 \n",
      "\n",
      "Epoch 4272\n",
      "-------------------------------\n",
      "loss: 0.236632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400207 \n",
      "\n",
      "Epoch 4273\n",
      "-------------------------------\n",
      "loss: 0.216321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399665 \n",
      "\n",
      "Epoch 4274\n",
      "-------------------------------\n",
      "loss: 0.232393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398523 \n",
      "\n",
      "Epoch 4275\n",
      "-------------------------------\n",
      "loss: 0.211950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397594 \n",
      "\n",
      "Epoch 4276\n",
      "-------------------------------\n",
      "loss: 0.228258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397455 \n",
      "\n",
      "Epoch 4277\n",
      "-------------------------------\n",
      "loss: 0.226467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398924 \n",
      "\n",
      "Epoch 4278\n",
      "-------------------------------\n",
      "loss: 0.228757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402250 \n",
      "\n",
      "Epoch 4279\n",
      "-------------------------------\n",
      "loss: 0.228345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402954 \n",
      "\n",
      "Epoch 4280\n",
      "-------------------------------\n",
      "loss: 0.223586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402232 \n",
      "\n",
      "Epoch 4281\n",
      "-------------------------------\n",
      "loss: 0.220687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400342 \n",
      "\n",
      "Epoch 4282\n",
      "-------------------------------\n",
      "loss: 0.229164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398606 \n",
      "\n",
      "Epoch 4283\n",
      "-------------------------------\n",
      "loss: 0.223021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397121 \n",
      "\n",
      "Epoch 4284\n",
      "-------------------------------\n",
      "loss: 0.207376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396382 \n",
      "\n",
      "Epoch 4285\n",
      "-------------------------------\n",
      "loss: 0.231242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396666 \n",
      "\n",
      "Epoch 4286\n",
      "-------------------------------\n",
      "loss: 0.226543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398342 \n",
      "\n",
      "Epoch 4287\n",
      "-------------------------------\n",
      "loss: 0.213304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401467 \n",
      "\n",
      "Epoch 4288\n",
      "-------------------------------\n",
      "loss: 0.221380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404826 \n",
      "\n",
      "Epoch 4289\n",
      "-------------------------------\n",
      "loss: 0.227256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405029 \n",
      "\n",
      "Epoch 4290\n",
      "-------------------------------\n",
      "loss: 0.216979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403148 \n",
      "\n",
      "Epoch 4291\n",
      "-------------------------------\n",
      "loss: 0.227784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400436 \n",
      "\n",
      "Epoch 4292\n",
      "-------------------------------\n",
      "loss: 0.224532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398155 \n",
      "\n",
      "Epoch 4293\n",
      "-------------------------------\n",
      "loss: 0.203028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397624 \n",
      "\n",
      "Epoch 4294\n",
      "-------------------------------\n",
      "loss: 0.232730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397484 \n",
      "\n",
      "Epoch 4295\n",
      "-------------------------------\n",
      "loss: 0.218156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397682 \n",
      "\n",
      "Epoch 4296\n",
      "-------------------------------\n",
      "loss: 0.215403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398689 \n",
      "\n",
      "Epoch 4297\n",
      "-------------------------------\n",
      "loss: 0.219336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400440 \n",
      "\n",
      "Epoch 4298\n",
      "-------------------------------\n",
      "loss: 0.232196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401506 \n",
      "\n",
      "Epoch 4299\n",
      "-------------------------------\n",
      "loss: 0.238801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400091 \n",
      "\n",
      "Epoch 4300\n",
      "-------------------------------\n",
      "loss: 0.220901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398953 \n",
      "\n",
      "Epoch 4301\n",
      "-------------------------------\n",
      "loss: 0.204201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399153 \n",
      "\n",
      "Epoch 4302\n",
      "-------------------------------\n",
      "loss: 0.212512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400844 \n",
      "\n",
      "Epoch 4303\n",
      "-------------------------------\n",
      "loss: 0.225370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403325 \n",
      "\n",
      "Epoch 4304\n",
      "-------------------------------\n",
      "loss: 0.233782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403924 \n",
      "\n",
      "Epoch 4305\n",
      "-------------------------------\n",
      "loss: 0.228999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403075 \n",
      "\n",
      "Epoch 4306\n",
      "-------------------------------\n",
      "loss: 0.229964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402076 \n",
      "\n",
      "Epoch 4307\n",
      "-------------------------------\n",
      "loss: 0.225736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401348 \n",
      "\n",
      "Epoch 4308\n",
      "-------------------------------\n",
      "loss: 0.226309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401923 \n",
      "\n",
      "Epoch 4309\n",
      "-------------------------------\n",
      "loss: 0.236770  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403299 \n",
      "\n",
      "Epoch 4310\n",
      "-------------------------------\n",
      "loss: 0.217342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404758 \n",
      "\n",
      "Epoch 4311\n",
      "-------------------------------\n",
      "loss: 0.223425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405123 \n",
      "\n",
      "Epoch 4312\n",
      "-------------------------------\n",
      "loss: 0.216705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405402 \n",
      "\n",
      "Epoch 4313\n",
      "-------------------------------\n",
      "loss: 0.223002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405672 \n",
      "\n",
      "Epoch 4314\n",
      "-------------------------------\n",
      "loss: 0.218349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404573 \n",
      "\n",
      "Epoch 4315\n",
      "-------------------------------\n",
      "loss: 0.223424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403629 \n",
      "\n",
      "Epoch 4316\n",
      "-------------------------------\n",
      "loss: 0.235723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401787 \n",
      "\n",
      "Epoch 4317\n",
      "-------------------------------\n",
      "loss: 0.215795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400629 \n",
      "\n",
      "Epoch 4318\n",
      "-------------------------------\n",
      "loss: 0.235208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400951 \n",
      "\n",
      "Epoch 4319\n",
      "-------------------------------\n",
      "loss: 0.223662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404292 \n",
      "\n",
      "Epoch 4320\n",
      "-------------------------------\n",
      "loss: 0.220223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406587 \n",
      "\n",
      "Epoch 4321\n",
      "-------------------------------\n",
      "loss: 0.219508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406683 \n",
      "\n",
      "Epoch 4322\n",
      "-------------------------------\n",
      "loss: 0.230393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403901 \n",
      "\n",
      "Epoch 4323\n",
      "-------------------------------\n",
      "loss: 0.224460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400512 \n",
      "\n",
      "Epoch 4324\n",
      "-------------------------------\n",
      "loss: 0.216465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399041 \n",
      "\n",
      "Epoch 4325\n",
      "-------------------------------\n",
      "loss: 0.214352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397561 \n",
      "\n",
      "Epoch 4326\n",
      "-------------------------------\n",
      "loss: 0.231763  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397585 \n",
      "\n",
      "Epoch 4327\n",
      "-------------------------------\n",
      "loss: 0.213359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398531 \n",
      "\n",
      "Epoch 4328\n",
      "-------------------------------\n",
      "loss: 0.218996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399684 \n",
      "\n",
      "Epoch 4329\n",
      "-------------------------------\n",
      "loss: 0.233258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399270 \n",
      "\n",
      "Epoch 4330\n",
      "-------------------------------\n",
      "loss: 0.233760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398826 \n",
      "\n",
      "Epoch 4331\n",
      "-------------------------------\n",
      "loss: 0.239540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398144 \n",
      "\n",
      "Epoch 4332\n",
      "-------------------------------\n",
      "loss: 0.215475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398447 \n",
      "\n",
      "Epoch 4333\n",
      "-------------------------------\n",
      "loss: 0.220634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399529 \n",
      "\n",
      "Epoch 4334\n",
      "-------------------------------\n",
      "loss: 0.228967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400537 \n",
      "\n",
      "Epoch 4335\n",
      "-------------------------------\n",
      "loss: 0.217765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402513 \n",
      "\n",
      "Epoch 4336\n",
      "-------------------------------\n",
      "loss: 0.202493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403933 \n",
      "\n",
      "Epoch 4337\n",
      "-------------------------------\n",
      "loss: 0.245152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403104 \n",
      "\n",
      "Epoch 4338\n",
      "-------------------------------\n",
      "loss: 0.219419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402414 \n",
      "\n",
      "Epoch 4339\n",
      "-------------------------------\n",
      "loss: 0.224717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402141 \n",
      "\n",
      "Epoch 4340\n",
      "-------------------------------\n",
      "loss: 0.224876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401876 \n",
      "\n",
      "Epoch 4341\n",
      "-------------------------------\n",
      "loss: 0.227499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401963 \n",
      "\n",
      "Epoch 4342\n",
      "-------------------------------\n",
      "loss: 0.219638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401756 \n",
      "\n",
      "Epoch 4343\n",
      "-------------------------------\n",
      "loss: 0.231254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402406 \n",
      "\n",
      "Epoch 4344\n",
      "-------------------------------\n",
      "loss: 0.230392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403896 \n",
      "\n",
      "Epoch 4345\n",
      "-------------------------------\n",
      "loss: 0.218343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405580 \n",
      "\n",
      "Epoch 4346\n",
      "-------------------------------\n",
      "loss: 0.220912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405882 \n",
      "\n",
      "Epoch 4347\n",
      "-------------------------------\n",
      "loss: 0.223754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405525 \n",
      "\n",
      "Epoch 4348\n",
      "-------------------------------\n",
      "loss: 0.231481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404791 \n",
      "\n",
      "Epoch 4349\n",
      "-------------------------------\n",
      "loss: 0.215362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404474 \n",
      "\n",
      "Epoch 4350\n",
      "-------------------------------\n",
      "loss: 0.227387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403360 \n",
      "\n",
      "Epoch 4351\n",
      "-------------------------------\n",
      "loss: 0.210893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403866 \n",
      "\n",
      "Epoch 4352\n",
      "-------------------------------\n",
      "loss: 0.220065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404442 \n",
      "\n",
      "Epoch 4353\n",
      "-------------------------------\n",
      "loss: 0.222241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405317 \n",
      "\n",
      "Epoch 4354\n",
      "-------------------------------\n",
      "loss: 0.245309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405979 \n",
      "\n",
      "Epoch 4355\n",
      "-------------------------------\n",
      "loss: 0.234702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405588 \n",
      "\n",
      "Epoch 4356\n",
      "-------------------------------\n",
      "loss: 0.215676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404408 \n",
      "\n",
      "Epoch 4357\n",
      "-------------------------------\n",
      "loss: 0.214839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403313 \n",
      "\n",
      "Epoch 4358\n",
      "-------------------------------\n",
      "loss: 0.220969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402476 \n",
      "\n",
      "Epoch 4359\n",
      "-------------------------------\n",
      "loss: 0.223875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402260 \n",
      "\n",
      "Epoch 4360\n",
      "-------------------------------\n",
      "loss: 0.215155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401911 \n",
      "\n",
      "Epoch 4361\n",
      "-------------------------------\n",
      "loss: 0.224640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402491 \n",
      "\n",
      "Epoch 4362\n",
      "-------------------------------\n",
      "loss: 0.218608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403462 \n",
      "\n",
      "Epoch 4363\n",
      "-------------------------------\n",
      "loss: 0.228009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403679 \n",
      "\n",
      "Epoch 4364\n",
      "-------------------------------\n",
      "loss: 0.224235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403592 \n",
      "\n",
      "Epoch 4365\n",
      "-------------------------------\n",
      "loss: 0.219871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403219 \n",
      "\n",
      "Epoch 4366\n",
      "-------------------------------\n",
      "loss: 0.216101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402957 \n",
      "\n",
      "Epoch 4367\n",
      "-------------------------------\n",
      "loss: 0.214897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402858 \n",
      "\n",
      "Epoch 4368\n",
      "-------------------------------\n",
      "loss: 0.217199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402889 \n",
      "\n",
      "Epoch 4369\n",
      "-------------------------------\n",
      "loss: 0.221822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402324 \n",
      "\n",
      "Epoch 4370\n",
      "-------------------------------\n",
      "loss: 0.227209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401824 \n",
      "\n",
      "Epoch 4371\n",
      "-------------------------------\n",
      "loss: 0.220436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401251 \n",
      "\n",
      "Epoch 4372\n",
      "-------------------------------\n",
      "loss: 0.220742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401165 \n",
      "\n",
      "Epoch 4373\n",
      "-------------------------------\n",
      "loss: 0.231103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401692 \n",
      "\n",
      "Epoch 4374\n",
      "-------------------------------\n",
      "loss: 0.221036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401968 \n",
      "\n",
      "Epoch 4375\n",
      "-------------------------------\n",
      "loss: 0.230246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401160 \n",
      "\n",
      "Epoch 4376\n",
      "-------------------------------\n",
      "loss: 0.211663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401041 \n",
      "\n",
      "Epoch 4377\n",
      "-------------------------------\n",
      "loss: 0.221734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400463 \n",
      "\n",
      "Epoch 4378\n",
      "-------------------------------\n",
      "loss: 0.223550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399153 \n",
      "\n",
      "Epoch 4379\n",
      "-------------------------------\n",
      "loss: 0.225340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398387 \n",
      "\n",
      "Epoch 4380\n",
      "-------------------------------\n",
      "loss: 0.221848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397875 \n",
      "\n",
      "Epoch 4381\n",
      "-------------------------------\n",
      "loss: 0.231204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398204 \n",
      "\n",
      "Epoch 4382\n",
      "-------------------------------\n",
      "loss: 0.227088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398325 \n",
      "\n",
      "Epoch 4383\n",
      "-------------------------------\n",
      "loss: 0.224894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399372 \n",
      "\n",
      "Epoch 4384\n",
      "-------------------------------\n",
      "loss: 0.224896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400217 \n",
      "\n",
      "Epoch 4385\n",
      "-------------------------------\n",
      "loss: 0.228276  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400852 \n",
      "\n",
      "Epoch 4386\n",
      "-------------------------------\n",
      "loss: 0.216552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401672 \n",
      "\n",
      "Epoch 4387\n",
      "-------------------------------\n",
      "loss: 0.230084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402370 \n",
      "\n",
      "Epoch 4388\n",
      "-------------------------------\n",
      "loss: 0.217563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402672 \n",
      "\n",
      "Epoch 4389\n",
      "-------------------------------\n",
      "loss: 0.223344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402672 \n",
      "\n",
      "Epoch 4390\n",
      "-------------------------------\n",
      "loss: 0.229631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402447 \n",
      "\n",
      "Epoch 4391\n",
      "-------------------------------\n",
      "loss: 0.219216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402334 \n",
      "\n",
      "Epoch 4392\n",
      "-------------------------------\n",
      "loss: 0.224091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401550 \n",
      "\n",
      "Epoch 4393\n",
      "-------------------------------\n",
      "loss: 0.215609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400525 \n",
      "\n",
      "Epoch 4394\n",
      "-------------------------------\n",
      "loss: 0.222551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401042 \n",
      "\n",
      "Epoch 4395\n",
      "-------------------------------\n",
      "loss: 0.219041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402188 \n",
      "\n",
      "Epoch 4396\n",
      "-------------------------------\n",
      "loss: 0.212579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403606 \n",
      "\n",
      "Epoch 4397\n",
      "-------------------------------\n",
      "loss: 0.209216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405019 \n",
      "\n",
      "Epoch 4398\n",
      "-------------------------------\n",
      "loss: 0.233843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404824 \n",
      "\n",
      "Epoch 4399\n",
      "-------------------------------\n",
      "loss: 0.224779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403107 \n",
      "\n",
      "Epoch 4400\n",
      "-------------------------------\n",
      "loss: 0.220724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401806 \n",
      "\n",
      "Epoch 4401\n",
      "-------------------------------\n",
      "loss: 0.225798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402645 \n",
      "\n",
      "Epoch 4402\n",
      "-------------------------------\n",
      "loss: 0.211992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402724 \n",
      "\n",
      "Epoch 4403\n",
      "-------------------------------\n",
      "loss: 0.231412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402308 \n",
      "\n",
      "Epoch 4404\n",
      "-------------------------------\n",
      "loss: 0.217284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404288 \n",
      "\n",
      "Epoch 4405\n",
      "-------------------------------\n",
      "loss: 0.218375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408888 \n",
      "\n",
      "Epoch 4406\n",
      "-------------------------------\n",
      "loss: 0.206305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412303 \n",
      "\n",
      "Epoch 4407\n",
      "-------------------------------\n",
      "loss: 0.226102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411935 \n",
      "\n",
      "Epoch 4408\n",
      "-------------------------------\n",
      "loss: 0.246278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408610 \n",
      "\n",
      "Epoch 4409\n",
      "-------------------------------\n",
      "loss: 0.239648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405781 \n",
      "\n",
      "Epoch 4410\n",
      "-------------------------------\n",
      "loss: 0.227386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404851 \n",
      "\n",
      "Epoch 4411\n",
      "-------------------------------\n",
      "loss: 0.218338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404877 \n",
      "\n",
      "Epoch 4412\n",
      "-------------------------------\n",
      "loss: 0.218628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404902 \n",
      "\n",
      "Epoch 4413\n",
      "-------------------------------\n",
      "loss: 0.226715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404684 \n",
      "\n",
      "Epoch 4414\n",
      "-------------------------------\n",
      "loss: 0.214214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404388 \n",
      "\n",
      "Epoch 4415\n",
      "-------------------------------\n",
      "loss: 0.225121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404787 \n",
      "\n",
      "Epoch 4416\n",
      "-------------------------------\n",
      "loss: 0.225525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403527 \n",
      "\n",
      "Epoch 4417\n",
      "-------------------------------\n",
      "loss: 0.218721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402375 \n",
      "\n",
      "Epoch 4418\n",
      "-------------------------------\n",
      "loss: 0.215312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400494 \n",
      "\n",
      "Epoch 4419\n",
      "-------------------------------\n",
      "loss: 0.230455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399342 \n",
      "\n",
      "Epoch 4420\n",
      "-------------------------------\n",
      "loss: 0.217584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398492 \n",
      "\n",
      "Epoch 4421\n",
      "-------------------------------\n",
      "loss: 0.219041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398367 \n",
      "\n",
      "Epoch 4422\n",
      "-------------------------------\n",
      "loss: 0.228255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399843 \n",
      "\n",
      "Epoch 4423\n",
      "-------------------------------\n",
      "loss: 0.219301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402537 \n",
      "\n",
      "Epoch 4424\n",
      "-------------------------------\n",
      "loss: 0.255076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403507 \n",
      "\n",
      "Epoch 4425\n",
      "-------------------------------\n",
      "loss: 0.213939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404305 \n",
      "\n",
      "Epoch 4426\n",
      "-------------------------------\n",
      "loss: 0.216520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406526 \n",
      "\n",
      "Epoch 4427\n",
      "-------------------------------\n",
      "loss: 0.244049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407378 \n",
      "\n",
      "Epoch 4428\n",
      "-------------------------------\n",
      "loss: 0.238618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406494 \n",
      "\n",
      "Epoch 4429\n",
      "-------------------------------\n",
      "loss: 0.217933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405401 \n",
      "\n",
      "Epoch 4430\n",
      "-------------------------------\n",
      "loss: 0.226828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404557 \n",
      "\n",
      "Epoch 4431\n",
      "-------------------------------\n",
      "loss: 0.230976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403718 \n",
      "\n",
      "Epoch 4432\n",
      "-------------------------------\n",
      "loss: 0.221882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403066 \n",
      "\n",
      "Epoch 4433\n",
      "-------------------------------\n",
      "loss: 0.235204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402002 \n",
      "\n",
      "Epoch 4434\n",
      "-------------------------------\n",
      "loss: 0.216298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402424 \n",
      "\n",
      "Epoch 4435\n",
      "-------------------------------\n",
      "loss: 0.216113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404941 \n",
      "\n",
      "Epoch 4436\n",
      "-------------------------------\n",
      "loss: 0.246290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407208 \n",
      "\n",
      "Epoch 4437\n",
      "-------------------------------\n",
      "loss: 0.235476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407274 \n",
      "\n",
      "Epoch 4438\n",
      "-------------------------------\n",
      "loss: 0.225686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405845 \n",
      "\n",
      "Epoch 4439\n",
      "-------------------------------\n",
      "loss: 0.203485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404706 \n",
      "\n",
      "Epoch 4440\n",
      "-------------------------------\n",
      "loss: 0.227078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402424 \n",
      "\n",
      "Epoch 4441\n",
      "-------------------------------\n",
      "loss: 0.210656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399968 \n",
      "\n",
      "Epoch 4442\n",
      "-------------------------------\n",
      "loss: 0.215762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398773 \n",
      "\n",
      "Epoch 4443\n",
      "-------------------------------\n",
      "loss: 0.212782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398832 \n",
      "\n",
      "Epoch 4444\n",
      "-------------------------------\n",
      "loss: 0.226907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398880 \n",
      "\n",
      "Epoch 4445\n",
      "-------------------------------\n",
      "loss: 0.227484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400278 \n",
      "\n",
      "Epoch 4446\n",
      "-------------------------------\n",
      "loss: 0.218002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401612 \n",
      "\n",
      "Epoch 4447\n",
      "-------------------------------\n",
      "loss: 0.218945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402278 \n",
      "\n",
      "Epoch 4448\n",
      "-------------------------------\n",
      "loss: 0.222674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401620 \n",
      "\n",
      "Epoch 4449\n",
      "-------------------------------\n",
      "loss: 0.226919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401088 \n",
      "\n",
      "Epoch 4450\n",
      "-------------------------------\n",
      "loss: 0.217860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401211 \n",
      "\n",
      "Epoch 4451\n",
      "-------------------------------\n",
      "loss: 0.223614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402281 \n",
      "\n",
      "Epoch 4452\n",
      "-------------------------------\n",
      "loss: 0.218158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403670 \n",
      "\n",
      "Epoch 4453\n",
      "-------------------------------\n",
      "loss: 0.228003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403381 \n",
      "\n",
      "Epoch 4454\n",
      "-------------------------------\n",
      "loss: 0.218353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401901 \n",
      "\n",
      "Epoch 4455\n",
      "-------------------------------\n",
      "loss: 0.230242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400901 \n",
      "\n",
      "Epoch 4456\n",
      "-------------------------------\n",
      "loss: 0.208243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400736 \n",
      "\n",
      "Epoch 4457\n",
      "-------------------------------\n",
      "loss: 0.227685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401473 \n",
      "\n",
      "Epoch 4458\n",
      "-------------------------------\n",
      "loss: 0.214051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401596 \n",
      "\n",
      "Epoch 4459\n",
      "-------------------------------\n",
      "loss: 0.216156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401634 \n",
      "\n",
      "Epoch 4460\n",
      "-------------------------------\n",
      "loss: 0.219773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401969 \n",
      "\n",
      "Epoch 4461\n",
      "-------------------------------\n",
      "loss: 0.212278  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.401369 \n",
      "\n",
      "Epoch 4462\n",
      "-------------------------------\n",
      "loss: 0.212934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400312 \n",
      "\n",
      "Epoch 4463\n",
      "-------------------------------\n",
      "loss: 0.226408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398152 \n",
      "\n",
      "Epoch 4464\n",
      "-------------------------------\n",
      "loss: 0.231637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397334 \n",
      "\n",
      "Epoch 4465\n",
      "-------------------------------\n",
      "loss: 0.227075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396734 \n",
      "\n",
      "Epoch 4466\n",
      "-------------------------------\n",
      "loss: 0.219908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397122 \n",
      "\n",
      "Epoch 4467\n",
      "-------------------------------\n",
      "loss: 0.221083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398332 \n",
      "\n",
      "Epoch 4468\n",
      "-------------------------------\n",
      "loss: 0.214150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399514 \n",
      "\n",
      "Epoch 4469\n",
      "-------------------------------\n",
      "loss: 0.221862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401471 \n",
      "\n",
      "Epoch 4470\n",
      "-------------------------------\n",
      "loss: 0.228876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402618 \n",
      "\n",
      "Epoch 4471\n",
      "-------------------------------\n",
      "loss: 0.202821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402582 \n",
      "\n",
      "Epoch 4472\n",
      "-------------------------------\n",
      "loss: 0.213468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402454 \n",
      "\n",
      "Epoch 4473\n",
      "-------------------------------\n",
      "loss: 0.241095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400374 \n",
      "\n",
      "Epoch 4474\n",
      "-------------------------------\n",
      "loss: 0.230885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398856 \n",
      "\n",
      "Epoch 4475\n",
      "-------------------------------\n",
      "loss: 0.230620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398533 \n",
      "\n",
      "Epoch 4476\n",
      "-------------------------------\n",
      "loss: 0.227421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400016 \n",
      "\n",
      "Epoch 4477\n",
      "-------------------------------\n",
      "loss: 0.222537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402296 \n",
      "\n",
      "Epoch 4478\n",
      "-------------------------------\n",
      "loss: 0.228292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403737 \n",
      "\n",
      "Epoch 4479\n",
      "-------------------------------\n",
      "loss: 0.244099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403879 \n",
      "\n",
      "Epoch 4480\n",
      "-------------------------------\n",
      "loss: 0.232128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402942 \n",
      "\n",
      "Epoch 4481\n",
      "-------------------------------\n",
      "loss: 0.219976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401890 \n",
      "\n",
      "Epoch 4482\n",
      "-------------------------------\n",
      "loss: 0.224177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401214 \n",
      "\n",
      "Epoch 4483\n",
      "-------------------------------\n",
      "loss: 0.216777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402001 \n",
      "\n",
      "Epoch 4484\n",
      "-------------------------------\n",
      "loss: 0.226227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402838 \n",
      "\n",
      "Epoch 4485\n",
      "-------------------------------\n",
      "loss: 0.216157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403557 \n",
      "\n",
      "Epoch 4486\n",
      "-------------------------------\n",
      "loss: 0.237851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403756 \n",
      "\n",
      "Epoch 4487\n",
      "-------------------------------\n",
      "loss: 0.233307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402358 \n",
      "\n",
      "Epoch 4488\n",
      "-------------------------------\n",
      "loss: 0.235943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400973 \n",
      "\n",
      "Epoch 4489\n",
      "-------------------------------\n",
      "loss: 0.221049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400738 \n",
      "\n",
      "Epoch 4490\n",
      "-------------------------------\n",
      "loss: 0.230545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401606 \n",
      "\n",
      "Epoch 4491\n",
      "-------------------------------\n",
      "loss: 0.221638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403689 \n",
      "\n",
      "Epoch 4492\n",
      "-------------------------------\n",
      "loss: 0.221009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404888 \n",
      "\n",
      "Epoch 4493\n",
      "-------------------------------\n",
      "loss: 0.224540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404572 \n",
      "\n",
      "Epoch 4494\n",
      "-------------------------------\n",
      "loss: 0.212890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403698 \n",
      "\n",
      "Epoch 4495\n",
      "-------------------------------\n",
      "loss: 0.245565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401677 \n",
      "\n",
      "Epoch 4496\n",
      "-------------------------------\n",
      "loss: 0.205702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400506 \n",
      "\n",
      "Epoch 4497\n",
      "-------------------------------\n",
      "loss: 0.229697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399970 \n",
      "\n",
      "Epoch 4498\n",
      "-------------------------------\n",
      "loss: 0.225739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400112 \n",
      "\n",
      "Epoch 4499\n",
      "-------------------------------\n",
      "loss: 0.213063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402102 \n",
      "\n",
      "Epoch 4500\n",
      "-------------------------------\n",
      "loss: 0.236053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405329 \n",
      "\n",
      "Epoch 4501\n",
      "-------------------------------\n",
      "loss: 0.220023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408871 \n",
      "\n",
      "Epoch 4502\n",
      "-------------------------------\n",
      "loss: 0.206999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411107 \n",
      "\n",
      "Epoch 4503\n",
      "-------------------------------\n",
      "loss: 0.217602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409646 \n",
      "\n",
      "Epoch 4504\n",
      "-------------------------------\n",
      "loss: 0.214373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406473 \n",
      "\n",
      "Epoch 4505\n",
      "-------------------------------\n",
      "loss: 0.240038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403633 \n",
      "\n",
      "Epoch 4506\n",
      "-------------------------------\n",
      "loss: 0.231631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401788 \n",
      "\n",
      "Epoch 4507\n",
      "-------------------------------\n",
      "loss: 0.226570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402119 \n",
      "\n",
      "Epoch 4508\n",
      "-------------------------------\n",
      "loss: 0.220343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402213 \n",
      "\n",
      "Epoch 4509\n",
      "-------------------------------\n",
      "loss: 0.229107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401163 \n",
      "\n",
      "Epoch 4510\n",
      "-------------------------------\n",
      "loss: 0.217830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400884 \n",
      "\n",
      "Epoch 4511\n",
      "-------------------------------\n",
      "loss: 0.227061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400551 \n",
      "\n",
      "Epoch 4512\n",
      "-------------------------------\n",
      "loss: 0.229415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401410 \n",
      "\n",
      "Epoch 4513\n",
      "-------------------------------\n",
      "loss: 0.219652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403132 \n",
      "\n",
      "Epoch 4514\n",
      "-------------------------------\n",
      "loss: 0.229238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403578 \n",
      "\n",
      "Epoch 4515\n",
      "-------------------------------\n",
      "loss: 0.220993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401715 \n",
      "\n",
      "Epoch 4516\n",
      "-------------------------------\n",
      "loss: 0.256203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397315 \n",
      "\n",
      "Epoch 4517\n",
      "-------------------------------\n",
      "loss: 0.212065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395967 \n",
      "\n",
      "Epoch 4518\n",
      "-------------------------------\n",
      "loss: 0.227129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395735 \n",
      "\n",
      "Epoch 4519\n",
      "-------------------------------\n",
      "loss: 0.226259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396242 \n",
      "\n",
      "Epoch 4520\n",
      "-------------------------------\n",
      "loss: 0.239944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396951 \n",
      "\n",
      "Epoch 4521\n",
      "-------------------------------\n",
      "loss: 0.218395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397491 \n",
      "\n",
      "Epoch 4522\n",
      "-------------------------------\n",
      "loss: 0.231987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398053 \n",
      "\n",
      "Epoch 4523\n",
      "-------------------------------\n",
      "loss: 0.231928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399421 \n",
      "\n",
      "Epoch 4524\n",
      "-------------------------------\n",
      "loss: 0.223815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402846 \n",
      "\n",
      "Epoch 4525\n",
      "-------------------------------\n",
      "loss: 0.227839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407604 \n",
      "\n",
      "Epoch 4526\n",
      "-------------------------------\n",
      "loss: 0.232881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409456 \n",
      "\n",
      "Epoch 4527\n",
      "-------------------------------\n",
      "loss: 0.216316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408277 \n",
      "\n",
      "Epoch 4528\n",
      "-------------------------------\n",
      "loss: 0.232415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403891 \n",
      "\n",
      "Epoch 4529\n",
      "-------------------------------\n",
      "loss: 0.223316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400572 \n",
      "\n",
      "Epoch 4530\n",
      "-------------------------------\n",
      "loss: 0.221377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399668 \n",
      "\n",
      "Epoch 4531\n",
      "-------------------------------\n",
      "loss: 0.233715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400154 \n",
      "\n",
      "Epoch 4532\n",
      "-------------------------------\n",
      "loss: 0.234091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400071 \n",
      "\n",
      "Epoch 4533\n",
      "-------------------------------\n",
      "loss: 0.235550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401079 \n",
      "\n",
      "Epoch 4534\n",
      "-------------------------------\n",
      "loss: 0.224780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402855 \n",
      "\n",
      "Epoch 4535\n",
      "-------------------------------\n",
      "loss: 0.223115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405073 \n",
      "\n",
      "Epoch 4536\n",
      "-------------------------------\n",
      "loss: 0.219059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407143 \n",
      "\n",
      "Epoch 4537\n",
      "-------------------------------\n",
      "loss: 0.213518  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.408031 \n",
      "\n",
      "Epoch 4538\n",
      "-------------------------------\n",
      "loss: 0.211794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407743 \n",
      "\n",
      "Epoch 4539\n",
      "-------------------------------\n",
      "loss: 0.223255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404047 \n",
      "\n",
      "Epoch 4540\n",
      "-------------------------------\n",
      "loss: 0.218039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399736 \n",
      "\n",
      "Epoch 4541\n",
      "-------------------------------\n",
      "loss: 0.223042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397260 \n",
      "\n",
      "Epoch 4542\n",
      "-------------------------------\n",
      "loss: 0.223008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396010 \n",
      "\n",
      "Epoch 4543\n",
      "-------------------------------\n",
      "loss: 0.214670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395500 \n",
      "\n",
      "Epoch 4544\n",
      "-------------------------------\n",
      "loss: 0.218803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395128 \n",
      "\n",
      "Epoch 4545\n",
      "-------------------------------\n",
      "loss: 0.221207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394926 \n",
      "\n",
      "Epoch 4546\n",
      "-------------------------------\n",
      "loss: 0.228757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396426 \n",
      "\n",
      "Epoch 4547\n",
      "-------------------------------\n",
      "loss: 0.219294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398291 \n",
      "\n",
      "Epoch 4548\n",
      "-------------------------------\n",
      "loss: 0.215279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399940 \n",
      "\n",
      "Epoch 4549\n",
      "-------------------------------\n",
      "loss: 0.214844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400224 \n",
      "\n",
      "Epoch 4550\n",
      "-------------------------------\n",
      "loss: 0.219001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400577 \n",
      "\n",
      "Epoch 4551\n",
      "-------------------------------\n",
      "loss: 0.220030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400681 \n",
      "\n",
      "Epoch 4552\n",
      "-------------------------------\n",
      "loss: 0.215502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400390 \n",
      "\n",
      "Epoch 4553\n",
      "-------------------------------\n",
      "loss: 0.225015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400350 \n",
      "\n",
      "Epoch 4554\n",
      "-------------------------------\n",
      "loss: 0.237942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400158 \n",
      "\n",
      "Epoch 4555\n",
      "-------------------------------\n",
      "loss: 0.206222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401017 \n",
      "\n",
      "Epoch 4556\n",
      "-------------------------------\n",
      "loss: 0.212017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402629 \n",
      "\n",
      "Epoch 4557\n",
      "-------------------------------\n",
      "loss: 0.221928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403756 \n",
      "\n",
      "Epoch 4558\n",
      "-------------------------------\n",
      "loss: 0.228154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403460 \n",
      "\n",
      "Epoch 4559\n",
      "-------------------------------\n",
      "loss: 0.212948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402668 \n",
      "\n",
      "Epoch 4560\n",
      "-------------------------------\n",
      "loss: 0.214256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402041 \n",
      "\n",
      "Epoch 4561\n",
      "-------------------------------\n",
      "loss: 0.216178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402258 \n",
      "\n",
      "Epoch 4562\n",
      "-------------------------------\n",
      "loss: 0.231471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401864 \n",
      "\n",
      "Epoch 4563\n",
      "-------------------------------\n",
      "loss: 0.220598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400882 \n",
      "\n",
      "Epoch 4564\n",
      "-------------------------------\n",
      "loss: 0.220189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400786 \n",
      "\n",
      "Epoch 4565\n",
      "-------------------------------\n",
      "loss: 0.225319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400499 \n",
      "\n",
      "Epoch 4566\n",
      "-------------------------------\n",
      "loss: 0.224968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400528 \n",
      "\n",
      "Epoch 4567\n",
      "-------------------------------\n",
      "loss: 0.221445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401191 \n",
      "\n",
      "Epoch 4568\n",
      "-------------------------------\n",
      "loss: 0.212914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402099 \n",
      "\n",
      "Epoch 4569\n",
      "-------------------------------\n",
      "loss: 0.223050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403822 \n",
      "\n",
      "Epoch 4570\n",
      "-------------------------------\n",
      "loss: 0.219478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404415 \n",
      "\n",
      "Epoch 4571\n",
      "-------------------------------\n",
      "loss: 0.216215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403257 \n",
      "\n",
      "Epoch 4572\n",
      "-------------------------------\n",
      "loss: 0.227190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401960 \n",
      "\n",
      "Epoch 4573\n",
      "-------------------------------\n",
      "loss: 0.218693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401767 \n",
      "\n",
      "Epoch 4574\n",
      "-------------------------------\n",
      "loss: 0.218000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403211 \n",
      "\n",
      "Epoch 4575\n",
      "-------------------------------\n",
      "loss: 0.212511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404134 \n",
      "\n",
      "Epoch 4576\n",
      "-------------------------------\n",
      "loss: 0.214581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404164 \n",
      "\n",
      "Epoch 4577\n",
      "-------------------------------\n",
      "loss: 0.217814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404376 \n",
      "\n",
      "Epoch 4578\n",
      "-------------------------------\n",
      "loss: 0.216617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403625 \n",
      "\n",
      "Epoch 4579\n",
      "-------------------------------\n",
      "loss: 0.230649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401082 \n",
      "\n",
      "Epoch 4580\n",
      "-------------------------------\n",
      "loss: 0.216758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398970 \n",
      "\n",
      "Epoch 4581\n",
      "-------------------------------\n",
      "loss: 0.212674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398623 \n",
      "\n",
      "Epoch 4582\n",
      "-------------------------------\n",
      "loss: 0.215541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398605 \n",
      "\n",
      "Epoch 4583\n",
      "-------------------------------\n",
      "loss: 0.211246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398806 \n",
      "\n",
      "Epoch 4584\n",
      "-------------------------------\n",
      "loss: 0.228198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399659 \n",
      "\n",
      "Epoch 4585\n",
      "-------------------------------\n",
      "loss: 0.211711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401615 \n",
      "\n",
      "Epoch 4586\n",
      "-------------------------------\n",
      "loss: 0.210687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404628 \n",
      "\n",
      "Epoch 4587\n",
      "-------------------------------\n",
      "loss: 0.201034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407749 \n",
      "\n",
      "Epoch 4588\n",
      "-------------------------------\n",
      "loss: 0.216213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408811 \n",
      "\n",
      "Epoch 4589\n",
      "-------------------------------\n",
      "loss: 0.223772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407479 \n",
      "\n",
      "Epoch 4590\n",
      "-------------------------------\n",
      "loss: 0.222566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404163 \n",
      "\n",
      "Epoch 4591\n",
      "-------------------------------\n",
      "loss: 0.212073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401774 \n",
      "\n",
      "Epoch 4592\n",
      "-------------------------------\n",
      "loss: 0.209014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400246 \n",
      "\n",
      "Epoch 4593\n",
      "-------------------------------\n",
      "loss: 0.233952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399099 \n",
      "\n",
      "Epoch 4594\n",
      "-------------------------------\n",
      "loss: 0.223374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398471 \n",
      "\n",
      "Epoch 4595\n",
      "-------------------------------\n",
      "loss: 0.220178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397590 \n",
      "\n",
      "Epoch 4596\n",
      "-------------------------------\n",
      "loss: 0.216261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397431 \n",
      "\n",
      "Epoch 4597\n",
      "-------------------------------\n",
      "loss: 0.227275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399157 \n",
      "\n",
      "Epoch 4598\n",
      "-------------------------------\n",
      "loss: 0.212807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401715 \n",
      "\n",
      "Epoch 4599\n",
      "-------------------------------\n",
      "loss: 0.230793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403293 \n",
      "\n",
      "Epoch 4600\n",
      "-------------------------------\n",
      "loss: 0.246022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401393 \n",
      "\n",
      "Epoch 4601\n",
      "-------------------------------\n",
      "loss: 0.211053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399069 \n",
      "\n",
      "Epoch 4602\n",
      "-------------------------------\n",
      "loss: 0.224013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397774 \n",
      "\n",
      "Epoch 4603\n",
      "-------------------------------\n",
      "loss: 0.219449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398128 \n",
      "\n",
      "Epoch 4604\n",
      "-------------------------------\n",
      "loss: 0.226741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400456 \n",
      "\n",
      "Epoch 4605\n",
      "-------------------------------\n",
      "loss: 0.240916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402104 \n",
      "\n",
      "Epoch 4606\n",
      "-------------------------------\n",
      "loss: 0.238950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402777 \n",
      "\n",
      "Epoch 4607\n",
      "-------------------------------\n",
      "loss: 0.217283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401895 \n",
      "\n",
      "Epoch 4608\n",
      "-------------------------------\n",
      "loss: 0.224947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400581 \n",
      "\n",
      "Epoch 4609\n",
      "-------------------------------\n",
      "loss: 0.216901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400771 \n",
      "\n",
      "Epoch 4610\n",
      "-------------------------------\n",
      "loss: 0.209774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401265 \n",
      "\n",
      "Epoch 4611\n",
      "-------------------------------\n",
      "loss: 0.228258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401394 \n",
      "\n",
      "Epoch 4612\n",
      "-------------------------------\n",
      "loss: 0.212560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402361 \n",
      "\n",
      "Epoch 4613\n",
      "-------------------------------\n",
      "loss: 0.213439  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.405232 \n",
      "\n",
      "Epoch 4614\n",
      "-------------------------------\n",
      "loss: 0.214875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410961 \n",
      "\n",
      "Epoch 4615\n",
      "-------------------------------\n",
      "loss: 0.241715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414277 \n",
      "\n",
      "Epoch 4616\n",
      "-------------------------------\n",
      "loss: 0.221560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414106 \n",
      "\n",
      "Epoch 4617\n",
      "-------------------------------\n",
      "loss: 0.220426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410314 \n",
      "\n",
      "Epoch 4618\n",
      "-------------------------------\n",
      "loss: 0.228418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405644 \n",
      "\n",
      "Epoch 4619\n",
      "-------------------------------\n",
      "loss: 0.206140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403149 \n",
      "\n",
      "Epoch 4620\n",
      "-------------------------------\n",
      "loss: 0.230007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403285 \n",
      "\n",
      "Epoch 4621\n",
      "-------------------------------\n",
      "loss: 0.231815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402141 \n",
      "\n",
      "Epoch 4622\n",
      "-------------------------------\n",
      "loss: 0.243118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399873 \n",
      "\n",
      "Epoch 4623\n",
      "-------------------------------\n",
      "loss: 0.232755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398751 \n",
      "\n",
      "Epoch 4624\n",
      "-------------------------------\n",
      "loss: 0.211288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401736 \n",
      "\n",
      "Epoch 4625\n",
      "-------------------------------\n",
      "loss: 0.234935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404075 \n",
      "\n",
      "Epoch 4626\n",
      "-------------------------------\n",
      "loss: 0.240627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403363 \n",
      "\n",
      "Epoch 4627\n",
      "-------------------------------\n",
      "loss: 0.212851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402169 \n",
      "\n",
      "Epoch 4628\n",
      "-------------------------------\n",
      "loss: 0.225889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399454 \n",
      "\n",
      "Epoch 4629\n",
      "-------------------------------\n",
      "loss: 0.207261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397241 \n",
      "\n",
      "Epoch 4630\n",
      "-------------------------------\n",
      "loss: 0.217351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395239 \n",
      "\n",
      "Epoch 4631\n",
      "-------------------------------\n",
      "loss: 0.227859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394867 \n",
      "\n",
      "Epoch 4632\n",
      "-------------------------------\n",
      "loss: 0.217529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395311 \n",
      "\n",
      "Epoch 4633\n",
      "-------------------------------\n",
      "loss: 0.212837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396178 \n",
      "\n",
      "Epoch 4634\n",
      "-------------------------------\n",
      "loss: 0.219131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398094 \n",
      "\n",
      "Epoch 4635\n",
      "-------------------------------\n",
      "loss: 0.212467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401841 \n",
      "\n",
      "Epoch 4636\n",
      "-------------------------------\n",
      "loss: 0.205311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405334 \n",
      "\n",
      "Epoch 4637\n",
      "-------------------------------\n",
      "loss: 0.223524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406636 \n",
      "\n",
      "Epoch 4638\n",
      "-------------------------------\n",
      "loss: 0.239639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403746 \n",
      "\n",
      "Epoch 4639\n",
      "-------------------------------\n",
      "loss: 0.234897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398822 \n",
      "\n",
      "Epoch 4640\n",
      "-------------------------------\n",
      "loss: 0.203464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397025 \n",
      "\n",
      "Epoch 4641\n",
      "-------------------------------\n",
      "loss: 0.251655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397697 \n",
      "\n",
      "Epoch 4642\n",
      "-------------------------------\n",
      "loss: 0.223267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398727 \n",
      "\n",
      "Epoch 4643\n",
      "-------------------------------\n",
      "loss: 0.217744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399394 \n",
      "\n",
      "Epoch 4644\n",
      "-------------------------------\n",
      "loss: 0.219199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401555 \n",
      "\n",
      "Epoch 4645\n",
      "-------------------------------\n",
      "loss: 0.206640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404383 \n",
      "\n",
      "Epoch 4646\n",
      "-------------------------------\n",
      "loss: 0.226193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405508 \n",
      "\n",
      "Epoch 4647\n",
      "-------------------------------\n",
      "loss: 0.216060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405652 \n",
      "\n",
      "Epoch 4648\n",
      "-------------------------------\n",
      "loss: 0.217068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405131 \n",
      "\n",
      "Epoch 4649\n",
      "-------------------------------\n",
      "loss: 0.230226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403888 \n",
      "\n",
      "Epoch 4650\n",
      "-------------------------------\n",
      "loss: 0.214883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403230 \n",
      "\n",
      "Epoch 4651\n",
      "-------------------------------\n",
      "loss: 0.217733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403090 \n",
      "\n",
      "Epoch 4652\n",
      "-------------------------------\n",
      "loss: 0.221677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402977 \n",
      "\n",
      "Epoch 4653\n",
      "-------------------------------\n",
      "loss: 0.217302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403266 \n",
      "\n",
      "Epoch 4654\n",
      "-------------------------------\n",
      "loss: 0.216996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402977 \n",
      "\n",
      "Epoch 4655\n",
      "-------------------------------\n",
      "loss: 0.229597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403652 \n",
      "\n",
      "Epoch 4656\n",
      "-------------------------------\n",
      "loss: 0.213643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404714 \n",
      "\n",
      "Epoch 4657\n",
      "-------------------------------\n",
      "loss: 0.233399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405183 \n",
      "\n",
      "Epoch 4658\n",
      "-------------------------------\n",
      "loss: 0.225769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404369 \n",
      "\n",
      "Epoch 4659\n",
      "-------------------------------\n",
      "loss: 0.217947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403159 \n",
      "\n",
      "Epoch 4660\n",
      "-------------------------------\n",
      "loss: 0.209328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402367 \n",
      "\n",
      "Epoch 4661\n",
      "-------------------------------\n",
      "loss: 0.222311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399913 \n",
      "\n",
      "Epoch 4662\n",
      "-------------------------------\n",
      "loss: 0.222474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398587 \n",
      "\n",
      "Epoch 4663\n",
      "-------------------------------\n",
      "loss: 0.221025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397531 \n",
      "\n",
      "Epoch 4664\n",
      "-------------------------------\n",
      "loss: 0.217356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397294 \n",
      "\n",
      "Epoch 4665\n",
      "-------------------------------\n",
      "loss: 0.223613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397496 \n",
      "\n",
      "Epoch 4666\n",
      "-------------------------------\n",
      "loss: 0.227833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398342 \n",
      "\n",
      "Epoch 4667\n",
      "-------------------------------\n",
      "loss: 0.217996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400047 \n",
      "\n",
      "Epoch 4668\n",
      "-------------------------------\n",
      "loss: 0.216342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403327 \n",
      "\n",
      "Epoch 4669\n",
      "-------------------------------\n",
      "loss: 0.213696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406462 \n",
      "\n",
      "Epoch 4670\n",
      "-------------------------------\n",
      "loss: 0.220277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407898 \n",
      "\n",
      "Epoch 4671\n",
      "-------------------------------\n",
      "loss: 0.248757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404408 \n",
      "\n",
      "Epoch 4672\n",
      "-------------------------------\n",
      "loss: 0.214684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399655 \n",
      "\n",
      "Epoch 4673\n",
      "-------------------------------\n",
      "loss: 0.214857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397630 \n",
      "\n",
      "Epoch 4674\n",
      "-------------------------------\n",
      "loss: 0.249856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397909 \n",
      "\n",
      "Epoch 4675\n",
      "-------------------------------\n",
      "loss: 0.227543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398384 \n",
      "\n",
      "Epoch 4676\n",
      "-------------------------------\n",
      "loss: 0.233182  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397646 \n",
      "\n",
      "Epoch 4677\n",
      "-------------------------------\n",
      "loss: 0.233802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399228 \n",
      "\n",
      "Epoch 4678\n",
      "-------------------------------\n",
      "loss: 0.218759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403690 \n",
      "\n",
      "Epoch 4679\n",
      "-------------------------------\n",
      "loss: 0.221914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408196 \n",
      "\n",
      "Epoch 4680\n",
      "-------------------------------\n",
      "loss: 0.209785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408799 \n",
      "\n",
      "Epoch 4681\n",
      "-------------------------------\n",
      "loss: 0.230990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405335 \n",
      "\n",
      "Epoch 4682\n",
      "-------------------------------\n",
      "loss: 0.218746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402460 \n",
      "\n",
      "Epoch 4683\n",
      "-------------------------------\n",
      "loss: 0.224462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400995 \n",
      "\n",
      "Epoch 4684\n",
      "-------------------------------\n",
      "loss: 0.211522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401477 \n",
      "\n",
      "Epoch 4685\n",
      "-------------------------------\n",
      "loss: 0.228442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401728 \n",
      "\n",
      "Epoch 4686\n",
      "-------------------------------\n",
      "loss: 0.236092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402024 \n",
      "\n",
      "Epoch 4687\n",
      "-------------------------------\n",
      "loss: 0.210814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403893 \n",
      "\n",
      "Epoch 4688\n",
      "-------------------------------\n",
      "loss: 0.227530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404798 \n",
      "\n",
      "Epoch 4689\n",
      "-------------------------------\n",
      "loss: 0.230883  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.404185 \n",
      "\n",
      "Epoch 4690\n",
      "-------------------------------\n",
      "loss: 0.229156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402454 \n",
      "\n",
      "Epoch 4691\n",
      "-------------------------------\n",
      "loss: 0.212190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402224 \n",
      "\n",
      "Epoch 4692\n",
      "-------------------------------\n",
      "loss: 0.212227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401745 \n",
      "\n",
      "Epoch 4693\n",
      "-------------------------------\n",
      "loss: 0.221778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402253 \n",
      "\n",
      "Epoch 4694\n",
      "-------------------------------\n",
      "loss: 0.218104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401892 \n",
      "\n",
      "Epoch 4695\n",
      "-------------------------------\n",
      "loss: 0.218910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400922 \n",
      "\n",
      "Epoch 4696\n",
      "-------------------------------\n",
      "loss: 0.218233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400718 \n",
      "\n",
      "Epoch 4697\n",
      "-------------------------------\n",
      "loss: 0.242899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400077 \n",
      "\n",
      "Epoch 4698\n",
      "-------------------------------\n",
      "loss: 0.223343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400589 \n",
      "\n",
      "Epoch 4699\n",
      "-------------------------------\n",
      "loss: 0.229728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401635 \n",
      "\n",
      "Epoch 4700\n",
      "-------------------------------\n",
      "loss: 0.218982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403373 \n",
      "\n",
      "Epoch 4701\n",
      "-------------------------------\n",
      "loss: 0.240567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404426 \n",
      "\n",
      "Epoch 4702\n",
      "-------------------------------\n",
      "loss: 0.223409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405121 \n",
      "\n",
      "Epoch 4703\n",
      "-------------------------------\n",
      "loss: 0.228896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405019 \n",
      "\n",
      "Epoch 4704\n",
      "-------------------------------\n",
      "loss: 0.218433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405245 \n",
      "\n",
      "Epoch 4705\n",
      "-------------------------------\n",
      "loss: 0.233560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404173 \n",
      "\n",
      "Epoch 4706\n",
      "-------------------------------\n",
      "loss: 0.213092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403490 \n",
      "\n",
      "Epoch 4707\n",
      "-------------------------------\n",
      "loss: 0.219603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401822 \n",
      "\n",
      "Epoch 4708\n",
      "-------------------------------\n",
      "loss: 0.215762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401314 \n",
      "\n",
      "Epoch 4709\n",
      "-------------------------------\n",
      "loss: 0.214551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401208 \n",
      "\n",
      "Epoch 4710\n",
      "-------------------------------\n",
      "loss: 0.220363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401779 \n",
      "\n",
      "Epoch 4711\n",
      "-------------------------------\n",
      "loss: 0.211847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402791 \n",
      "\n",
      "Epoch 4712\n",
      "-------------------------------\n",
      "loss: 0.210371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404200 \n",
      "\n",
      "Epoch 4713\n",
      "-------------------------------\n",
      "loss: 0.215753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403595 \n",
      "\n",
      "Epoch 4714\n",
      "-------------------------------\n",
      "loss: 0.210487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402323 \n",
      "\n",
      "Epoch 4715\n",
      "-------------------------------\n",
      "loss: 0.214260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399972 \n",
      "\n",
      "Epoch 4716\n",
      "-------------------------------\n",
      "loss: 0.226146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398397 \n",
      "\n",
      "Epoch 4717\n",
      "-------------------------------\n",
      "loss: 0.220421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397978 \n",
      "\n",
      "Epoch 4718\n",
      "-------------------------------\n",
      "loss: 0.216285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397206 \n",
      "\n",
      "Epoch 4719\n",
      "-------------------------------\n",
      "loss: 0.212223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397783 \n",
      "\n",
      "Epoch 4720\n",
      "-------------------------------\n",
      "loss: 0.215890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398324 \n",
      "\n",
      "Epoch 4721\n",
      "-------------------------------\n",
      "loss: 0.215358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399210 \n",
      "\n",
      "Epoch 4722\n",
      "-------------------------------\n",
      "loss: 0.210250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399901 \n",
      "\n",
      "Epoch 4723\n",
      "-------------------------------\n",
      "loss: 0.212719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399476 \n",
      "\n",
      "Epoch 4724\n",
      "-------------------------------\n",
      "loss: 0.228504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398004 \n",
      "\n",
      "Epoch 4725\n",
      "-------------------------------\n",
      "loss: 0.207915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396761 \n",
      "\n",
      "Epoch 4726\n",
      "-------------------------------\n",
      "loss: 0.218160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396239 \n",
      "\n",
      "Epoch 4727\n",
      "-------------------------------\n",
      "loss: 0.210942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396031 \n",
      "\n",
      "Epoch 4728\n",
      "-------------------------------\n",
      "loss: 0.217962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395505 \n",
      "\n",
      "Epoch 4729\n",
      "-------------------------------\n",
      "loss: 0.223895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395503 \n",
      "\n",
      "Epoch 4730\n",
      "-------------------------------\n",
      "loss: 0.222926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396445 \n",
      "\n",
      "Epoch 4731\n",
      "-------------------------------\n",
      "loss: 0.217213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397551 \n",
      "\n",
      "Epoch 4732\n",
      "-------------------------------\n",
      "loss: 0.222725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400102 \n",
      "\n",
      "Epoch 4733\n",
      "-------------------------------\n",
      "loss: 0.214042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402383 \n",
      "\n",
      "Epoch 4734\n",
      "-------------------------------\n",
      "loss: 0.243782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401522 \n",
      "\n",
      "Epoch 4735\n",
      "-------------------------------\n",
      "loss: 0.210476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399104 \n",
      "\n",
      "Epoch 4736\n",
      "-------------------------------\n",
      "loss: 0.208122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398318 \n",
      "\n",
      "Epoch 4737\n",
      "-------------------------------\n",
      "loss: 0.211467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397303 \n",
      "\n",
      "Epoch 4738\n",
      "-------------------------------\n",
      "loss: 0.219903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398015 \n",
      "\n",
      "Epoch 4739\n",
      "-------------------------------\n",
      "loss: 0.221239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398797 \n",
      "\n",
      "Epoch 4740\n",
      "-------------------------------\n",
      "loss: 0.220978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398827 \n",
      "\n",
      "Epoch 4741\n",
      "-------------------------------\n",
      "loss: 0.214593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398288 \n",
      "\n",
      "Epoch 4742\n",
      "-------------------------------\n",
      "loss: 0.228576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398606 \n",
      "\n",
      "Epoch 4743\n",
      "-------------------------------\n",
      "loss: 0.217394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399781 \n",
      "\n",
      "Epoch 4744\n",
      "-------------------------------\n",
      "loss: 0.203480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402799 \n",
      "\n",
      "Epoch 4745\n",
      "-------------------------------\n",
      "loss: 0.223798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403586 \n",
      "\n",
      "Epoch 4746\n",
      "-------------------------------\n",
      "loss: 0.227906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402845 \n",
      "\n",
      "Epoch 4747\n",
      "-------------------------------\n",
      "loss: 0.229072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400290 \n",
      "\n",
      "Epoch 4748\n",
      "-------------------------------\n",
      "loss: 0.231025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399362 \n",
      "\n",
      "Epoch 4749\n",
      "-------------------------------\n",
      "loss: 0.222805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399415 \n",
      "\n",
      "Epoch 4750\n",
      "-------------------------------\n",
      "loss: 0.223666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398795 \n",
      "\n",
      "Epoch 4751\n",
      "-------------------------------\n",
      "loss: 0.215901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398279 \n",
      "\n",
      "Epoch 4752\n",
      "-------------------------------\n",
      "loss: 0.214616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398806 \n",
      "\n",
      "Epoch 4753\n",
      "-------------------------------\n",
      "loss: 0.223998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399998 \n",
      "\n",
      "Epoch 4754\n",
      "-------------------------------\n",
      "loss: 0.206595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401481 \n",
      "\n",
      "Epoch 4755\n",
      "-------------------------------\n",
      "loss: 0.224273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403228 \n",
      "\n",
      "Epoch 4756\n",
      "-------------------------------\n",
      "loss: 0.215620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404307 \n",
      "\n",
      "Epoch 4757\n",
      "-------------------------------\n",
      "loss: 0.210553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402994 \n",
      "\n",
      "Epoch 4758\n",
      "-------------------------------\n",
      "loss: 0.212260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401098 \n",
      "\n",
      "Epoch 4759\n",
      "-------------------------------\n",
      "loss: 0.222492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399785 \n",
      "\n",
      "Epoch 4760\n",
      "-------------------------------\n",
      "loss: 0.217487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398922 \n",
      "\n",
      "Epoch 4761\n",
      "-------------------------------\n",
      "loss: 0.220941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398694 \n",
      "\n",
      "Epoch 4762\n",
      "-------------------------------\n",
      "loss: 0.228247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398944 \n",
      "\n",
      "Epoch 4763\n",
      "-------------------------------\n",
      "loss: 0.227069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399389 \n",
      "\n",
      "Epoch 4764\n",
      "-------------------------------\n",
      "loss: 0.218959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399440 \n",
      "\n",
      "Epoch 4765\n",
      "-------------------------------\n",
      "loss: 0.211017  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399379 \n",
      "\n",
      "Epoch 4766\n",
      "-------------------------------\n",
      "loss: 0.222766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398857 \n",
      "\n",
      "Epoch 4767\n",
      "-------------------------------\n",
      "loss: 0.224985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398215 \n",
      "\n",
      "Epoch 4768\n",
      "-------------------------------\n",
      "loss: 0.210313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398586 \n",
      "\n",
      "Epoch 4769\n",
      "-------------------------------\n",
      "loss: 0.212881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400374 \n",
      "\n",
      "Epoch 4770\n",
      "-------------------------------\n",
      "loss: 0.224367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401852 \n",
      "\n",
      "Epoch 4771\n",
      "-------------------------------\n",
      "loss: 0.221551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402035 \n",
      "\n",
      "Epoch 4772\n",
      "-------------------------------\n",
      "loss: 0.225877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401940 \n",
      "\n",
      "Epoch 4773\n",
      "-------------------------------\n",
      "loss: 0.213166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401767 \n",
      "\n",
      "Epoch 4774\n",
      "-------------------------------\n",
      "loss: 0.214417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401813 \n",
      "\n",
      "Epoch 4775\n",
      "-------------------------------\n",
      "loss: 0.222726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402414 \n",
      "\n",
      "Epoch 4776\n",
      "-------------------------------\n",
      "loss: 0.211967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403716 \n",
      "\n",
      "Epoch 4777\n",
      "-------------------------------\n",
      "loss: 0.212727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406553 \n",
      "\n",
      "Epoch 4778\n",
      "-------------------------------\n",
      "loss: 0.231020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408503 \n",
      "\n",
      "Epoch 4779\n",
      "-------------------------------\n",
      "loss: 0.206115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409341 \n",
      "\n",
      "Epoch 4780\n",
      "-------------------------------\n",
      "loss: 0.218794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407431 \n",
      "\n",
      "Epoch 4781\n",
      "-------------------------------\n",
      "loss: 0.229151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405265 \n",
      "\n",
      "Epoch 4782\n",
      "-------------------------------\n",
      "loss: 0.209247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403709 \n",
      "\n",
      "Epoch 4783\n",
      "-------------------------------\n",
      "loss: 0.212708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403680 \n",
      "\n",
      "Epoch 4784\n",
      "-------------------------------\n",
      "loss: 0.230847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402650 \n",
      "\n",
      "Epoch 4785\n",
      "-------------------------------\n",
      "loss: 0.224974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402205 \n",
      "\n",
      "Epoch 4786\n",
      "-------------------------------\n",
      "loss: 0.227832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402629 \n",
      "\n",
      "Epoch 4787\n",
      "-------------------------------\n",
      "loss: 0.217035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403816 \n",
      "\n",
      "Epoch 4788\n",
      "-------------------------------\n",
      "loss: 0.229962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404621 \n",
      "\n",
      "Epoch 4789\n",
      "-------------------------------\n",
      "loss: 0.228468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404322 \n",
      "\n",
      "Epoch 4790\n",
      "-------------------------------\n",
      "loss: 0.225558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403947 \n",
      "\n",
      "Epoch 4791\n",
      "-------------------------------\n",
      "loss: 0.228177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403064 \n",
      "\n",
      "Epoch 4792\n",
      "-------------------------------\n",
      "loss: 0.222301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401897 \n",
      "\n",
      "Epoch 4793\n",
      "-------------------------------\n",
      "loss: 0.236258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400742 \n",
      "\n",
      "Epoch 4794\n",
      "-------------------------------\n",
      "loss: 0.222566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399893 \n",
      "\n",
      "Epoch 4795\n",
      "-------------------------------\n",
      "loss: 0.211264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400236 \n",
      "\n",
      "Epoch 4796\n",
      "-------------------------------\n",
      "loss: 0.220495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401247 \n",
      "\n",
      "Epoch 4797\n",
      "-------------------------------\n",
      "loss: 0.220266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401159 \n",
      "\n",
      "Epoch 4798\n",
      "-------------------------------\n",
      "loss: 0.206598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401085 \n",
      "\n",
      "Epoch 4799\n",
      "-------------------------------\n",
      "loss: 0.207300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400424 \n",
      "\n",
      "Epoch 4800\n",
      "-------------------------------\n",
      "loss: 0.234092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398919 \n",
      "\n",
      "Epoch 4801\n",
      "-------------------------------\n",
      "loss: 0.228232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397265 \n",
      "\n",
      "Epoch 4802\n",
      "-------------------------------\n",
      "loss: 0.216925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396471 \n",
      "\n",
      "Epoch 4803\n",
      "-------------------------------\n",
      "loss: 0.217102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395771 \n",
      "\n",
      "Epoch 4804\n",
      "-------------------------------\n",
      "loss: 0.227364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395426 \n",
      "\n",
      "Epoch 4805\n",
      "-------------------------------\n",
      "loss: 0.218669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395989 \n",
      "\n",
      "Epoch 4806\n",
      "-------------------------------\n",
      "loss: 0.226368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398024 \n",
      "\n",
      "Epoch 4807\n",
      "-------------------------------\n",
      "loss: 0.208906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400565 \n",
      "\n",
      "Epoch 4808\n",
      "-------------------------------\n",
      "loss: 0.238141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400665 \n",
      "\n",
      "Epoch 4809\n",
      "-------------------------------\n",
      "loss: 0.211992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399072 \n",
      "\n",
      "Epoch 4810\n",
      "-------------------------------\n",
      "loss: 0.227784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396547 \n",
      "\n",
      "Epoch 4811\n",
      "-------------------------------\n",
      "loss: 0.209030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396356 \n",
      "\n",
      "Epoch 4812\n",
      "-------------------------------\n",
      "loss: 0.219165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397124 \n",
      "\n",
      "Epoch 4813\n",
      "-------------------------------\n",
      "loss: 0.216400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398398 \n",
      "\n",
      "Epoch 4814\n",
      "-------------------------------\n",
      "loss: 0.211794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399732 \n",
      "\n",
      "Epoch 4815\n",
      "-------------------------------\n",
      "loss: 0.203940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400355 \n",
      "\n",
      "Epoch 4816\n",
      "-------------------------------\n",
      "loss: 0.208319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400830 \n",
      "\n",
      "Epoch 4817\n",
      "-------------------------------\n",
      "loss: 0.207640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401723 \n",
      "\n",
      "Epoch 4818\n",
      "-------------------------------\n",
      "loss: 0.212828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403708 \n",
      "\n",
      "Epoch 4819\n",
      "-------------------------------\n",
      "loss: 0.215325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403911 \n",
      "\n",
      "Epoch 4820\n",
      "-------------------------------\n",
      "loss: 0.213676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402521 \n",
      "\n",
      "Epoch 4821\n",
      "-------------------------------\n",
      "loss: 0.224478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401345 \n",
      "\n",
      "Epoch 4822\n",
      "-------------------------------\n",
      "loss: 0.218639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400919 \n",
      "\n",
      "Epoch 4823\n",
      "-------------------------------\n",
      "loss: 0.209463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400923 \n",
      "\n",
      "Epoch 4824\n",
      "-------------------------------\n",
      "loss: 0.216728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401124 \n",
      "\n",
      "Epoch 4825\n",
      "-------------------------------\n",
      "loss: 0.214816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401571 \n",
      "\n",
      "Epoch 4826\n",
      "-------------------------------\n",
      "loss: 0.234071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402703 \n",
      "\n",
      "Epoch 4827\n",
      "-------------------------------\n",
      "loss: 0.224644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404968 \n",
      "\n",
      "Epoch 4828\n",
      "-------------------------------\n",
      "loss: 0.214671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405677 \n",
      "\n",
      "Epoch 4829\n",
      "-------------------------------\n",
      "loss: 0.222783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404034 \n",
      "\n",
      "Epoch 4830\n",
      "-------------------------------\n",
      "loss: 0.212968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401494 \n",
      "\n",
      "Epoch 4831\n",
      "-------------------------------\n",
      "loss: 0.205870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400269 \n",
      "\n",
      "Epoch 4832\n",
      "-------------------------------\n",
      "loss: 0.214095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400646 \n",
      "\n",
      "Epoch 4833\n",
      "-------------------------------\n",
      "loss: 0.207818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401279 \n",
      "\n",
      "Epoch 4834\n",
      "-------------------------------\n",
      "loss: 0.221934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401361 \n",
      "\n",
      "Epoch 4835\n",
      "-------------------------------\n",
      "loss: 0.214927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401645 \n",
      "\n",
      "Epoch 4836\n",
      "-------------------------------\n",
      "loss: 0.224693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402179 \n",
      "\n",
      "Epoch 4837\n",
      "-------------------------------\n",
      "loss: 0.225984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401288 \n",
      "\n",
      "Epoch 4838\n",
      "-------------------------------\n",
      "loss: 0.227738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401509 \n",
      "\n",
      "Epoch 4839\n",
      "-------------------------------\n",
      "loss: 0.211294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402160 \n",
      "\n",
      "Epoch 4840\n",
      "-------------------------------\n",
      "loss: 0.200926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404011 \n",
      "\n",
      "Epoch 4841\n",
      "-------------------------------\n",
      "loss: 0.221631  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403764 \n",
      "\n",
      "Epoch 4842\n",
      "-------------------------------\n",
      "loss: 0.260684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401355 \n",
      "\n",
      "Epoch 4843\n",
      "-------------------------------\n",
      "loss: 0.218776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399452 \n",
      "\n",
      "Epoch 4844\n",
      "-------------------------------\n",
      "loss: 0.213051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397819 \n",
      "\n",
      "Epoch 4845\n",
      "-------------------------------\n",
      "loss: 0.236396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397104 \n",
      "\n",
      "Epoch 4846\n",
      "-------------------------------\n",
      "loss: 0.216939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397284 \n",
      "\n",
      "Epoch 4847\n",
      "-------------------------------\n",
      "loss: 0.209129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397736 \n",
      "\n",
      "Epoch 4848\n",
      "-------------------------------\n",
      "loss: 0.233451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398387 \n",
      "\n",
      "Epoch 4849\n",
      "-------------------------------\n",
      "loss: 0.228403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398809 \n",
      "\n",
      "Epoch 4850\n",
      "-------------------------------\n",
      "loss: 0.218997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398636 \n",
      "\n",
      "Epoch 4851\n",
      "-------------------------------\n",
      "loss: 0.228200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398373 \n",
      "\n",
      "Epoch 4852\n",
      "-------------------------------\n",
      "loss: 0.216166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398522 \n",
      "\n",
      "Epoch 4853\n",
      "-------------------------------\n",
      "loss: 0.216464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398601 \n",
      "\n",
      "Epoch 4854\n",
      "-------------------------------\n",
      "loss: 0.216734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398976 \n",
      "\n",
      "Epoch 4855\n",
      "-------------------------------\n",
      "loss: 0.210134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399150 \n",
      "\n",
      "Epoch 4856\n",
      "-------------------------------\n",
      "loss: 0.207557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399695 \n",
      "\n",
      "Epoch 4857\n",
      "-------------------------------\n",
      "loss: 0.211741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401274 \n",
      "\n",
      "Epoch 4858\n",
      "-------------------------------\n",
      "loss: 0.208952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402089 \n",
      "\n",
      "Epoch 4859\n",
      "-------------------------------\n",
      "loss: 0.219472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401340 \n",
      "\n",
      "Epoch 4860\n",
      "-------------------------------\n",
      "loss: 0.229210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399908 \n",
      "\n",
      "Epoch 4861\n",
      "-------------------------------\n",
      "loss: 0.225510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399079 \n",
      "\n",
      "Epoch 4862\n",
      "-------------------------------\n",
      "loss: 0.214308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399170 \n",
      "\n",
      "Epoch 4863\n",
      "-------------------------------\n",
      "loss: 0.229843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399995 \n",
      "\n",
      "Epoch 4864\n",
      "-------------------------------\n",
      "loss: 0.217393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401264 \n",
      "\n",
      "Epoch 4865\n",
      "-------------------------------\n",
      "loss: 0.223422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402507 \n",
      "\n",
      "Epoch 4866\n",
      "-------------------------------\n",
      "loss: 0.212048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403913 \n",
      "\n",
      "Epoch 4867\n",
      "-------------------------------\n",
      "loss: 0.211993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405564 \n",
      "\n",
      "Epoch 4868\n",
      "-------------------------------\n",
      "loss: 0.223492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406158 \n",
      "\n",
      "Epoch 4869\n",
      "-------------------------------\n",
      "loss: 0.228734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406075 \n",
      "\n",
      "Epoch 4870\n",
      "-------------------------------\n",
      "loss: 0.212487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405036 \n",
      "\n",
      "Epoch 4871\n",
      "-------------------------------\n",
      "loss: 0.212001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404132 \n",
      "\n",
      "Epoch 4872\n",
      "-------------------------------\n",
      "loss: 0.221369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403985 \n",
      "\n",
      "Epoch 4873\n",
      "-------------------------------\n",
      "loss: 0.219304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403681 \n",
      "\n",
      "Epoch 4874\n",
      "-------------------------------\n",
      "loss: 0.222448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403955 \n",
      "\n",
      "Epoch 4875\n",
      "-------------------------------\n",
      "loss: 0.208853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405657 \n",
      "\n",
      "Epoch 4876\n",
      "-------------------------------\n",
      "loss: 0.221897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406542 \n",
      "\n",
      "Epoch 4877\n",
      "-------------------------------\n",
      "loss: 0.213989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406963 \n",
      "\n",
      "Epoch 4878\n",
      "-------------------------------\n",
      "loss: 0.205447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405047 \n",
      "\n",
      "Epoch 4879\n",
      "-------------------------------\n",
      "loss: 0.227293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402739 \n",
      "\n",
      "Epoch 4880\n",
      "-------------------------------\n",
      "loss: 0.201126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400882 \n",
      "\n",
      "Epoch 4881\n",
      "-------------------------------\n",
      "loss: 0.215770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399160 \n",
      "\n",
      "Epoch 4882\n",
      "-------------------------------\n",
      "loss: 0.220930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397870 \n",
      "\n",
      "Epoch 4883\n",
      "-------------------------------\n",
      "loss: 0.223372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397097 \n",
      "\n",
      "Epoch 4884\n",
      "-------------------------------\n",
      "loss: 0.222954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397072 \n",
      "\n",
      "Epoch 4885\n",
      "-------------------------------\n",
      "loss: 0.224806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397915 \n",
      "\n",
      "Epoch 4886\n",
      "-------------------------------\n",
      "loss: 0.217571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399675 \n",
      "\n",
      "Epoch 4887\n",
      "-------------------------------\n",
      "loss: 0.207365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401254 \n",
      "\n",
      "Epoch 4888\n",
      "-------------------------------\n",
      "loss: 0.242985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400656 \n",
      "\n",
      "Epoch 4889\n",
      "-------------------------------\n",
      "loss: 0.205625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399041 \n",
      "\n",
      "Epoch 4890\n",
      "-------------------------------\n",
      "loss: 0.230420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398552 \n",
      "\n",
      "Epoch 4891\n",
      "-------------------------------\n",
      "loss: 0.206273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399025 \n",
      "\n",
      "Epoch 4892\n",
      "-------------------------------\n",
      "loss: 0.239638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399483 \n",
      "\n",
      "Epoch 4893\n",
      "-------------------------------\n",
      "loss: 0.227308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399512 \n",
      "\n",
      "Epoch 4894\n",
      "-------------------------------\n",
      "loss: 0.226072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399448 \n",
      "\n",
      "Epoch 4895\n",
      "-------------------------------\n",
      "loss: 0.209631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400709 \n",
      "\n",
      "Epoch 4896\n",
      "-------------------------------\n",
      "loss: 0.222905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403451 \n",
      "\n",
      "Epoch 4897\n",
      "-------------------------------\n",
      "loss: 0.215112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405317 \n",
      "\n",
      "Epoch 4898\n",
      "-------------------------------\n",
      "loss: 0.229915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404913 \n",
      "\n",
      "Epoch 4899\n",
      "-------------------------------\n",
      "loss: 0.218031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402989 \n",
      "\n",
      "Epoch 4900\n",
      "-------------------------------\n",
      "loss: 0.210775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400789 \n",
      "\n",
      "Epoch 4901\n",
      "-------------------------------\n",
      "loss: 0.227171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399826 \n",
      "\n",
      "Epoch 4902\n",
      "-------------------------------\n",
      "loss: 0.223307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400245 \n",
      "\n",
      "Epoch 4903\n",
      "-------------------------------\n",
      "loss: 0.215965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401642 \n",
      "\n",
      "Epoch 4904\n",
      "-------------------------------\n",
      "loss: 0.223181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403326 \n",
      "\n",
      "Epoch 4905\n",
      "-------------------------------\n",
      "loss: 0.215728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405144 \n",
      "\n",
      "Epoch 4906\n",
      "-------------------------------\n",
      "loss: 0.216183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405422 \n",
      "\n",
      "Epoch 4907\n",
      "-------------------------------\n",
      "loss: 0.222055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404599 \n",
      "\n",
      "Epoch 4908\n",
      "-------------------------------\n",
      "loss: 0.218310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401885 \n",
      "\n",
      "Epoch 4909\n",
      "-------------------------------\n",
      "loss: 0.217164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399764 \n",
      "\n",
      "Epoch 4910\n",
      "-------------------------------\n",
      "loss: 0.221322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399510 \n",
      "\n",
      "Epoch 4911\n",
      "-------------------------------\n",
      "loss: 0.214192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399808 \n",
      "\n",
      "Epoch 4912\n",
      "-------------------------------\n",
      "loss: 0.218733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400093 \n",
      "\n",
      "Epoch 4913\n",
      "-------------------------------\n",
      "loss: 0.220985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401417 \n",
      "\n",
      "Epoch 4914\n",
      "-------------------------------\n",
      "loss: 0.213204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403483 \n",
      "\n",
      "Epoch 4915\n",
      "-------------------------------\n",
      "loss: 0.220404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405021 \n",
      "\n",
      "Epoch 4916\n",
      "-------------------------------\n",
      "loss: 0.222449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404773 \n",
      "\n",
      "Epoch 4917\n",
      "-------------------------------\n",
      "loss: 0.195523  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403746 \n",
      "\n",
      "Epoch 4918\n",
      "-------------------------------\n",
      "loss: 0.222714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401725 \n",
      "\n",
      "Epoch 4919\n",
      "-------------------------------\n",
      "loss: 0.219671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399258 \n",
      "\n",
      "Epoch 4920\n",
      "-------------------------------\n",
      "loss: 0.218404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398411 \n",
      "\n",
      "Epoch 4921\n",
      "-------------------------------\n",
      "loss: 0.219230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398043 \n",
      "\n",
      "Epoch 4922\n",
      "-------------------------------\n",
      "loss: 0.217665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398510 \n",
      "\n",
      "Epoch 4923\n",
      "-------------------------------\n",
      "loss: 0.218933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399572 \n",
      "\n",
      "Epoch 4924\n",
      "-------------------------------\n",
      "loss: 0.222673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399752 \n",
      "\n",
      "Epoch 4925\n",
      "-------------------------------\n",
      "loss: 0.202135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399752 \n",
      "\n",
      "Epoch 4926\n",
      "-------------------------------\n",
      "loss: 0.216996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400519 \n",
      "\n",
      "Epoch 4927\n",
      "-------------------------------\n",
      "loss: 0.241605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401237 \n",
      "\n",
      "Epoch 4928\n",
      "-------------------------------\n",
      "loss: 0.223457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400404 \n",
      "\n",
      "Epoch 4929\n",
      "-------------------------------\n",
      "loss: 0.229037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399374 \n",
      "\n",
      "Epoch 4930\n",
      "-------------------------------\n",
      "loss: 0.217814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398624 \n",
      "\n",
      "Epoch 4931\n",
      "-------------------------------\n",
      "loss: 0.206239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397732 \n",
      "\n",
      "Epoch 4932\n",
      "-------------------------------\n",
      "loss: 0.227995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396994 \n",
      "\n",
      "Epoch 4933\n",
      "-------------------------------\n",
      "loss: 0.214179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397116 \n",
      "\n",
      "Epoch 4934\n",
      "-------------------------------\n",
      "loss: 0.217574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397113 \n",
      "\n",
      "Epoch 4935\n",
      "-------------------------------\n",
      "loss: 0.224004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397298 \n",
      "\n",
      "Epoch 4936\n",
      "-------------------------------\n",
      "loss: 0.226180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396770 \n",
      "\n",
      "Epoch 4937\n",
      "-------------------------------\n",
      "loss: 0.210970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396004 \n",
      "\n",
      "Epoch 4938\n",
      "-------------------------------\n",
      "loss: 0.217890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394600 \n",
      "\n",
      "Epoch 4939\n",
      "-------------------------------\n",
      "loss: 0.217162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393723 \n",
      "\n",
      "Epoch 4940\n",
      "-------------------------------\n",
      "loss: 0.213322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393556 \n",
      "\n",
      "Epoch 4941\n",
      "-------------------------------\n",
      "loss: 0.220323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393565 \n",
      "\n",
      "Epoch 4942\n",
      "-------------------------------\n",
      "loss: 0.219576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394122 \n",
      "\n",
      "Epoch 4943\n",
      "-------------------------------\n",
      "loss: 0.227799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396026 \n",
      "\n",
      "Epoch 4944\n",
      "-------------------------------\n",
      "loss: 0.220539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397864 \n",
      "\n",
      "Epoch 4945\n",
      "-------------------------------\n",
      "loss: 0.223481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398135 \n",
      "\n",
      "Epoch 4946\n",
      "-------------------------------\n",
      "loss: 0.232417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396445 \n",
      "\n",
      "Epoch 4947\n",
      "-------------------------------\n",
      "loss: 0.217353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395410 \n",
      "\n",
      "Epoch 4948\n",
      "-------------------------------\n",
      "loss: 0.211080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395201 \n",
      "\n",
      "Epoch 4949\n",
      "-------------------------------\n",
      "loss: 0.226482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395746 \n",
      "\n",
      "Epoch 4950\n",
      "-------------------------------\n",
      "loss: 0.221981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397235 \n",
      "\n",
      "Epoch 4951\n",
      "-------------------------------\n",
      "loss: 0.211397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398094 \n",
      "\n",
      "Epoch 4952\n",
      "-------------------------------\n",
      "loss: 0.206181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399895 \n",
      "\n",
      "Epoch 4953\n",
      "-------------------------------\n",
      "loss: 0.212330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401085 \n",
      "\n",
      "Epoch 4954\n",
      "-------------------------------\n",
      "loss: 0.214953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401579 \n",
      "\n",
      "Epoch 4955\n",
      "-------------------------------\n",
      "loss: 0.224006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401298 \n",
      "\n",
      "Epoch 4956\n",
      "-------------------------------\n",
      "loss: 0.218429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400835 \n",
      "\n",
      "Epoch 4957\n",
      "-------------------------------\n",
      "loss: 0.212668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401270 \n",
      "\n",
      "Epoch 4958\n",
      "-------------------------------\n",
      "loss: 0.200959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401146 \n",
      "\n",
      "Epoch 4959\n",
      "-------------------------------\n",
      "loss: 0.213952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401236 \n",
      "\n",
      "Epoch 4960\n",
      "-------------------------------\n",
      "loss: 0.212495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402718 \n",
      "\n",
      "Epoch 4961\n",
      "-------------------------------\n",
      "loss: 0.211837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403964 \n",
      "\n",
      "Epoch 4962\n",
      "-------------------------------\n",
      "loss: 0.237600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402366 \n",
      "\n",
      "Epoch 4963\n",
      "-------------------------------\n",
      "loss: 0.216431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400399 \n",
      "\n",
      "Epoch 4964\n",
      "-------------------------------\n",
      "loss: 0.216136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399743 \n",
      "\n",
      "Epoch 4965\n",
      "-------------------------------\n",
      "loss: 0.214276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400003 \n",
      "\n",
      "Epoch 4966\n",
      "-------------------------------\n",
      "loss: 0.234672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400665 \n",
      "\n",
      "Epoch 4967\n",
      "-------------------------------\n",
      "loss: 0.223161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401162 \n",
      "\n",
      "Epoch 4968\n",
      "-------------------------------\n",
      "loss: 0.208296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402328 \n",
      "\n",
      "Epoch 4969\n",
      "-------------------------------\n",
      "loss: 0.218260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403644 \n",
      "\n",
      "Epoch 4970\n",
      "-------------------------------\n",
      "loss: 0.209860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404675 \n",
      "\n",
      "Epoch 4971\n",
      "-------------------------------\n",
      "loss: 0.221813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405237 \n",
      "\n",
      "Epoch 4972\n",
      "-------------------------------\n",
      "loss: 0.217361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404188 \n",
      "\n",
      "Epoch 4973\n",
      "-------------------------------\n",
      "loss: 0.211280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401871 \n",
      "\n",
      "Epoch 4974\n",
      "-------------------------------\n",
      "loss: 0.220081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400564 \n",
      "\n",
      "Epoch 4975\n",
      "-------------------------------\n",
      "loss: 0.205195  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399092 \n",
      "\n",
      "Epoch 4976\n",
      "-------------------------------\n",
      "loss: 0.199076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398508 \n",
      "\n",
      "Epoch 4977\n",
      "-------------------------------\n",
      "loss: 0.222217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397944 \n",
      "\n",
      "Epoch 4978\n",
      "-------------------------------\n",
      "loss: 0.218939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397817 \n",
      "\n",
      "Epoch 4979\n",
      "-------------------------------\n",
      "loss: 0.217651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398651 \n",
      "\n",
      "Epoch 4980\n",
      "-------------------------------\n",
      "loss: 0.212966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399176 \n",
      "\n",
      "Epoch 4981\n",
      "-------------------------------\n",
      "loss: 0.222404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399356 \n",
      "\n",
      "Epoch 4982\n",
      "-------------------------------\n",
      "loss: 0.214761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398972 \n",
      "\n",
      "Epoch 4983\n",
      "-------------------------------\n",
      "loss: 0.225653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396606 \n",
      "\n",
      "Epoch 4984\n",
      "-------------------------------\n",
      "loss: 0.224442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394399 \n",
      "\n",
      "Epoch 4985\n",
      "-------------------------------\n",
      "loss: 0.220137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393330 \n",
      "\n",
      "Epoch 4986\n",
      "-------------------------------\n",
      "loss: 0.213211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393266 \n",
      "\n",
      "Epoch 4987\n",
      "-------------------------------\n",
      "loss: 0.218701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393254 \n",
      "\n",
      "Epoch 4988\n",
      "-------------------------------\n",
      "loss: 0.229096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393310 \n",
      "\n",
      "Epoch 4989\n",
      "-------------------------------\n",
      "loss: 0.213058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394852 \n",
      "\n",
      "Epoch 4990\n",
      "-------------------------------\n",
      "loss: 0.213917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398137 \n",
      "\n",
      "Epoch 4991\n",
      "-------------------------------\n",
      "loss: 0.219935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400748 \n",
      "\n",
      "Epoch 4992\n",
      "-------------------------------\n",
      "loss: 0.225747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401418 \n",
      "\n",
      "Epoch 4993\n",
      "-------------------------------\n",
      "loss: 0.206710  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400788 \n",
      "\n",
      "Epoch 4994\n",
      "-------------------------------\n",
      "loss: 0.208236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398488 \n",
      "\n",
      "Epoch 4995\n",
      "-------------------------------\n",
      "loss: 0.216553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395267 \n",
      "\n",
      "Epoch 4996\n",
      "-------------------------------\n",
      "loss: 0.221131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393805 \n",
      "\n",
      "Epoch 4997\n",
      "-------------------------------\n",
      "loss: 0.217577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393719 \n",
      "\n",
      "Epoch 4998\n",
      "-------------------------------\n",
      "loss: 0.206202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394280 \n",
      "\n",
      "Epoch 4999\n",
      "-------------------------------\n",
      "loss: 0.213466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394685 \n",
      "\n",
      "Epoch 5000\n",
      "-------------------------------\n",
      "loss: 0.216838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395661 \n",
      "\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 53 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 53 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-66/metadata\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if optChoice == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "elif optChoice == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "else:\n",
    "    optimizer = None\n",
    "    print('no optimizer chosen...')\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=neptuneProject,\n",
    "    api_token=api_token,  \n",
    "    capture_hardware_metrics=True,\n",
    "    capture_stderr=True,\n",
    "    capture_stdout=True,\n",
    ")\n",
    "\n",
    "PARAMS = {\n",
    "    \"modelID\": modelID,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": learningRate,\n",
    "    \"optimizer\": optChoice,\n",
    "    \"patience\": patience,\n",
    "    \"subsampleFreq\": subsampleFreq,\n",
    "    \"secondsInWindow\": secondsInWindow,\n",
    "    \"nperseg\": nperseg,\n",
    "    \"noverlap\": noverlap,\n",
    "    \"window\": stringify_unsupported(window),\n",
    "    \"loss_fn\": stringify_unsupported(loss_fn),\n",
    "    \"architectureString\": str(model),\n",
    "    \"numParameters\": sdm.count_parameters(model)\n",
    "}\n",
    "run[\"parameters\"] = PARAMS\n",
    "\n",
    "noImprovementCount = 0\n",
    "\n",
    "#epochs = 2\n",
    "\n",
    "try:\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = sdm.train(trainDataLoader, model, loss_fn, optimizer, device)\n",
    "        test_loss = sdm.test(validDataLoader, model, loss_fn, device)\n",
    "\n",
    "        if test_loss < bestTestLoss:\n",
    "            noImprovementCount = 0\n",
    "            bestTestLoss = test_loss\n",
    "            \n",
    "            model_scripted = torch.jit.script(model) \n",
    "            model_scripted.save(modelPath + 'model_%s.pt' % str(modelID))\n",
    "    \n",
    "            run[\"best_test_loss\"] =  bestTestLoss\n",
    "            run[\"best_test_epoch\"] = t\n",
    "            print(\"\\nSaved a new best model!\\n\")\n",
    "        else:\n",
    "            noImprovementCount = noImprovementCount + 1\n",
    "\n",
    "        run[\"train/loss\"].append(train_loss)\n",
    "        run[\"test/loss\"].append(test_loss)\n",
    "\n",
    "        if noImprovementCount >= patience:   \n",
    "            print(\"Early stopping invoked....\")\n",
    "            break\n",
    "\n",
    "    run.stop()\n",
    "    print(\"Done!\")\n",
    "except:\n",
    "    run.stop()\n",
    "    print(\"Training aborted...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12a577",
   "metadata": {},
   "source": [
    "# LOAD SAVED MODEL (TORCHSCRIPT) IF NECESSARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afe26a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.389803 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelID = '982815'\n",
    "\n",
    "model = torch.jit.load(modelPath + 'model_%s.pt' % str(modelID))\n",
    "bestTestLoss = sdm.test(validDataLoader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3474b",
   "metadata": {},
   "source": [
    "# PLOT RESULTS OF FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a858773f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT PREDICTION VERSUS TRUTH\n",
    "\n",
    "trainPlotFlag = True\n",
    "    \n",
    "if trainPlotFlag:\n",
    "    x = trainXTensor\n",
    "    trainTitle = 'train'\n",
    "else:\n",
    "    x = validXTensor\n",
    "    trainTitle = 'valididation'\n",
    "\n",
    "model.to('cpu')\n",
    "predict = model(x).cpu().detach().numpy()\n",
    "model.to(device)\n",
    "\n",
    "if predict.shape[1] == 1:\n",
    "    yPred = predict[:,0]\n",
    "    if trainPlotFlag:\n",
    "        yTrue = yTrainTimeDomain[:,0]\n",
    "    else:\n",
    "        yTrue = yValidTimeDomain[:,0]\n",
    "else:\n",
    "    _, yPred = realSTFTtoTimeSeries(predict)\n",
    "    if trainPlotFlag:\n",
    "        y = y_trainRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "    else:\n",
    "        y = y_validRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "        \n",
    "\n",
    "lossTemp = loss_fn(torch.tensor(yPred), torch.tensor(yTrue)).item()\n",
    "title = 'Data: ' + trainTitle + ' (loss: %s)' % str(lossTemp)\n",
    "plt.figure()\n",
    "plt.plot(yPred, label='predict')\n",
    "plt.plot(yTrue, label='true')\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc1e38",
   "metadata": {},
   "source": [
    "# GET BEST MODEL DATA FROM NEPTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2888482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys/id</th>\n",
       "      <th>best_test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRED-66</td>\n",
       "      <td>0.389803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRED-65</td>\n",
       "      <td>0.677281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRED-64</td>\n",
       "      <td>0.648604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRED-63</td>\n",
       "      <td>0.665345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRED-62</td>\n",
       "      <td>0.676881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRED-61</td>\n",
       "      <td>0.666001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRED-60</td>\n",
       "      <td>0.674732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRED-59</td>\n",
       "      <td>0.391365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRED-54</td>\n",
       "      <td>0.391573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRED-53</td>\n",
       "      <td>0.423721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRED-46</td>\n",
       "      <td>0.405430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRED-43</td>\n",
       "      <td>0.390877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PRED-38</td>\n",
       "      <td>0.398955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRED-35</td>\n",
       "      <td>0.403722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRED-34</td>\n",
       "      <td>0.417772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRED-32</td>\n",
       "      <td>0.408214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRED-31</td>\n",
       "      <td>0.409690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRED-58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRED-57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRED-56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRED-55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sys/id  best_test_loss\n",
       "0   PRED-66        0.389803\n",
       "1   PRED-65        0.677281\n",
       "2   PRED-64        0.648604\n",
       "3   PRED-63        0.665345\n",
       "4   PRED-62        0.676881\n",
       "5   PRED-61        0.666001\n",
       "6   PRED-60        0.674732\n",
       "7   PRED-59        0.391365\n",
       "12  PRED-54        0.391573\n",
       "13  PRED-53        0.423721\n",
       "14  PRED-46        0.405430\n",
       "15  PRED-43        0.390877\n",
       "16  PRED-38        0.398955\n",
       "17  PRED-35        0.403722\n",
       "18  PRED-34        0.417772\n",
       "19  PRED-32        0.408214\n",
       "20  PRED-31        0.409690\n",
       "8   PRED-58             NaN\n",
       "9   PRED-57             NaN\n",
       "10  PRED-56             NaN\n",
       "11  PRED-55             NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdm.neptuneBestRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671c8d3",
   "metadata": {},
   "source": [
    "# SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c14b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "fs = 1\n",
    "nperseg = 32\n",
    "noverlap = 31\n",
    "#windowType = ('tukey', .25)\n",
    "windowType = np.ones(nperseg)\n",
    "\n",
    "\n",
    "a = np.random.rand(100)\n",
    "f, t, S = stft(a, fs=fs, window=windowType, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "b = torch.stft(torch.tensor(a), \n",
    "               n_fft = nperseg, \n",
    "               hop_length = 1, \n",
    "               return_complex=True, \n",
    "               normalized=False, \n",
    "               onesided=True, \n",
    "               pad_mode='constant').numpy()\n",
    "\n",
    "np.abs(np.divide(b,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d95ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import get_window\n",
    "a = get_window(('tukey', .25), nperseg)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        return loss\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, layerOrderedDict):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(layerOrderedDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# GIVEN A LIST OF LAYER SIZES MAKE AN ORDERED DICTIONARY FOR INITIALIZING A PYTORCH NET\n",
    "\n",
    "def listToOrderedDict(sizeList):\n",
    "    n = len(sizeList)\n",
    "    tupleList = []\n",
    "    for i in range(n - 1):\n",
    "        tupleList.append(('bn%s' % str(i), nn.BatchNorm1d(sizeList[i])))\n",
    "        tupleList.append(('l%s' % str(i), nn.Linear(sizeList[i], sizeList[i+1])))\n",
    "        tupleList.append(('r%s' % str(i), nn.ReLU()))\n",
    "    return OrderedDict(tupleList[:-1])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "'''\n",
    "\n",
    "'''\n",
    "    layerSizeList = [trainXTensor.shape[1]] + hiddenLayerSizes + [trainYTensor.shape[1]]\n",
    "    layerOrderedDict = sdm.listToOrderedDict(layerSizeList)\n",
    "    model = sdm.NeuralNetwork(layerOrderedDict)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.13",
   "language": "python",
   "name": "pytorch-1.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
