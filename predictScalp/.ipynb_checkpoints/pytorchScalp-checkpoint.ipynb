{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d3475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scalpDeepModels as sdm\n",
    "\n",
    "import importlib\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef38d8",
   "metadata": {},
   "source": [
    "# PARAMETERS - GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f63db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "patient = 'UFSEEG031'\n",
    "targetScalpElectrodes = ['F7', 'F8', 'F3', 'F4', 'C3', 'C4', 'P7', 'P8', 'P3', 'P4']\n",
    "mode = 'Sleep'\n",
    "\n",
    "stftSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/freqRTheta_%s_%s_%s.npz' % (patient, targetScalpElectrodes, mode)\n",
    "timeDomainSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeDomain_%s_%s_%s.npz' % (patient, targetScalpElectrodes, mode)\n",
    "timeFreqSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeFreqRTheta_%s_%s_%s.npz' % (patient, targetScalpElectrodes, mode)\n",
    "\n",
    "modelPath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/'\n",
    "\n",
    "neptuneProject = 'jettinger35/predictScalp'\n",
    "api_token = os.environ.get('NEPTUNE_API_TOKEN')\n",
    "\n",
    "subsampleFreq = 128   # FINAL FREQUENCY IN HERTZ AFTER SUBSAMPLING\n",
    "secondsInWindow = 1\n",
    "nperseg = subsampleFreq * secondsInWindow\n",
    "noverlap = nperseg - 1\n",
    "window = ('tukey', .25)\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7fce9",
   "metadata": {},
   "source": [
    "# PARAMETERS - TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224077ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 1024\n",
    "learningRate = 1e-3\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "optChoice = 'adam'\n",
    "\n",
    "patience = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6db8c0",
   "metadata": {},
   "source": [
    "# UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7e2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT STFT FROM R,THETA TO COMPLEX\n",
    "# dim(z) = (# timesteps, # freq bins x 2 (2 reals = 1 complex))\n",
    "\n",
    "def rThetaToComplex(z):\n",
    "    rows, cols = z.shape\n",
    "    shortTermFourier = np.zeros((rows, cols // 2), dtype=np.csingle)\n",
    "    for i in range(rows):\n",
    "        for k in range(cols // 2):\n",
    "            r = z[i,k]\n",
    "            theta = z[i, (k + cols // 2)]\n",
    "            shortTermFourier[i,k] =  r * np.exp(complex(0, theta))\n",
    "    return shortTermFourier.transpose() # dim = (# freq bins, # timepoints)\n",
    "\n",
    "# CONVERT REAL STFT TO COMPLEX STFT, INVERT TO GET THE ISTFT (I.E. TIME SERIES), THEN PLOT\n",
    "\n",
    "def realSTFTtoTimeSeries(realSTFT):\n",
    "    shortTermFourierComplex = rThetaToComplex(realSTFT)\n",
    "    times, inverseShortFourier = istft(shortTermFourierComplex, \n",
    "                                       fs=subsampleFreq, \n",
    "                                       window=window, \n",
    "                                       nperseg=nperseg, \n",
    "                                       noverlap=noverlap)\n",
    "    return times, inverseShortFourier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbd749",
   "metadata": {},
   "source": [
    "# LOAD NUMPY DATA ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9bda99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([132096, 5655]),\n",
       " torch.Size([132096, 10]),\n",
       " torch.Size([33024, 5655]),\n",
       " torch.Size([33024, 10]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSwitch = 'time'\n",
    "\n",
    "if dataSwitch == 'freq':\n",
    "    # STFT DATA\n",
    "\n",
    "    npzfile = np.load(stftSavePath)\n",
    "    x_trainRTheta = npzfile['x_trainRTheta']\n",
    "    x_validRTheta = npzfile['x_validRTheta'] \n",
    "    y_trainRTheta = npzfile['y_trainRTheta'] \n",
    "    y_validRTheta = npzfile['y_validRTheta']\n",
    "\n",
    "    trainXTensor = torch.Tensor(x_trainRTheta)\n",
    "    trainYTensor = torch.Tensor(y_trainRTheta)\n",
    "    validXTensor = torch.Tensor(x_validRTheta)\n",
    "    validYTensor = torch.Tensor(y_validRTheta)\n",
    "\n",
    "elif dataSwitch == 'time':\n",
    "    # TIME DOMAIN DATA\n",
    "\n",
    "    npzfile = np.load(timeDomainSavePath)\n",
    "    xTrainTimeDomain = npzfile['xTrainTimeDomain']\n",
    "    xValidTimeDomain = npzfile['xValidTimeDomain'] \n",
    "    yTrainTimeDomain = npzfile['yTrainTimeDomain'] \n",
    "    yValidTimeDomain = npzfile['yValidTimeDomain']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrainTimeDomain)\n",
    "    trainYTensor = torch.Tensor(yTrainTimeDomain)\n",
    "    validXTensor = torch.Tensor(xValidTimeDomain)\n",
    "    validYTensor = torch.Tensor(yValidTimeDomain)\n",
    "    \n",
    "elif dataSwitch == 'timeFreq':\n",
    "    \n",
    "    npzfile = np.load(timeFreqSavePath)\n",
    "    xTrain = npzfile['x_trainTimeFreq']\n",
    "    xValid = npzfile['x_validTimeFreq'] \n",
    "    yTrain = npzfile['y_trainTimeFreq'] \n",
    "    yValid = npzfile['y_validTimeFreq']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrain)\n",
    "    trainYTensor = torch.Tensor(yTrain)\n",
    "    validXTensor = torch.Tensor(xValid)\n",
    "    validYTensor = torch.Tensor(yValid)\n",
    "\n",
    "trainXTensor.shape, trainYTensor.shape, validXTensor.shape, validYTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cedd53c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 10]) torch.float32\n",
      "\n",
      "test: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# CREATE PYTORCH DATALOADERS\n",
    "\n",
    "trainDataset = TensorDataset(trainXTensor,trainYTensor)\n",
    "trainDataLoader = DataLoader(trainDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"train: \")\n",
    "for X, y in trainDataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "try:    \n",
    "    validDataset = TensorDataset(validXTensor,validYTensor)\n",
    "    validDataLoader = DataLoader(validDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    print(\"\\nvalidation: \")\n",
    "    for X, y in validDataLoader:\n",
    "        print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "        break\n",
    "        \n",
    "    validFlag = True\n",
    "except:\n",
    "    validFlag = False\n",
    "    print(\"No validation dataset...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243c05c",
   "metadata": {},
   "source": [
    "# DEFINE THE MODEL FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeaad9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: 59169\n",
      "Number of parameters:  4231736\n",
      "Sequential(\n",
      "  (bn0): BatchNorm1d(5655, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l0): Linear(in_features=5655, out_features=512, bias=True)\n",
      "  (r0): ReLU()\n",
      "  (d0): Dropout(p=0.5, inplace=False)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r1): ReLU()\n",
      "  (d1): Dropout(p=0.5, inplace=False)\n",
      "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r2): ReLU()\n",
      "  (d2): Dropout(p=0.5, inplace=False)\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r3): ReLU()\n",
      "  (d3): Dropout(p=0.5, inplace=False)\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r4): ReLU()\n",
      "  (d4): Dropout(p=0.5, inplace=False)\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r5): ReLU()\n",
      "  (d5): Dropout(p=0.5, inplace=False)\n",
      "  (bn6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "importlib.reload(sdm) # reload in case we've made any architecture changes\n",
    "\n",
    "modelID = np.random.randint(0, 10**6)\n",
    "\n",
    "# DEFINE ARCHITECTURE HERE\n",
    "inputSize = trainXTensor.shape[1]\n",
    "outputSize = trainYTensor.shape[1]\n",
    "hiddenLayerSizes = [512,512,512,512,512,512]\n",
    "\n",
    "nnStructure = [inputSize] + hiddenLayerSizes + [outputSize]\n",
    "layerDict = sdm.listToOrderedDict_1(nnStructure)\n",
    "\n",
    "#layerDict = sdm.residualAddDict(inputSize, 512, 5)\n",
    "#layerDict = sdm.residualConcatDict(inputSize, hiddenLayerSizes)\n",
    "\n",
    "model = nn.Sequential(layerDict)\n",
    "bestTestLoss = float('inf')\n",
    "    \n",
    "print(\"Model ID: \" + str(modelID))\n",
    "print(\"Number of parameters: \", sdm.count_parameters(model))\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68e5ed",
   "metadata": {},
   "source": [
    "# TRAIN (LOG DATA TO NEPTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64c6012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-68\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/65035940/ipykernel_63546/340263425.py:33: NeptuneUnsupportedType: You're attempting to log a type that is not directly supported by Neptune (<class 'list'>).\n",
      "        Convert the value to a supported type, such as a string or float, or use stringify_unsupported(obj)\n",
      "        for dictionaries or collections that contain unsupported values.\n",
      "        For more, see https://docs.neptune.ai/help/value_of_unsupported_type\n",
      "  run[\"parameters\"] = PARAMS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.773921  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.606807 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.730293  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.606711 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.721249  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.605477 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.715504  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.605882 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.705234  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.605788 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.696394  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.605890 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.700264  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.605482 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.687111  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.605266 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.665495  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.604995 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.686270  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.603137 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.690346  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.603456 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.661788  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.601639 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.642853  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.600000 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.654948  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.600056 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.640496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.598383 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.636550  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.597686 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.645248  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.596996 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.638527  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.596766 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.615472  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.596675 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.626122  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.597097 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.630109  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.594743 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.612924  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.594102 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.619503  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.593205 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.614857  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.592776 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.606280  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.592340 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.612594  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.591741 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.607604  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.590993 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.591325  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.587071 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.597985  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.584962 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.589218  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.582030 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.588464  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.578968 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.597559  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.576217 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.582839  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.571960 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.568519  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.568710 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.556718  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.562860 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.556036  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.557664 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.559301  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.553481 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.573875  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.549110 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.548909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.544841 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.556044  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.538092 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.556769  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.534701 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.542319  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.530214 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.541329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.527690 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.532196  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.526399 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.524783  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.523957 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.521236  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.521737 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.522225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.518943 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.526277  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.516895 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.513641  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.516259 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.515889  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.513691 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.532259  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.512229 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.504771  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.512011 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.508455  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.512384 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.540767  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.511554 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.524696  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.507746 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.524730  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.506674 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.496323  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.506428 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.509514  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.508319 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.507424  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.508117 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.513909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.507158 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.502456  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.503592 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.488129  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.501060 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.500996  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.498665 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.515114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.497328 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.518187  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.494697 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.509344  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.493395 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.496664  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.490319 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.498875  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.489376 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.493512  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.487594 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.504147  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486583 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.481434  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486247 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.506310  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486142 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.490231  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486582 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.486338  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486313 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.486351  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486362 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.496039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486535 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.484189  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.485945 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.483757  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.485205 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.483149  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486806 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.498985  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.487448 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.495590  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.487065 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.490910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486749 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.486177  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.487174 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.487957  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.486583 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.488040  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.485990 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.481464  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.485695 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.477525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.485261 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.497651  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.483054 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.471842  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.481470 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.490186  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.480928 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.484799  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.480570 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.483226  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.479219 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.480380  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.478811 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.485409  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.477903 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.488664  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.477692 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.474837  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.477558 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.472706  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.476652 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.474895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.476377 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.474511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.476851 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.471496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.476778 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.479597  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.475388 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.480324  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.477446 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.468395  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.480790 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.485114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.481283 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.483063  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.481202 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.470695  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.479378 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.468075  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.474568 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.462669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.472726 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.477086  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.470790 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.462914  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.469693 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.469521  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.469443 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.468637  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.469710 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.451008  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.468990 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.468548  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.469038 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.479476  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.468823 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.471366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.468893 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.459408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.469146 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.466944  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.469150 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.457333  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.470114 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.451846  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.470619 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.471181  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.470352 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.465843  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.470610 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.463233  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.472441 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.464739  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.472347 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.456377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.472137 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.461459  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.472835 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.454015  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.472432 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.469613  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.473251 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.453649  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.473486 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.455668  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.472698 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.465507  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.470257 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.459629  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.467122 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.463938  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.465811 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.468565  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.466249 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.457868  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.466098 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.462031  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.466574 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.459065  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.466173 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.457538  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.465369 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.464370  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.467731 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.463946  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.475407 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.458334  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.479417 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.457523  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.476959 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.462791  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.470903 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.456754  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.469363 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.462488  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.468619 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.456804  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.469071 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.458378  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.468427 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.454271  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.464844 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.454723  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.464132 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.456206  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.465657 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.451426  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.465975 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.453207  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.464256 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.456471  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.464336 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.453073  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.463117 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.449967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462336 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.463722  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462139 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.447899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462124 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.459508  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462238 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.448666  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.463061 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.440947  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.463202 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.459428  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.463016 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.456005  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462513 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.460235  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462476 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.452047  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.461060 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.453522  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460454 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.451260  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460253 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.457872  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460913 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.453521  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.461442 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.449271  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462340 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.457271  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462648 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.452258  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.462122 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.444014  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460280 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.444968  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460374 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.450553  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460859 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.452222  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460814 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.440079  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.461059 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.448559  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460852 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.450883  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.461042 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.452977  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.461700 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.446166  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.463855 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.438718  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.463911 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.445973  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.461970 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.438172  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.459834 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.443555  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.459486 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.437971  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460450 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.438641  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.461564 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.445578  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460311 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.436575  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.458256 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.443703  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.458749 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.438863  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460214 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.444156  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460922 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.449387  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.459585 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.440812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.457101 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.451733  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455688 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.445376  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.456578 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.436395  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.456099 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.451825  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.456625 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.444962  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.458818 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.445121  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460894 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.434114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460882 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.458046  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.459492 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.437711  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.457860 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.444337  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.457166 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.455131  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455407 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.442172  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455233 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.441056  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.455280 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.438402  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.456759 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.433622  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.458138 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.437686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.458183 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.440398  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.456259 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.442238  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455166 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.441094  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455402 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.435003  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.456580 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.444655  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.459128 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.449053  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.460428 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.445367  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.458753 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.450144  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455564 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.443195  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454592 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.438865  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455653 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.456650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454979 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.448544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454969 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.436281  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455835 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.442955  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.456871 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.448084  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455582 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.436124  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454182 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.436095  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454294 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.428228  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454737 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.445760  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454738 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.431343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455159 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.437450  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.458498 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.444715  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.459923 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.443156  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.457284 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.432067  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455912 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.429450  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455768 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.439177  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455352 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.444819  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454418 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.441910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453588 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.428298  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454215 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.422607  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454221 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.427252  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454180 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.437440  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454096 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.429685  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454042 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.438690  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453831 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.448886  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453223 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.433137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453749 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.431682  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455339 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.440087  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.456055 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.440015  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.457334 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.427650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455921 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.441268  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453340 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.440142  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451235 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.428923  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450674 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.431806  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449719 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.435777  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449092 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.430274  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450685 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.436909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451584 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.446262  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453367 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.428515  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454397 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.435303  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454563 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.445666  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454856 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.428291  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454228 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.413624  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454039 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.429439  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452954 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.433895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452420 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.420718  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452486 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.440493  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454270 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.430606  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.455120 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.428905  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452881 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.424054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451083 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.431312  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451150 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.424373  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452060 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.421783  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451091 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.423099  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452049 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.424590  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453764 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.432745  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454785 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.431304  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453697 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.425523  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452964 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.440172  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454016 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.435147  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.454856 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.423799  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.454867 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.440581  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453460 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.426999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453192 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.439323  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452650 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.419506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452060 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.424287  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451423 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.435661  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450431 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.430205  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451402 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.427258  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451353 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.423530  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449322 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.429764  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449472 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.423420  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448897 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.424749  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448734 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.430084  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450941 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.419511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451845 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.421163  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451322 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.432045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450739 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.435006  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451402 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.431547  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451748 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.425280  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451146 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.428791  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451324 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.422562  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452165 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.432377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451871 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.426112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.453212 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.427352  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452834 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.429869  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451823 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.436180  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450688 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.428311  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449673 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.427266  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449107 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.434528  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448307 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.416333  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447677 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.430333  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447875 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.433596  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448659 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.423754  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448208 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.433694  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448945 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.427397  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449947 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.429768  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450954 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.422915  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452581 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.423133  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451767 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.433510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450636 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.435852  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450413 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.429012  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451273 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.422525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450842 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.420073  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.452616 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.428126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451031 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.425025  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449466 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.420880  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449311 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.429953  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449932 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.421216  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450322 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.427448  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450898 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.413962  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450414 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.426240  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450222 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.417810  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448880 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.424544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448742 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.424845  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448652 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.411143  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448611 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.417799  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448334 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.416209  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449630 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.414917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448909 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.423782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449907 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.419706  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449156 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.414995  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448468 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.410410  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448081 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.424919  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447940 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.422463  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447262 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.413663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446537 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.419846  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446458 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.422655  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446792 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.422669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448305 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.420693  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448288 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.415698  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448006 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.423455  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448288 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.414794  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449196 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.419480  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450892 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.427449  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451677 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.433211  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.450579 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.418364  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449843 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.420883  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449115 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.420908  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447974 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.423865  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448901 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.418603  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449565 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.436385  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449523 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.419851  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448921 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.425257  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448687 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.427210  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447581 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.407505  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447850 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.414881  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447495 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.427127  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448278 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.421273  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448405 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.412242  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446758 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.420987  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445656 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.419359  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445007 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.420212  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444468 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.405998  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445242 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.432491  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446449 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.415520  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446619 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.402961  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447296 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.413405  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447221 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.413944  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446271 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.412717  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445593 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.405816  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445063 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.407375  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444777 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.410780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444329 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.430953  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444623 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.426568  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444965 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.412167  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447015 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.411877  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448869 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.411517  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450210 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.415741  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450109 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.414913  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449444 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.426913  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449307 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.408501  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448914 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.410108  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448348 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.411410  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448325 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.406330  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449272 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.409229  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448335 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.408480  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448086 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.422604  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447809 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.412333  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447523 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.416203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447277 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.415517  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447337 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.415601  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446825 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.409097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446969 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.419948  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450125 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.410917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449616 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.406655  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448843 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.411921  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447242 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.406828  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448151 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.409040  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449620 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.431343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450968 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.422606  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449373 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.403909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448011 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.406538  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449604 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.403703  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451420 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.407173  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449665 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.417381  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448547 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.408577  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447214 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.411247  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447091 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.420465  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446558 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.412355  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445011 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.401127  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445059 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.415924  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447804 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.404372  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448468 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.406247  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447973 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.411598  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447358 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.414464  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447358 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.415563  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448649 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.402633  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448282 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.426676  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448470 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.410101  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448419 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.412140  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.447235 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.412294  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446747 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.409004  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446292 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.406074  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447430 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.414333  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448614 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.400867  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449550 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.407255  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450282 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.404164  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450614 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.404296  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.451380 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.412582  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.450114 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.408874  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449625 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.395547  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449680 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.408045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.449237 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.403153  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448810 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.401045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447453 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.406691  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447710 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.406002  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447094 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.410898  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446203 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.398114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444348 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.409257  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444505 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.402670  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444146 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.411504  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444893 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.407966  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446293 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.402981  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447397 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.400037  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447546 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.403525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447085 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.403467  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446981 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.403444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445690 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.401203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444848 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.407201  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445379 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.403565  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444718 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.395358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447054 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.409607  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446758 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.413162  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447095 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.402533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445104 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.404648  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443853 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.399605  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444499 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.408922  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443775 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.413669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442964 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.404809  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443395 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.410168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445256 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.399301  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446252 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.402317  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446524 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.401827  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445993 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.408884  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445557 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.405085  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445452 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.401287  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447493 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.405490  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446866 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.403151  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446415 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.402635  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445462 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.381632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445025 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.397059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443652 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.405354  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442666 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.403494  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442145 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.381812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441874 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.402326  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442779 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.411614  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442646 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.407107  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443089 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.401263  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444703 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.403670  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444455 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.391847  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443156 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.398152  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441156 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.408506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440421 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.408667  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440336 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.404284  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440149 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.401669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440802 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.401840  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441714 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.406755  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443830 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.395512  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445741 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.400893  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444697 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.410845  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443654 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.391697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442068 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.397051  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441537 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.403179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441207 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.397307  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441435 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.400635  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442500 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.391516  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444332 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.398203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446438 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.403776  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445852 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.392202  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444622 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.385337  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446134 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.402615  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446166 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.391603  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446229 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.407263  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446990 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.407797  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448549 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.404553  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447096 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.390308  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443777 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.403723  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442025 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.399788  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441402 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.401068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441358 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.398025  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444181 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.410486  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444854 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.401864  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443540 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.394868  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442611 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.400069  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443321 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.392493  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445390 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.408039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445866 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.402630  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445443 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.406434  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444766 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.391301  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444491 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.394814  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444861 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.405957  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445327 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.407179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444796 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.402308  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443220 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.398875  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441266 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.388154  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440855 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.389977  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440229 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.395685  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441011 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.396089  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441054 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.392555  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442595 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.385910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444237 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.397907  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444077 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.399117  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443852 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.395494  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444423 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.402650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443215 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.400360  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442051 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.402284  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441387 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.390558  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441785 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.405678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441070 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.380747  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441840 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.384653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443097 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.391460  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443328 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.393185  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441753 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.395002  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441255 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.393850  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441056 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.389233  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441421 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.387384  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442211 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.390038  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441978 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.399122  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442752 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.399195  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444183 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.389610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442184 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.396875  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441077 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.385679  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441212 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.389638  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442281 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.389665  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441518 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.400678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441227 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.405744  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443753 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.391341  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445980 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.401510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445486 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.407403  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443116 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.392342  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441731 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.381667  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442384 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.393941  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442968 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.401591  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441455 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.385568  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442849 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.388182  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443319 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.400601  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443277 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.389934  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443207 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.406410  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443590 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.384609  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442973 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.390199  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441845 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.380989  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441166 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.404691  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442238 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.392365  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441868 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.390031  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441091 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.389066  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440229 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.391179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440970 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.397840  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441677 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.398544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440507 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.390482  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439932 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.388163  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440516 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.396722  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440619 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.390827  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440974 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.389651  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440729 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.379507  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439725 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.399786  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439154 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.380030  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439384 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.377344  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439878 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.397622  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440134 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.390525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440964 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.388366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439145 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.380262  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438714 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.385111  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438872 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.379784  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438892 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.394501  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438258 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.388822  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437684 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.387429  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439615 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.384265  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439591 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.395526  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441116 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.397705  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440621 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.391425  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439936 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.396076  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440607 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.381410  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441839 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.386167  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442127 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.398363  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442621 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.393072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443215 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.384997  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443336 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.387498  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442880 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.386573  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442803 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.373913  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442065 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.386715  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442081 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.382704  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441636 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.393713  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441198 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.382731  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441110 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.381885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441237 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.386758  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440251 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.386195  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440847 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.377368  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441240 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.382062  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440596 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.384286  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440053 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.385991  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438886 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.388917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438707 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.385998  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440298 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.381457  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440536 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.392855  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439956 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.382652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440477 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.384648  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441374 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.381559  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441797 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.394475  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442365 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.391811  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441268 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.384456  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441203 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.392027  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442316 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.385892  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443021 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.390814  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442574 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.383229  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442316 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.382077  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440419 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.381551  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440552 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.382468  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440785 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.375504  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440846 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.399199  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440656 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.384228  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440144 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.386423  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439221 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.389550  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438766 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.378222  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438163 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.384549  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438642 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.372688  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440883 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.388073  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441950 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.376430  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443461 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.385974  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443219 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.393516  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443512 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.383427  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442644 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.378047  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443042 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.388126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442824 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.384779  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442318 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.381182  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442610 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.391686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442656 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.397627  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442916 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.391134  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443202 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.377852  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443127 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.371290  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444204 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.377468  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443731 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.383137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443688 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.387017  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441270 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.388398  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442293 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.382217  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442079 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.375106  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443914 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.384115  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443437 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.377201  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441503 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.389730  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441167 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.383623  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439346 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.377281  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440986 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.383571  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440856 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.382683  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440327 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.391064  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440760 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.385912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440814 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.384027  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439868 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.379135  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440390 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.383702  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441437 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.372046  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441028 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.385370  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441420 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.377809  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441476 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.384393  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440292 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.384770  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439064 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.383370  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439860 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.377036  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441508 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.383065  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441300 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.388832  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440661 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.380283  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440867 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.397625  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441604 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.382023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442290 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.387934  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442597 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.380946  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440853 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.377829  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440576 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.376180  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442266 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.386768  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443238 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.393409  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443802 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.386423  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443952 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.375746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444272 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.376444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444792 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.384439  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445720 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.383923  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445077 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.375412  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443376 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.370510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442695 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.383773  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441826 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.375339  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441618 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.386221  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441718 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.380072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442515 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.381687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442730 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.388934  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443487 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.373641  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443427 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.376484  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443126 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.389685  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443507 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.376433  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444082 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.379024  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444783 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.385498  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444403 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.372446  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443216 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.388515  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441937 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.378502  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441299 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.383365  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440745 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.365326  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441035 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.375214  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441990 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.385587  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.443230 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.376765  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443035 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.382642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444595 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.379508  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444662 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.381632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444549 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.370929  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445384 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.365225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444901 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.369561  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443338 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.377027  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441949 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.375834  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440211 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.370991  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439255 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.373411  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439732 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.385025  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442090 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.383266  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443363 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.381125  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443494 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.377535  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442111 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.373947  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441898 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.380390  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441897 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.376567  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442909 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.373418  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443389 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.378839  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444892 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.382953  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445782 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.375425  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446038 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.370912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444932 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.376139  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445116 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.375503  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446532 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.379680  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447263 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.387934  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445931 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.377906  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442403 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.378885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440278 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.380891  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440517 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.383501  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440394 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.377998  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440927 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.389359  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441202 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.377110  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439942 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.376897  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440322 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.365050  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440896 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.371918  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440264 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.370313  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439979 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.380965  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439634 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.371147  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439545 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.375646  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439681 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.384097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439660 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.387750  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439480 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.379508  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438445 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.383564  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439566 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.376865  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441479 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.376028  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442978 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.371792  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443172 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.375837  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444764 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.365861  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442586 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.374537  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440991 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.378649  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439708 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.371064  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439422 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.370788  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439594 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.369428  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439326 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.374838  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439070 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.373424  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439578 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.372418  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440949 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.372554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439926 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.370700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438544 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.374493  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438305 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.375707  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437654 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.372419  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437503 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.375750  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437919 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.372580  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439628 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.372466  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441417 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.376511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442407 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.373279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443089 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.376414  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442233 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.368428  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442480 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.368059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442627 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.374345  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444248 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.367915  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444473 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.383930  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444838 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.375777  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446484 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.365421  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.447748 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.378490  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446604 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.367211  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445101 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.371540  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443590 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.375250  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443231 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.368594  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443250 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.370820  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441828 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.371225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441983 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.371550  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442391 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.376372  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442022 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.372197  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442285 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.371045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442186 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.372894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441841 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.377172  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440719 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.373481  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440207 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.362274  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440404 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.367814  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440931 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.366700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441928 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.368951  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442028 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.380759  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442266 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.362618  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443625 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.372536  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443522 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.368640  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443008 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.377886  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441300 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.377898  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440609 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.380297  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439617 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.374861  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439047 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.371086  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438689 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.367705  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438241 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.372999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438460 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.383806  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438493 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.362581  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439177 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.372150  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440088 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.357499  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440281 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.377765  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441100 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.365986  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441170 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.368104  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440990 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.365729  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441891 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.366366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442128 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.370725  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442173 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.371029  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441404 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.357990  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440814 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.359922  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439835 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.378826  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439601 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.375722  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439519 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.369417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439145 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.368873  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439527 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.373581  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440715 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.375707  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440994 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.372017  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442191 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.372971  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443232 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.369111  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443143 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.377773  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442675 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.365107  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442971 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.378796  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442264 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.367538  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442835 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.364530  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442188 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.362679  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442894 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.369855  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443132 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.368393  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443201 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.361310  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442154 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.365245  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442658 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.356289  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442186 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.361285  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441053 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.377599  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439967 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.365654  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440254 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.362876  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440287 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.367663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441132 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.367289  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441248 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.363142  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441492 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.368319  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441777 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.365893  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441073 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.366268  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440305 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.354615  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439698 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.363949  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439861 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.358944  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439179 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.369869  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.439473 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.370128  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439148 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.363310  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438848 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.365813  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439608 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.362498  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439564 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.357072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439520 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.358517  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440547 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.365929  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439964 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.358693  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440442 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.364458  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439560 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.374549  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439585 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.367704  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441011 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.363253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440541 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.369830  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441193 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.362080  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440847 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.369987  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441812 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.364363  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442732 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.369638  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442350 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.368169  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442336 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.376004  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442043 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.363780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442953 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.358059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443286 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.363727  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443425 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.365652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444146 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.367367  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443529 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.364087  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444002 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.366391  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443649 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.366676  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443052 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.374647  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441757 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.373829  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440744 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.366357  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440269 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.367411  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440004 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.364072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439384 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.366614  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439380 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.365145  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439944 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.368706  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440048 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.366632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440869 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.366145  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441549 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.365302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441728 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.366630  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442192 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.360582  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441444 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.360035  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441799 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.357101  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441027 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.358040  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441974 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.360427  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442958 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.364481  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441893 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.362009  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442621 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.364159  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441952 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.360302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442150 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.362581  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441701 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.362761  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441429 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.357374  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442997 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.370652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442734 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.376401  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442118 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.368785  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441036 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.358081  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440517 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.360043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440682 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.371500  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441355 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.359171  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441578 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.368302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441326 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.361054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441199 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.359937  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439782 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.367425  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441849 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.356504  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441955 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.358188  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441737 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.365846  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442238 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.361457  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442622 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.363915  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442889 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.369384  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442061 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.361590  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441179 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.361387  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441510 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.363823  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441456 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.351430  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442675 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.365188  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442498 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.364223  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442431 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.363534  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443353 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.363546  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442369 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.362570  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442239 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.363867  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442759 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.367151  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443034 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.368113  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442390 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.365897  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441536 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.364620  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441253 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.366503  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442204 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.358356  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443217 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.365265  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443006 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.361057  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442398 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.364014  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442458 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.368073  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440939 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.352781  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440773 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.350493  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440719 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.354522  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441324 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.365147  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441536 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.367114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440889 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.369752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440464 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.362462  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439805 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.362322  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440176 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.357559  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440432 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.364490  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441492 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.366039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442330 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.365222  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443470 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.367215  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443592 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.360566  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443140 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.357897  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442062 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.363834  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442063 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.356444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441916 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.354382  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442330 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.374622  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441742 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.363688  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442638 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.361823  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442227 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.358734  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441733 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.358988  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441166 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.360512  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441212 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.363162  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440735 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.379391  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440686 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.363792  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440053 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.364900  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440084 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.357968  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440326 \n",
      "\n",
      "Epoch 1001\n",
      "-------------------------------\n",
      "loss: 0.350587  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440977 \n",
      "\n",
      "Epoch 1002\n",
      "-------------------------------\n",
      "loss: 0.365632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442312 \n",
      "\n",
      "Epoch 1003\n",
      "-------------------------------\n",
      "loss: 0.365536  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442892 \n",
      "\n",
      "Epoch 1004\n",
      "-------------------------------\n",
      "loss: 0.361130  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443652 \n",
      "\n",
      "Epoch 1005\n",
      "-------------------------------\n",
      "loss: 0.366780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444428 \n",
      "\n",
      "Epoch 1006\n",
      "-------------------------------\n",
      "loss: 0.361473  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443706 \n",
      "\n",
      "Epoch 1007\n",
      "-------------------------------\n",
      "loss: 0.361239  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442123 \n",
      "\n",
      "Epoch 1008\n",
      "-------------------------------\n",
      "loss: 0.364322  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441596 \n",
      "\n",
      "Epoch 1009\n",
      "-------------------------------\n",
      "loss: 0.364319  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441101 \n",
      "\n",
      "Epoch 1010\n",
      "-------------------------------\n",
      "loss: 0.363574  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441666 \n",
      "\n",
      "Epoch 1011\n",
      "-------------------------------\n",
      "loss: 0.361186  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443015 \n",
      "\n",
      "Epoch 1012\n",
      "-------------------------------\n",
      "loss: 0.352938  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442426 \n",
      "\n",
      "Epoch 1013\n",
      "-------------------------------\n",
      "loss: 0.356443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442906 \n",
      "\n",
      "Epoch 1014\n",
      "-------------------------------\n",
      "loss: 0.363976  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442571 \n",
      "\n",
      "Epoch 1015\n",
      "-------------------------------\n",
      "loss: 0.356286  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443076 \n",
      "\n",
      "Epoch 1016\n",
      "-------------------------------\n",
      "loss: 0.349450  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442545 \n",
      "\n",
      "Epoch 1017\n",
      "-------------------------------\n",
      "loss: 0.358475  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441319 \n",
      "\n",
      "Epoch 1018\n",
      "-------------------------------\n",
      "loss: 0.351044  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442120 \n",
      "\n",
      "Epoch 1019\n",
      "-------------------------------\n",
      "loss: 0.363979  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441328 \n",
      "\n",
      "Epoch 1020\n",
      "-------------------------------\n",
      "loss: 0.358380  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441300 \n",
      "\n",
      "Epoch 1021\n",
      "-------------------------------\n",
      "loss: 0.363324  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441718 \n",
      "\n",
      "Epoch 1022\n",
      "-------------------------------\n",
      "loss: 0.357586  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442461 \n",
      "\n",
      "Epoch 1023\n",
      "-------------------------------\n",
      "loss: 0.358059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442405 \n",
      "\n",
      "Epoch 1024\n",
      "-------------------------------\n",
      "loss: 0.349136  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442130 \n",
      "\n",
      "Epoch 1025\n",
      "-------------------------------\n",
      "loss: 0.354982  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441559 \n",
      "\n",
      "Epoch 1026\n",
      "-------------------------------\n",
      "loss: 0.366083  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441136 \n",
      "\n",
      "Epoch 1027\n",
      "-------------------------------\n",
      "loss: 0.365062  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440519 \n",
      "\n",
      "Epoch 1028\n",
      "-------------------------------\n",
      "loss: 0.349150  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440560 \n",
      "\n",
      "Epoch 1029\n",
      "-------------------------------\n",
      "loss: 0.352449  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440463 \n",
      "\n",
      "Epoch 1030\n",
      "-------------------------------\n",
      "loss: 0.358197  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440397 \n",
      "\n",
      "Epoch 1031\n",
      "-------------------------------\n",
      "loss: 0.368058  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441106 \n",
      "\n",
      "Epoch 1032\n",
      "-------------------------------\n",
      "loss: 0.353568  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440990 \n",
      "\n",
      "Epoch 1033\n",
      "-------------------------------\n",
      "loss: 0.364177  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440797 \n",
      "\n",
      "Epoch 1034\n",
      "-------------------------------\n",
      "loss: 0.357908  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441608 \n",
      "\n",
      "Epoch 1035\n",
      "-------------------------------\n",
      "loss: 0.353595  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441765 \n",
      "\n",
      "Epoch 1036\n",
      "-------------------------------\n",
      "loss: 0.365187  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441805 \n",
      "\n",
      "Epoch 1037\n",
      "-------------------------------\n",
      "loss: 0.351282  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441280 \n",
      "\n",
      "Epoch 1038\n",
      "-------------------------------\n",
      "loss: 0.362514  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441981 \n",
      "\n",
      "Epoch 1039\n",
      "-------------------------------\n",
      "loss: 0.352255  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442168 \n",
      "\n",
      "Epoch 1040\n",
      "-------------------------------\n",
      "loss: 0.356402  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443050 \n",
      "\n",
      "Epoch 1041\n",
      "-------------------------------\n",
      "loss: 0.344689  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444310 \n",
      "\n",
      "Epoch 1042\n",
      "-------------------------------\n",
      "loss: 0.347017  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444542 \n",
      "\n",
      "Epoch 1043\n",
      "-------------------------------\n",
      "loss: 0.348922  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444250 \n",
      "\n",
      "Epoch 1044\n",
      "-------------------------------\n",
      "loss: 0.360527  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444112 \n",
      "\n",
      "Epoch 1045\n",
      "-------------------------------\n",
      "loss: 0.354482  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443765 \n",
      "\n",
      "Epoch 1046\n",
      "-------------------------------\n",
      "loss: 0.350738  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442900 \n",
      "\n",
      "Epoch 1047\n",
      "-------------------------------\n",
      "loss: 0.363300  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442999 \n",
      "\n",
      "Epoch 1048\n",
      "-------------------------------\n",
      "loss: 0.359323  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442284 \n",
      "\n",
      "Epoch 1049\n",
      "-------------------------------\n",
      "loss: 0.356673  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441665 \n",
      "\n",
      "Epoch 1050\n",
      "-------------------------------\n",
      "loss: 0.352788  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441540 \n",
      "\n",
      "Epoch 1051\n",
      "-------------------------------\n",
      "loss: 0.352865  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442447 \n",
      "\n",
      "Epoch 1052\n",
      "-------------------------------\n",
      "loss: 0.354548  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442948 \n",
      "\n",
      "Epoch 1053\n",
      "-------------------------------\n",
      "loss: 0.356376  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442493 \n",
      "\n",
      "Epoch 1054\n",
      "-------------------------------\n",
      "loss: 0.356782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443041 \n",
      "\n",
      "Epoch 1055\n",
      "-------------------------------\n",
      "loss: 0.359756  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442706 \n",
      "\n",
      "Epoch 1056\n",
      "-------------------------------\n",
      "loss: 0.344866  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442763 \n",
      "\n",
      "Epoch 1057\n",
      "-------------------------------\n",
      "loss: 0.350742  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443501 \n",
      "\n",
      "Epoch 1058\n",
      "-------------------------------\n",
      "loss: 0.356168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444673 \n",
      "\n",
      "Epoch 1059\n",
      "-------------------------------\n",
      "loss: 0.355486  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445919 \n",
      "\n",
      "Epoch 1060\n",
      "-------------------------------\n",
      "loss: 0.356939  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445759 \n",
      "\n",
      "Epoch 1061\n",
      "-------------------------------\n",
      "loss: 0.355371  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445497 \n",
      "\n",
      "Epoch 1062\n",
      "-------------------------------\n",
      "loss: 0.347562  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445350 \n",
      "\n",
      "Epoch 1063\n",
      "-------------------------------\n",
      "loss: 0.353792  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445128 \n",
      "\n",
      "Epoch 1064\n",
      "-------------------------------\n",
      "loss: 0.345263  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444219 \n",
      "\n",
      "Epoch 1065\n",
      "-------------------------------\n",
      "loss: 0.357305  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443020 \n",
      "\n",
      "Epoch 1066\n",
      "-------------------------------\n",
      "loss: 0.361294  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443437 \n",
      "\n",
      "Epoch 1067\n",
      "-------------------------------\n",
      "loss: 0.358895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442617 \n",
      "\n",
      "Epoch 1068\n",
      "-------------------------------\n",
      "loss: 0.357664  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442745 \n",
      "\n",
      "Epoch 1069\n",
      "-------------------------------\n",
      "loss: 0.349215  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442084 \n",
      "\n",
      "Epoch 1070\n",
      "-------------------------------\n",
      "loss: 0.361364  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443086 \n",
      "\n",
      "Epoch 1071\n",
      "-------------------------------\n",
      "loss: 0.358334  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444170 \n",
      "\n",
      "Epoch 1072\n",
      "-------------------------------\n",
      "loss: 0.350143  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444700 \n",
      "\n",
      "Epoch 1073\n",
      "-------------------------------\n",
      "loss: 0.359367  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445923 \n",
      "\n",
      "Epoch 1074\n",
      "-------------------------------\n",
      "loss: 0.362416  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446053 \n",
      "\n",
      "Epoch 1075\n",
      "-------------------------------\n",
      "loss: 0.360545  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446518 \n",
      "\n",
      "Epoch 1076\n",
      "-------------------------------\n",
      "loss: 0.348270  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446559 \n",
      "\n",
      "Epoch 1077\n",
      "-------------------------------\n",
      "loss: 0.358038  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447509 \n",
      "\n",
      "Epoch 1078\n",
      "-------------------------------\n",
      "loss: 0.359660  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446175 \n",
      "\n",
      "Epoch 1079\n",
      "-------------------------------\n",
      "loss: 0.361510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445480 \n",
      "\n",
      "Epoch 1080\n",
      "-------------------------------\n",
      "loss: 0.359737  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444715 \n",
      "\n",
      "Epoch 1081\n",
      "-------------------------------\n",
      "loss: 0.357397  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444849 \n",
      "\n",
      "Epoch 1082\n",
      "-------------------------------\n",
      "loss: 0.358894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442804 \n",
      "\n",
      "Epoch 1083\n",
      "-------------------------------\n",
      "loss: 0.364068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441339 \n",
      "\n",
      "Epoch 1084\n",
      "-------------------------------\n",
      "loss: 0.353995  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441265 \n",
      "\n",
      "Epoch 1085\n",
      "-------------------------------\n",
      "loss: 0.354843  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442012 \n",
      "\n",
      "Epoch 1086\n",
      "-------------------------------\n",
      "loss: 0.362609  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442709 \n",
      "\n",
      "Epoch 1087\n",
      "-------------------------------\n",
      "loss: 0.361684  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443209 \n",
      "\n",
      "Epoch 1088\n",
      "-------------------------------\n",
      "loss: 0.345748  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442630 \n",
      "\n",
      "Epoch 1089\n",
      "-------------------------------\n",
      "loss: 0.346643  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441030 \n",
      "\n",
      "Epoch 1090\n",
      "-------------------------------\n",
      "loss: 0.358659  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441643 \n",
      "\n",
      "Epoch 1091\n",
      "-------------------------------\n",
      "loss: 0.353651  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442151 \n",
      "\n",
      "Epoch 1092\n",
      "-------------------------------\n",
      "loss: 0.363041  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443152 \n",
      "\n",
      "Epoch 1093\n",
      "-------------------------------\n",
      "loss: 0.359796  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442338 \n",
      "\n",
      "Epoch 1094\n",
      "-------------------------------\n",
      "loss: 0.355521  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443243 \n",
      "\n",
      "Epoch 1095\n",
      "-------------------------------\n",
      "loss: 0.358859  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442564 \n",
      "\n",
      "Epoch 1096\n",
      "-------------------------------\n",
      "loss: 0.356861  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442413 \n",
      "\n",
      "Epoch 1097\n",
      "-------------------------------\n",
      "loss: 0.359393  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442222 \n",
      "\n",
      "Epoch 1098\n",
      "-------------------------------\n",
      "loss: 0.347859  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443287 \n",
      "\n",
      "Epoch 1099\n",
      "-------------------------------\n",
      "loss: 0.343028  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443536 \n",
      "\n",
      "Epoch 1100\n",
      "-------------------------------\n",
      "loss: 0.360032  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443311 \n",
      "\n",
      "Epoch 1101\n",
      "-------------------------------\n",
      "loss: 0.350496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442948 \n",
      "\n",
      "Epoch 1102\n",
      "-------------------------------\n",
      "loss: 0.351034  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441948 \n",
      "\n",
      "Epoch 1103\n",
      "-------------------------------\n",
      "loss: 0.349537  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441673 \n",
      "\n",
      "Epoch 1104\n",
      "-------------------------------\n",
      "loss: 0.352979  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442094 \n",
      "\n",
      "Epoch 1105\n",
      "-------------------------------\n",
      "loss: 0.358864  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442641 \n",
      "\n",
      "Epoch 1106\n",
      "-------------------------------\n",
      "loss: 0.356957  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442618 \n",
      "\n",
      "Epoch 1107\n",
      "-------------------------------\n",
      "loss: 0.351087  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442038 \n",
      "\n",
      "Epoch 1108\n",
      "-------------------------------\n",
      "loss: 0.340227  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442474 \n",
      "\n",
      "Epoch 1109\n",
      "-------------------------------\n",
      "loss: 0.339541  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442042 \n",
      "\n",
      "Epoch 1110\n",
      "-------------------------------\n",
      "loss: 0.354959  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442874 \n",
      "\n",
      "Epoch 1111\n",
      "-------------------------------\n",
      "loss: 0.356960  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442276 \n",
      "\n",
      "Epoch 1112\n",
      "-------------------------------\n",
      "loss: 0.363399  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440803 \n",
      "\n",
      "Epoch 1113\n",
      "-------------------------------\n",
      "loss: 0.350926  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440075 \n",
      "\n",
      "Epoch 1114\n",
      "-------------------------------\n",
      "loss: 0.363832  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439949 \n",
      "\n",
      "Epoch 1115\n",
      "-------------------------------\n",
      "loss: 0.356449  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440331 \n",
      "\n",
      "Epoch 1116\n",
      "-------------------------------\n",
      "loss: 0.350323  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439482 \n",
      "\n",
      "Epoch 1117\n",
      "-------------------------------\n",
      "loss: 0.362097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440385 \n",
      "\n",
      "Epoch 1118\n",
      "-------------------------------\n",
      "loss: 0.354663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440774 \n",
      "\n",
      "Epoch 1119\n",
      "-------------------------------\n",
      "loss: 0.348488  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442205 \n",
      "\n",
      "Epoch 1120\n",
      "-------------------------------\n",
      "loss: 0.354057  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442633 \n",
      "\n",
      "Epoch 1121\n",
      "-------------------------------\n",
      "loss: 0.349733  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442295 \n",
      "\n",
      "Epoch 1122\n",
      "-------------------------------\n",
      "loss: 0.351812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441797 \n",
      "\n",
      "Epoch 1123\n",
      "-------------------------------\n",
      "loss: 0.357957  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441920 \n",
      "\n",
      "Epoch 1124\n",
      "-------------------------------\n",
      "loss: 0.351108  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441789 \n",
      "\n",
      "Epoch 1125\n",
      "-------------------------------\n",
      "loss: 0.352076  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441596 \n",
      "\n",
      "Epoch 1126\n",
      "-------------------------------\n",
      "loss: 0.353565  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441688 \n",
      "\n",
      "Epoch 1127\n",
      "-------------------------------\n",
      "loss: 0.353358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441762 \n",
      "\n",
      "Epoch 1128\n",
      "-------------------------------\n",
      "loss: 0.348994  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443462 \n",
      "\n",
      "Epoch 1129\n",
      "-------------------------------\n",
      "loss: 0.354739  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443151 \n",
      "\n",
      "Epoch 1130\n",
      "-------------------------------\n",
      "loss: 0.356612  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443371 \n",
      "\n",
      "Epoch 1131\n",
      "-------------------------------\n",
      "loss: 0.352019  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443306 \n",
      "\n",
      "Epoch 1132\n",
      "-------------------------------\n",
      "loss: 0.360993  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443235 \n",
      "\n",
      "Epoch 1133\n",
      "-------------------------------\n",
      "loss: 0.349268  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441456 \n",
      "\n",
      "Epoch 1134\n",
      "-------------------------------\n",
      "loss: 0.355909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441559 \n",
      "\n",
      "Epoch 1135\n",
      "-------------------------------\n",
      "loss: 0.350554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442013 \n",
      "\n",
      "Epoch 1136\n",
      "-------------------------------\n",
      "loss: 0.348119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443000 \n",
      "\n",
      "Epoch 1137\n",
      "-------------------------------\n",
      "loss: 0.346994  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444340 \n",
      "\n",
      "Epoch 1138\n",
      "-------------------------------\n",
      "loss: 0.356381  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444409 \n",
      "\n",
      "Epoch 1139\n",
      "-------------------------------\n",
      "loss: 0.365662  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444226 \n",
      "\n",
      "Epoch 1140\n",
      "-------------------------------\n",
      "loss: 0.352845  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445046 \n",
      "\n",
      "Epoch 1141\n",
      "-------------------------------\n",
      "loss: 0.354509  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445315 \n",
      "\n",
      "Epoch 1142\n",
      "-------------------------------\n",
      "loss: 0.355276  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445425 \n",
      "\n",
      "Epoch 1143\n",
      "-------------------------------\n",
      "loss: 0.355567  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444337 \n",
      "\n",
      "Epoch 1144\n",
      "-------------------------------\n",
      "loss: 0.354091  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443626 \n",
      "\n",
      "Epoch 1145\n",
      "-------------------------------\n",
      "loss: 0.363746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442429 \n",
      "\n",
      "Epoch 1146\n",
      "-------------------------------\n",
      "loss: 0.356644  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442348 \n",
      "\n",
      "Epoch 1147\n",
      "-------------------------------\n",
      "loss: 0.354359  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442060 \n",
      "\n",
      "Epoch 1148\n",
      "-------------------------------\n",
      "loss: 0.351017  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442342 \n",
      "\n",
      "Epoch 1149\n",
      "-------------------------------\n",
      "loss: 0.353684  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442588 \n",
      "\n",
      "Epoch 1150\n",
      "-------------------------------\n",
      "loss: 0.353683  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443197 \n",
      "\n",
      "Epoch 1151\n",
      "-------------------------------\n",
      "loss: 0.359070  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442814 \n",
      "\n",
      "Epoch 1152\n",
      "-------------------------------\n",
      "loss: 0.352149  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442580 \n",
      "\n",
      "Epoch 1153\n",
      "-------------------------------\n",
      "loss: 0.344719  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441689 \n",
      "\n",
      "Epoch 1154\n",
      "-------------------------------\n",
      "loss: 0.347697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442334 \n",
      "\n",
      "Epoch 1155\n",
      "-------------------------------\n",
      "loss: 0.354719  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441428 \n",
      "\n",
      "Epoch 1156\n",
      "-------------------------------\n",
      "loss: 0.354600  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440586 \n",
      "\n",
      "Epoch 1157\n",
      "-------------------------------\n",
      "loss: 0.353877  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440857 \n",
      "\n",
      "Epoch 1158\n",
      "-------------------------------\n",
      "loss: 0.363992  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442227 \n",
      "\n",
      "Epoch 1159\n",
      "-------------------------------\n",
      "loss: 0.358024  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442459 \n",
      "\n",
      "Epoch 1160\n",
      "-------------------------------\n",
      "loss: 0.350162  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442157 \n",
      "\n",
      "Epoch 1161\n",
      "-------------------------------\n",
      "loss: 0.345768  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441490 \n",
      "\n",
      "Epoch 1162\n",
      "-------------------------------\n",
      "loss: 0.354967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441462 \n",
      "\n",
      "Epoch 1163\n",
      "-------------------------------\n",
      "loss: 0.357203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442052 \n",
      "\n",
      "Epoch 1164\n",
      "-------------------------------\n",
      "loss: 0.352652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442087 \n",
      "\n",
      "Epoch 1165\n",
      "-------------------------------\n",
      "loss: 0.352109  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442208 \n",
      "\n",
      "Epoch 1166\n",
      "-------------------------------\n",
      "loss: 0.351995  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442320 \n",
      "\n",
      "Epoch 1167\n",
      "-------------------------------\n",
      "loss: 0.353072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441270 \n",
      "\n",
      "Epoch 1168\n",
      "-------------------------------\n",
      "loss: 0.354868  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441344 \n",
      "\n",
      "Epoch 1169\n",
      "-------------------------------\n",
      "loss: 0.343586  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442309 \n",
      "\n",
      "Epoch 1170\n",
      "-------------------------------\n",
      "loss: 0.344354  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441713 \n",
      "\n",
      "Epoch 1171\n",
      "-------------------------------\n",
      "loss: 0.356393  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442741 \n",
      "\n",
      "Epoch 1172\n",
      "-------------------------------\n",
      "loss: 0.349546  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441586 \n",
      "\n",
      "Epoch 1173\n",
      "-------------------------------\n",
      "loss: 0.352341  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442197 \n",
      "\n",
      "Epoch 1174\n",
      "-------------------------------\n",
      "loss: 0.347506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443199 \n",
      "\n",
      "Epoch 1175\n",
      "-------------------------------\n",
      "loss: 0.355491  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445092 \n",
      "\n",
      "Epoch 1176\n",
      "-------------------------------\n",
      "loss: 0.345024  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445523 \n",
      "\n",
      "Epoch 1177\n",
      "-------------------------------\n",
      "loss: 0.359686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444494 \n",
      "\n",
      "Epoch 1178\n",
      "-------------------------------\n",
      "loss: 0.353131  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443842 \n",
      "\n",
      "Epoch 1179\n",
      "-------------------------------\n",
      "loss: 0.348814  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442940 \n",
      "\n",
      "Epoch 1180\n",
      "-------------------------------\n",
      "loss: 0.345959  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441404 \n",
      "\n",
      "Epoch 1181\n",
      "-------------------------------\n",
      "loss: 0.355243  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441617 \n",
      "\n",
      "Epoch 1182\n",
      "-------------------------------\n",
      "loss: 0.351893  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442683 \n",
      "\n",
      "Epoch 1183\n",
      "-------------------------------\n",
      "loss: 0.353597  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442690 \n",
      "\n",
      "Epoch 1184\n",
      "-------------------------------\n",
      "loss: 0.345773  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443087 \n",
      "\n",
      "Epoch 1185\n",
      "-------------------------------\n",
      "loss: 0.347377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442596 \n",
      "\n",
      "Epoch 1186\n",
      "-------------------------------\n",
      "loss: 0.346447  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442783 \n",
      "\n",
      "Epoch 1187\n",
      "-------------------------------\n",
      "loss: 0.352107  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442864 \n",
      "\n",
      "Epoch 1188\n",
      "-------------------------------\n",
      "loss: 0.350093  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442212 \n",
      "\n",
      "Epoch 1189\n",
      "-------------------------------\n",
      "loss: 0.352772  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441362 \n",
      "\n",
      "Epoch 1190\n",
      "-------------------------------\n",
      "loss: 0.341616  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441359 \n",
      "\n",
      "Epoch 1191\n",
      "-------------------------------\n",
      "loss: 0.349332  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441785 \n",
      "\n",
      "Epoch 1192\n",
      "-------------------------------\n",
      "loss: 0.345633  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442490 \n",
      "\n",
      "Epoch 1193\n",
      "-------------------------------\n",
      "loss: 0.350150  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443114 \n",
      "\n",
      "Epoch 1194\n",
      "-------------------------------\n",
      "loss: 0.353443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443496 \n",
      "\n",
      "Epoch 1195\n",
      "-------------------------------\n",
      "loss: 0.353007  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443611 \n",
      "\n",
      "Epoch 1196\n",
      "-------------------------------\n",
      "loss: 0.346786  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443040 \n",
      "\n",
      "Epoch 1197\n",
      "-------------------------------\n",
      "loss: 0.352396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443719 \n",
      "\n",
      "Epoch 1198\n",
      "-------------------------------\n",
      "loss: 0.347035  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442743 \n",
      "\n",
      "Epoch 1199\n",
      "-------------------------------\n",
      "loss: 0.352330  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443277 \n",
      "\n",
      "Epoch 1200\n",
      "-------------------------------\n",
      "loss: 0.341375  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442975 \n",
      "\n",
      "Epoch 1201\n",
      "-------------------------------\n",
      "loss: 0.359029  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442681 \n",
      "\n",
      "Epoch 1202\n",
      "-------------------------------\n",
      "loss: 0.347198  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442391 \n",
      "\n",
      "Epoch 1203\n",
      "-------------------------------\n",
      "loss: 0.353198  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443648 \n",
      "\n",
      "Epoch 1204\n",
      "-------------------------------\n",
      "loss: 0.353155  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443752 \n",
      "\n",
      "Epoch 1205\n",
      "-------------------------------\n",
      "loss: 0.360401  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443718 \n",
      "\n",
      "Epoch 1206\n",
      "-------------------------------\n",
      "loss: 0.346431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443172 \n",
      "\n",
      "Epoch 1207\n",
      "-------------------------------\n",
      "loss: 0.347615  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443586 \n",
      "\n",
      "Epoch 1208\n",
      "-------------------------------\n",
      "loss: 0.351632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444378 \n",
      "\n",
      "Epoch 1209\n",
      "-------------------------------\n",
      "loss: 0.358810  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444419 \n",
      "\n",
      "Epoch 1210\n",
      "-------------------------------\n",
      "loss: 0.346569  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443549 \n",
      "\n",
      "Epoch 1211\n",
      "-------------------------------\n",
      "loss: 0.345455  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442985 \n",
      "\n",
      "Epoch 1212\n",
      "-------------------------------\n",
      "loss: 0.348551  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443483 \n",
      "\n",
      "Epoch 1213\n",
      "-------------------------------\n",
      "loss: 0.352497  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443310 \n",
      "\n",
      "Epoch 1214\n",
      "-------------------------------\n",
      "loss: 0.346012  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443480 \n",
      "\n",
      "Epoch 1215\n",
      "-------------------------------\n",
      "loss: 0.354171  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443385 \n",
      "\n",
      "Epoch 1216\n",
      "-------------------------------\n",
      "loss: 0.348708  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444209 \n",
      "\n",
      "Epoch 1217\n",
      "-------------------------------\n",
      "loss: 0.348593  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444124 \n",
      "\n",
      "Epoch 1218\n",
      "-------------------------------\n",
      "loss: 0.344093  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443438 \n",
      "\n",
      "Epoch 1219\n",
      "-------------------------------\n",
      "loss: 0.347958  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442617 \n",
      "\n",
      "Epoch 1220\n",
      "-------------------------------\n",
      "loss: 0.345800  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442670 \n",
      "\n",
      "Epoch 1221\n",
      "-------------------------------\n",
      "loss: 0.349432  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443199 \n",
      "\n",
      "Epoch 1222\n",
      "-------------------------------\n",
      "loss: 0.359174  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443221 \n",
      "\n",
      "Epoch 1223\n",
      "-------------------------------\n",
      "loss: 0.344926  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444449 \n",
      "\n",
      "Epoch 1224\n",
      "-------------------------------\n",
      "loss: 0.357230  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444534 \n",
      "\n",
      "Epoch 1225\n",
      "-------------------------------\n",
      "loss: 0.358425  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443537 \n",
      "\n",
      "Epoch 1226\n",
      "-------------------------------\n",
      "loss: 0.357213  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443578 \n",
      "\n",
      "Epoch 1227\n",
      "-------------------------------\n",
      "loss: 0.353019  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442690 \n",
      "\n",
      "Epoch 1228\n",
      "-------------------------------\n",
      "loss: 0.350828  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441878 \n",
      "\n",
      "Epoch 1229\n",
      "-------------------------------\n",
      "loss: 0.346070  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442675 \n",
      "\n",
      "Epoch 1230\n",
      "-------------------------------\n",
      "loss: 0.347129  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442812 \n",
      "\n",
      "Epoch 1231\n",
      "-------------------------------\n",
      "loss: 0.350989  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443063 \n",
      "\n",
      "Epoch 1232\n",
      "-------------------------------\n",
      "loss: 0.349579  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442987 \n",
      "\n",
      "Epoch 1233\n",
      "-------------------------------\n",
      "loss: 0.348875  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443088 \n",
      "\n",
      "Epoch 1234\n",
      "-------------------------------\n",
      "loss: 0.345063  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442434 \n",
      "\n",
      "Epoch 1235\n",
      "-------------------------------\n",
      "loss: 0.340056  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442677 \n",
      "\n",
      "Epoch 1236\n",
      "-------------------------------\n",
      "loss: 0.345081  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443004 \n",
      "\n",
      "Epoch 1237\n",
      "-------------------------------\n",
      "loss: 0.356553  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442350 \n",
      "\n",
      "Epoch 1238\n",
      "-------------------------------\n",
      "loss: 0.350000  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440647 \n",
      "\n",
      "Epoch 1239\n",
      "-------------------------------\n",
      "loss: 0.343812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440865 \n",
      "\n",
      "Epoch 1240\n",
      "-------------------------------\n",
      "loss: 0.355246  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442013 \n",
      "\n",
      "Epoch 1241\n",
      "-------------------------------\n",
      "loss: 0.346601  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443980 \n",
      "\n",
      "Epoch 1242\n",
      "-------------------------------\n",
      "loss: 0.350688  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444991 \n",
      "\n",
      "Epoch 1243\n",
      "-------------------------------\n",
      "loss: 0.351669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443408 \n",
      "\n",
      "Epoch 1244\n",
      "-------------------------------\n",
      "loss: 0.348871  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441869 \n",
      "\n",
      "Epoch 1245\n",
      "-------------------------------\n",
      "loss: 0.348952  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441424 \n",
      "\n",
      "Epoch 1246\n",
      "-------------------------------\n",
      "loss: 0.344077  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441690 \n",
      "\n",
      "Epoch 1247\n",
      "-------------------------------\n",
      "loss: 0.345760  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441733 \n",
      "\n",
      "Epoch 1248\n",
      "-------------------------------\n",
      "loss: 0.355453  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441902 \n",
      "\n",
      "Epoch 1249\n",
      "-------------------------------\n",
      "loss: 0.348080  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442212 \n",
      "\n",
      "Epoch 1250\n",
      "-------------------------------\n",
      "loss: 0.353137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442805 \n",
      "\n",
      "Epoch 1251\n",
      "-------------------------------\n",
      "loss: 0.347450  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443285 \n",
      "\n",
      "Epoch 1252\n",
      "-------------------------------\n",
      "loss: 0.345990  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444648 \n",
      "\n",
      "Epoch 1253\n",
      "-------------------------------\n",
      "loss: 0.344377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445339 \n",
      "\n",
      "Epoch 1254\n",
      "-------------------------------\n",
      "loss: 0.340626  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445299 \n",
      "\n",
      "Epoch 1255\n",
      "-------------------------------\n",
      "loss: 0.349044  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444341 \n",
      "\n",
      "Epoch 1256\n",
      "-------------------------------\n",
      "loss: 0.342710  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442877 \n",
      "\n",
      "Epoch 1257\n",
      "-------------------------------\n",
      "loss: 0.350003  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442969 \n",
      "\n",
      "Epoch 1258\n",
      "-------------------------------\n",
      "loss: 0.344360  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442736 \n",
      "\n",
      "Epoch 1259\n",
      "-------------------------------\n",
      "loss: 0.347935  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441569 \n",
      "\n",
      "Epoch 1260\n",
      "-------------------------------\n",
      "loss: 0.346965  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440741 \n",
      "\n",
      "Epoch 1261\n",
      "-------------------------------\n",
      "loss: 0.359339  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441265 \n",
      "\n",
      "Epoch 1262\n",
      "-------------------------------\n",
      "loss: 0.343801  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443405 \n",
      "\n",
      "Epoch 1263\n",
      "-------------------------------\n",
      "loss: 0.345380  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.446942 \n",
      "\n",
      "Epoch 1264\n",
      "-------------------------------\n",
      "loss: 0.353050  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448439 \n",
      "\n",
      "Epoch 1265\n",
      "-------------------------------\n",
      "loss: 0.349937  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447165 \n",
      "\n",
      "Epoch 1266\n",
      "-------------------------------\n",
      "loss: 0.358079  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444331 \n",
      "\n",
      "Epoch 1267\n",
      "-------------------------------\n",
      "loss: 0.351206  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443221 \n",
      "\n",
      "Epoch 1268\n",
      "-------------------------------\n",
      "loss: 0.345716  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443510 \n",
      "\n",
      "Epoch 1269\n",
      "-------------------------------\n",
      "loss: 0.334186  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444060 \n",
      "\n",
      "Epoch 1270\n",
      "-------------------------------\n",
      "loss: 0.343304  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444500 \n",
      "\n",
      "Epoch 1271\n",
      "-------------------------------\n",
      "loss: 0.344394  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443661 \n",
      "\n",
      "Epoch 1272\n",
      "-------------------------------\n",
      "loss: 0.343234  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442904 \n",
      "\n",
      "Epoch 1273\n",
      "-------------------------------\n",
      "loss: 0.352823  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443493 \n",
      "\n",
      "Epoch 1274\n",
      "-------------------------------\n",
      "loss: 0.349834  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444866 \n",
      "\n",
      "Epoch 1275\n",
      "-------------------------------\n",
      "loss: 0.344346  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445587 \n",
      "\n",
      "Epoch 1276\n",
      "-------------------------------\n",
      "loss: 0.348067  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446015 \n",
      "\n",
      "Epoch 1277\n",
      "-------------------------------\n",
      "loss: 0.349985  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444411 \n",
      "\n",
      "Epoch 1278\n",
      "-------------------------------\n",
      "loss: 0.341189  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443118 \n",
      "\n",
      "Epoch 1279\n",
      "-------------------------------\n",
      "loss: 0.340322  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440873 \n",
      "\n",
      "Epoch 1280\n",
      "-------------------------------\n",
      "loss: 0.344750  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441291 \n",
      "\n",
      "Epoch 1281\n",
      "-------------------------------\n",
      "loss: 0.340422  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440485 \n",
      "\n",
      "Epoch 1282\n",
      "-------------------------------\n",
      "loss: 0.343470  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440688 \n",
      "\n",
      "Epoch 1283\n",
      "-------------------------------\n",
      "loss: 0.341323  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440782 \n",
      "\n",
      "Epoch 1284\n",
      "-------------------------------\n",
      "loss: 0.352196  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442883 \n",
      "\n",
      "Epoch 1285\n",
      "-------------------------------\n",
      "loss: 0.344952  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444225 \n",
      "\n",
      "Epoch 1286\n",
      "-------------------------------\n",
      "loss: 0.341472  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445121 \n",
      "\n",
      "Epoch 1287\n",
      "-------------------------------\n",
      "loss: 0.348961  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445195 \n",
      "\n",
      "Epoch 1288\n",
      "-------------------------------\n",
      "loss: 0.349179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445299 \n",
      "\n",
      "Epoch 1289\n",
      "-------------------------------\n",
      "loss: 0.357081  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443520 \n",
      "\n",
      "Epoch 1290\n",
      "-------------------------------\n",
      "loss: 0.337370  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444186 \n",
      "\n",
      "Epoch 1291\n",
      "-------------------------------\n",
      "loss: 0.344869  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443819 \n",
      "\n",
      "Epoch 1292\n",
      "-------------------------------\n",
      "loss: 0.350740  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443460 \n",
      "\n",
      "Epoch 1293\n",
      "-------------------------------\n",
      "loss: 0.335070  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442850 \n",
      "\n",
      "Epoch 1294\n",
      "-------------------------------\n",
      "loss: 0.349084  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444199 \n",
      "\n",
      "Epoch 1295\n",
      "-------------------------------\n",
      "loss: 0.335974  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444177 \n",
      "\n",
      "Epoch 1296\n",
      "-------------------------------\n",
      "loss: 0.354173  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444763 \n",
      "\n",
      "Epoch 1297\n",
      "-------------------------------\n",
      "loss: 0.343280  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443971 \n",
      "\n",
      "Epoch 1298\n",
      "-------------------------------\n",
      "loss: 0.350464  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443641 \n",
      "\n",
      "Epoch 1299\n",
      "-------------------------------\n",
      "loss: 0.348824  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442271 \n",
      "\n",
      "Epoch 1300\n",
      "-------------------------------\n",
      "loss: 0.353650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441683 \n",
      "\n",
      "Epoch 1301\n",
      "-------------------------------\n",
      "loss: 0.348700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442189 \n",
      "\n",
      "Epoch 1302\n",
      "-------------------------------\n",
      "loss: 0.349721  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442135 \n",
      "\n",
      "Epoch 1303\n",
      "-------------------------------\n",
      "loss: 0.347544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443290 \n",
      "\n",
      "Epoch 1304\n",
      "-------------------------------\n",
      "loss: 0.346164  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444464 \n",
      "\n",
      "Epoch 1305\n",
      "-------------------------------\n",
      "loss: 0.357560  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445606 \n",
      "\n",
      "Epoch 1306\n",
      "-------------------------------\n",
      "loss: 0.351768  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446363 \n",
      "\n",
      "Epoch 1307\n",
      "-------------------------------\n",
      "loss: 0.335982  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448151 \n",
      "\n",
      "Epoch 1308\n",
      "-------------------------------\n",
      "loss: 0.344677  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.448372 \n",
      "\n",
      "Epoch 1309\n",
      "-------------------------------\n",
      "loss: 0.357415  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447493 \n",
      "\n",
      "Epoch 1310\n",
      "-------------------------------\n",
      "loss: 0.354091  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445922 \n",
      "\n",
      "Epoch 1311\n",
      "-------------------------------\n",
      "loss: 0.342923  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444942 \n",
      "\n",
      "Epoch 1312\n",
      "-------------------------------\n",
      "loss: 0.334031  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444218 \n",
      "\n",
      "Epoch 1313\n",
      "-------------------------------\n",
      "loss: 0.345502  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442667 \n",
      "\n",
      "Epoch 1314\n",
      "-------------------------------\n",
      "loss: 0.349840  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442154 \n",
      "\n",
      "Epoch 1315\n",
      "-------------------------------\n",
      "loss: 0.340171  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441682 \n",
      "\n",
      "Epoch 1316\n",
      "-------------------------------\n",
      "loss: 0.344728  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442090 \n",
      "\n",
      "Epoch 1317\n",
      "-------------------------------\n",
      "loss: 0.341520  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443017 \n",
      "\n",
      "Epoch 1318\n",
      "-------------------------------\n",
      "loss: 0.344789  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442951 \n",
      "\n",
      "Epoch 1319\n",
      "-------------------------------\n",
      "loss: 0.335633  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444024 \n",
      "\n",
      "Epoch 1320\n",
      "-------------------------------\n",
      "loss: 0.345921  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445022 \n",
      "\n",
      "Epoch 1321\n",
      "-------------------------------\n",
      "loss: 0.346518  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445730 \n",
      "\n",
      "Epoch 1322\n",
      "-------------------------------\n",
      "loss: 0.346094  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444959 \n",
      "\n",
      "Epoch 1323\n",
      "-------------------------------\n",
      "loss: 0.346830  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445409 \n",
      "\n",
      "Epoch 1324\n",
      "-------------------------------\n",
      "loss: 0.347302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445201 \n",
      "\n",
      "Epoch 1325\n",
      "-------------------------------\n",
      "loss: 0.356227  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444381 \n",
      "\n",
      "Epoch 1326\n",
      "-------------------------------\n",
      "loss: 0.344118  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444026 \n",
      "\n",
      "Epoch 1327\n",
      "-------------------------------\n",
      "loss: 0.342835  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442999 \n",
      "\n",
      "Epoch 1328\n",
      "-------------------------------\n",
      "loss: 0.341442  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443099 \n",
      "\n",
      "Epoch 1329\n",
      "-------------------------------\n",
      "loss: 0.345649  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443351 \n",
      "\n",
      "Epoch 1330\n",
      "-------------------------------\n",
      "loss: 0.334247  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443725 \n",
      "\n",
      "Epoch 1331\n",
      "-------------------------------\n",
      "loss: 0.341949  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444078 \n",
      "\n",
      "Epoch 1332\n",
      "-------------------------------\n",
      "loss: 0.345767  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444454 \n",
      "\n",
      "Epoch 1333\n",
      "-------------------------------\n",
      "loss: 0.341533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443904 \n",
      "\n",
      "Epoch 1334\n",
      "-------------------------------\n",
      "loss: 0.343003  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443616 \n",
      "\n",
      "Epoch 1335\n",
      "-------------------------------\n",
      "loss: 0.349059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443463 \n",
      "\n",
      "Epoch 1336\n",
      "-------------------------------\n",
      "loss: 0.353851  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443111 \n",
      "\n",
      "Epoch 1337\n",
      "-------------------------------\n",
      "loss: 0.341188  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443018 \n",
      "\n",
      "Epoch 1338\n",
      "-------------------------------\n",
      "loss: 0.347595  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442525 \n",
      "\n",
      "Epoch 1339\n",
      "-------------------------------\n",
      "loss: 0.345026  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441794 \n",
      "\n",
      "Epoch 1340\n",
      "-------------------------------\n",
      "loss: 0.340898  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442306 \n",
      "\n",
      "Epoch 1341\n",
      "-------------------------------\n",
      "loss: 0.354343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442355 \n",
      "\n",
      "Epoch 1342\n",
      "-------------------------------\n",
      "loss: 0.347666  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442823 \n",
      "\n",
      "Epoch 1343\n",
      "-------------------------------\n",
      "loss: 0.344078  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442174 \n",
      "\n",
      "Epoch 1344\n",
      "-------------------------------\n",
      "loss: 0.349966  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442449 \n",
      "\n",
      "Epoch 1345\n",
      "-------------------------------\n",
      "loss: 0.346271  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442326 \n",
      "\n",
      "Epoch 1346\n",
      "-------------------------------\n",
      "loss: 0.343245  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443334 \n",
      "\n",
      "Epoch 1347\n",
      "-------------------------------\n",
      "loss: 0.348669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442824 \n",
      "\n",
      "Epoch 1348\n",
      "-------------------------------\n",
      "loss: 0.345175  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443235 \n",
      "\n",
      "Epoch 1349\n",
      "-------------------------------\n",
      "loss: 0.339279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443218 \n",
      "\n",
      "Epoch 1350\n",
      "-------------------------------\n",
      "loss: 0.343895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443126 \n",
      "\n",
      "Epoch 1351\n",
      "-------------------------------\n",
      "loss: 0.342912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442845 \n",
      "\n",
      "Epoch 1352\n",
      "-------------------------------\n",
      "loss: 0.339765  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442598 \n",
      "\n",
      "Epoch 1353\n",
      "-------------------------------\n",
      "loss: 0.332687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442958 \n",
      "\n",
      "Epoch 1354\n",
      "-------------------------------\n",
      "loss: 0.343320  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442803 \n",
      "\n",
      "Epoch 1355\n",
      "-------------------------------\n",
      "loss: 0.347695  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441672 \n",
      "\n",
      "Epoch 1356\n",
      "-------------------------------\n",
      "loss: 0.343668  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441845 \n",
      "\n",
      "Epoch 1357\n",
      "-------------------------------\n",
      "loss: 0.347708  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442470 \n",
      "\n",
      "Epoch 1358\n",
      "-------------------------------\n",
      "loss: 0.345726  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441391 \n",
      "\n",
      "Epoch 1359\n",
      "-------------------------------\n",
      "loss: 0.341031  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441313 \n",
      "\n",
      "Epoch 1360\n",
      "-------------------------------\n",
      "loss: 0.348029  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441560 \n",
      "\n",
      "Epoch 1361\n",
      "-------------------------------\n",
      "loss: 0.344085  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441840 \n",
      "\n",
      "Epoch 1362\n",
      "-------------------------------\n",
      "loss: 0.339448  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441981 \n",
      "\n",
      "Epoch 1363\n",
      "-------------------------------\n",
      "loss: 0.344102  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441369 \n",
      "\n",
      "Epoch 1364\n",
      "-------------------------------\n",
      "loss: 0.338863  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443233 \n",
      "\n",
      "Epoch 1365\n",
      "-------------------------------\n",
      "loss: 0.349459  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443389 \n",
      "\n",
      "Epoch 1366\n",
      "-------------------------------\n",
      "loss: 0.345613  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444166 \n",
      "\n",
      "Epoch 1367\n",
      "-------------------------------\n",
      "loss: 0.354469  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444238 \n",
      "\n",
      "Epoch 1368\n",
      "-------------------------------\n",
      "loss: 0.335029  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444845 \n",
      "\n",
      "Epoch 1369\n",
      "-------------------------------\n",
      "loss: 0.354293  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443987 \n",
      "\n",
      "Epoch 1370\n",
      "-------------------------------\n",
      "loss: 0.342037  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444629 \n",
      "\n",
      "Epoch 1371\n",
      "-------------------------------\n",
      "loss: 0.344690  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444281 \n",
      "\n",
      "Epoch 1372\n",
      "-------------------------------\n",
      "loss: 0.355224  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444124 \n",
      "\n",
      "Epoch 1373\n",
      "-------------------------------\n",
      "loss: 0.337097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443510 \n",
      "\n",
      "Epoch 1374\n",
      "-------------------------------\n",
      "loss: 0.342891  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444016 \n",
      "\n",
      "Epoch 1375\n",
      "-------------------------------\n",
      "loss: 0.344276  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444760 \n",
      "\n",
      "Epoch 1376\n",
      "-------------------------------\n",
      "loss: 0.349285  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445546 \n",
      "\n",
      "Epoch 1377\n",
      "-------------------------------\n",
      "loss: 0.341510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445680 \n",
      "\n",
      "Epoch 1378\n",
      "-------------------------------\n",
      "loss: 0.337089  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444813 \n",
      "\n",
      "Epoch 1379\n",
      "-------------------------------\n",
      "loss: 0.346180  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445438 \n",
      "\n",
      "Epoch 1380\n",
      "-------------------------------\n",
      "loss: 0.339585  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445556 \n",
      "\n",
      "Epoch 1381\n",
      "-------------------------------\n",
      "loss: 0.348290  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445194 \n",
      "\n",
      "Epoch 1382\n",
      "-------------------------------\n",
      "loss: 0.356371  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444225 \n",
      "\n",
      "Epoch 1383\n",
      "-------------------------------\n",
      "loss: 0.357760  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444396 \n",
      "\n",
      "Epoch 1384\n",
      "-------------------------------\n",
      "loss: 0.347056  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444150 \n",
      "\n",
      "Epoch 1385\n",
      "-------------------------------\n",
      "loss: 0.343658  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445332 \n",
      "\n",
      "Epoch 1386\n",
      "-------------------------------\n",
      "loss: 0.342766  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445967 \n",
      "\n",
      "Epoch 1387\n",
      "-------------------------------\n",
      "loss: 0.346025  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446821 \n",
      "\n",
      "Epoch 1388\n",
      "-------------------------------\n",
      "loss: 0.346088  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446700 \n",
      "\n",
      "Epoch 1389\n",
      "-------------------------------\n",
      "loss: 0.344940  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445937 \n",
      "\n",
      "Epoch 1390\n",
      "-------------------------------\n",
      "loss: 0.346461  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445334 \n",
      "\n",
      "Epoch 1391\n",
      "-------------------------------\n",
      "loss: 0.338613  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444436 \n",
      "\n",
      "Epoch 1392\n",
      "-------------------------------\n",
      "loss: 0.338038  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443531 \n",
      "\n",
      "Epoch 1393\n",
      "-------------------------------\n",
      "loss: 0.339500  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442822 \n",
      "\n",
      "Epoch 1394\n",
      "-------------------------------\n",
      "loss: 0.347042  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443118 \n",
      "\n",
      "Epoch 1395\n",
      "-------------------------------\n",
      "loss: 0.337987  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443486 \n",
      "\n",
      "Epoch 1396\n",
      "-------------------------------\n",
      "loss: 0.335083  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443675 \n",
      "\n",
      "Epoch 1397\n",
      "-------------------------------\n",
      "loss: 0.345310  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444719 \n",
      "\n",
      "Epoch 1398\n",
      "-------------------------------\n",
      "loss: 0.342802  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444893 \n",
      "\n",
      "Epoch 1399\n",
      "-------------------------------\n",
      "loss: 0.343623  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444932 \n",
      "\n",
      "Epoch 1400\n",
      "-------------------------------\n",
      "loss: 0.340484  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445449 \n",
      "\n",
      "Epoch 1401\n",
      "-------------------------------\n",
      "loss: 0.349403  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445222 \n",
      "\n",
      "Epoch 1402\n",
      "-------------------------------\n",
      "loss: 0.344050  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445565 \n",
      "\n",
      "Epoch 1403\n",
      "-------------------------------\n",
      "loss: 0.345008  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446049 \n",
      "\n",
      "Epoch 1404\n",
      "-------------------------------\n",
      "loss: 0.345659  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445959 \n",
      "\n",
      "Epoch 1405\n",
      "-------------------------------\n",
      "loss: 0.331414  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445634 \n",
      "\n",
      "Epoch 1406\n",
      "-------------------------------\n",
      "loss: 0.346638  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445005 \n",
      "\n",
      "Epoch 1407\n",
      "-------------------------------\n",
      "loss: 0.350067  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444142 \n",
      "\n",
      "Epoch 1408\n",
      "-------------------------------\n",
      "loss: 0.336305  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443555 \n",
      "\n",
      "Epoch 1409\n",
      "-------------------------------\n",
      "loss: 0.340835  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444214 \n",
      "\n",
      "Epoch 1410\n",
      "-------------------------------\n",
      "loss: 0.341448  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442837 \n",
      "\n",
      "Epoch 1411\n",
      "-------------------------------\n",
      "loss: 0.339806  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442921 \n",
      "\n",
      "Epoch 1412\n",
      "-------------------------------\n",
      "loss: 0.334422  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442985 \n",
      "\n",
      "Epoch 1413\n",
      "-------------------------------\n",
      "loss: 0.354329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444341 \n",
      "\n",
      "Epoch 1414\n",
      "-------------------------------\n",
      "loss: 0.341431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444743 \n",
      "\n",
      "Epoch 1415\n",
      "-------------------------------\n",
      "loss: 0.350777  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.444395 \n",
      "\n",
      "Epoch 1416\n",
      "-------------------------------\n",
      "loss: 0.343429  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445358 \n",
      "\n",
      "Epoch 1417\n",
      "-------------------------------\n",
      "loss: 0.340218  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444837 \n",
      "\n",
      "Epoch 1418\n",
      "-------------------------------\n",
      "loss: 0.340447  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444056 \n",
      "\n",
      "Epoch 1419\n",
      "-------------------------------\n",
      "loss: 0.342576  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443665 \n",
      "\n",
      "Epoch 1420\n",
      "-------------------------------\n",
      "loss: 0.348272  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443199 \n",
      "\n",
      "Epoch 1421\n",
      "-------------------------------\n",
      "loss: 0.347134  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442394 \n",
      "\n",
      "Epoch 1422\n",
      "-------------------------------\n",
      "loss: 0.336257  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441600 \n",
      "\n",
      "Epoch 1423\n",
      "-------------------------------\n",
      "loss: 0.349267  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441802 \n",
      "\n",
      "Epoch 1424\n",
      "-------------------------------\n",
      "loss: 0.345239  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443586 \n",
      "\n",
      "Epoch 1425\n",
      "-------------------------------\n",
      "loss: 0.346023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444015 \n",
      "\n",
      "Epoch 1426\n",
      "-------------------------------\n",
      "loss: 0.344838  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445056 \n",
      "\n",
      "Epoch 1427\n",
      "-------------------------------\n",
      "loss: 0.344037  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444943 \n",
      "\n",
      "Epoch 1428\n",
      "-------------------------------\n",
      "loss: 0.335683  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445319 \n",
      "\n",
      "Epoch 1429\n",
      "-------------------------------\n",
      "loss: 0.351125  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444638 \n",
      "\n",
      "Epoch 1430\n",
      "-------------------------------\n",
      "loss: 0.336956  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444391 \n",
      "\n",
      "Epoch 1431\n",
      "-------------------------------\n",
      "loss: 0.348813  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444794 \n",
      "\n",
      "Epoch 1432\n",
      "-------------------------------\n",
      "loss: 0.342578  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444943 \n",
      "\n",
      "Epoch 1433\n",
      "-------------------------------\n",
      "loss: 0.334072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443849 \n",
      "\n",
      "Epoch 1434\n",
      "-------------------------------\n",
      "loss: 0.334018  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443691 \n",
      "\n",
      "Epoch 1435\n",
      "-------------------------------\n",
      "loss: 0.330811  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444011 \n",
      "\n",
      "Epoch 1436\n",
      "-------------------------------\n",
      "loss: 0.334535  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444474 \n",
      "\n",
      "Epoch 1437\n",
      "-------------------------------\n",
      "loss: 0.334469  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444019 \n",
      "\n",
      "Epoch 1438\n",
      "-------------------------------\n",
      "loss: 0.349207  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443747 \n",
      "\n",
      "Epoch 1439\n",
      "-------------------------------\n",
      "loss: 0.349131  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443207 \n",
      "\n",
      "Epoch 1440\n",
      "-------------------------------\n",
      "loss: 0.341884  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443191 \n",
      "\n",
      "Epoch 1441\n",
      "-------------------------------\n",
      "loss: 0.346427  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443457 \n",
      "\n",
      "Epoch 1442\n",
      "-------------------------------\n",
      "loss: 0.350425  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443044 \n",
      "\n",
      "Epoch 1443\n",
      "-------------------------------\n",
      "loss: 0.342605  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443382 \n",
      "\n",
      "Epoch 1444\n",
      "-------------------------------\n",
      "loss: 0.338558  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443475 \n",
      "\n",
      "Epoch 1445\n",
      "-------------------------------\n",
      "loss: 0.338828  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444939 \n",
      "\n",
      "Epoch 1446\n",
      "-------------------------------\n",
      "loss: 0.340297  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444646 \n",
      "\n",
      "Epoch 1447\n",
      "-------------------------------\n",
      "loss: 0.341459  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443823 \n",
      "\n",
      "Epoch 1448\n",
      "-------------------------------\n",
      "loss: 0.335602  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442777 \n",
      "\n",
      "Epoch 1449\n",
      "-------------------------------\n",
      "loss: 0.338575  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443437 \n",
      "\n",
      "Epoch 1450\n",
      "-------------------------------\n",
      "loss: 0.336979  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443230 \n",
      "\n",
      "Epoch 1451\n",
      "-------------------------------\n",
      "loss: 0.347802  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443710 \n",
      "\n",
      "Epoch 1452\n",
      "-------------------------------\n",
      "loss: 0.340838  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442975 \n",
      "\n",
      "Epoch 1453\n",
      "-------------------------------\n",
      "loss: 0.341752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443041 \n",
      "\n",
      "Epoch 1454\n",
      "-------------------------------\n",
      "loss: 0.340765  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443370 \n",
      "\n",
      "Epoch 1455\n",
      "-------------------------------\n",
      "loss: 0.346272  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443910 \n",
      "\n",
      "Epoch 1456\n",
      "-------------------------------\n",
      "loss: 0.335892  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444272 \n",
      "\n",
      "Epoch 1457\n",
      "-------------------------------\n",
      "loss: 0.336686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444022 \n",
      "\n",
      "Epoch 1458\n",
      "-------------------------------\n",
      "loss: 0.342726  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444630 \n",
      "\n",
      "Epoch 1459\n",
      "-------------------------------\n",
      "loss: 0.339762  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444743 \n",
      "\n",
      "Epoch 1460\n",
      "-------------------------------\n",
      "loss: 0.339886  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444985 \n",
      "\n",
      "Epoch 1461\n",
      "-------------------------------\n",
      "loss: 0.341055  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444880 \n",
      "\n",
      "Epoch 1462\n",
      "-------------------------------\n",
      "loss: 0.345404  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445109 \n",
      "\n",
      "Epoch 1463\n",
      "-------------------------------\n",
      "loss: 0.346925  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443926 \n",
      "\n",
      "Epoch 1464\n",
      "-------------------------------\n",
      "loss: 0.333514  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442198 \n",
      "\n",
      "Epoch 1465\n",
      "-------------------------------\n",
      "loss: 0.342455  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441928 \n",
      "\n",
      "Epoch 1466\n",
      "-------------------------------\n",
      "loss: 0.339273  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442028 \n",
      "\n",
      "Epoch 1467\n",
      "-------------------------------\n",
      "loss: 0.345591  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442862 \n",
      "\n",
      "Epoch 1468\n",
      "-------------------------------\n",
      "loss: 0.341644  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443103 \n",
      "\n",
      "Epoch 1469\n",
      "-------------------------------\n",
      "loss: 0.343697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442910 \n",
      "\n",
      "Epoch 1470\n",
      "-------------------------------\n",
      "loss: 0.337957  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443187 \n",
      "\n",
      "Epoch 1471\n",
      "-------------------------------\n",
      "loss: 0.337377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442913 \n",
      "\n",
      "Epoch 1472\n",
      "-------------------------------\n",
      "loss: 0.335310  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442940 \n",
      "\n",
      "Epoch 1473\n",
      "-------------------------------\n",
      "loss: 0.342229  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443163 \n",
      "\n",
      "Epoch 1474\n",
      "-------------------------------\n",
      "loss: 0.340627  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443240 \n",
      "\n",
      "Epoch 1475\n",
      "-------------------------------\n",
      "loss: 0.341967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444185 \n",
      "\n",
      "Epoch 1476\n",
      "-------------------------------\n",
      "loss: 0.337356  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444070 \n",
      "\n",
      "Epoch 1477\n",
      "-------------------------------\n",
      "loss: 0.335948  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443009 \n",
      "\n",
      "Epoch 1478\n",
      "-------------------------------\n",
      "loss: 0.346358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442990 \n",
      "\n",
      "Epoch 1479\n",
      "-------------------------------\n",
      "loss: 0.341365  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442190 \n",
      "\n",
      "Epoch 1480\n",
      "-------------------------------\n",
      "loss: 0.349679  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441709 \n",
      "\n",
      "Epoch 1481\n",
      "-------------------------------\n",
      "loss: 0.347866  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441547 \n",
      "\n",
      "Epoch 1482\n",
      "-------------------------------\n",
      "loss: 0.349112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440974 \n",
      "\n",
      "Epoch 1483\n",
      "-------------------------------\n",
      "loss: 0.331673  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440931 \n",
      "\n",
      "Epoch 1484\n",
      "-------------------------------\n",
      "loss: 0.339889  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441388 \n",
      "\n",
      "Epoch 1485\n",
      "-------------------------------\n",
      "loss: 0.348175  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441425 \n",
      "\n",
      "Epoch 1486\n",
      "-------------------------------\n",
      "loss: 0.341213  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440215 \n",
      "\n",
      "Epoch 1487\n",
      "-------------------------------\n",
      "loss: 0.343097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440739 \n",
      "\n",
      "Epoch 1488\n",
      "-------------------------------\n",
      "loss: 0.344068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441131 \n",
      "\n",
      "Epoch 1489\n",
      "-------------------------------\n",
      "loss: 0.339191  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441034 \n",
      "\n",
      "Epoch 1490\n",
      "-------------------------------\n",
      "loss: 0.338122  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442156 \n",
      "\n",
      "Epoch 1491\n",
      "-------------------------------\n",
      "loss: 0.338617  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442944 \n",
      "\n",
      "Epoch 1492\n",
      "-------------------------------\n",
      "loss: 0.340056  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444146 \n",
      "\n",
      "Epoch 1493\n",
      "-------------------------------\n",
      "loss: 0.341511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444478 \n",
      "\n",
      "Epoch 1494\n",
      "-------------------------------\n",
      "loss: 0.342290  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445057 \n",
      "\n",
      "Epoch 1495\n",
      "-------------------------------\n",
      "loss: 0.336699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445132 \n",
      "\n",
      "Epoch 1496\n",
      "-------------------------------\n",
      "loss: 0.343900  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444929 \n",
      "\n",
      "Epoch 1497\n",
      "-------------------------------\n",
      "loss: 0.346416  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443606 \n",
      "\n",
      "Epoch 1498\n",
      "-------------------------------\n",
      "loss: 0.340698  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442781 \n",
      "\n",
      "Epoch 1499\n",
      "-------------------------------\n",
      "loss: 0.343154  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442374 \n",
      "\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "loss: 0.336336  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442986 \n",
      "\n",
      "Epoch 1501\n",
      "-------------------------------\n",
      "loss: 0.339320  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442987 \n",
      "\n",
      "Epoch 1502\n",
      "-------------------------------\n",
      "loss: 0.336727  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442571 \n",
      "\n",
      "Epoch 1503\n",
      "-------------------------------\n",
      "loss: 0.335992  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442333 \n",
      "\n",
      "Epoch 1504\n",
      "-------------------------------\n",
      "loss: 0.341823  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441526 \n",
      "\n",
      "Epoch 1505\n",
      "-------------------------------\n",
      "loss: 0.343364  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442176 \n",
      "\n",
      "Epoch 1506\n",
      "-------------------------------\n",
      "loss: 0.346499  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441881 \n",
      "\n",
      "Epoch 1507\n",
      "-------------------------------\n",
      "loss: 0.333351  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442005 \n",
      "\n",
      "Epoch 1508\n",
      "-------------------------------\n",
      "loss: 0.337631  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441671 \n",
      "\n",
      "Epoch 1509\n",
      "-------------------------------\n",
      "loss: 0.332469  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442416 \n",
      "\n",
      "Epoch 1510\n",
      "-------------------------------\n",
      "loss: 0.342092  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443060 \n",
      "\n",
      "Epoch 1511\n",
      "-------------------------------\n",
      "loss: 0.336894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441931 \n",
      "\n",
      "Epoch 1512\n",
      "-------------------------------\n",
      "loss: 0.326445  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442496 \n",
      "\n",
      "Epoch 1513\n",
      "-------------------------------\n",
      "loss: 0.339576  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441547 \n",
      "\n",
      "Epoch 1514\n",
      "-------------------------------\n",
      "loss: 0.338814  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440694 \n",
      "\n",
      "Epoch 1515\n",
      "-------------------------------\n",
      "loss: 0.335830  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441199 \n",
      "\n",
      "Epoch 1516\n",
      "-------------------------------\n",
      "loss: 0.337010  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442072 \n",
      "\n",
      "Epoch 1517\n",
      "-------------------------------\n",
      "loss: 0.335059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442888 \n",
      "\n",
      "Epoch 1518\n",
      "-------------------------------\n",
      "loss: 0.340520  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444615 \n",
      "\n",
      "Epoch 1519\n",
      "-------------------------------\n",
      "loss: 0.334584  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445175 \n",
      "\n",
      "Epoch 1520\n",
      "-------------------------------\n",
      "loss: 0.339650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444558 \n",
      "\n",
      "Epoch 1521\n",
      "-------------------------------\n",
      "loss: 0.338746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443501 \n",
      "\n",
      "Epoch 1522\n",
      "-------------------------------\n",
      "loss: 0.332108  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442288 \n",
      "\n",
      "Epoch 1523\n",
      "-------------------------------\n",
      "loss: 0.336610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443748 \n",
      "\n",
      "Epoch 1524\n",
      "-------------------------------\n",
      "loss: 0.330896  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443820 \n",
      "\n",
      "Epoch 1525\n",
      "-------------------------------\n",
      "loss: 0.336013  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444786 \n",
      "\n",
      "Epoch 1526\n",
      "-------------------------------\n",
      "loss: 0.339164  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444261 \n",
      "\n",
      "Epoch 1527\n",
      "-------------------------------\n",
      "loss: 0.335599  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444373 \n",
      "\n",
      "Epoch 1528\n",
      "-------------------------------\n",
      "loss: 0.343429  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444849 \n",
      "\n",
      "Epoch 1529\n",
      "-------------------------------\n",
      "loss: 0.338293  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445231 \n",
      "\n",
      "Epoch 1530\n",
      "-------------------------------\n",
      "loss: 0.332370  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445505 \n",
      "\n",
      "Epoch 1531\n",
      "-------------------------------\n",
      "loss: 0.335524  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445061 \n",
      "\n",
      "Epoch 1532\n",
      "-------------------------------\n",
      "loss: 0.332817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444920 \n",
      "\n",
      "Epoch 1533\n",
      "-------------------------------\n",
      "loss: 0.341494  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443931 \n",
      "\n",
      "Epoch 1534\n",
      "-------------------------------\n",
      "loss: 0.330229  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444005 \n",
      "\n",
      "Epoch 1535\n",
      "-------------------------------\n",
      "loss: 0.334708  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443912 \n",
      "\n",
      "Epoch 1536\n",
      "-------------------------------\n",
      "loss: 0.341009  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444280 \n",
      "\n",
      "Epoch 1537\n",
      "-------------------------------\n",
      "loss: 0.334054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443326 \n",
      "\n",
      "Epoch 1538\n",
      "-------------------------------\n",
      "loss: 0.335927  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443523 \n",
      "\n",
      "Epoch 1539\n",
      "-------------------------------\n",
      "loss: 0.333589  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442672 \n",
      "\n",
      "Epoch 1540\n",
      "-------------------------------\n",
      "loss: 0.341289  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442445 \n",
      "\n",
      "Epoch 1541\n",
      "-------------------------------\n",
      "loss: 0.342179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441774 \n",
      "\n",
      "Epoch 1542\n",
      "-------------------------------\n",
      "loss: 0.332032  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442168 \n",
      "\n",
      "Epoch 1543\n",
      "-------------------------------\n",
      "loss: 0.339337  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442206 \n",
      "\n",
      "Epoch 1544\n",
      "-------------------------------\n",
      "loss: 0.333380  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442748 \n",
      "\n",
      "Epoch 1545\n",
      "-------------------------------\n",
      "loss: 0.333793  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443101 \n",
      "\n",
      "Epoch 1546\n",
      "-------------------------------\n",
      "loss: 0.337982  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443208 \n",
      "\n",
      "Epoch 1547\n",
      "-------------------------------\n",
      "loss: 0.332093  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442743 \n",
      "\n",
      "Epoch 1548\n",
      "-------------------------------\n",
      "loss: 0.335276  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442658 \n",
      "\n",
      "Epoch 1549\n",
      "-------------------------------\n",
      "loss: 0.332238  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442778 \n",
      "\n",
      "Epoch 1550\n",
      "-------------------------------\n",
      "loss: 0.335382  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442405 \n",
      "\n",
      "Epoch 1551\n",
      "-------------------------------\n",
      "loss: 0.351301  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441782 \n",
      "\n",
      "Epoch 1552\n",
      "-------------------------------\n",
      "loss: 0.341861  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441927 \n",
      "\n",
      "Epoch 1553\n",
      "-------------------------------\n",
      "loss: 0.328156  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441060 \n",
      "\n",
      "Epoch 1554\n",
      "-------------------------------\n",
      "loss: 0.340124  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440801 \n",
      "\n",
      "Epoch 1555\n",
      "-------------------------------\n",
      "loss: 0.347377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440367 \n",
      "\n",
      "Epoch 1556\n",
      "-------------------------------\n",
      "loss: 0.339510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441116 \n",
      "\n",
      "Epoch 1557\n",
      "-------------------------------\n",
      "loss: 0.334959  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442003 \n",
      "\n",
      "Epoch 1558\n",
      "-------------------------------\n",
      "loss: 0.336231  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443256 \n",
      "\n",
      "Epoch 1559\n",
      "-------------------------------\n",
      "loss: 0.330521  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443866 \n",
      "\n",
      "Epoch 1560\n",
      "-------------------------------\n",
      "loss: 0.333541  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444512 \n",
      "\n",
      "Epoch 1561\n",
      "-------------------------------\n",
      "loss: 0.334506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445907 \n",
      "\n",
      "Epoch 1562\n",
      "-------------------------------\n",
      "loss: 0.340470  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445765 \n",
      "\n",
      "Epoch 1563\n",
      "-------------------------------\n",
      "loss: 0.340367  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445128 \n",
      "\n",
      "Epoch 1564\n",
      "-------------------------------\n",
      "loss: 0.339955  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444076 \n",
      "\n",
      "Epoch 1565\n",
      "-------------------------------\n",
      "loss: 0.338968  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444088 \n",
      "\n",
      "Epoch 1566\n",
      "-------------------------------\n",
      "loss: 0.335999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443487 \n",
      "\n",
      "Epoch 1567\n",
      "-------------------------------\n",
      "loss: 0.334073  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.444342 \n",
      "\n",
      "Epoch 1568\n",
      "-------------------------------\n",
      "loss: 0.330839  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443432 \n",
      "\n",
      "Epoch 1569\n",
      "-------------------------------\n",
      "loss: 0.337373  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442711 \n",
      "\n",
      "Epoch 1570\n",
      "-------------------------------\n",
      "loss: 0.332217  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442702 \n",
      "\n",
      "Epoch 1571\n",
      "-------------------------------\n",
      "loss: 0.341089  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443900 \n",
      "\n",
      "Epoch 1572\n",
      "-------------------------------\n",
      "loss: 0.334869  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444757 \n",
      "\n",
      "Epoch 1573\n",
      "-------------------------------\n",
      "loss: 0.334958  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444549 \n",
      "\n",
      "Epoch 1574\n",
      "-------------------------------\n",
      "loss: 0.340973  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443501 \n",
      "\n",
      "Epoch 1575\n",
      "-------------------------------\n",
      "loss: 0.345829  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442293 \n",
      "\n",
      "Epoch 1576\n",
      "-------------------------------\n",
      "loss: 0.333922  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441708 \n",
      "\n",
      "Epoch 1577\n",
      "-------------------------------\n",
      "loss: 0.331862  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441061 \n",
      "\n",
      "Epoch 1578\n",
      "-------------------------------\n",
      "loss: 0.337121  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440974 \n",
      "\n",
      "Epoch 1579\n",
      "-------------------------------\n",
      "loss: 0.345065  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440432 \n",
      "\n",
      "Epoch 1580\n",
      "-------------------------------\n",
      "loss: 0.336652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440664 \n",
      "\n",
      "Epoch 1581\n",
      "-------------------------------\n",
      "loss: 0.337887  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442660 \n",
      "\n",
      "Epoch 1582\n",
      "-------------------------------\n",
      "loss: 0.340494  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444957 \n",
      "\n",
      "Epoch 1583\n",
      "-------------------------------\n",
      "loss: 0.336098  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445424 \n",
      "\n",
      "Epoch 1584\n",
      "-------------------------------\n",
      "loss: 0.337657  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446074 \n",
      "\n",
      "Epoch 1585\n",
      "-------------------------------\n",
      "loss: 0.343039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444918 \n",
      "\n",
      "Epoch 1586\n",
      "-------------------------------\n",
      "loss: 0.331339  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443925 \n",
      "\n",
      "Epoch 1587\n",
      "-------------------------------\n",
      "loss: 0.340004  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442410 \n",
      "\n",
      "Epoch 1588\n",
      "-------------------------------\n",
      "loss: 0.337389  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441850 \n",
      "\n",
      "Epoch 1589\n",
      "-------------------------------\n",
      "loss: 0.342935  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442033 \n",
      "\n",
      "Epoch 1590\n",
      "-------------------------------\n",
      "loss: 0.330073  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441221 \n",
      "\n",
      "Epoch 1591\n",
      "-------------------------------\n",
      "loss: 0.340099  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442027 \n",
      "\n",
      "Epoch 1592\n",
      "-------------------------------\n",
      "loss: 0.337007  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442355 \n",
      "\n",
      "Epoch 1593\n",
      "-------------------------------\n",
      "loss: 0.335187  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443438 \n",
      "\n",
      "Epoch 1594\n",
      "-------------------------------\n",
      "loss: 0.327711  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443572 \n",
      "\n",
      "Epoch 1595\n",
      "-------------------------------\n",
      "loss: 0.340690  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443303 \n",
      "\n",
      "Epoch 1596\n",
      "-------------------------------\n",
      "loss: 0.336812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444004 \n",
      "\n",
      "Epoch 1597\n",
      "-------------------------------\n",
      "loss: 0.341262  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443791 \n",
      "\n",
      "Epoch 1598\n",
      "-------------------------------\n",
      "loss: 0.335886  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444558 \n",
      "\n",
      "Epoch 1599\n",
      "-------------------------------\n",
      "loss: 0.330093  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444552 \n",
      "\n",
      "Epoch 1600\n",
      "-------------------------------\n",
      "loss: 0.339497  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445783 \n",
      "\n",
      "Epoch 1601\n",
      "-------------------------------\n",
      "loss: 0.345128  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446615 \n",
      "\n",
      "Epoch 1602\n",
      "-------------------------------\n",
      "loss: 0.331650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446551 \n",
      "\n",
      "Epoch 1603\n",
      "-------------------------------\n",
      "loss: 0.327968  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446594 \n",
      "\n",
      "Epoch 1604\n",
      "-------------------------------\n",
      "loss: 0.339661  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446525 \n",
      "\n",
      "Epoch 1605\n",
      "-------------------------------\n",
      "loss: 0.336800  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445734 \n",
      "\n",
      "Epoch 1606\n",
      "-------------------------------\n",
      "loss: 0.338933  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443642 \n",
      "\n",
      "Epoch 1607\n",
      "-------------------------------\n",
      "loss: 0.333286  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442509 \n",
      "\n",
      "Epoch 1608\n",
      "-------------------------------\n",
      "loss: 0.336483  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442583 \n",
      "\n",
      "Epoch 1609\n",
      "-------------------------------\n",
      "loss: 0.333546  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442325 \n",
      "\n",
      "Epoch 1610\n",
      "-------------------------------\n",
      "loss: 0.337061  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441785 \n",
      "\n",
      "Epoch 1611\n",
      "-------------------------------\n",
      "loss: 0.333232  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441877 \n",
      "\n",
      "Epoch 1612\n",
      "-------------------------------\n",
      "loss: 0.335615  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442837 \n",
      "\n",
      "Epoch 1613\n",
      "-------------------------------\n",
      "loss: 0.335709  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442628 \n",
      "\n",
      "Epoch 1614\n",
      "-------------------------------\n",
      "loss: 0.331202  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442731 \n",
      "\n",
      "Epoch 1615\n",
      "-------------------------------\n",
      "loss: 0.337700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442995 \n",
      "\n",
      "Epoch 1616\n",
      "-------------------------------\n",
      "loss: 0.343506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442838 \n",
      "\n",
      "Epoch 1617\n",
      "-------------------------------\n",
      "loss: 0.337083  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443001 \n",
      "\n",
      "Epoch 1618\n",
      "-------------------------------\n",
      "loss: 0.337140  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442842 \n",
      "\n",
      "Epoch 1619\n",
      "-------------------------------\n",
      "loss: 0.327746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442808 \n",
      "\n",
      "Epoch 1620\n",
      "-------------------------------\n",
      "loss: 0.337852  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442583 \n",
      "\n",
      "Epoch 1621\n",
      "-------------------------------\n",
      "loss: 0.336098  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441277 \n",
      "\n",
      "Epoch 1622\n",
      "-------------------------------\n",
      "loss: 0.336168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441034 \n",
      "\n",
      "Epoch 1623\n",
      "-------------------------------\n",
      "loss: 0.337723  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440908 \n",
      "\n",
      "Epoch 1624\n",
      "-------------------------------\n",
      "loss: 0.336469  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442166 \n",
      "\n",
      "Epoch 1625\n",
      "-------------------------------\n",
      "loss: 0.336248  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443237 \n",
      "\n",
      "Epoch 1626\n",
      "-------------------------------\n",
      "loss: 0.325346  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443085 \n",
      "\n",
      "Epoch 1627\n",
      "-------------------------------\n",
      "loss: 0.332883  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442484 \n",
      "\n",
      "Epoch 1628\n",
      "-------------------------------\n",
      "loss: 0.337379  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442621 \n",
      "\n",
      "Epoch 1629\n",
      "-------------------------------\n",
      "loss: 0.338234  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442440 \n",
      "\n",
      "Epoch 1630\n",
      "-------------------------------\n",
      "loss: 0.333419  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441899 \n",
      "\n",
      "Epoch 1631\n",
      "-------------------------------\n",
      "loss: 0.331587  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442471 \n",
      "\n",
      "Epoch 1632\n",
      "-------------------------------\n",
      "loss: 0.335070  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442629 \n",
      "\n",
      "Epoch 1633\n",
      "-------------------------------\n",
      "loss: 0.333893  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442414 \n",
      "\n",
      "Epoch 1634\n",
      "-------------------------------\n",
      "loss: 0.338906  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442315 \n",
      "\n",
      "Epoch 1635\n",
      "-------------------------------\n",
      "loss: 0.330144  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442678 \n",
      "\n",
      "Epoch 1636\n",
      "-------------------------------\n",
      "loss: 0.343937  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442049 \n",
      "\n",
      "Epoch 1637\n",
      "-------------------------------\n",
      "loss: 0.337101  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442270 \n",
      "\n",
      "Epoch 1638\n",
      "-------------------------------\n",
      "loss: 0.336158  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440873 \n",
      "\n",
      "Epoch 1639\n",
      "-------------------------------\n",
      "loss: 0.339511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442251 \n",
      "\n",
      "Epoch 1640\n",
      "-------------------------------\n",
      "loss: 0.341770  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442499 \n",
      "\n",
      "Epoch 1641\n",
      "-------------------------------\n",
      "loss: 0.333469  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443640 \n",
      "\n",
      "Epoch 1642\n",
      "-------------------------------\n",
      "loss: 0.336701  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443544 \n",
      "\n",
      "Epoch 1643\n",
      "-------------------------------\n",
      "loss: 0.329946  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.444055 \n",
      "\n",
      "Epoch 1644\n",
      "-------------------------------\n",
      "loss: 0.343326  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443146 \n",
      "\n",
      "Epoch 1645\n",
      "-------------------------------\n",
      "loss: 0.339721  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442550 \n",
      "\n",
      "Epoch 1646\n",
      "-------------------------------\n",
      "loss: 0.329663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441277 \n",
      "\n",
      "Epoch 1647\n",
      "-------------------------------\n",
      "loss: 0.336513  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440239 \n",
      "\n",
      "Epoch 1648\n",
      "-------------------------------\n",
      "loss: 0.333817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439859 \n",
      "\n",
      "Epoch 1649\n",
      "-------------------------------\n",
      "loss: 0.336572  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439898 \n",
      "\n",
      "Epoch 1650\n",
      "-------------------------------\n",
      "loss: 0.334800  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440450 \n",
      "\n",
      "Epoch 1651\n",
      "-------------------------------\n",
      "loss: 0.334991  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440836 \n",
      "\n",
      "Epoch 1652\n",
      "-------------------------------\n",
      "loss: 0.334418  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441929 \n",
      "\n",
      "Epoch 1653\n",
      "-------------------------------\n",
      "loss: 0.343610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443252 \n",
      "\n",
      "Epoch 1654\n",
      "-------------------------------\n",
      "loss: 0.335412  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443166 \n",
      "\n",
      "Epoch 1655\n",
      "-------------------------------\n",
      "loss: 0.334780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445029 \n",
      "\n",
      "Epoch 1656\n",
      "-------------------------------\n",
      "loss: 0.330756  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444842 \n",
      "\n",
      "Epoch 1657\n",
      "-------------------------------\n",
      "loss: 0.344349  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444608 \n",
      "\n",
      "Epoch 1658\n",
      "-------------------------------\n",
      "loss: 0.337026  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443732 \n",
      "\n",
      "Epoch 1659\n",
      "-------------------------------\n",
      "loss: 0.333682  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442823 \n",
      "\n",
      "Epoch 1660\n",
      "-------------------------------\n",
      "loss: 0.334182  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442459 \n",
      "\n",
      "Epoch 1661\n",
      "-------------------------------\n",
      "loss: 0.326506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441223 \n",
      "\n",
      "Epoch 1662\n",
      "-------------------------------\n",
      "loss: 0.349101  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441500 \n",
      "\n",
      "Epoch 1663\n",
      "-------------------------------\n",
      "loss: 0.332095  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441426 \n",
      "\n",
      "Epoch 1664\n",
      "-------------------------------\n",
      "loss: 0.335506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442564 \n",
      "\n",
      "Epoch 1665\n",
      "-------------------------------\n",
      "loss: 0.336050  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443018 \n",
      "\n",
      "Epoch 1666\n",
      "-------------------------------\n",
      "loss: 0.336662  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443378 \n",
      "\n",
      "Epoch 1667\n",
      "-------------------------------\n",
      "loss: 0.333396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443003 \n",
      "\n",
      "Epoch 1668\n",
      "-------------------------------\n",
      "loss: 0.335238  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442089 \n",
      "\n",
      "Epoch 1669\n",
      "-------------------------------\n",
      "loss: 0.329103  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442229 \n",
      "\n",
      "Epoch 1670\n",
      "-------------------------------\n",
      "loss: 0.339607  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442354 \n",
      "\n",
      "Epoch 1671\n",
      "-------------------------------\n",
      "loss: 0.330007  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442487 \n",
      "\n",
      "Epoch 1672\n",
      "-------------------------------\n",
      "loss: 0.333474  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443047 \n",
      "\n",
      "Epoch 1673\n",
      "-------------------------------\n",
      "loss: 0.327982  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442998 \n",
      "\n",
      "Epoch 1674\n",
      "-------------------------------\n",
      "loss: 0.331139  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441693 \n",
      "\n",
      "Epoch 1675\n",
      "-------------------------------\n",
      "loss: 0.335128  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442155 \n",
      "\n",
      "Epoch 1676\n",
      "-------------------------------\n",
      "loss: 0.324919  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442241 \n",
      "\n",
      "Epoch 1677\n",
      "-------------------------------\n",
      "loss: 0.332408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442609 \n",
      "\n",
      "Epoch 1678\n",
      "-------------------------------\n",
      "loss: 0.342320  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441798 \n",
      "\n",
      "Epoch 1679\n",
      "-------------------------------\n",
      "loss: 0.340422  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441740 \n",
      "\n",
      "Epoch 1680\n",
      "-------------------------------\n",
      "loss: 0.328638  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442258 \n",
      "\n",
      "Epoch 1681\n",
      "-------------------------------\n",
      "loss: 0.333579  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441390 \n",
      "\n",
      "Epoch 1682\n",
      "-------------------------------\n",
      "loss: 0.339066  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441746 \n",
      "\n",
      "Epoch 1683\n",
      "-------------------------------\n",
      "loss: 0.338975  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442544 \n",
      "\n",
      "Epoch 1684\n",
      "-------------------------------\n",
      "loss: 0.335934  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443680 \n",
      "\n",
      "Epoch 1685\n",
      "-------------------------------\n",
      "loss: 0.333074  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443367 \n",
      "\n",
      "Epoch 1686\n",
      "-------------------------------\n",
      "loss: 0.330560  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443059 \n",
      "\n",
      "Epoch 1687\n",
      "-------------------------------\n",
      "loss: 0.337812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443373 \n",
      "\n",
      "Epoch 1688\n",
      "-------------------------------\n",
      "loss: 0.339366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443024 \n",
      "\n",
      "Epoch 1689\n",
      "-------------------------------\n",
      "loss: 0.337297  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442921 \n",
      "\n",
      "Epoch 1690\n",
      "-------------------------------\n",
      "loss: 0.336674  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441918 \n",
      "\n",
      "Epoch 1691\n",
      "-------------------------------\n",
      "loss: 0.337929  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442208 \n",
      "\n",
      "Epoch 1692\n",
      "-------------------------------\n",
      "loss: 0.332435  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442814 \n",
      "\n",
      "Epoch 1693\n",
      "-------------------------------\n",
      "loss: 0.340942  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442885 \n",
      "\n",
      "Epoch 1694\n",
      "-------------------------------\n",
      "loss: 0.329966  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443575 \n",
      "\n",
      "Epoch 1695\n",
      "-------------------------------\n",
      "loss: 0.330496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444458 \n",
      "\n",
      "Epoch 1696\n",
      "-------------------------------\n",
      "loss: 0.335113  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443973 \n",
      "\n",
      "Epoch 1697\n",
      "-------------------------------\n",
      "loss: 0.336013  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444908 \n",
      "\n",
      "Epoch 1698\n",
      "-------------------------------\n",
      "loss: 0.341154  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444835 \n",
      "\n",
      "Epoch 1699\n",
      "-------------------------------\n",
      "loss: 0.340433  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444022 \n",
      "\n",
      "Epoch 1700\n",
      "-------------------------------\n",
      "loss: 0.335956  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442955 \n",
      "\n",
      "Epoch 1701\n",
      "-------------------------------\n",
      "loss: 0.327499  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442933 \n",
      "\n",
      "Epoch 1702\n",
      "-------------------------------\n",
      "loss: 0.334167  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441886 \n",
      "\n",
      "Epoch 1703\n",
      "-------------------------------\n",
      "loss: 0.325079  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443354 \n",
      "\n",
      "Epoch 1704\n",
      "-------------------------------\n",
      "loss: 0.330085  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444114 \n",
      "\n",
      "Epoch 1705\n",
      "-------------------------------\n",
      "loss: 0.333267  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444028 \n",
      "\n",
      "Epoch 1706\n",
      "-------------------------------\n",
      "loss: 0.339900  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443091 \n",
      "\n",
      "Epoch 1707\n",
      "-------------------------------\n",
      "loss: 0.337401  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442519 \n",
      "\n",
      "Epoch 1708\n",
      "-------------------------------\n",
      "loss: 0.331195  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440937 \n",
      "\n",
      "Epoch 1709\n",
      "-------------------------------\n",
      "loss: 0.331600  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442510 \n",
      "\n",
      "Epoch 1710\n",
      "-------------------------------\n",
      "loss: 0.332190  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442787 \n",
      "\n",
      "Epoch 1711\n",
      "-------------------------------\n",
      "loss: 0.331783  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443586 \n",
      "\n",
      "Epoch 1712\n",
      "-------------------------------\n",
      "loss: 0.331982  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443454 \n",
      "\n",
      "Epoch 1713\n",
      "-------------------------------\n",
      "loss: 0.333637  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443595 \n",
      "\n",
      "Epoch 1714\n",
      "-------------------------------\n",
      "loss: 0.337556  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443096 \n",
      "\n",
      "Epoch 1715\n",
      "-------------------------------\n",
      "loss: 0.337139  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442392 \n",
      "\n",
      "Epoch 1716\n",
      "-------------------------------\n",
      "loss: 0.328040  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441715 \n",
      "\n",
      "Epoch 1717\n",
      "-------------------------------\n",
      "loss: 0.329358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442817 \n",
      "\n",
      "Epoch 1718\n",
      "-------------------------------\n",
      "loss: 0.336190  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443741 \n",
      "\n",
      "Epoch 1719\n",
      "-------------------------------\n",
      "loss: 0.333961  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.443770 \n",
      "\n",
      "Epoch 1720\n",
      "-------------------------------\n",
      "loss: 0.331845  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443360 \n",
      "\n",
      "Epoch 1721\n",
      "-------------------------------\n",
      "loss: 0.335669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443545 \n",
      "\n",
      "Epoch 1722\n",
      "-------------------------------\n",
      "loss: 0.324086  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443102 \n",
      "\n",
      "Epoch 1723\n",
      "-------------------------------\n",
      "loss: 0.331258  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442154 \n",
      "\n",
      "Epoch 1724\n",
      "-------------------------------\n",
      "loss: 0.333289  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442602 \n",
      "\n",
      "Epoch 1725\n",
      "-------------------------------\n",
      "loss: 0.331229  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442066 \n",
      "\n",
      "Epoch 1726\n",
      "-------------------------------\n",
      "loss: 0.326053  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441641 \n",
      "\n",
      "Epoch 1727\n",
      "-------------------------------\n",
      "loss: 0.334819  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441833 \n",
      "\n",
      "Epoch 1728\n",
      "-------------------------------\n",
      "loss: 0.337075  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441405 \n",
      "\n",
      "Epoch 1729\n",
      "-------------------------------\n",
      "loss: 0.334928  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440777 \n",
      "\n",
      "Epoch 1730\n",
      "-------------------------------\n",
      "loss: 0.332919  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440776 \n",
      "\n",
      "Epoch 1731\n",
      "-------------------------------\n",
      "loss: 0.331323  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441329 \n",
      "\n",
      "Epoch 1732\n",
      "-------------------------------\n",
      "loss: 0.331368  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440660 \n",
      "\n",
      "Epoch 1733\n",
      "-------------------------------\n",
      "loss: 0.328858  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440379 \n",
      "\n",
      "Epoch 1734\n",
      "-------------------------------\n",
      "loss: 0.335876  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440020 \n",
      "\n",
      "Epoch 1735\n",
      "-------------------------------\n",
      "loss: 0.333684  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440913 \n",
      "\n",
      "Epoch 1736\n",
      "-------------------------------\n",
      "loss: 0.324782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441502 \n",
      "\n",
      "Epoch 1737\n",
      "-------------------------------\n",
      "loss: 0.333349  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442830 \n",
      "\n",
      "Epoch 1738\n",
      "-------------------------------\n",
      "loss: 0.324884  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443506 \n",
      "\n",
      "Epoch 1739\n",
      "-------------------------------\n",
      "loss: 0.325771  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444236 \n",
      "\n",
      "Epoch 1740\n",
      "-------------------------------\n",
      "loss: 0.326859  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443979 \n",
      "\n",
      "Epoch 1741\n",
      "-------------------------------\n",
      "loss: 0.336993  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444553 \n",
      "\n",
      "Epoch 1742\n",
      "-------------------------------\n",
      "loss: 0.327885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443777 \n",
      "\n",
      "Epoch 1743\n",
      "-------------------------------\n",
      "loss: 0.334725  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442045 \n",
      "\n",
      "Epoch 1744\n",
      "-------------------------------\n",
      "loss: 0.331699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441883 \n",
      "\n",
      "Epoch 1745\n",
      "-------------------------------\n",
      "loss: 0.330538  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442653 \n",
      "\n",
      "Epoch 1746\n",
      "-------------------------------\n",
      "loss: 0.342806  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442281 \n",
      "\n",
      "Epoch 1747\n",
      "-------------------------------\n",
      "loss: 0.336535  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442475 \n",
      "\n",
      "Epoch 1748\n",
      "-------------------------------\n",
      "loss: 0.338015  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443374 \n",
      "\n",
      "Epoch 1749\n",
      "-------------------------------\n",
      "loss: 0.332995  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444037 \n",
      "\n",
      "Epoch 1750\n",
      "-------------------------------\n",
      "loss: 0.327634  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444870 \n",
      "\n",
      "Epoch 1751\n",
      "-------------------------------\n",
      "loss: 0.328036  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445354 \n",
      "\n",
      "Epoch 1752\n",
      "-------------------------------\n",
      "loss: 0.332429  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445141 \n",
      "\n",
      "Epoch 1753\n",
      "-------------------------------\n",
      "loss: 0.334821  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443497 \n",
      "\n",
      "Epoch 1754\n",
      "-------------------------------\n",
      "loss: 0.319220  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443320 \n",
      "\n",
      "Epoch 1755\n",
      "-------------------------------\n",
      "loss: 0.327126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443128 \n",
      "\n",
      "Epoch 1756\n",
      "-------------------------------\n",
      "loss: 0.328840  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441838 \n",
      "\n",
      "Epoch 1757\n",
      "-------------------------------\n",
      "loss: 0.335222  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441223 \n",
      "\n",
      "Epoch 1758\n",
      "-------------------------------\n",
      "loss: 0.324821  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442004 \n",
      "\n",
      "Epoch 1759\n",
      "-------------------------------\n",
      "loss: 0.333992  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442163 \n",
      "\n",
      "Epoch 1760\n",
      "-------------------------------\n",
      "loss: 0.329933  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443508 \n",
      "\n",
      "Epoch 1761\n",
      "-------------------------------\n",
      "loss: 0.335051  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443598 \n",
      "\n",
      "Epoch 1762\n",
      "-------------------------------\n",
      "loss: 0.339569  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443838 \n",
      "\n",
      "Epoch 1763\n",
      "-------------------------------\n",
      "loss: 0.328068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444127 \n",
      "\n",
      "Epoch 1764\n",
      "-------------------------------\n",
      "loss: 0.326537  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444335 \n",
      "\n",
      "Epoch 1765\n",
      "-------------------------------\n",
      "loss: 0.330623  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444374 \n",
      "\n",
      "Epoch 1766\n",
      "-------------------------------\n",
      "loss: 0.334487  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442995 \n",
      "\n",
      "Epoch 1767\n",
      "-------------------------------\n",
      "loss: 0.333045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442966 \n",
      "\n",
      "Epoch 1768\n",
      "-------------------------------\n",
      "loss: 0.328790  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442742 \n",
      "\n",
      "Epoch 1769\n",
      "-------------------------------\n",
      "loss: 0.335305  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442342 \n",
      "\n",
      "Epoch 1770\n",
      "-------------------------------\n",
      "loss: 0.337586  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442088 \n",
      "\n",
      "Epoch 1771\n",
      "-------------------------------\n",
      "loss: 0.331374  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442443 \n",
      "\n",
      "Epoch 1772\n",
      "-------------------------------\n",
      "loss: 0.327729  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442542 \n",
      "\n",
      "Epoch 1773\n",
      "-------------------------------\n",
      "loss: 0.333809  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442525 \n",
      "\n",
      "Epoch 1774\n",
      "-------------------------------\n",
      "loss: 0.334358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441879 \n",
      "\n",
      "Epoch 1775\n",
      "-------------------------------\n",
      "loss: 0.325870  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441815 \n",
      "\n",
      "Epoch 1776\n",
      "-------------------------------\n",
      "loss: 0.336771  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441537 \n",
      "\n",
      "Epoch 1777\n",
      "-------------------------------\n",
      "loss: 0.336454  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442133 \n",
      "\n",
      "Epoch 1778\n",
      "-------------------------------\n",
      "loss: 0.324254  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442038 \n",
      "\n",
      "Epoch 1779\n",
      "-------------------------------\n",
      "loss: 0.331072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441801 \n",
      "\n",
      "Epoch 1780\n",
      "-------------------------------\n",
      "loss: 0.323394  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442620 \n",
      "\n",
      "Epoch 1781\n",
      "-------------------------------\n",
      "loss: 0.321068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442816 \n",
      "\n",
      "Epoch 1782\n",
      "-------------------------------\n",
      "loss: 0.323926  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443393 \n",
      "\n",
      "Epoch 1783\n",
      "-------------------------------\n",
      "loss: 0.329417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443454 \n",
      "\n",
      "Epoch 1784\n",
      "-------------------------------\n",
      "loss: 0.328510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443678 \n",
      "\n",
      "Epoch 1785\n",
      "-------------------------------\n",
      "loss: 0.323948  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443973 \n",
      "\n",
      "Epoch 1786\n",
      "-------------------------------\n",
      "loss: 0.326439  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444419 \n",
      "\n",
      "Epoch 1787\n",
      "-------------------------------\n",
      "loss: 0.335973  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442913 \n",
      "\n",
      "Epoch 1788\n",
      "-------------------------------\n",
      "loss: 0.333384  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442479 \n",
      "\n",
      "Epoch 1789\n",
      "-------------------------------\n",
      "loss: 0.317913  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442420 \n",
      "\n",
      "Epoch 1790\n",
      "-------------------------------\n",
      "loss: 0.341699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442351 \n",
      "\n",
      "Epoch 1791\n",
      "-------------------------------\n",
      "loss: 0.332062  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442708 \n",
      "\n",
      "Epoch 1792\n",
      "-------------------------------\n",
      "loss: 0.330977  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442271 \n",
      "\n",
      "Epoch 1793\n",
      "-------------------------------\n",
      "loss: 0.341373  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442291 \n",
      "\n",
      "Epoch 1794\n",
      "-------------------------------\n",
      "loss: 0.341580  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441946 \n",
      "\n",
      "Epoch 1795\n",
      "-------------------------------\n",
      "loss: 0.328940  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442081 \n",
      "\n",
      "Epoch 1796\n",
      "-------------------------------\n",
      "loss: 0.331054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442614 \n",
      "\n",
      "Epoch 1797\n",
      "-------------------------------\n",
      "loss: 0.330641  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443469 \n",
      "\n",
      "Epoch 1798\n",
      "-------------------------------\n",
      "loss: 0.338543  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443249 \n",
      "\n",
      "Epoch 1799\n",
      "-------------------------------\n",
      "loss: 0.336186  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442804 \n",
      "\n",
      "Epoch 1800\n",
      "-------------------------------\n",
      "loss: 0.331174  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441489 \n",
      "\n",
      "Epoch 1801\n",
      "-------------------------------\n",
      "loss: 0.328843  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440947 \n",
      "\n",
      "Epoch 1802\n",
      "-------------------------------\n",
      "loss: 0.328693  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440031 \n",
      "\n",
      "Epoch 1803\n",
      "-------------------------------\n",
      "loss: 0.323403  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440906 \n",
      "\n",
      "Epoch 1804\n",
      "-------------------------------\n",
      "loss: 0.328118  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440380 \n",
      "\n",
      "Epoch 1805\n",
      "-------------------------------\n",
      "loss: 0.341245  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441301 \n",
      "\n",
      "Epoch 1806\n",
      "-------------------------------\n",
      "loss: 0.332597  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442035 \n",
      "\n",
      "Epoch 1807\n",
      "-------------------------------\n",
      "loss: 0.322959  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442359 \n",
      "\n",
      "Epoch 1808\n",
      "-------------------------------\n",
      "loss: 0.331122  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443583 \n",
      "\n",
      "Epoch 1809\n",
      "-------------------------------\n",
      "loss: 0.327090  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444691 \n",
      "\n",
      "Epoch 1810\n",
      "-------------------------------\n",
      "loss: 0.321882  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444161 \n",
      "\n",
      "Epoch 1811\n",
      "-------------------------------\n",
      "loss: 0.332631  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444251 \n",
      "\n",
      "Epoch 1812\n",
      "-------------------------------\n",
      "loss: 0.328637  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443357 \n",
      "\n",
      "Epoch 1813\n",
      "-------------------------------\n",
      "loss: 0.339356  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442269 \n",
      "\n",
      "Epoch 1814\n",
      "-------------------------------\n",
      "loss: 0.335713  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440818 \n",
      "\n",
      "Epoch 1815\n",
      "-------------------------------\n",
      "loss: 0.334672  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441252 \n",
      "\n",
      "Epoch 1816\n",
      "-------------------------------\n",
      "loss: 0.328380  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440800 \n",
      "\n",
      "Epoch 1817\n",
      "-------------------------------\n",
      "loss: 0.326203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441530 \n",
      "\n",
      "Epoch 1818\n",
      "-------------------------------\n",
      "loss: 0.334784  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442318 \n",
      "\n",
      "Epoch 1819\n",
      "-------------------------------\n",
      "loss: 0.322653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442625 \n",
      "\n",
      "Epoch 1820\n",
      "-------------------------------\n",
      "loss: 0.339549  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443883 \n",
      "\n",
      "Epoch 1821\n",
      "-------------------------------\n",
      "loss: 0.338112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444444 \n",
      "\n",
      "Epoch 1822\n",
      "-------------------------------\n",
      "loss: 0.336592  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443037 \n",
      "\n",
      "Epoch 1823\n",
      "-------------------------------\n",
      "loss: 0.330454  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442022 \n",
      "\n",
      "Epoch 1824\n",
      "-------------------------------\n",
      "loss: 0.335988  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442085 \n",
      "\n",
      "Epoch 1825\n",
      "-------------------------------\n",
      "loss: 0.329320  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442174 \n",
      "\n",
      "Epoch 1826\n",
      "-------------------------------\n",
      "loss: 0.329858  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441390 \n",
      "\n",
      "Epoch 1827\n",
      "-------------------------------\n",
      "loss: 0.336672  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442208 \n",
      "\n",
      "Epoch 1828\n",
      "-------------------------------\n",
      "loss: 0.330088  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441409 \n",
      "\n",
      "Epoch 1829\n",
      "-------------------------------\n",
      "loss: 0.333784  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441661 \n",
      "\n",
      "Epoch 1830\n",
      "-------------------------------\n",
      "loss: 0.334059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441893 \n",
      "\n",
      "Epoch 1831\n",
      "-------------------------------\n",
      "loss: 0.335624  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441701 \n",
      "\n",
      "Epoch 1832\n",
      "-------------------------------\n",
      "loss: 0.333360  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441044 \n",
      "\n",
      "Epoch 1833\n",
      "-------------------------------\n",
      "loss: 0.333567  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440224 \n",
      "\n",
      "Epoch 1834\n",
      "-------------------------------\n",
      "loss: 0.329043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441769 \n",
      "\n",
      "Epoch 1835\n",
      "-------------------------------\n",
      "loss: 0.325663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441725 \n",
      "\n",
      "Epoch 1836\n",
      "-------------------------------\n",
      "loss: 0.321640  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441634 \n",
      "\n",
      "Epoch 1837\n",
      "-------------------------------\n",
      "loss: 0.329863  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441985 \n",
      "\n",
      "Epoch 1838\n",
      "-------------------------------\n",
      "loss: 0.329894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443138 \n",
      "\n",
      "Epoch 1839\n",
      "-------------------------------\n",
      "loss: 0.327181  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443348 \n",
      "\n",
      "Epoch 1840\n",
      "-------------------------------\n",
      "loss: 0.329379  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443474 \n",
      "\n",
      "Epoch 1841\n",
      "-------------------------------\n",
      "loss: 0.323961  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443546 \n",
      "\n",
      "Epoch 1842\n",
      "-------------------------------\n",
      "loss: 0.333646  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443840 \n",
      "\n",
      "Epoch 1843\n",
      "-------------------------------\n",
      "loss: 0.329292  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443660 \n",
      "\n",
      "Epoch 1844\n",
      "-------------------------------\n",
      "loss: 0.336619  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443596 \n",
      "\n",
      "Epoch 1845\n",
      "-------------------------------\n",
      "loss: 0.343022  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442718 \n",
      "\n",
      "Epoch 1846\n",
      "-------------------------------\n",
      "loss: 0.325578  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442631 \n",
      "\n",
      "Epoch 1847\n",
      "-------------------------------\n",
      "loss: 0.329214  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441980 \n",
      "\n",
      "Epoch 1848\n",
      "-------------------------------\n",
      "loss: 0.328193  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441022 \n",
      "\n",
      "Epoch 1849\n",
      "-------------------------------\n",
      "loss: 0.334740  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440717 \n",
      "\n",
      "Epoch 1850\n",
      "-------------------------------\n",
      "loss: 0.332051  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441056 \n",
      "\n",
      "Epoch 1851\n",
      "-------------------------------\n",
      "loss: 0.339226  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440729 \n",
      "\n",
      "Epoch 1852\n",
      "-------------------------------\n",
      "loss: 0.331522  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440921 \n",
      "\n",
      "Epoch 1853\n",
      "-------------------------------\n",
      "loss: 0.336168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441185 \n",
      "\n",
      "Epoch 1854\n",
      "-------------------------------\n",
      "loss: 0.325151  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441441 \n",
      "\n",
      "Epoch 1855\n",
      "-------------------------------\n",
      "loss: 0.326172  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441150 \n",
      "\n",
      "Epoch 1856\n",
      "-------------------------------\n",
      "loss: 0.326119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441323 \n",
      "\n",
      "Epoch 1857\n",
      "-------------------------------\n",
      "loss: 0.331111  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440890 \n",
      "\n",
      "Epoch 1858\n",
      "-------------------------------\n",
      "loss: 0.331170  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441092 \n",
      "\n",
      "Epoch 1859\n",
      "-------------------------------\n",
      "loss: 0.327805  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441894 \n",
      "\n",
      "Epoch 1860\n",
      "-------------------------------\n",
      "loss: 0.324993  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442524 \n",
      "\n",
      "Epoch 1861\n",
      "-------------------------------\n",
      "loss: 0.320820  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444382 \n",
      "\n",
      "Epoch 1862\n",
      "-------------------------------\n",
      "loss: 0.335553  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444759 \n",
      "\n",
      "Epoch 1863\n",
      "-------------------------------\n",
      "loss: 0.329511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443994 \n",
      "\n",
      "Epoch 1864\n",
      "-------------------------------\n",
      "loss: 0.330183  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443289 \n",
      "\n",
      "Epoch 1865\n",
      "-------------------------------\n",
      "loss: 0.326386  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442040 \n",
      "\n",
      "Epoch 1866\n",
      "-------------------------------\n",
      "loss: 0.320472  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441747 \n",
      "\n",
      "Epoch 1867\n",
      "-------------------------------\n",
      "loss: 0.326745  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441775 \n",
      "\n",
      "Epoch 1868\n",
      "-------------------------------\n",
      "loss: 0.332342  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440765 \n",
      "\n",
      "Epoch 1869\n",
      "-------------------------------\n",
      "loss: 0.327004  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442017 \n",
      "\n",
      "Epoch 1870\n",
      "-------------------------------\n",
      "loss: 0.332135  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441795 \n",
      "\n",
      "Epoch 1871\n",
      "-------------------------------\n",
      "loss: 0.330974  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442745 \n",
      "\n",
      "Epoch 1872\n",
      "-------------------------------\n",
      "loss: 0.328065  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443347 \n",
      "\n",
      "Epoch 1873\n",
      "-------------------------------\n",
      "loss: 0.335657  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443997 \n",
      "\n",
      "Epoch 1874\n",
      "-------------------------------\n",
      "loss: 0.322993  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444937 \n",
      "\n",
      "Epoch 1875\n",
      "-------------------------------\n",
      "loss: 0.331163  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445108 \n",
      "\n",
      "Epoch 1876\n",
      "-------------------------------\n",
      "loss: 0.341344  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443350 \n",
      "\n",
      "Epoch 1877\n",
      "-------------------------------\n",
      "loss: 0.329878  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442186 \n",
      "\n",
      "Epoch 1878\n",
      "-------------------------------\n",
      "loss: 0.334022  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441058 \n",
      "\n",
      "Epoch 1879\n",
      "-------------------------------\n",
      "loss: 0.328112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440480 \n",
      "\n",
      "Epoch 1880\n",
      "-------------------------------\n",
      "loss: 0.337586  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439824 \n",
      "\n",
      "Epoch 1881\n",
      "-------------------------------\n",
      "loss: 0.328227  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439735 \n",
      "\n",
      "Epoch 1882\n",
      "-------------------------------\n",
      "loss: 0.336545  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439941 \n",
      "\n",
      "Epoch 1883\n",
      "-------------------------------\n",
      "loss: 0.338654  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440404 \n",
      "\n",
      "Epoch 1884\n",
      "-------------------------------\n",
      "loss: 0.331043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440266 \n",
      "\n",
      "Epoch 1885\n",
      "-------------------------------\n",
      "loss: 0.331007  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440914 \n",
      "\n",
      "Epoch 1886\n",
      "-------------------------------\n",
      "loss: 0.328606  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441090 \n",
      "\n",
      "Epoch 1887\n",
      "-------------------------------\n",
      "loss: 0.330346  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441147 \n",
      "\n",
      "Epoch 1888\n",
      "-------------------------------\n",
      "loss: 0.328191  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441332 \n",
      "\n",
      "Epoch 1889\n",
      "-------------------------------\n",
      "loss: 0.331822  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441881 \n",
      "\n",
      "Epoch 1890\n",
      "-------------------------------\n",
      "loss: 0.328769  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443245 \n",
      "\n",
      "Epoch 1891\n",
      "-------------------------------\n",
      "loss: 0.330636  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443888 \n",
      "\n",
      "Epoch 1892\n",
      "-------------------------------\n",
      "loss: 0.326342  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443055 \n",
      "\n",
      "Epoch 1893\n",
      "-------------------------------\n",
      "loss: 0.332261  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441980 \n",
      "\n",
      "Epoch 1894\n",
      "-------------------------------\n",
      "loss: 0.333821  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441522 \n",
      "\n",
      "Epoch 1895\n",
      "-------------------------------\n",
      "loss: 0.331517  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440817 \n",
      "\n",
      "Epoch 1896\n",
      "-------------------------------\n",
      "loss: 0.330140  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440736 \n",
      "\n",
      "Epoch 1897\n",
      "-------------------------------\n",
      "loss: 0.327517  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440898 \n",
      "\n",
      "Epoch 1898\n",
      "-------------------------------\n",
      "loss: 0.322974  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440938 \n",
      "\n",
      "Epoch 1899\n",
      "-------------------------------\n",
      "loss: 0.334634  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441547 \n",
      "\n",
      "Epoch 1900\n",
      "-------------------------------\n",
      "loss: 0.325500  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441768 \n",
      "\n",
      "Epoch 1901\n",
      "-------------------------------\n",
      "loss: 0.330488  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442912 \n",
      "\n",
      "Epoch 1902\n",
      "-------------------------------\n",
      "loss: 0.326105  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442135 \n",
      "\n",
      "Epoch 1903\n",
      "-------------------------------\n",
      "loss: 0.325374  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441367 \n",
      "\n",
      "Epoch 1904\n",
      "-------------------------------\n",
      "loss: 0.326820  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442572 \n",
      "\n",
      "Epoch 1905\n",
      "-------------------------------\n",
      "loss: 0.324411  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441726 \n",
      "\n",
      "Epoch 1906\n",
      "-------------------------------\n",
      "loss: 0.336677  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441386 \n",
      "\n",
      "Epoch 1907\n",
      "-------------------------------\n",
      "loss: 0.332911  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440551 \n",
      "\n",
      "Epoch 1908\n",
      "-------------------------------\n",
      "loss: 0.327640  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439534 \n",
      "\n",
      "Epoch 1909\n",
      "-------------------------------\n",
      "loss: 0.333272  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440242 \n",
      "\n",
      "Epoch 1910\n",
      "-------------------------------\n",
      "loss: 0.329181  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441587 \n",
      "\n",
      "Epoch 1911\n",
      "-------------------------------\n",
      "loss: 0.321613  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442548 \n",
      "\n",
      "Epoch 1912\n",
      "-------------------------------\n",
      "loss: 0.334374  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443055 \n",
      "\n",
      "Epoch 1913\n",
      "-------------------------------\n",
      "loss: 0.330034  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443267 \n",
      "\n",
      "Epoch 1914\n",
      "-------------------------------\n",
      "loss: 0.338912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442894 \n",
      "\n",
      "Epoch 1915\n",
      "-------------------------------\n",
      "loss: 0.327306  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443079 \n",
      "\n",
      "Epoch 1916\n",
      "-------------------------------\n",
      "loss: 0.338865  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443955 \n",
      "\n",
      "Epoch 1917\n",
      "-------------------------------\n",
      "loss: 0.337159  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444244 \n",
      "\n",
      "Epoch 1918\n",
      "-------------------------------\n",
      "loss: 0.335241  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444550 \n",
      "\n",
      "Epoch 1919\n",
      "-------------------------------\n",
      "loss: 0.336004  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445943 \n",
      "\n",
      "Epoch 1920\n",
      "-------------------------------\n",
      "loss: 0.336103  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445374 \n",
      "\n",
      "Epoch 1921\n",
      "-------------------------------\n",
      "loss: 0.337119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444974 \n",
      "\n",
      "Epoch 1922\n",
      "-------------------------------\n",
      "loss: 0.326187  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444349 \n",
      "\n",
      "Epoch 1923\n",
      "-------------------------------\n",
      "loss: 0.325288  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444220 \n",
      "\n",
      "Epoch 1924\n",
      "-------------------------------\n",
      "loss: 0.323992  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444221 \n",
      "\n",
      "Epoch 1925\n",
      "-------------------------------\n",
      "loss: 0.323329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445238 \n",
      "\n",
      "Epoch 1926\n",
      "-------------------------------\n",
      "loss: 0.323946  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444183 \n",
      "\n",
      "Epoch 1927\n",
      "-------------------------------\n",
      "loss: 0.336249  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444057 \n",
      "\n",
      "Epoch 1928\n",
      "-------------------------------\n",
      "loss: 0.328424  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442254 \n",
      "\n",
      "Epoch 1929\n",
      "-------------------------------\n",
      "loss: 0.334064  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441849 \n",
      "\n",
      "Epoch 1930\n",
      "-------------------------------\n",
      "loss: 0.332099  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442045 \n",
      "\n",
      "Epoch 1931\n",
      "-------------------------------\n",
      "loss: 0.327199  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441786 \n",
      "\n",
      "Epoch 1932\n",
      "-------------------------------\n",
      "loss: 0.331893  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442699 \n",
      "\n",
      "Epoch 1933\n",
      "-------------------------------\n",
      "loss: 0.333573  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442020 \n",
      "\n",
      "Epoch 1934\n",
      "-------------------------------\n",
      "loss: 0.340315  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441969 \n",
      "\n",
      "Epoch 1935\n",
      "-------------------------------\n",
      "loss: 0.326373  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441482 \n",
      "\n",
      "Epoch 1936\n",
      "-------------------------------\n",
      "loss: 0.326530  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442039 \n",
      "\n",
      "Epoch 1937\n",
      "-------------------------------\n",
      "loss: 0.328834  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443159 \n",
      "\n",
      "Epoch 1938\n",
      "-------------------------------\n",
      "loss: 0.324811  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443175 \n",
      "\n",
      "Epoch 1939\n",
      "-------------------------------\n",
      "loss: 0.326121  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443066 \n",
      "\n",
      "Epoch 1940\n",
      "-------------------------------\n",
      "loss: 0.328055  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442593 \n",
      "\n",
      "Epoch 1941\n",
      "-------------------------------\n",
      "loss: 0.328208  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442955 \n",
      "\n",
      "Epoch 1942\n",
      "-------------------------------\n",
      "loss: 0.326361  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442447 \n",
      "\n",
      "Epoch 1943\n",
      "-------------------------------\n",
      "loss: 0.327942  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441822 \n",
      "\n",
      "Epoch 1944\n",
      "-------------------------------\n",
      "loss: 0.331643  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440742 \n",
      "\n",
      "Epoch 1945\n",
      "-------------------------------\n",
      "loss: 0.334917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440015 \n",
      "\n",
      "Epoch 1946\n",
      "-------------------------------\n",
      "loss: 0.335216  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441038 \n",
      "\n",
      "Epoch 1947\n",
      "-------------------------------\n",
      "loss: 0.329999  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440820 \n",
      "\n",
      "Epoch 1948\n",
      "-------------------------------\n",
      "loss: 0.325451  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440957 \n",
      "\n",
      "Epoch 1949\n",
      "-------------------------------\n",
      "loss: 0.329168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441952 \n",
      "\n",
      "Epoch 1950\n",
      "-------------------------------\n",
      "loss: 0.325720  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442689 \n",
      "\n",
      "Epoch 1951\n",
      "-------------------------------\n",
      "loss: 0.326408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443356 \n",
      "\n",
      "Epoch 1952\n",
      "-------------------------------\n",
      "loss: 0.326983  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443273 \n",
      "\n",
      "Epoch 1953\n",
      "-------------------------------\n",
      "loss: 0.344743  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443776 \n",
      "\n",
      "Epoch 1954\n",
      "-------------------------------\n",
      "loss: 0.335081  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443791 \n",
      "\n",
      "Epoch 1955\n",
      "-------------------------------\n",
      "loss: 0.329464  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443387 \n",
      "\n",
      "Epoch 1956\n",
      "-------------------------------\n",
      "loss: 0.329443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442183 \n",
      "\n",
      "Epoch 1957\n",
      "-------------------------------\n",
      "loss: 0.334057  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441930 \n",
      "\n",
      "Epoch 1958\n",
      "-------------------------------\n",
      "loss: 0.337137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441945 \n",
      "\n",
      "Epoch 1959\n",
      "-------------------------------\n",
      "loss: 0.333239  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442169 \n",
      "\n",
      "Epoch 1960\n",
      "-------------------------------\n",
      "loss: 0.323898  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443879 \n",
      "\n",
      "Epoch 1961\n",
      "-------------------------------\n",
      "loss: 0.337557  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445250 \n",
      "\n",
      "Epoch 1962\n",
      "-------------------------------\n",
      "loss: 0.330635  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445028 \n",
      "\n",
      "Epoch 1963\n",
      "-------------------------------\n",
      "loss: 0.336646  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445532 \n",
      "\n",
      "Epoch 1964\n",
      "-------------------------------\n",
      "loss: 0.323486  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444208 \n",
      "\n",
      "Epoch 1965\n",
      "-------------------------------\n",
      "loss: 0.334603  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442767 \n",
      "\n",
      "Epoch 1966\n",
      "-------------------------------\n",
      "loss: 0.325031  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442453 \n",
      "\n",
      "Epoch 1967\n",
      "-------------------------------\n",
      "loss: 0.331498  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440201 \n",
      "\n",
      "Epoch 1968\n",
      "-------------------------------\n",
      "loss: 0.325233  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439739 \n",
      "\n",
      "Epoch 1969\n",
      "-------------------------------\n",
      "loss: 0.330404  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439621 \n",
      "\n",
      "Epoch 1970\n",
      "-------------------------------\n",
      "loss: 0.333346  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439523 \n",
      "\n",
      "Epoch 1971\n",
      "-------------------------------\n",
      "loss: 0.323575  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439973 \n",
      "\n",
      "Epoch 1972\n",
      "-------------------------------\n",
      "loss: 0.326011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439400 \n",
      "\n",
      "Epoch 1973\n",
      "-------------------------------\n",
      "loss: 0.328139  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440250 \n",
      "\n",
      "Epoch 1974\n",
      "-------------------------------\n",
      "loss: 0.324718  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440425 \n",
      "\n",
      "Epoch 1975\n",
      "-------------------------------\n",
      "loss: 0.325801  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440999 \n",
      "\n",
      "Epoch 1976\n",
      "-------------------------------\n",
      "loss: 0.328523  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442389 \n",
      "\n",
      "Epoch 1977\n",
      "-------------------------------\n",
      "loss: 0.321824  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443377 \n",
      "\n",
      "Epoch 1978\n",
      "-------------------------------\n",
      "loss: 0.319278  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442713 \n",
      "\n",
      "Epoch 1979\n",
      "-------------------------------\n",
      "loss: 0.320742  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443787 \n",
      "\n",
      "Epoch 1980\n",
      "-------------------------------\n",
      "loss: 0.333328  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442953 \n",
      "\n",
      "Epoch 1981\n",
      "-------------------------------\n",
      "loss: 0.331593  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443060 \n",
      "\n",
      "Epoch 1982\n",
      "-------------------------------\n",
      "loss: 0.331990  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442899 \n",
      "\n",
      "Epoch 1983\n",
      "-------------------------------\n",
      "loss: 0.325121  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442759 \n",
      "\n",
      "Epoch 1984\n",
      "-------------------------------\n",
      "loss: 0.329595  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442110 \n",
      "\n",
      "Epoch 1985\n",
      "-------------------------------\n",
      "loss: 0.326225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442245 \n",
      "\n",
      "Epoch 1986\n",
      "-------------------------------\n",
      "loss: 0.330993  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442378 \n",
      "\n",
      "Epoch 1987\n",
      "-------------------------------\n",
      "loss: 0.330151  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441462 \n",
      "\n",
      "Epoch 1988\n",
      "-------------------------------\n",
      "loss: 0.327715  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442273 \n",
      "\n",
      "Epoch 1989\n",
      "-------------------------------\n",
      "loss: 0.336670  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442021 \n",
      "\n",
      "Epoch 1990\n",
      "-------------------------------\n",
      "loss: 0.324897  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443370 \n",
      "\n",
      "Epoch 1991\n",
      "-------------------------------\n",
      "loss: 0.327789  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444616 \n",
      "\n",
      "Epoch 1992\n",
      "-------------------------------\n",
      "loss: 0.329803  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443828 \n",
      "\n",
      "Epoch 1993\n",
      "-------------------------------\n",
      "loss: 0.329421  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443144 \n",
      "\n",
      "Epoch 1994\n",
      "-------------------------------\n",
      "loss: 0.330168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442872 \n",
      "\n",
      "Epoch 1995\n",
      "-------------------------------\n",
      "loss: 0.321669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442271 \n",
      "\n",
      "Epoch 1996\n",
      "-------------------------------\n",
      "loss: 0.335687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442745 \n",
      "\n",
      "Epoch 1997\n",
      "-------------------------------\n",
      "loss: 0.327012  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442154 \n",
      "\n",
      "Epoch 1998\n",
      "-------------------------------\n",
      "loss: 0.326967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442772 \n",
      "\n",
      "Epoch 1999\n",
      "-------------------------------\n",
      "loss: 0.331510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443159 \n",
      "\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "loss: 0.330680  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442508 \n",
      "\n",
      "Epoch 2001\n",
      "-------------------------------\n",
      "loss: 0.325027  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442511 \n",
      "\n",
      "Epoch 2002\n",
      "-------------------------------\n",
      "loss: 0.325399  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442293 \n",
      "\n",
      "Epoch 2003\n",
      "-------------------------------\n",
      "loss: 0.327348  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441118 \n",
      "\n",
      "Epoch 2004\n",
      "-------------------------------\n",
      "loss: 0.323557  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441266 \n",
      "\n",
      "Epoch 2005\n",
      "-------------------------------\n",
      "loss: 0.325937  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440990 \n",
      "\n",
      "Epoch 2006\n",
      "-------------------------------\n",
      "loss: 0.333600  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441230 \n",
      "\n",
      "Epoch 2007\n",
      "-------------------------------\n",
      "loss: 0.321416  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440972 \n",
      "\n",
      "Epoch 2008\n",
      "-------------------------------\n",
      "loss: 0.330573  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440092 \n",
      "\n",
      "Epoch 2009\n",
      "-------------------------------\n",
      "loss: 0.320906  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441039 \n",
      "\n",
      "Epoch 2010\n",
      "-------------------------------\n",
      "loss: 0.321591  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441532 \n",
      "\n",
      "Epoch 2011\n",
      "-------------------------------\n",
      "loss: 0.331011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441351 \n",
      "\n",
      "Epoch 2012\n",
      "-------------------------------\n",
      "loss: 0.326649  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441504 \n",
      "\n",
      "Epoch 2013\n",
      "-------------------------------\n",
      "loss: 0.323183  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442567 \n",
      "\n",
      "Epoch 2014\n",
      "-------------------------------\n",
      "loss: 0.324966  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441906 \n",
      "\n",
      "Epoch 2015\n",
      "-------------------------------\n",
      "loss: 0.332357  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442898 \n",
      "\n",
      "Epoch 2016\n",
      "-------------------------------\n",
      "loss: 0.332538  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441911 \n",
      "\n",
      "Epoch 2017\n",
      "-------------------------------\n",
      "loss: 0.333095  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441107 \n",
      "\n",
      "Epoch 2018\n",
      "-------------------------------\n",
      "loss: 0.323929  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440742 \n",
      "\n",
      "Epoch 2019\n",
      "-------------------------------\n",
      "loss: 0.322923  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440470 \n",
      "\n",
      "Epoch 2020\n",
      "-------------------------------\n",
      "loss: 0.320645  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440294 \n",
      "\n",
      "Epoch 2021\n",
      "-------------------------------\n",
      "loss: 0.325213  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440812 \n",
      "\n",
      "Epoch 2022\n",
      "-------------------------------\n",
      "loss: 0.320885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440686 \n",
      "\n",
      "Epoch 2023\n",
      "-------------------------------\n",
      "loss: 0.331701  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.439991 \n",
      "\n",
      "Epoch 2024\n",
      "-------------------------------\n",
      "loss: 0.330725  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439629 \n",
      "\n",
      "Epoch 2025\n",
      "-------------------------------\n",
      "loss: 0.327725  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439396 \n",
      "\n",
      "Epoch 2026\n",
      "-------------------------------\n",
      "loss: 0.325525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440150 \n",
      "\n",
      "Epoch 2027\n",
      "-------------------------------\n",
      "loss: 0.324520  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439998 \n",
      "\n",
      "Epoch 2028\n",
      "-------------------------------\n",
      "loss: 0.326487  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439903 \n",
      "\n",
      "Epoch 2029\n",
      "-------------------------------\n",
      "loss: 0.331013  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440836 \n",
      "\n",
      "Epoch 2030\n",
      "-------------------------------\n",
      "loss: 0.320206  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441940 \n",
      "\n",
      "Epoch 2031\n",
      "-------------------------------\n",
      "loss: 0.327271  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442179 \n",
      "\n",
      "Epoch 2032\n",
      "-------------------------------\n",
      "loss: 0.328173  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442947 \n",
      "\n",
      "Epoch 2033\n",
      "-------------------------------\n",
      "loss: 0.323960  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443071 \n",
      "\n",
      "Epoch 2034\n",
      "-------------------------------\n",
      "loss: 0.329794  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442277 \n",
      "\n",
      "Epoch 2035\n",
      "-------------------------------\n",
      "loss: 0.329515  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441627 \n",
      "\n",
      "Epoch 2036\n",
      "-------------------------------\n",
      "loss: 0.322527  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441597 \n",
      "\n",
      "Epoch 2037\n",
      "-------------------------------\n",
      "loss: 0.322603  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441742 \n",
      "\n",
      "Epoch 2038\n",
      "-------------------------------\n",
      "loss: 0.327286  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442201 \n",
      "\n",
      "Epoch 2039\n",
      "-------------------------------\n",
      "loss: 0.330811  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442548 \n",
      "\n",
      "Epoch 2040\n",
      "-------------------------------\n",
      "loss: 0.325581  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442416 \n",
      "\n",
      "Epoch 2041\n",
      "-------------------------------\n",
      "loss: 0.327166  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443211 \n",
      "\n",
      "Epoch 2042\n",
      "-------------------------------\n",
      "loss: 0.325673  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442997 \n",
      "\n",
      "Epoch 2043\n",
      "-------------------------------\n",
      "loss: 0.319064  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442737 \n",
      "\n",
      "Epoch 2044\n",
      "-------------------------------\n",
      "loss: 0.322782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442910 \n",
      "\n",
      "Epoch 2045\n",
      "-------------------------------\n",
      "loss: 0.332510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442505 \n",
      "\n",
      "Epoch 2046\n",
      "-------------------------------\n",
      "loss: 0.327725  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441606 \n",
      "\n",
      "Epoch 2047\n",
      "-------------------------------\n",
      "loss: 0.333048  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441275 \n",
      "\n",
      "Epoch 2048\n",
      "-------------------------------\n",
      "loss: 0.330802  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441696 \n",
      "\n",
      "Epoch 2049\n",
      "-------------------------------\n",
      "loss: 0.320198  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442114 \n",
      "\n",
      "Epoch 2050\n",
      "-------------------------------\n",
      "loss: 0.322169  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441935 \n",
      "\n",
      "Epoch 2051\n",
      "-------------------------------\n",
      "loss: 0.331361  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441632 \n",
      "\n",
      "Epoch 2052\n",
      "-------------------------------\n",
      "loss: 0.331376  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442078 \n",
      "\n",
      "Epoch 2053\n",
      "-------------------------------\n",
      "loss: 0.321392  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442160 \n",
      "\n",
      "Epoch 2054\n",
      "-------------------------------\n",
      "loss: 0.332740  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442432 \n",
      "\n",
      "Epoch 2055\n",
      "-------------------------------\n",
      "loss: 0.328343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442465 \n",
      "\n",
      "Epoch 2056\n",
      "-------------------------------\n",
      "loss: 0.332666  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441109 \n",
      "\n",
      "Epoch 2057\n",
      "-------------------------------\n",
      "loss: 0.325922  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441735 \n",
      "\n",
      "Epoch 2058\n",
      "-------------------------------\n",
      "loss: 0.328181  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441852 \n",
      "\n",
      "Epoch 2059\n",
      "-------------------------------\n",
      "loss: 0.327024  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442792 \n",
      "\n",
      "Epoch 2060\n",
      "-------------------------------\n",
      "loss: 0.336027  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443278 \n",
      "\n",
      "Epoch 2061\n",
      "-------------------------------\n",
      "loss: 0.329920  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442926 \n",
      "\n",
      "Epoch 2062\n",
      "-------------------------------\n",
      "loss: 0.330215  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442632 \n",
      "\n",
      "Epoch 2063\n",
      "-------------------------------\n",
      "loss: 0.326613  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441201 \n",
      "\n",
      "Epoch 2064\n",
      "-------------------------------\n",
      "loss: 0.319815  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442497 \n",
      "\n",
      "Epoch 2065\n",
      "-------------------------------\n",
      "loss: 0.330018  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441550 \n",
      "\n",
      "Epoch 2066\n",
      "-------------------------------\n",
      "loss: 0.323530  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441585 \n",
      "\n",
      "Epoch 2067\n",
      "-------------------------------\n",
      "loss: 0.324388  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441889 \n",
      "\n",
      "Epoch 2068\n",
      "-------------------------------\n",
      "loss: 0.325771  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441578 \n",
      "\n",
      "Epoch 2069\n",
      "-------------------------------\n",
      "loss: 0.324643  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441964 \n",
      "\n",
      "Epoch 2070\n",
      "-------------------------------\n",
      "loss: 0.327823  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442927 \n",
      "\n",
      "Epoch 2071\n",
      "-------------------------------\n",
      "loss: 0.333570  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441774 \n",
      "\n",
      "Epoch 2072\n",
      "-------------------------------\n",
      "loss: 0.328309  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442522 \n",
      "\n",
      "Epoch 2073\n",
      "-------------------------------\n",
      "loss: 0.333209  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442486 \n",
      "\n",
      "Epoch 2074\n",
      "-------------------------------\n",
      "loss: 0.312034  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441709 \n",
      "\n",
      "Epoch 2075\n",
      "-------------------------------\n",
      "loss: 0.324614  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440577 \n",
      "\n",
      "Epoch 2076\n",
      "-------------------------------\n",
      "loss: 0.329831  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439673 \n",
      "\n",
      "Epoch 2077\n",
      "-------------------------------\n",
      "loss: 0.322655  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439512 \n",
      "\n",
      "Epoch 2078\n",
      "-------------------------------\n",
      "loss: 0.329302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439902 \n",
      "\n",
      "Epoch 2079\n",
      "-------------------------------\n",
      "loss: 0.333443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440358 \n",
      "\n",
      "Epoch 2080\n",
      "-------------------------------\n",
      "loss: 0.330781  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441215 \n",
      "\n",
      "Epoch 2081\n",
      "-------------------------------\n",
      "loss: 0.325948  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441304 \n",
      "\n",
      "Epoch 2082\n",
      "-------------------------------\n",
      "loss: 0.329652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440688 \n",
      "\n",
      "Epoch 2083\n",
      "-------------------------------\n",
      "loss: 0.323839  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441685 \n",
      "\n",
      "Epoch 2084\n",
      "-------------------------------\n",
      "loss: 0.322736  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442385 \n",
      "\n",
      "Epoch 2085\n",
      "-------------------------------\n",
      "loss: 0.325119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444339 \n",
      "\n",
      "Epoch 2086\n",
      "-------------------------------\n",
      "loss: 0.324454  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446509 \n",
      "\n",
      "Epoch 2087\n",
      "-------------------------------\n",
      "loss: 0.332115  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446125 \n",
      "\n",
      "Epoch 2088\n",
      "-------------------------------\n",
      "loss: 0.315348  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444867 \n",
      "\n",
      "Epoch 2089\n",
      "-------------------------------\n",
      "loss: 0.332504  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443517 \n",
      "\n",
      "Epoch 2090\n",
      "-------------------------------\n",
      "loss: 0.322876  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441392 \n",
      "\n",
      "Epoch 2091\n",
      "-------------------------------\n",
      "loss: 0.320297  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440379 \n",
      "\n",
      "Epoch 2092\n",
      "-------------------------------\n",
      "loss: 0.320494  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440598 \n",
      "\n",
      "Epoch 2093\n",
      "-------------------------------\n",
      "loss: 0.328553  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440702 \n",
      "\n",
      "Epoch 2094\n",
      "-------------------------------\n",
      "loss: 0.325654  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440614 \n",
      "\n",
      "Epoch 2095\n",
      "-------------------------------\n",
      "loss: 0.326614  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442086 \n",
      "\n",
      "Epoch 2096\n",
      "-------------------------------\n",
      "loss: 0.324930  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441842 \n",
      "\n",
      "Epoch 2097\n",
      "-------------------------------\n",
      "loss: 0.316623  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443838 \n",
      "\n",
      "Epoch 2098\n",
      "-------------------------------\n",
      "loss: 0.321263  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444857 \n",
      "\n",
      "Epoch 2099\n",
      "-------------------------------\n",
      "loss: 0.329035  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.446071 \n",
      "\n",
      "Epoch 2100\n",
      "-------------------------------\n",
      "loss: 0.323064  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445155 \n",
      "\n",
      "Epoch 2101\n",
      "-------------------------------\n",
      "loss: 0.325318  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442993 \n",
      "\n",
      "Epoch 2102\n",
      "-------------------------------\n",
      "loss: 0.315938  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442228 \n",
      "\n",
      "Epoch 2103\n",
      "-------------------------------\n",
      "loss: 0.324901  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441243 \n",
      "\n",
      "Epoch 2104\n",
      "-------------------------------\n",
      "loss: 0.329607  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441549 \n",
      "\n",
      "Epoch 2105\n",
      "-------------------------------\n",
      "loss: 0.325752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441264 \n",
      "\n",
      "Epoch 2106\n",
      "-------------------------------\n",
      "loss: 0.332909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441585 \n",
      "\n",
      "Epoch 2107\n",
      "-------------------------------\n",
      "loss: 0.333164  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440800 \n",
      "\n",
      "Epoch 2108\n",
      "-------------------------------\n",
      "loss: 0.326477  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442362 \n",
      "\n",
      "Epoch 2109\n",
      "-------------------------------\n",
      "loss: 0.322012  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441886 \n",
      "\n",
      "Epoch 2110\n",
      "-------------------------------\n",
      "loss: 0.329642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442442 \n",
      "\n",
      "Epoch 2111\n",
      "-------------------------------\n",
      "loss: 0.332756  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442950 \n",
      "\n",
      "Epoch 2112\n",
      "-------------------------------\n",
      "loss: 0.329445  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441829 \n",
      "\n",
      "Epoch 2113\n",
      "-------------------------------\n",
      "loss: 0.318093  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442372 \n",
      "\n",
      "Epoch 2114\n",
      "-------------------------------\n",
      "loss: 0.321791  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443374 \n",
      "\n",
      "Epoch 2115\n",
      "-------------------------------\n",
      "loss: 0.321150  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443150 \n",
      "\n",
      "Epoch 2116\n",
      "-------------------------------\n",
      "loss: 0.325868  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443568 \n",
      "\n",
      "Epoch 2117\n",
      "-------------------------------\n",
      "loss: 0.319584  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443329 \n",
      "\n",
      "Epoch 2118\n",
      "-------------------------------\n",
      "loss: 0.316594  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444105 \n",
      "\n",
      "Epoch 2119\n",
      "-------------------------------\n",
      "loss: 0.323511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443598 \n",
      "\n",
      "Epoch 2120\n",
      "-------------------------------\n",
      "loss: 0.324329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443062 \n",
      "\n",
      "Epoch 2121\n",
      "-------------------------------\n",
      "loss: 0.325999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442643 \n",
      "\n",
      "Epoch 2122\n",
      "-------------------------------\n",
      "loss: 0.325415  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442069 \n",
      "\n",
      "Epoch 2123\n",
      "-------------------------------\n",
      "loss: 0.323372  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441160 \n",
      "\n",
      "Epoch 2124\n",
      "-------------------------------\n",
      "loss: 0.325746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441066 \n",
      "\n",
      "Epoch 2125\n",
      "-------------------------------\n",
      "loss: 0.324045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440539 \n",
      "\n",
      "Epoch 2126\n",
      "-------------------------------\n",
      "loss: 0.330804  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440080 \n",
      "\n",
      "Epoch 2127\n",
      "-------------------------------\n",
      "loss: 0.322107  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439879 \n",
      "\n",
      "Epoch 2128\n",
      "-------------------------------\n",
      "loss: 0.327918  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440409 \n",
      "\n",
      "Epoch 2129\n",
      "-------------------------------\n",
      "loss: 0.331556  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441135 \n",
      "\n",
      "Epoch 2130\n",
      "-------------------------------\n",
      "loss: 0.319259  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441117 \n",
      "\n",
      "Epoch 2131\n",
      "-------------------------------\n",
      "loss: 0.337261  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440987 \n",
      "\n",
      "Epoch 2132\n",
      "-------------------------------\n",
      "loss: 0.318098  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441254 \n",
      "\n",
      "Epoch 2133\n",
      "-------------------------------\n",
      "loss: 0.327321  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442368 \n",
      "\n",
      "Epoch 2134\n",
      "-------------------------------\n",
      "loss: 0.319310  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442493 \n",
      "\n",
      "Epoch 2135\n",
      "-------------------------------\n",
      "loss: 0.323214  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442497 \n",
      "\n",
      "Epoch 2136\n",
      "-------------------------------\n",
      "loss: 0.321956  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441342 \n",
      "\n",
      "Epoch 2137\n",
      "-------------------------------\n",
      "loss: 0.324871  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441620 \n",
      "\n",
      "Epoch 2138\n",
      "-------------------------------\n",
      "loss: 0.319849  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440919 \n",
      "\n",
      "Epoch 2139\n",
      "-------------------------------\n",
      "loss: 0.324051  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441188 \n",
      "\n",
      "Epoch 2140\n",
      "-------------------------------\n",
      "loss: 0.326086  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439783 \n",
      "\n",
      "Epoch 2141\n",
      "-------------------------------\n",
      "loss: 0.323197  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440668 \n",
      "\n",
      "Epoch 2142\n",
      "-------------------------------\n",
      "loss: 0.326005  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440886 \n",
      "\n",
      "Epoch 2143\n",
      "-------------------------------\n",
      "loss: 0.335895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440604 \n",
      "\n",
      "Epoch 2144\n",
      "-------------------------------\n",
      "loss: 0.326104  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441556 \n",
      "\n",
      "Epoch 2145\n",
      "-------------------------------\n",
      "loss: 0.326228  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441146 \n",
      "\n",
      "Epoch 2146\n",
      "-------------------------------\n",
      "loss: 0.326476  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441764 \n",
      "\n",
      "Epoch 2147\n",
      "-------------------------------\n",
      "loss: 0.324549  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441466 \n",
      "\n",
      "Epoch 2148\n",
      "-------------------------------\n",
      "loss: 0.320676  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442479 \n",
      "\n",
      "Epoch 2149\n",
      "-------------------------------\n",
      "loss: 0.333356  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442421 \n",
      "\n",
      "Epoch 2150\n",
      "-------------------------------\n",
      "loss: 0.329496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441875 \n",
      "\n",
      "Epoch 2151\n",
      "-------------------------------\n",
      "loss: 0.330890  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442308 \n",
      "\n",
      "Epoch 2152\n",
      "-------------------------------\n",
      "loss: 0.324625  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442106 \n",
      "\n",
      "Epoch 2153\n",
      "-------------------------------\n",
      "loss: 0.320066  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442174 \n",
      "\n",
      "Epoch 2154\n",
      "-------------------------------\n",
      "loss: 0.332911  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442061 \n",
      "\n",
      "Epoch 2155\n",
      "-------------------------------\n",
      "loss: 0.328299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441910 \n",
      "\n",
      "Epoch 2156\n",
      "-------------------------------\n",
      "loss: 0.324358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441912 \n",
      "\n",
      "Epoch 2157\n",
      "-------------------------------\n",
      "loss: 0.326960  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442857 \n",
      "\n",
      "Epoch 2158\n",
      "-------------------------------\n",
      "loss: 0.319089  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442504 \n",
      "\n",
      "Epoch 2159\n",
      "-------------------------------\n",
      "loss: 0.321747  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443629 \n",
      "\n",
      "Epoch 2160\n",
      "-------------------------------\n",
      "loss: 0.321035  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442286 \n",
      "\n",
      "Epoch 2161\n",
      "-------------------------------\n",
      "loss: 0.322459  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441834 \n",
      "\n",
      "Epoch 2162\n",
      "-------------------------------\n",
      "loss: 0.325372  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442131 \n",
      "\n",
      "Epoch 2163\n",
      "-------------------------------\n",
      "loss: 0.328022  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441786 \n",
      "\n",
      "Epoch 2164\n",
      "-------------------------------\n",
      "loss: 0.316567  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441528 \n",
      "\n",
      "Epoch 2165\n",
      "-------------------------------\n",
      "loss: 0.320974  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441386 \n",
      "\n",
      "Epoch 2166\n",
      "-------------------------------\n",
      "loss: 0.322939  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440918 \n",
      "\n",
      "Epoch 2167\n",
      "-------------------------------\n",
      "loss: 0.316316  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439475 \n",
      "\n",
      "Epoch 2168\n",
      "-------------------------------\n",
      "loss: 0.325110  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439319 \n",
      "\n",
      "Epoch 2169\n",
      "-------------------------------\n",
      "loss: 0.324266  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439936 \n",
      "\n",
      "Epoch 2170\n",
      "-------------------------------\n",
      "loss: 0.327863  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440425 \n",
      "\n",
      "Epoch 2171\n",
      "-------------------------------\n",
      "loss: 0.318276  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440961 \n",
      "\n",
      "Epoch 2172\n",
      "-------------------------------\n",
      "loss: 0.324934  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441567 \n",
      "\n",
      "Epoch 2173\n",
      "-------------------------------\n",
      "loss: 0.326975  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441671 \n",
      "\n",
      "Epoch 2174\n",
      "-------------------------------\n",
      "loss: 0.325246  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442335 \n",
      "\n",
      "Epoch 2175\n",
      "-------------------------------\n",
      "loss: 0.322160  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441695 \n",
      "\n",
      "Epoch 2176\n",
      "-------------------------------\n",
      "loss: 0.317095  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441894 \n",
      "\n",
      "Epoch 2177\n",
      "-------------------------------\n",
      "loss: 0.321218  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441916 \n",
      "\n",
      "Epoch 2178\n",
      "-------------------------------\n",
      "loss: 0.328910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441954 \n",
      "\n",
      "Epoch 2179\n",
      "-------------------------------\n",
      "loss: 0.320403  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441841 \n",
      "\n",
      "Epoch 2180\n",
      "-------------------------------\n",
      "loss: 0.324099  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442747 \n",
      "\n",
      "Epoch 2181\n",
      "-------------------------------\n",
      "loss: 0.330993  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442428 \n",
      "\n",
      "Epoch 2182\n",
      "-------------------------------\n",
      "loss: 0.326201  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442151 \n",
      "\n",
      "Epoch 2183\n",
      "-------------------------------\n",
      "loss: 0.324851  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443516 \n",
      "\n",
      "Epoch 2184\n",
      "-------------------------------\n",
      "loss: 0.321070  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443415 \n",
      "\n",
      "Epoch 2185\n",
      "-------------------------------\n",
      "loss: 0.325729  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443751 \n",
      "\n",
      "Epoch 2186\n",
      "-------------------------------\n",
      "loss: 0.324828  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443944 \n",
      "\n",
      "Epoch 2187\n",
      "-------------------------------\n",
      "loss: 0.334164  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443518 \n",
      "\n",
      "Epoch 2188\n",
      "-------------------------------\n",
      "loss: 0.319094  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443442 \n",
      "\n",
      "Epoch 2189\n",
      "-------------------------------\n",
      "loss: 0.317514  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443719 \n",
      "\n",
      "Epoch 2190\n",
      "-------------------------------\n",
      "loss: 0.330248  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444202 \n",
      "\n",
      "Epoch 2191\n",
      "-------------------------------\n",
      "loss: 0.325652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443535 \n",
      "\n",
      "Epoch 2192\n",
      "-------------------------------\n",
      "loss: 0.329906  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443380 \n",
      "\n",
      "Epoch 2193\n",
      "-------------------------------\n",
      "loss: 0.319252  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441993 \n",
      "\n",
      "Epoch 2194\n",
      "-------------------------------\n",
      "loss: 0.328502  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441625 \n",
      "\n",
      "Epoch 2195\n",
      "-------------------------------\n",
      "loss: 0.327490  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441309 \n",
      "\n",
      "Epoch 2196\n",
      "-------------------------------\n",
      "loss: 0.317648  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441869 \n",
      "\n",
      "Epoch 2197\n",
      "-------------------------------\n",
      "loss: 0.326857  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442997 \n",
      "\n",
      "Epoch 2198\n",
      "-------------------------------\n",
      "loss: 0.328182  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444110 \n",
      "\n",
      "Epoch 2199\n",
      "-------------------------------\n",
      "loss: 0.324366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444156 \n",
      "\n",
      "Epoch 2200\n",
      "-------------------------------\n",
      "loss: 0.316439  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444790 \n",
      "\n",
      "Epoch 2201\n",
      "-------------------------------\n",
      "loss: 0.322002  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444215 \n",
      "\n",
      "Epoch 2202\n",
      "-------------------------------\n",
      "loss: 0.321185  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443530 \n",
      "\n",
      "Epoch 2203\n",
      "-------------------------------\n",
      "loss: 0.326316  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441887 \n",
      "\n",
      "Epoch 2204\n",
      "-------------------------------\n",
      "loss: 0.329423  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440439 \n",
      "\n",
      "Epoch 2205\n",
      "-------------------------------\n",
      "loss: 0.321115  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439613 \n",
      "\n",
      "Epoch 2206\n",
      "-------------------------------\n",
      "loss: 0.327076  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439435 \n",
      "\n",
      "Epoch 2207\n",
      "-------------------------------\n",
      "loss: 0.315639  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439301 \n",
      "\n",
      "Epoch 2208\n",
      "-------------------------------\n",
      "loss: 0.319829  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440876 \n",
      "\n",
      "Epoch 2209\n",
      "-------------------------------\n",
      "loss: 0.319927  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442650 \n",
      "\n",
      "Epoch 2210\n",
      "-------------------------------\n",
      "loss: 0.317876  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442573 \n",
      "\n",
      "Epoch 2211\n",
      "-------------------------------\n",
      "loss: 0.328011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442426 \n",
      "\n",
      "Epoch 2212\n",
      "-------------------------------\n",
      "loss: 0.321687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441544 \n",
      "\n",
      "Epoch 2213\n",
      "-------------------------------\n",
      "loss: 0.320346  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440354 \n",
      "\n",
      "Epoch 2214\n",
      "-------------------------------\n",
      "loss: 0.322752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440409 \n",
      "\n",
      "Epoch 2215\n",
      "-------------------------------\n",
      "loss: 0.326479  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440555 \n",
      "\n",
      "Epoch 2216\n",
      "-------------------------------\n",
      "loss: 0.327968  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441087 \n",
      "\n",
      "Epoch 2217\n",
      "-------------------------------\n",
      "loss: 0.322753  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442614 \n",
      "\n",
      "Epoch 2218\n",
      "-------------------------------\n",
      "loss: 0.322329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442355 \n",
      "\n",
      "Epoch 2219\n",
      "-------------------------------\n",
      "loss: 0.330299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442299 \n",
      "\n",
      "Epoch 2220\n",
      "-------------------------------\n",
      "loss: 0.322929  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443042 \n",
      "\n",
      "Epoch 2221\n",
      "-------------------------------\n",
      "loss: 0.326287  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443203 \n",
      "\n",
      "Epoch 2222\n",
      "-------------------------------\n",
      "loss: 0.326899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443334 \n",
      "\n",
      "Epoch 2223\n",
      "-------------------------------\n",
      "loss: 0.319833  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443625 \n",
      "\n",
      "Epoch 2224\n",
      "-------------------------------\n",
      "loss: 0.318069  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443147 \n",
      "\n",
      "Epoch 2225\n",
      "-------------------------------\n",
      "loss: 0.328137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441977 \n",
      "\n",
      "Epoch 2226\n",
      "-------------------------------\n",
      "loss: 0.321017  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441781 \n",
      "\n",
      "Epoch 2227\n",
      "-------------------------------\n",
      "loss: 0.323990  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441617 \n",
      "\n",
      "Epoch 2228\n",
      "-------------------------------\n",
      "loss: 0.330715  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441849 \n",
      "\n",
      "Epoch 2229\n",
      "-------------------------------\n",
      "loss: 0.316533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441609 \n",
      "\n",
      "Epoch 2230\n",
      "-------------------------------\n",
      "loss: 0.321411  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441681 \n",
      "\n",
      "Epoch 2231\n",
      "-------------------------------\n",
      "loss: 0.322028  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441745 \n",
      "\n",
      "Epoch 2232\n",
      "-------------------------------\n",
      "loss: 0.322194  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442200 \n",
      "\n",
      "Epoch 2233\n",
      "-------------------------------\n",
      "loss: 0.314380  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441403 \n",
      "\n",
      "Epoch 2234\n",
      "-------------------------------\n",
      "loss: 0.329913  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441975 \n",
      "\n",
      "Epoch 2235\n",
      "-------------------------------\n",
      "loss: 0.325208  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441119 \n",
      "\n",
      "Epoch 2236\n",
      "-------------------------------\n",
      "loss: 0.330519  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440894 \n",
      "\n",
      "Epoch 2237\n",
      "-------------------------------\n",
      "loss: 0.320941  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440454 \n",
      "\n",
      "Epoch 2238\n",
      "-------------------------------\n",
      "loss: 0.315087  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441571 \n",
      "\n",
      "Epoch 2239\n",
      "-------------------------------\n",
      "loss: 0.326423  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440760 \n",
      "\n",
      "Epoch 2240\n",
      "-------------------------------\n",
      "loss: 0.325523  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441234 \n",
      "\n",
      "Epoch 2241\n",
      "-------------------------------\n",
      "loss: 0.322439  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440589 \n",
      "\n",
      "Epoch 2242\n",
      "-------------------------------\n",
      "loss: 0.321816  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438831 \n",
      "\n",
      "Epoch 2243\n",
      "-------------------------------\n",
      "loss: 0.327353  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438626 \n",
      "\n",
      "Epoch 2244\n",
      "-------------------------------\n",
      "loss: 0.325179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439277 \n",
      "\n",
      "Epoch 2245\n",
      "-------------------------------\n",
      "loss: 0.326619  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439408 \n",
      "\n",
      "Epoch 2246\n",
      "-------------------------------\n",
      "loss: 0.323140  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440646 \n",
      "\n",
      "Epoch 2247\n",
      "-------------------------------\n",
      "loss: 0.320559  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441011 \n",
      "\n",
      "Epoch 2248\n",
      "-------------------------------\n",
      "loss: 0.325623  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441084 \n",
      "\n",
      "Epoch 2249\n",
      "-------------------------------\n",
      "loss: 0.331420  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442040 \n",
      "\n",
      "Epoch 2250\n",
      "-------------------------------\n",
      "loss: 0.320829  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442759 \n",
      "\n",
      "Epoch 2251\n",
      "-------------------------------\n",
      "loss: 0.327203  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442840 \n",
      "\n",
      "Epoch 2252\n",
      "-------------------------------\n",
      "loss: 0.325119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442673 \n",
      "\n",
      "Epoch 2253\n",
      "-------------------------------\n",
      "loss: 0.321793  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442656 \n",
      "\n",
      "Epoch 2254\n",
      "-------------------------------\n",
      "loss: 0.322917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442898 \n",
      "\n",
      "Epoch 2255\n",
      "-------------------------------\n",
      "loss: 0.323634  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443947 \n",
      "\n",
      "Epoch 2256\n",
      "-------------------------------\n",
      "loss: 0.310619  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443656 \n",
      "\n",
      "Epoch 2257\n",
      "-------------------------------\n",
      "loss: 0.320242  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443907 \n",
      "\n",
      "Epoch 2258\n",
      "-------------------------------\n",
      "loss: 0.323541  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444416 \n",
      "\n",
      "Epoch 2259\n",
      "-------------------------------\n",
      "loss: 0.326440  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444710 \n",
      "\n",
      "Epoch 2260\n",
      "-------------------------------\n",
      "loss: 0.322967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444480 \n",
      "\n",
      "Epoch 2261\n",
      "-------------------------------\n",
      "loss: 0.318673  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443176 \n",
      "\n",
      "Epoch 2262\n",
      "-------------------------------\n",
      "loss: 0.323607  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442570 \n",
      "\n",
      "Epoch 2263\n",
      "-------------------------------\n",
      "loss: 0.314866  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442018 \n",
      "\n",
      "Epoch 2264\n",
      "-------------------------------\n",
      "loss: 0.322956  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441907 \n",
      "\n",
      "Epoch 2265\n",
      "-------------------------------\n",
      "loss: 0.321407  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442899 \n",
      "\n",
      "Epoch 2266\n",
      "-------------------------------\n",
      "loss: 0.320573  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443169 \n",
      "\n",
      "Epoch 2267\n",
      "-------------------------------\n",
      "loss: 0.330492  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442431 \n",
      "\n",
      "Epoch 2268\n",
      "-------------------------------\n",
      "loss: 0.322349  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442536 \n",
      "\n",
      "Epoch 2269\n",
      "-------------------------------\n",
      "loss: 0.321658  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443275 \n",
      "\n",
      "Epoch 2270\n",
      "-------------------------------\n",
      "loss: 0.323310  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444311 \n",
      "\n",
      "Epoch 2271\n",
      "-------------------------------\n",
      "loss: 0.317894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445357 \n",
      "\n",
      "Epoch 2272\n",
      "-------------------------------\n",
      "loss: 0.318003  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444613 \n",
      "\n",
      "Epoch 2273\n",
      "-------------------------------\n",
      "loss: 0.318731  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444289 \n",
      "\n",
      "Epoch 2274\n",
      "-------------------------------\n",
      "loss: 0.321700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444328 \n",
      "\n",
      "Epoch 2275\n",
      "-------------------------------\n",
      "loss: 0.323994  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443277 \n",
      "\n",
      "Epoch 2276\n",
      "-------------------------------\n",
      "loss: 0.322852  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442396 \n",
      "\n",
      "Epoch 2277\n",
      "-------------------------------\n",
      "loss: 0.319429  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443013 \n",
      "\n",
      "Epoch 2278\n",
      "-------------------------------\n",
      "loss: 0.321737  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442896 \n",
      "\n",
      "Epoch 2279\n",
      "-------------------------------\n",
      "loss: 0.318981  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443611 \n",
      "\n",
      "Epoch 2280\n",
      "-------------------------------\n",
      "loss: 0.324254  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443234 \n",
      "\n",
      "Epoch 2281\n",
      "-------------------------------\n",
      "loss: 0.321885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443322 \n",
      "\n",
      "Epoch 2282\n",
      "-------------------------------\n",
      "loss: 0.320813  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443551 \n",
      "\n",
      "Epoch 2283\n",
      "-------------------------------\n",
      "loss: 0.324862  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443281 \n",
      "\n",
      "Epoch 2284\n",
      "-------------------------------\n",
      "loss: 0.319647  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442943 \n",
      "\n",
      "Epoch 2285\n",
      "-------------------------------\n",
      "loss: 0.332413  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442249 \n",
      "\n",
      "Epoch 2286\n",
      "-------------------------------\n",
      "loss: 0.322249  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442121 \n",
      "\n",
      "Epoch 2287\n",
      "-------------------------------\n",
      "loss: 0.322798  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441174 \n",
      "\n",
      "Epoch 2288\n",
      "-------------------------------\n",
      "loss: 0.323233  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442607 \n",
      "\n",
      "Epoch 2289\n",
      "-------------------------------\n",
      "loss: 0.329748  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442837 \n",
      "\n",
      "Epoch 2290\n",
      "-------------------------------\n",
      "loss: 0.315381  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442687 \n",
      "\n",
      "Epoch 2291\n",
      "-------------------------------\n",
      "loss: 0.324622  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442147 \n",
      "\n",
      "Epoch 2292\n",
      "-------------------------------\n",
      "loss: 0.309482  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441528 \n",
      "\n",
      "Epoch 2293\n",
      "-------------------------------\n",
      "loss: 0.325686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441573 \n",
      "\n",
      "Epoch 2294\n",
      "-------------------------------\n",
      "loss: 0.318311  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441125 \n",
      "\n",
      "Epoch 2295\n",
      "-------------------------------\n",
      "loss: 0.323490  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440955 \n",
      "\n",
      "Epoch 2296\n",
      "-------------------------------\n",
      "loss: 0.324948  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440284 \n",
      "\n",
      "Epoch 2297\n",
      "-------------------------------\n",
      "loss: 0.319230  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440178 \n",
      "\n",
      "Epoch 2298\n",
      "-------------------------------\n",
      "loss: 0.318626  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440818 \n",
      "\n",
      "Epoch 2299\n",
      "-------------------------------\n",
      "loss: 0.321123  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441978 \n",
      "\n",
      "Epoch 2300\n",
      "-------------------------------\n",
      "loss: 0.321531  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442078 \n",
      "\n",
      "Epoch 2301\n",
      "-------------------------------\n",
      "loss: 0.321852  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442553 \n",
      "\n",
      "Epoch 2302\n",
      "-------------------------------\n",
      "loss: 0.318803  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442112 \n",
      "\n",
      "Epoch 2303\n",
      "-------------------------------\n",
      "loss: 0.320546  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441596 \n",
      "\n",
      "Epoch 2304\n",
      "-------------------------------\n",
      "loss: 0.324269  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441795 \n",
      "\n",
      "Epoch 2305\n",
      "-------------------------------\n",
      "loss: 0.322133  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441419 \n",
      "\n",
      "Epoch 2306\n",
      "-------------------------------\n",
      "loss: 0.313747  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441669 \n",
      "\n",
      "Epoch 2307\n",
      "-------------------------------\n",
      "loss: 0.321204  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442354 \n",
      "\n",
      "Epoch 2308\n",
      "-------------------------------\n",
      "loss: 0.314256  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442832 \n",
      "\n",
      "Epoch 2309\n",
      "-------------------------------\n",
      "loss: 0.322540  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442332 \n",
      "\n",
      "Epoch 2310\n",
      "-------------------------------\n",
      "loss: 0.328575  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441645 \n",
      "\n",
      "Epoch 2311\n",
      "-------------------------------\n",
      "loss: 0.324378  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441826 \n",
      "\n",
      "Epoch 2312\n",
      "-------------------------------\n",
      "loss: 0.327641  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440896 \n",
      "\n",
      "Epoch 2313\n",
      "-------------------------------\n",
      "loss: 0.317443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441200 \n",
      "\n",
      "Epoch 2314\n",
      "-------------------------------\n",
      "loss: 0.333258  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441940 \n",
      "\n",
      "Epoch 2315\n",
      "-------------------------------\n",
      "loss: 0.324946  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443197 \n",
      "\n",
      "Epoch 2316\n",
      "-------------------------------\n",
      "loss: 0.319585  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443647 \n",
      "\n",
      "Epoch 2317\n",
      "-------------------------------\n",
      "loss: 0.325358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442993 \n",
      "\n",
      "Epoch 2318\n",
      "-------------------------------\n",
      "loss: 0.324130  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442051 \n",
      "\n",
      "Epoch 2319\n",
      "-------------------------------\n",
      "loss: 0.318668  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441538 \n",
      "\n",
      "Epoch 2320\n",
      "-------------------------------\n",
      "loss: 0.321117  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441367 \n",
      "\n",
      "Epoch 2321\n",
      "-------------------------------\n",
      "loss: 0.316010  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441119 \n",
      "\n",
      "Epoch 2322\n",
      "-------------------------------\n",
      "loss: 0.320960  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440936 \n",
      "\n",
      "Epoch 2323\n",
      "-------------------------------\n",
      "loss: 0.319352  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442324 \n",
      "\n",
      "Epoch 2324\n",
      "-------------------------------\n",
      "loss: 0.317672  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442456 \n",
      "\n",
      "Epoch 2325\n",
      "-------------------------------\n",
      "loss: 0.319735  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442296 \n",
      "\n",
      "Epoch 2326\n",
      "-------------------------------\n",
      "loss: 0.325736  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442751 \n",
      "\n",
      "Epoch 2327\n",
      "-------------------------------\n",
      "loss: 0.324054  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.444041 \n",
      "\n",
      "Epoch 2328\n",
      "-------------------------------\n",
      "loss: 0.321728  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444330 \n",
      "\n",
      "Epoch 2329\n",
      "-------------------------------\n",
      "loss: 0.321072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444161 \n",
      "\n",
      "Epoch 2330\n",
      "-------------------------------\n",
      "loss: 0.316520  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443339 \n",
      "\n",
      "Epoch 2331\n",
      "-------------------------------\n",
      "loss: 0.322559  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442971 \n",
      "\n",
      "Epoch 2332\n",
      "-------------------------------\n",
      "loss: 0.325283  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442141 \n",
      "\n",
      "Epoch 2333\n",
      "-------------------------------\n",
      "loss: 0.322563  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442116 \n",
      "\n",
      "Epoch 2334\n",
      "-------------------------------\n",
      "loss: 0.314043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441135 \n",
      "\n",
      "Epoch 2335\n",
      "-------------------------------\n",
      "loss: 0.310302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440866 \n",
      "\n",
      "Epoch 2336\n",
      "-------------------------------\n",
      "loss: 0.325546  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440549 \n",
      "\n",
      "Epoch 2337\n",
      "-------------------------------\n",
      "loss: 0.325529  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440896 \n",
      "\n",
      "Epoch 2338\n",
      "-------------------------------\n",
      "loss: 0.322253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441778 \n",
      "\n",
      "Epoch 2339\n",
      "-------------------------------\n",
      "loss: 0.320935  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442878 \n",
      "\n",
      "Epoch 2340\n",
      "-------------------------------\n",
      "loss: 0.310605  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442766 \n",
      "\n",
      "Epoch 2341\n",
      "-------------------------------\n",
      "loss: 0.324059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443630 \n",
      "\n",
      "Epoch 2342\n",
      "-------------------------------\n",
      "loss: 0.326325  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443309 \n",
      "\n",
      "Epoch 2343\n",
      "-------------------------------\n",
      "loss: 0.319919  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443177 \n",
      "\n",
      "Epoch 2344\n",
      "-------------------------------\n",
      "loss: 0.322634  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443179 \n",
      "\n",
      "Epoch 2345\n",
      "-------------------------------\n",
      "loss: 0.323779  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443299 \n",
      "\n",
      "Epoch 2346\n",
      "-------------------------------\n",
      "loss: 0.321448  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442861 \n",
      "\n",
      "Epoch 2347\n",
      "-------------------------------\n",
      "loss: 0.327040  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443233 \n",
      "\n",
      "Epoch 2348\n",
      "-------------------------------\n",
      "loss: 0.321291  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443345 \n",
      "\n",
      "Epoch 2349\n",
      "-------------------------------\n",
      "loss: 0.310205  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443886 \n",
      "\n",
      "Epoch 2350\n",
      "-------------------------------\n",
      "loss: 0.317967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443740 \n",
      "\n",
      "Epoch 2351\n",
      "-------------------------------\n",
      "loss: 0.322750  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443018 \n",
      "\n",
      "Epoch 2352\n",
      "-------------------------------\n",
      "loss: 0.323011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443101 \n",
      "\n",
      "Epoch 2353\n",
      "-------------------------------\n",
      "loss: 0.317703  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442377 \n",
      "\n",
      "Epoch 2354\n",
      "-------------------------------\n",
      "loss: 0.318707  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441087 \n",
      "\n",
      "Epoch 2355\n",
      "-------------------------------\n",
      "loss: 0.323279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440574 \n",
      "\n",
      "Epoch 2356\n",
      "-------------------------------\n",
      "loss: 0.329523  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441474 \n",
      "\n",
      "Epoch 2357\n",
      "-------------------------------\n",
      "loss: 0.319819  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440714 \n",
      "\n",
      "Epoch 2358\n",
      "-------------------------------\n",
      "loss: 0.323170  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441432 \n",
      "\n",
      "Epoch 2359\n",
      "-------------------------------\n",
      "loss: 0.316194  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442083 \n",
      "\n",
      "Epoch 2360\n",
      "-------------------------------\n",
      "loss: 0.315780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442899 \n",
      "\n",
      "Epoch 2361\n",
      "-------------------------------\n",
      "loss: 0.331610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443137 \n",
      "\n",
      "Epoch 2362\n",
      "-------------------------------\n",
      "loss: 0.310307  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442331 \n",
      "\n",
      "Epoch 2363\n",
      "-------------------------------\n",
      "loss: 0.323334  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443191 \n",
      "\n",
      "Epoch 2364\n",
      "-------------------------------\n",
      "loss: 0.321698  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443196 \n",
      "\n",
      "Epoch 2365\n",
      "-------------------------------\n",
      "loss: 0.317968  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443464 \n",
      "\n",
      "Epoch 2366\n",
      "-------------------------------\n",
      "loss: 0.320324  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443550 \n",
      "\n",
      "Epoch 2367\n",
      "-------------------------------\n",
      "loss: 0.323319  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443930 \n",
      "\n",
      "Epoch 2368\n",
      "-------------------------------\n",
      "loss: 0.317874  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443580 \n",
      "\n",
      "Epoch 2369\n",
      "-------------------------------\n",
      "loss: 0.322937  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443955 \n",
      "\n",
      "Epoch 2370\n",
      "-------------------------------\n",
      "loss: 0.320222  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442944 \n",
      "\n",
      "Epoch 2371\n",
      "-------------------------------\n",
      "loss: 0.321512  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443759 \n",
      "\n",
      "Epoch 2372\n",
      "-------------------------------\n",
      "loss: 0.319586  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443060 \n",
      "\n",
      "Epoch 2373\n",
      "-------------------------------\n",
      "loss: 0.320220  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444235 \n",
      "\n",
      "Epoch 2374\n",
      "-------------------------------\n",
      "loss: 0.319545  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444729 \n",
      "\n",
      "Epoch 2375\n",
      "-------------------------------\n",
      "loss: 0.324140  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444129 \n",
      "\n",
      "Epoch 2376\n",
      "-------------------------------\n",
      "loss: 0.313279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443837 \n",
      "\n",
      "Epoch 2377\n",
      "-------------------------------\n",
      "loss: 0.323296  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442618 \n",
      "\n",
      "Epoch 2378\n",
      "-------------------------------\n",
      "loss: 0.318662  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441305 \n",
      "\n",
      "Epoch 2379\n",
      "-------------------------------\n",
      "loss: 0.316444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441161 \n",
      "\n",
      "Epoch 2380\n",
      "-------------------------------\n",
      "loss: 0.330063  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441241 \n",
      "\n",
      "Epoch 2381\n",
      "-------------------------------\n",
      "loss: 0.315478  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441813 \n",
      "\n",
      "Epoch 2382\n",
      "-------------------------------\n",
      "loss: 0.321737  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441878 \n",
      "\n",
      "Epoch 2383\n",
      "-------------------------------\n",
      "loss: 0.317490  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442122 \n",
      "\n",
      "Epoch 2384\n",
      "-------------------------------\n",
      "loss: 0.320367  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443154 \n",
      "\n",
      "Epoch 2385\n",
      "-------------------------------\n",
      "loss: 0.322861  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443861 \n",
      "\n",
      "Epoch 2386\n",
      "-------------------------------\n",
      "loss: 0.315773  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443499 \n",
      "\n",
      "Epoch 2387\n",
      "-------------------------------\n",
      "loss: 0.319242  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444282 \n",
      "\n",
      "Epoch 2388\n",
      "-------------------------------\n",
      "loss: 0.321766  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444128 \n",
      "\n",
      "Epoch 2389\n",
      "-------------------------------\n",
      "loss: 0.317153  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443106 \n",
      "\n",
      "Epoch 2390\n",
      "-------------------------------\n",
      "loss: 0.319565  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443122 \n",
      "\n",
      "Epoch 2391\n",
      "-------------------------------\n",
      "loss: 0.324642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443185 \n",
      "\n",
      "Epoch 2392\n",
      "-------------------------------\n",
      "loss: 0.327027  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443421 \n",
      "\n",
      "Epoch 2393\n",
      "-------------------------------\n",
      "loss: 0.321921  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442922 \n",
      "\n",
      "Epoch 2394\n",
      "-------------------------------\n",
      "loss: 0.322335  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442891 \n",
      "\n",
      "Epoch 2395\n",
      "-------------------------------\n",
      "loss: 0.316869  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444067 \n",
      "\n",
      "Epoch 2396\n",
      "-------------------------------\n",
      "loss: 0.322873  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444046 \n",
      "\n",
      "Epoch 2397\n",
      "-------------------------------\n",
      "loss: 0.319557  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444529 \n",
      "\n",
      "Epoch 2398\n",
      "-------------------------------\n",
      "loss: 0.324202  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443920 \n",
      "\n",
      "Epoch 2399\n",
      "-------------------------------\n",
      "loss: 0.317431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444519 \n",
      "\n",
      "Epoch 2400\n",
      "-------------------------------\n",
      "loss: 0.327818  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445119 \n",
      "\n",
      "Epoch 2401\n",
      "-------------------------------\n",
      "loss: 0.322478  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444168 \n",
      "\n",
      "Epoch 2402\n",
      "-------------------------------\n",
      "loss: 0.325149  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443424 \n",
      "\n",
      "Epoch 2403\n",
      "-------------------------------\n",
      "loss: 0.318830  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.443286 \n",
      "\n",
      "Epoch 2404\n",
      "-------------------------------\n",
      "loss: 0.321832  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443025 \n",
      "\n",
      "Epoch 2405\n",
      "-------------------------------\n",
      "loss: 0.315392  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443507 \n",
      "\n",
      "Epoch 2406\n",
      "-------------------------------\n",
      "loss: 0.318331  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443872 \n",
      "\n",
      "Epoch 2407\n",
      "-------------------------------\n",
      "loss: 0.316844  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444388 \n",
      "\n",
      "Epoch 2408\n",
      "-------------------------------\n",
      "loss: 0.323471  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444658 \n",
      "\n",
      "Epoch 2409\n",
      "-------------------------------\n",
      "loss: 0.315213  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444031 \n",
      "\n",
      "Epoch 2410\n",
      "-------------------------------\n",
      "loss: 0.315392  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443118 \n",
      "\n",
      "Epoch 2411\n",
      "-------------------------------\n",
      "loss: 0.318289  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443199 \n",
      "\n",
      "Epoch 2412\n",
      "-------------------------------\n",
      "loss: 0.327414  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441913 \n",
      "\n",
      "Epoch 2413\n",
      "-------------------------------\n",
      "loss: 0.318830  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440996 \n",
      "\n",
      "Epoch 2414\n",
      "-------------------------------\n",
      "loss: 0.321677  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440222 \n",
      "\n",
      "Epoch 2415\n",
      "-------------------------------\n",
      "loss: 0.327290  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439867 \n",
      "\n",
      "Epoch 2416\n",
      "-------------------------------\n",
      "loss: 0.318918  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440668 \n",
      "\n",
      "Epoch 2417\n",
      "-------------------------------\n",
      "loss: 0.311097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440481 \n",
      "\n",
      "Epoch 2418\n",
      "-------------------------------\n",
      "loss: 0.324052  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440925 \n",
      "\n",
      "Epoch 2419\n",
      "-------------------------------\n",
      "loss: 0.320157  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441506 \n",
      "\n",
      "Epoch 2420\n",
      "-------------------------------\n",
      "loss: 0.315948  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441925 \n",
      "\n",
      "Epoch 2421\n",
      "-------------------------------\n",
      "loss: 0.329043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441814 \n",
      "\n",
      "Epoch 2422\n",
      "-------------------------------\n",
      "loss: 0.329706  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442200 \n",
      "\n",
      "Epoch 2423\n",
      "-------------------------------\n",
      "loss: 0.319563  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442452 \n",
      "\n",
      "Epoch 2424\n",
      "-------------------------------\n",
      "loss: 0.324068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442018 \n",
      "\n",
      "Epoch 2425\n",
      "-------------------------------\n",
      "loss: 0.320972  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441764 \n",
      "\n",
      "Epoch 2426\n",
      "-------------------------------\n",
      "loss: 0.320874  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440718 \n",
      "\n",
      "Epoch 2427\n",
      "-------------------------------\n",
      "loss: 0.315997  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440496 \n",
      "\n",
      "Epoch 2428\n",
      "-------------------------------\n",
      "loss: 0.324607  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440599 \n",
      "\n",
      "Epoch 2429\n",
      "-------------------------------\n",
      "loss: 0.325372  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439775 \n",
      "\n",
      "Epoch 2430\n",
      "-------------------------------\n",
      "loss: 0.324650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440555 \n",
      "\n",
      "Epoch 2431\n",
      "-------------------------------\n",
      "loss: 0.320040  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441228 \n",
      "\n",
      "Epoch 2432\n",
      "-------------------------------\n",
      "loss: 0.316729  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441860 \n",
      "\n",
      "Epoch 2433\n",
      "-------------------------------\n",
      "loss: 0.326904  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442353 \n",
      "\n",
      "Epoch 2434\n",
      "-------------------------------\n",
      "loss: 0.319227  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442813 \n",
      "\n",
      "Epoch 2435\n",
      "-------------------------------\n",
      "loss: 0.322989  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441914 \n",
      "\n",
      "Epoch 2436\n",
      "-------------------------------\n",
      "loss: 0.321265  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441502 \n",
      "\n",
      "Epoch 2437\n",
      "-------------------------------\n",
      "loss: 0.320606  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440313 \n",
      "\n",
      "Epoch 2438\n",
      "-------------------------------\n",
      "loss: 0.327131  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440523 \n",
      "\n",
      "Epoch 2439\n",
      "-------------------------------\n",
      "loss: 0.305816  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440382 \n",
      "\n",
      "Epoch 2440\n",
      "-------------------------------\n",
      "loss: 0.320739  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440823 \n",
      "\n",
      "Epoch 2441\n",
      "-------------------------------\n",
      "loss: 0.325962  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440989 \n",
      "\n",
      "Epoch 2442\n",
      "-------------------------------\n",
      "loss: 0.315940  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441418 \n",
      "\n",
      "Epoch 2443\n",
      "-------------------------------\n",
      "loss: 0.318947  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441004 \n",
      "\n",
      "Epoch 2444\n",
      "-------------------------------\n",
      "loss: 0.323166  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441162 \n",
      "\n",
      "Epoch 2445\n",
      "-------------------------------\n",
      "loss: 0.320257  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440952 \n",
      "\n",
      "Epoch 2446\n",
      "-------------------------------\n",
      "loss: 0.319757  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441217 \n",
      "\n",
      "Epoch 2447\n",
      "-------------------------------\n",
      "loss: 0.323453  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441734 \n",
      "\n",
      "Epoch 2448\n",
      "-------------------------------\n",
      "loss: 0.317610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441661 \n",
      "\n",
      "Epoch 2449\n",
      "-------------------------------\n",
      "loss: 0.326234  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441513 \n",
      "\n",
      "Epoch 2450\n",
      "-------------------------------\n",
      "loss: 0.316533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441957 \n",
      "\n",
      "Epoch 2451\n",
      "-------------------------------\n",
      "loss: 0.312787  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442173 \n",
      "\n",
      "Epoch 2452\n",
      "-------------------------------\n",
      "loss: 0.314486  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441553 \n",
      "\n",
      "Epoch 2453\n",
      "-------------------------------\n",
      "loss: 0.318737  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442339 \n",
      "\n",
      "Epoch 2454\n",
      "-------------------------------\n",
      "loss: 0.324357  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441770 \n",
      "\n",
      "Epoch 2455\n",
      "-------------------------------\n",
      "loss: 0.328359  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440769 \n",
      "\n",
      "Epoch 2456\n",
      "-------------------------------\n",
      "loss: 0.313003  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441231 \n",
      "\n",
      "Epoch 2457\n",
      "-------------------------------\n",
      "loss: 0.318544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440839 \n",
      "\n",
      "Epoch 2458\n",
      "-------------------------------\n",
      "loss: 0.314554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441035 \n",
      "\n",
      "Epoch 2459\n",
      "-------------------------------\n",
      "loss: 0.311603  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441343 \n",
      "\n",
      "Epoch 2460\n",
      "-------------------------------\n",
      "loss: 0.324023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441924 \n",
      "\n",
      "Epoch 2461\n",
      "-------------------------------\n",
      "loss: 0.317636  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442776 \n",
      "\n",
      "Epoch 2462\n",
      "-------------------------------\n",
      "loss: 0.329185  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443823 \n",
      "\n",
      "Epoch 2463\n",
      "-------------------------------\n",
      "loss: 0.324579  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444534 \n",
      "\n",
      "Epoch 2464\n",
      "-------------------------------\n",
      "loss: 0.313890  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444580 \n",
      "\n",
      "Epoch 2465\n",
      "-------------------------------\n",
      "loss: 0.320700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443247 \n",
      "\n",
      "Epoch 2466\n",
      "-------------------------------\n",
      "loss: 0.320268  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443838 \n",
      "\n",
      "Epoch 2467\n",
      "-------------------------------\n",
      "loss: 0.318891  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443853 \n",
      "\n",
      "Epoch 2468\n",
      "-------------------------------\n",
      "loss: 0.324732  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443327 \n",
      "\n",
      "Epoch 2469\n",
      "-------------------------------\n",
      "loss: 0.315746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442181 \n",
      "\n",
      "Epoch 2470\n",
      "-------------------------------\n",
      "loss: 0.323349  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441136 \n",
      "\n",
      "Epoch 2471\n",
      "-------------------------------\n",
      "loss: 0.315057  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441291 \n",
      "\n",
      "Epoch 2472\n",
      "-------------------------------\n",
      "loss: 0.319990  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441325 \n",
      "\n",
      "Epoch 2473\n",
      "-------------------------------\n",
      "loss: 0.322863  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441096 \n",
      "\n",
      "Epoch 2474\n",
      "-------------------------------\n",
      "loss: 0.322561  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442401 \n",
      "\n",
      "Epoch 2475\n",
      "-------------------------------\n",
      "loss: 0.315589  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444349 \n",
      "\n",
      "Epoch 2476\n",
      "-------------------------------\n",
      "loss: 0.317809  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445584 \n",
      "\n",
      "Epoch 2477\n",
      "-------------------------------\n",
      "loss: 0.318715  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445367 \n",
      "\n",
      "Epoch 2478\n",
      "-------------------------------\n",
      "loss: 0.310341  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444087 \n",
      "\n",
      "Epoch 2479\n",
      "-------------------------------\n",
      "loss: 0.316173  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.443242 \n",
      "\n",
      "Epoch 2480\n",
      "-------------------------------\n",
      "loss: 0.320271  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441643 \n",
      "\n",
      "Epoch 2481\n",
      "-------------------------------\n",
      "loss: 0.307744  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441267 \n",
      "\n",
      "Epoch 2482\n",
      "-------------------------------\n",
      "loss: 0.317997  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441036 \n",
      "\n",
      "Epoch 2483\n",
      "-------------------------------\n",
      "loss: 0.320569  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440866 \n",
      "\n",
      "Epoch 2484\n",
      "-------------------------------\n",
      "loss: 0.311080  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441716 \n",
      "\n",
      "Epoch 2485\n",
      "-------------------------------\n",
      "loss: 0.316344  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442021 \n",
      "\n",
      "Epoch 2486\n",
      "-------------------------------\n",
      "loss: 0.318610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442202 \n",
      "\n",
      "Epoch 2487\n",
      "-------------------------------\n",
      "loss: 0.317533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443290 \n",
      "\n",
      "Epoch 2488\n",
      "-------------------------------\n",
      "loss: 0.317793  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443297 \n",
      "\n",
      "Epoch 2489\n",
      "-------------------------------\n",
      "loss: 0.309915  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442615 \n",
      "\n",
      "Epoch 2490\n",
      "-------------------------------\n",
      "loss: 0.315433  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441536 \n",
      "\n",
      "Epoch 2491\n",
      "-------------------------------\n",
      "loss: 0.323578  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441680 \n",
      "\n",
      "Epoch 2492\n",
      "-------------------------------\n",
      "loss: 0.320183  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440553 \n",
      "\n",
      "Epoch 2493\n",
      "-------------------------------\n",
      "loss: 0.313457  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440655 \n",
      "\n",
      "Epoch 2494\n",
      "-------------------------------\n",
      "loss: 0.324639  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440608 \n",
      "\n",
      "Epoch 2495\n",
      "-------------------------------\n",
      "loss: 0.321120  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440847 \n",
      "\n",
      "Epoch 2496\n",
      "-------------------------------\n",
      "loss: 0.324378  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441194 \n",
      "\n",
      "Epoch 2497\n",
      "-------------------------------\n",
      "loss: 0.320426  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441924 \n",
      "\n",
      "Epoch 2498\n",
      "-------------------------------\n",
      "loss: 0.308355  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443484 \n",
      "\n",
      "Epoch 2499\n",
      "-------------------------------\n",
      "loss: 0.321700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445051 \n",
      "\n",
      "Epoch 2500\n",
      "-------------------------------\n",
      "loss: 0.316209  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445837 \n",
      "\n",
      "Epoch 2501\n",
      "-------------------------------\n",
      "loss: 0.316259  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.447117 \n",
      "\n",
      "Epoch 2502\n",
      "-------------------------------\n",
      "loss: 0.318689  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445992 \n",
      "\n",
      "Epoch 2503\n",
      "-------------------------------\n",
      "loss: 0.318319  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445131 \n",
      "\n",
      "Epoch 2504\n",
      "-------------------------------\n",
      "loss: 0.321526  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442720 \n",
      "\n",
      "Epoch 2505\n",
      "-------------------------------\n",
      "loss: 0.319328  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442201 \n",
      "\n",
      "Epoch 2506\n",
      "-------------------------------\n",
      "loss: 0.318782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441207 \n",
      "\n",
      "Epoch 2507\n",
      "-------------------------------\n",
      "loss: 0.321217  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442035 \n",
      "\n",
      "Epoch 2508\n",
      "-------------------------------\n",
      "loss: 0.316351  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442611 \n",
      "\n",
      "Epoch 2509\n",
      "-------------------------------\n",
      "loss: 0.316186  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442518 \n",
      "\n",
      "Epoch 2510\n",
      "-------------------------------\n",
      "loss: 0.314423  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442524 \n",
      "\n",
      "Epoch 2511\n",
      "-------------------------------\n",
      "loss: 0.321446  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442239 \n",
      "\n",
      "Epoch 2512\n",
      "-------------------------------\n",
      "loss: 0.313986  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442202 \n",
      "\n",
      "Epoch 2513\n",
      "-------------------------------\n",
      "loss: 0.318619  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441947 \n",
      "\n",
      "Epoch 2514\n",
      "-------------------------------\n",
      "loss: 0.315005  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441593 \n",
      "\n",
      "Epoch 2515\n",
      "-------------------------------\n",
      "loss: 0.322729  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440360 \n",
      "\n",
      "Epoch 2516\n",
      "-------------------------------\n",
      "loss: 0.318269  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441695 \n",
      "\n",
      "Epoch 2517\n",
      "-------------------------------\n",
      "loss: 0.324623  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441388 \n",
      "\n",
      "Epoch 2518\n",
      "-------------------------------\n",
      "loss: 0.313807  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441391 \n",
      "\n",
      "Epoch 2519\n",
      "-------------------------------\n",
      "loss: 0.314783  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442141 \n",
      "\n",
      "Epoch 2520\n",
      "-------------------------------\n",
      "loss: 0.314258  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442238 \n",
      "\n",
      "Epoch 2521\n",
      "-------------------------------\n",
      "loss: 0.315945  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442521 \n",
      "\n",
      "Epoch 2522\n",
      "-------------------------------\n",
      "loss: 0.319798  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444290 \n",
      "\n",
      "Epoch 2523\n",
      "-------------------------------\n",
      "loss: 0.314036  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444807 \n",
      "\n",
      "Epoch 2524\n",
      "-------------------------------\n",
      "loss: 0.327358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444391 \n",
      "\n",
      "Epoch 2525\n",
      "-------------------------------\n",
      "loss: 0.312247  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442861 \n",
      "\n",
      "Epoch 2526\n",
      "-------------------------------\n",
      "loss: 0.311617  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441388 \n",
      "\n",
      "Epoch 2527\n",
      "-------------------------------\n",
      "loss: 0.312825  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441001 \n",
      "\n",
      "Epoch 2528\n",
      "-------------------------------\n",
      "loss: 0.320996  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440031 \n",
      "\n",
      "Epoch 2529\n",
      "-------------------------------\n",
      "loss: 0.319374  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440483 \n",
      "\n",
      "Epoch 2530\n",
      "-------------------------------\n",
      "loss: 0.322893  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440282 \n",
      "\n",
      "Epoch 2531\n",
      "-------------------------------\n",
      "loss: 0.322095  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440919 \n",
      "\n",
      "Epoch 2532\n",
      "-------------------------------\n",
      "loss: 0.322731  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441058 \n",
      "\n",
      "Epoch 2533\n",
      "-------------------------------\n",
      "loss: 0.320994  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442317 \n",
      "\n",
      "Epoch 2534\n",
      "-------------------------------\n",
      "loss: 0.314730  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443636 \n",
      "\n",
      "Epoch 2535\n",
      "-------------------------------\n",
      "loss: 0.321027  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444718 \n",
      "\n",
      "Epoch 2536\n",
      "-------------------------------\n",
      "loss: 0.323034  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446158 \n",
      "\n",
      "Epoch 2537\n",
      "-------------------------------\n",
      "loss: 0.329907  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446555 \n",
      "\n",
      "Epoch 2538\n",
      "-------------------------------\n",
      "loss: 0.320416  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444364 \n",
      "\n",
      "Epoch 2539\n",
      "-------------------------------\n",
      "loss: 0.320529  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442705 \n",
      "\n",
      "Epoch 2540\n",
      "-------------------------------\n",
      "loss: 0.318633  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441887 \n",
      "\n",
      "Epoch 2541\n",
      "-------------------------------\n",
      "loss: 0.313263  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441333 \n",
      "\n",
      "Epoch 2542\n",
      "-------------------------------\n",
      "loss: 0.320589  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441451 \n",
      "\n",
      "Epoch 2543\n",
      "-------------------------------\n",
      "loss: 0.322457  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441126 \n",
      "\n",
      "Epoch 2544\n",
      "-------------------------------\n",
      "loss: 0.313896  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441820 \n",
      "\n",
      "Epoch 2545\n",
      "-------------------------------\n",
      "loss: 0.319132  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441944 \n",
      "\n",
      "Epoch 2546\n",
      "-------------------------------\n",
      "loss: 0.314003  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442283 \n",
      "\n",
      "Epoch 2547\n",
      "-------------------------------\n",
      "loss: 0.321142  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442801 \n",
      "\n",
      "Epoch 2548\n",
      "-------------------------------\n",
      "loss: 0.322215  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443153 \n",
      "\n",
      "Epoch 2549\n",
      "-------------------------------\n",
      "loss: 0.316167  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442458 \n",
      "\n",
      "Epoch 2550\n",
      "-------------------------------\n",
      "loss: 0.317097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442171 \n",
      "\n",
      "Epoch 2551\n",
      "-------------------------------\n",
      "loss: 0.320092  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441475 \n",
      "\n",
      "Epoch 2552\n",
      "-------------------------------\n",
      "loss: 0.312318  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441251 \n",
      "\n",
      "Epoch 2553\n",
      "-------------------------------\n",
      "loss: 0.313840  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440233 \n",
      "\n",
      "Epoch 2554\n",
      "-------------------------------\n",
      "loss: 0.318956  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440179 \n",
      "\n",
      "Epoch 2555\n",
      "-------------------------------\n",
      "loss: 0.320962  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440013 \n",
      "\n",
      "Epoch 2556\n",
      "-------------------------------\n",
      "loss: 0.319127  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440120 \n",
      "\n",
      "Epoch 2557\n",
      "-------------------------------\n",
      "loss: 0.319564  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440772 \n",
      "\n",
      "Epoch 2558\n",
      "-------------------------------\n",
      "loss: 0.311738  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441368 \n",
      "\n",
      "Epoch 2559\n",
      "-------------------------------\n",
      "loss: 0.317283  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441964 \n",
      "\n",
      "Epoch 2560\n",
      "-------------------------------\n",
      "loss: 0.321095  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441789 \n",
      "\n",
      "Epoch 2561\n",
      "-------------------------------\n",
      "loss: 0.316710  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442911 \n",
      "\n",
      "Epoch 2562\n",
      "-------------------------------\n",
      "loss: 0.317812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443046 \n",
      "\n",
      "Epoch 2563\n",
      "-------------------------------\n",
      "loss: 0.321748  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443702 \n",
      "\n",
      "Epoch 2564\n",
      "-------------------------------\n",
      "loss: 0.321039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443305 \n",
      "\n",
      "Epoch 2565\n",
      "-------------------------------\n",
      "loss: 0.307592  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444539 \n",
      "\n",
      "Epoch 2566\n",
      "-------------------------------\n",
      "loss: 0.319179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444273 \n",
      "\n",
      "Epoch 2567\n",
      "-------------------------------\n",
      "loss: 0.320526  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444094 \n",
      "\n",
      "Epoch 2568\n",
      "-------------------------------\n",
      "loss: 0.321068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442281 \n",
      "\n",
      "Epoch 2569\n",
      "-------------------------------\n",
      "loss: 0.313405  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441272 \n",
      "\n",
      "Epoch 2570\n",
      "-------------------------------\n",
      "loss: 0.319360  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441152 \n",
      "\n",
      "Epoch 2571\n",
      "-------------------------------\n",
      "loss: 0.319916  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440807 \n",
      "\n",
      "Epoch 2572\n",
      "-------------------------------\n",
      "loss: 0.312663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440859 \n",
      "\n",
      "Epoch 2573\n",
      "-------------------------------\n",
      "loss: 0.311524  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441677 \n",
      "\n",
      "Epoch 2574\n",
      "-------------------------------\n",
      "loss: 0.319477  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440418 \n",
      "\n",
      "Epoch 2575\n",
      "-------------------------------\n",
      "loss: 0.324537  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440080 \n",
      "\n",
      "Epoch 2576\n",
      "-------------------------------\n",
      "loss: 0.319904  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440539 \n",
      "\n",
      "Epoch 2577\n",
      "-------------------------------\n",
      "loss: 0.313570  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440968 \n",
      "\n",
      "Epoch 2578\n",
      "-------------------------------\n",
      "loss: 0.317007  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441995 \n",
      "\n",
      "Epoch 2579\n",
      "-------------------------------\n",
      "loss: 0.319555  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441067 \n",
      "\n",
      "Epoch 2580\n",
      "-------------------------------\n",
      "loss: 0.318240  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441372 \n",
      "\n",
      "Epoch 2581\n",
      "-------------------------------\n",
      "loss: 0.318090  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440957 \n",
      "\n",
      "Epoch 2582\n",
      "-------------------------------\n",
      "loss: 0.317079  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441009 \n",
      "\n",
      "Epoch 2583\n",
      "-------------------------------\n",
      "loss: 0.319201  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440725 \n",
      "\n",
      "Epoch 2584\n",
      "-------------------------------\n",
      "loss: 0.314746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441500 \n",
      "\n",
      "Epoch 2585\n",
      "-------------------------------\n",
      "loss: 0.323277  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440995 \n",
      "\n",
      "Epoch 2586\n",
      "-------------------------------\n",
      "loss: 0.317123  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440570 \n",
      "\n",
      "Epoch 2587\n",
      "-------------------------------\n",
      "loss: 0.318581  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440962 \n",
      "\n",
      "Epoch 2588\n",
      "-------------------------------\n",
      "loss: 0.319696  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440151 \n",
      "\n",
      "Epoch 2589\n",
      "-------------------------------\n",
      "loss: 0.317820  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440943 \n",
      "\n",
      "Epoch 2590\n",
      "-------------------------------\n",
      "loss: 0.314588  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440894 \n",
      "\n",
      "Epoch 2591\n",
      "-------------------------------\n",
      "loss: 0.314225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441751 \n",
      "\n",
      "Epoch 2592\n",
      "-------------------------------\n",
      "loss: 0.322553  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442517 \n",
      "\n",
      "Epoch 2593\n",
      "-------------------------------\n",
      "loss: 0.315579  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441619 \n",
      "\n",
      "Epoch 2594\n",
      "-------------------------------\n",
      "loss: 0.327025  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441515 \n",
      "\n",
      "Epoch 2595\n",
      "-------------------------------\n",
      "loss: 0.312335  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441581 \n",
      "\n",
      "Epoch 2596\n",
      "-------------------------------\n",
      "loss: 0.306985  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440750 \n",
      "\n",
      "Epoch 2597\n",
      "-------------------------------\n",
      "loss: 0.320421  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441831 \n",
      "\n",
      "Epoch 2598\n",
      "-------------------------------\n",
      "loss: 0.322416  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441300 \n",
      "\n",
      "Epoch 2599\n",
      "-------------------------------\n",
      "loss: 0.321007  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440703 \n",
      "\n",
      "Epoch 2600\n",
      "-------------------------------\n",
      "loss: 0.317187  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440974 \n",
      "\n",
      "Epoch 2601\n",
      "-------------------------------\n",
      "loss: 0.312017  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441265 \n",
      "\n",
      "Epoch 2602\n",
      "-------------------------------\n",
      "loss: 0.314790  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441101 \n",
      "\n",
      "Epoch 2603\n",
      "-------------------------------\n",
      "loss: 0.317080  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441827 \n",
      "\n",
      "Epoch 2604\n",
      "-------------------------------\n",
      "loss: 0.312604  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443335 \n",
      "\n",
      "Epoch 2605\n",
      "-------------------------------\n",
      "loss: 0.320496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443844 \n",
      "\n",
      "Epoch 2606\n",
      "-------------------------------\n",
      "loss: 0.318861  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443468 \n",
      "\n",
      "Epoch 2607\n",
      "-------------------------------\n",
      "loss: 0.326964  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442320 \n",
      "\n",
      "Epoch 2608\n",
      "-------------------------------\n",
      "loss: 0.321896  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440775 \n",
      "\n",
      "Epoch 2609\n",
      "-------------------------------\n",
      "loss: 0.321805  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439479 \n",
      "\n",
      "Epoch 2610\n",
      "-------------------------------\n",
      "loss: 0.320267  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439607 \n",
      "\n",
      "Epoch 2611\n",
      "-------------------------------\n",
      "loss: 0.317072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439354 \n",
      "\n",
      "Epoch 2612\n",
      "-------------------------------\n",
      "loss: 0.319658  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439615 \n",
      "\n",
      "Epoch 2613\n",
      "-------------------------------\n",
      "loss: 0.320785  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440955 \n",
      "\n",
      "Epoch 2614\n",
      "-------------------------------\n",
      "loss: 0.314126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441349 \n",
      "\n",
      "Epoch 2615\n",
      "-------------------------------\n",
      "loss: 0.324174  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441626 \n",
      "\n",
      "Epoch 2616\n",
      "-------------------------------\n",
      "loss: 0.321227  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441347 \n",
      "\n",
      "Epoch 2617\n",
      "-------------------------------\n",
      "loss: 0.317495  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440276 \n",
      "\n",
      "Epoch 2618\n",
      "-------------------------------\n",
      "loss: 0.315273  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439307 \n",
      "\n",
      "Epoch 2619\n",
      "-------------------------------\n",
      "loss: 0.314785  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439375 \n",
      "\n",
      "Epoch 2620\n",
      "-------------------------------\n",
      "loss: 0.326234  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439633 \n",
      "\n",
      "Epoch 2621\n",
      "-------------------------------\n",
      "loss: 0.310408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439461 \n",
      "\n",
      "Epoch 2622\n",
      "-------------------------------\n",
      "loss: 0.316073  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440881 \n",
      "\n",
      "Epoch 2623\n",
      "-------------------------------\n",
      "loss: 0.324210  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441328 \n",
      "\n",
      "Epoch 2624\n",
      "-------------------------------\n",
      "loss: 0.311686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442180 \n",
      "\n",
      "Epoch 2625\n",
      "-------------------------------\n",
      "loss: 0.315782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444144 \n",
      "\n",
      "Epoch 2626\n",
      "-------------------------------\n",
      "loss: 0.324548  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444147 \n",
      "\n",
      "Epoch 2627\n",
      "-------------------------------\n",
      "loss: 0.316808  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443946 \n",
      "\n",
      "Epoch 2628\n",
      "-------------------------------\n",
      "loss: 0.316811  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445036 \n",
      "\n",
      "Epoch 2629\n",
      "-------------------------------\n",
      "loss: 0.315925  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444566 \n",
      "\n",
      "Epoch 2630\n",
      "-------------------------------\n",
      "loss: 0.322596  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.446116 \n",
      "\n",
      "Epoch 2631\n",
      "-------------------------------\n",
      "loss: 0.313135  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.445102 \n",
      "\n",
      "Epoch 2632\n",
      "-------------------------------\n",
      "loss: 0.317482  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443713 \n",
      "\n",
      "Epoch 2633\n",
      "-------------------------------\n",
      "loss: 0.312759  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442495 \n",
      "\n",
      "Epoch 2634\n",
      "-------------------------------\n",
      "loss: 0.321989  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440531 \n",
      "\n",
      "Epoch 2635\n",
      "-------------------------------\n",
      "loss: 0.319895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440115 \n",
      "\n",
      "Epoch 2636\n",
      "-------------------------------\n",
      "loss: 0.329315  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438980 \n",
      "\n",
      "Epoch 2637\n",
      "-------------------------------\n",
      "loss: 0.317112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438810 \n",
      "\n",
      "Epoch 2638\n",
      "-------------------------------\n",
      "loss: 0.319107  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438314 \n",
      "\n",
      "Epoch 2639\n",
      "-------------------------------\n",
      "loss: 0.318674  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438324 \n",
      "\n",
      "Epoch 2640\n",
      "-------------------------------\n",
      "loss: 0.318156  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438766 \n",
      "\n",
      "Epoch 2641\n",
      "-------------------------------\n",
      "loss: 0.317058  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439741 \n",
      "\n",
      "Epoch 2642\n",
      "-------------------------------\n",
      "loss: 0.320431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440318 \n",
      "\n",
      "Epoch 2643\n",
      "-------------------------------\n",
      "loss: 0.316563  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441787 \n",
      "\n",
      "Epoch 2644\n",
      "-------------------------------\n",
      "loss: 0.322128  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442711 \n",
      "\n",
      "Epoch 2645\n",
      "-------------------------------\n",
      "loss: 0.316445  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442539 \n",
      "\n",
      "Epoch 2646\n",
      "-------------------------------\n",
      "loss: 0.323874  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442299 \n",
      "\n",
      "Epoch 2647\n",
      "-------------------------------\n",
      "loss: 0.319774  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441499 \n",
      "\n",
      "Epoch 2648\n",
      "-------------------------------\n",
      "loss: 0.323084  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440245 \n",
      "\n",
      "Epoch 2649\n",
      "-------------------------------\n",
      "loss: 0.316798  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440004 \n",
      "\n",
      "Epoch 2650\n",
      "-------------------------------\n",
      "loss: 0.310209  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439272 \n",
      "\n",
      "Epoch 2651\n",
      "-------------------------------\n",
      "loss: 0.318672  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439214 \n",
      "\n",
      "Epoch 2652\n",
      "-------------------------------\n",
      "loss: 0.314415  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439799 \n",
      "\n",
      "Epoch 2653\n",
      "-------------------------------\n",
      "loss: 0.314591  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439792 \n",
      "\n",
      "Epoch 2654\n",
      "-------------------------------\n",
      "loss: 0.319008  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441228 \n",
      "\n",
      "Epoch 2655\n",
      "-------------------------------\n",
      "loss: 0.318936  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443201 \n",
      "\n",
      "Epoch 2656\n",
      "-------------------------------\n",
      "loss: 0.318068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444388 \n",
      "\n",
      "Epoch 2657\n",
      "-------------------------------\n",
      "loss: 0.326123  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444586 \n",
      "\n",
      "Epoch 2658\n",
      "-------------------------------\n",
      "loss: 0.323611  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443779 \n",
      "\n",
      "Epoch 2659\n",
      "-------------------------------\n",
      "loss: 0.313593  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444191 \n",
      "\n",
      "Epoch 2660\n",
      "-------------------------------\n",
      "loss: 0.319132  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443337 \n",
      "\n",
      "Epoch 2661\n",
      "-------------------------------\n",
      "loss: 0.320035  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442313 \n",
      "\n",
      "Epoch 2662\n",
      "-------------------------------\n",
      "loss: 0.317023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442700 \n",
      "\n",
      "Epoch 2663\n",
      "-------------------------------\n",
      "loss: 0.321487  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443348 \n",
      "\n",
      "Epoch 2664\n",
      "-------------------------------\n",
      "loss: 0.311873  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442681 \n",
      "\n",
      "Epoch 2665\n",
      "-------------------------------\n",
      "loss: 0.323025  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443415 \n",
      "\n",
      "Epoch 2666\n",
      "-------------------------------\n",
      "loss: 0.315050  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444193 \n",
      "\n",
      "Epoch 2667\n",
      "-------------------------------\n",
      "loss: 0.314547  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444792 \n",
      "\n",
      "Epoch 2668\n",
      "-------------------------------\n",
      "loss: 0.317355  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443276 \n",
      "\n",
      "Epoch 2669\n",
      "-------------------------------\n",
      "loss: 0.318015  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442022 \n",
      "\n",
      "Epoch 2670\n",
      "-------------------------------\n",
      "loss: 0.321854  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440045 \n",
      "\n",
      "Epoch 2671\n",
      "-------------------------------\n",
      "loss: 0.312098  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438780 \n",
      "\n",
      "Epoch 2672\n",
      "-------------------------------\n",
      "loss: 0.311574  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437921 \n",
      "\n",
      "Epoch 2673\n",
      "-------------------------------\n",
      "loss: 0.315672  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438971 \n",
      "\n",
      "Epoch 2674\n",
      "-------------------------------\n",
      "loss: 0.312413  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439972 \n",
      "\n",
      "Epoch 2675\n",
      "-------------------------------\n",
      "loss: 0.313267  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440756 \n",
      "\n",
      "Epoch 2676\n",
      "-------------------------------\n",
      "loss: 0.316894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441362 \n",
      "\n",
      "Epoch 2677\n",
      "-------------------------------\n",
      "loss: 0.318618  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441837 \n",
      "\n",
      "Epoch 2678\n",
      "-------------------------------\n",
      "loss: 0.315033  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443083 \n",
      "\n",
      "Epoch 2679\n",
      "-------------------------------\n",
      "loss: 0.312699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442665 \n",
      "\n",
      "Epoch 2680\n",
      "-------------------------------\n",
      "loss: 0.322843  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443253 \n",
      "\n",
      "Epoch 2681\n",
      "-------------------------------\n",
      "loss: 0.314878  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442147 \n",
      "\n",
      "Epoch 2682\n",
      "-------------------------------\n",
      "loss: 0.310049  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441625 \n",
      "\n",
      "Epoch 2683\n",
      "-------------------------------\n",
      "loss: 0.311836  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440364 \n",
      "\n",
      "Epoch 2684\n",
      "-------------------------------\n",
      "loss: 0.320981  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439855 \n",
      "\n",
      "Epoch 2685\n",
      "-------------------------------\n",
      "loss: 0.317885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439996 \n",
      "\n",
      "Epoch 2686\n",
      "-------------------------------\n",
      "loss: 0.316754  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439730 \n",
      "\n",
      "Epoch 2687\n",
      "-------------------------------\n",
      "loss: 0.315463  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440202 \n",
      "\n",
      "Epoch 2688\n",
      "-------------------------------\n",
      "loss: 0.315798  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440771 \n",
      "\n",
      "Epoch 2689\n",
      "-------------------------------\n",
      "loss: 0.323217  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440946 \n",
      "\n",
      "Epoch 2690\n",
      "-------------------------------\n",
      "loss: 0.309322  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441388 \n",
      "\n",
      "Epoch 2691\n",
      "-------------------------------\n",
      "loss: 0.310856  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440730 \n",
      "\n",
      "Epoch 2692\n",
      "-------------------------------\n",
      "loss: 0.313497  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440454 \n",
      "\n",
      "Epoch 2693\n",
      "-------------------------------\n",
      "loss: 0.314384  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440103 \n",
      "\n",
      "Epoch 2694\n",
      "-------------------------------\n",
      "loss: 0.317364  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440261 \n",
      "\n",
      "Epoch 2695\n",
      "-------------------------------\n",
      "loss: 0.314450  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440545 \n",
      "\n",
      "Epoch 2696\n",
      "-------------------------------\n",
      "loss: 0.314506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440298 \n",
      "\n",
      "Epoch 2697\n",
      "-------------------------------\n",
      "loss: 0.316191  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440637 \n",
      "\n",
      "Epoch 2698\n",
      "-------------------------------\n",
      "loss: 0.309237  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441569 \n",
      "\n",
      "Epoch 2699\n",
      "-------------------------------\n",
      "loss: 0.316696  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442131 \n",
      "\n",
      "Epoch 2700\n",
      "-------------------------------\n",
      "loss: 0.319264  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442754 \n",
      "\n",
      "Epoch 2701\n",
      "-------------------------------\n",
      "loss: 0.318180  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442541 \n",
      "\n",
      "Epoch 2702\n",
      "-------------------------------\n",
      "loss: 0.318717  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442283 \n",
      "\n",
      "Epoch 2703\n",
      "-------------------------------\n",
      "loss: 0.319980  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441414 \n",
      "\n",
      "Epoch 2704\n",
      "-------------------------------\n",
      "loss: 0.316329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441194 \n",
      "\n",
      "Epoch 2705\n",
      "-------------------------------\n",
      "loss: 0.318752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440932 \n",
      "\n",
      "Epoch 2706\n",
      "-------------------------------\n",
      "loss: 0.316503  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441208 \n",
      "\n",
      "Epoch 2707\n",
      "-------------------------------\n",
      "loss: 0.316031  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440880 \n",
      "\n",
      "Epoch 2708\n",
      "-------------------------------\n",
      "loss: 0.312557  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440814 \n",
      "\n",
      "Epoch 2709\n",
      "-------------------------------\n",
      "loss: 0.321483  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441833 \n",
      "\n",
      "Epoch 2710\n",
      "-------------------------------\n",
      "loss: 0.319115  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441758 \n",
      "\n",
      "Epoch 2711\n",
      "-------------------------------\n",
      "loss: 0.305893  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441988 \n",
      "\n",
      "Epoch 2712\n",
      "-------------------------------\n",
      "loss: 0.317199  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442311 \n",
      "\n",
      "Epoch 2713\n",
      "-------------------------------\n",
      "loss: 0.317910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443559 \n",
      "\n",
      "Epoch 2714\n",
      "-------------------------------\n",
      "loss: 0.314679  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443317 \n",
      "\n",
      "Epoch 2715\n",
      "-------------------------------\n",
      "loss: 0.321580  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444133 \n",
      "\n",
      "Epoch 2716\n",
      "-------------------------------\n",
      "loss: 0.321564  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442346 \n",
      "\n",
      "Epoch 2717\n",
      "-------------------------------\n",
      "loss: 0.316750  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441975 \n",
      "\n",
      "Epoch 2718\n",
      "-------------------------------\n",
      "loss: 0.316406  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441309 \n",
      "\n",
      "Epoch 2719\n",
      "-------------------------------\n",
      "loss: 0.311548  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441281 \n",
      "\n",
      "Epoch 2720\n",
      "-------------------------------\n",
      "loss: 0.314949  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441375 \n",
      "\n",
      "Epoch 2721\n",
      "-------------------------------\n",
      "loss: 0.319335  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441886 \n",
      "\n",
      "Epoch 2722\n",
      "-------------------------------\n",
      "loss: 0.307952  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442052 \n",
      "\n",
      "Epoch 2723\n",
      "-------------------------------\n",
      "loss: 0.321608  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440941 \n",
      "\n",
      "Epoch 2724\n",
      "-------------------------------\n",
      "loss: 0.324665  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440860 \n",
      "\n",
      "Epoch 2725\n",
      "-------------------------------\n",
      "loss: 0.311916  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440406 \n",
      "\n",
      "Epoch 2726\n",
      "-------------------------------\n",
      "loss: 0.313923  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439967 \n",
      "\n",
      "Epoch 2727\n",
      "-------------------------------\n",
      "loss: 0.315535  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441397 \n",
      "\n",
      "Epoch 2728\n",
      "-------------------------------\n",
      "loss: 0.315909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441252 \n",
      "\n",
      "Epoch 2729\n",
      "-------------------------------\n",
      "loss: 0.316823  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441971 \n",
      "\n",
      "Epoch 2730\n",
      "-------------------------------\n",
      "loss: 0.310773  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441057 \n",
      "\n",
      "Epoch 2731\n",
      "-------------------------------\n",
      "loss: 0.306279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440417 \n",
      "\n",
      "Epoch 2732\n",
      "-------------------------------\n",
      "loss: 0.311864  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440363 \n",
      "\n",
      "Epoch 2733\n",
      "-------------------------------\n",
      "loss: 0.319776  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440098 \n",
      "\n",
      "Epoch 2734\n",
      "-------------------------------\n",
      "loss: 0.313636  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439410 \n",
      "\n",
      "Epoch 2735\n",
      "-------------------------------\n",
      "loss: 0.308807  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440976 \n",
      "\n",
      "Epoch 2736\n",
      "-------------------------------\n",
      "loss: 0.315555  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441380 \n",
      "\n",
      "Epoch 2737\n",
      "-------------------------------\n",
      "loss: 0.315871  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440490 \n",
      "\n",
      "Epoch 2738\n",
      "-------------------------------\n",
      "loss: 0.319642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439897 \n",
      "\n",
      "Epoch 2739\n",
      "-------------------------------\n",
      "loss: 0.314211  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440857 \n",
      "\n",
      "Epoch 2740\n",
      "-------------------------------\n",
      "loss: 0.314673  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441674 \n",
      "\n",
      "Epoch 2741\n",
      "-------------------------------\n",
      "loss: 0.311792  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441453 \n",
      "\n",
      "Epoch 2742\n",
      "-------------------------------\n",
      "loss: 0.309625  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441727 \n",
      "\n",
      "Epoch 2743\n",
      "-------------------------------\n",
      "loss: 0.319083  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442484 \n",
      "\n",
      "Epoch 2744\n",
      "-------------------------------\n",
      "loss: 0.311057  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441759 \n",
      "\n",
      "Epoch 2745\n",
      "-------------------------------\n",
      "loss: 0.317898  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441410 \n",
      "\n",
      "Epoch 2746\n",
      "-------------------------------\n",
      "loss: 0.311320  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440592 \n",
      "\n",
      "Epoch 2747\n",
      "-------------------------------\n",
      "loss: 0.315796  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440485 \n",
      "\n",
      "Epoch 2748\n",
      "-------------------------------\n",
      "loss: 0.305471  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440169 \n",
      "\n",
      "Epoch 2749\n",
      "-------------------------------\n",
      "loss: 0.317931  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440011 \n",
      "\n",
      "Epoch 2750\n",
      "-------------------------------\n",
      "loss: 0.311730  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439522 \n",
      "\n",
      "Epoch 2751\n",
      "-------------------------------\n",
      "loss: 0.315695  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439797 \n",
      "\n",
      "Epoch 2752\n",
      "-------------------------------\n",
      "loss: 0.316625  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441007 \n",
      "\n",
      "Epoch 2753\n",
      "-------------------------------\n",
      "loss: 0.324997  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441510 \n",
      "\n",
      "Epoch 2754\n",
      "-------------------------------\n",
      "loss: 0.317255  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441700 \n",
      "\n",
      "Epoch 2755\n",
      "-------------------------------\n",
      "loss: 0.321435  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440835 \n",
      "\n",
      "Epoch 2756\n",
      "-------------------------------\n",
      "loss: 0.316689  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439897 \n",
      "\n",
      "Epoch 2757\n",
      "-------------------------------\n",
      "loss: 0.317460  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437811 \n",
      "\n",
      "Epoch 2758\n",
      "-------------------------------\n",
      "loss: 0.314421  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437541 \n",
      "\n",
      "Epoch 2759\n",
      "-------------------------------\n",
      "loss: 0.319554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.436742 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 2760\n",
      "-------------------------------\n",
      "loss: 0.314569  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437079 \n",
      "\n",
      "Epoch 2761\n",
      "-------------------------------\n",
      "loss: 0.310812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.436944 \n",
      "\n",
      "Epoch 2762\n",
      "-------------------------------\n",
      "loss: 0.324306  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437271 \n",
      "\n",
      "Epoch 2763\n",
      "-------------------------------\n",
      "loss: 0.311761  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438094 \n",
      "\n",
      "Epoch 2764\n",
      "-------------------------------\n",
      "loss: 0.323836  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438679 \n",
      "\n",
      "Epoch 2765\n",
      "-------------------------------\n",
      "loss: 0.307534  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439589 \n",
      "\n",
      "Epoch 2766\n",
      "-------------------------------\n",
      "loss: 0.319485  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440762 \n",
      "\n",
      "Epoch 2767\n",
      "-------------------------------\n",
      "loss: 0.319937  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440411 \n",
      "\n",
      "Epoch 2768\n",
      "-------------------------------\n",
      "loss: 0.313946  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439529 \n",
      "\n",
      "Epoch 2769\n",
      "-------------------------------\n",
      "loss: 0.310757  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439886 \n",
      "\n",
      "Epoch 2770\n",
      "-------------------------------\n",
      "loss: 0.326429  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439173 \n",
      "\n",
      "Epoch 2771\n",
      "-------------------------------\n",
      "loss: 0.311083  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439725 \n",
      "\n",
      "Epoch 2772\n",
      "-------------------------------\n",
      "loss: 0.318600  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439524 \n",
      "\n",
      "Epoch 2773\n",
      "-------------------------------\n",
      "loss: 0.315384  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440264 \n",
      "\n",
      "Epoch 2774\n",
      "-------------------------------\n",
      "loss: 0.321640  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440743 \n",
      "\n",
      "Epoch 2775\n",
      "-------------------------------\n",
      "loss: 0.319097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440749 \n",
      "\n",
      "Epoch 2776\n",
      "-------------------------------\n",
      "loss: 0.310938  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442042 \n",
      "\n",
      "Epoch 2777\n",
      "-------------------------------\n",
      "loss: 0.315151  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443435 \n",
      "\n",
      "Epoch 2778\n",
      "-------------------------------\n",
      "loss: 0.315746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443222 \n",
      "\n",
      "Epoch 2779\n",
      "-------------------------------\n",
      "loss: 0.318343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444132 \n",
      "\n",
      "Epoch 2780\n",
      "-------------------------------\n",
      "loss: 0.312270  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444564 \n",
      "\n",
      "Epoch 2781\n",
      "-------------------------------\n",
      "loss: 0.309165  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444062 \n",
      "\n",
      "Epoch 2782\n",
      "-------------------------------\n",
      "loss: 0.313075  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.443473 \n",
      "\n",
      "Epoch 2783\n",
      "-------------------------------\n",
      "loss: 0.313437  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443331 \n",
      "\n",
      "Epoch 2784\n",
      "-------------------------------\n",
      "loss: 0.325432  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443138 \n",
      "\n",
      "Epoch 2785\n",
      "-------------------------------\n",
      "loss: 0.313952  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442456 \n",
      "\n",
      "Epoch 2786\n",
      "-------------------------------\n",
      "loss: 0.320427  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441431 \n",
      "\n",
      "Epoch 2787\n",
      "-------------------------------\n",
      "loss: 0.318469  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441383 \n",
      "\n",
      "Epoch 2788\n",
      "-------------------------------\n",
      "loss: 0.317691  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441127 \n",
      "\n",
      "Epoch 2789\n",
      "-------------------------------\n",
      "loss: 0.315498  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441285 \n",
      "\n",
      "Epoch 2790\n",
      "-------------------------------\n",
      "loss: 0.319127  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440916 \n",
      "\n",
      "Epoch 2791\n",
      "-------------------------------\n",
      "loss: 0.313603  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441675 \n",
      "\n",
      "Epoch 2792\n",
      "-------------------------------\n",
      "loss: 0.310326  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441102 \n",
      "\n",
      "Epoch 2793\n",
      "-------------------------------\n",
      "loss: 0.309697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442163 \n",
      "\n",
      "Epoch 2794\n",
      "-------------------------------\n",
      "loss: 0.314546  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442480 \n",
      "\n",
      "Epoch 2795\n",
      "-------------------------------\n",
      "loss: 0.315601  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443291 \n",
      "\n",
      "Epoch 2796\n",
      "-------------------------------\n",
      "loss: 0.317311  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443036 \n",
      "\n",
      "Epoch 2797\n",
      "-------------------------------\n",
      "loss: 0.311315  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443246 \n",
      "\n",
      "Epoch 2798\n",
      "-------------------------------\n",
      "loss: 0.312447  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443299 \n",
      "\n",
      "Epoch 2799\n",
      "-------------------------------\n",
      "loss: 0.311768  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442496 \n",
      "\n",
      "Epoch 2800\n",
      "-------------------------------\n",
      "loss: 0.322772  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441223 \n",
      "\n",
      "Epoch 2801\n",
      "-------------------------------\n",
      "loss: 0.313957  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441349 \n",
      "\n",
      "Epoch 2802\n",
      "-------------------------------\n",
      "loss: 0.320790  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441506 \n",
      "\n",
      "Epoch 2803\n",
      "-------------------------------\n",
      "loss: 0.314340  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442047 \n",
      "\n",
      "Epoch 2804\n",
      "-------------------------------\n",
      "loss: 0.318276  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442055 \n",
      "\n",
      "Epoch 2805\n",
      "-------------------------------\n",
      "loss: 0.314732  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443097 \n",
      "\n",
      "Epoch 2806\n",
      "-------------------------------\n",
      "loss: 0.316870  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442365 \n",
      "\n",
      "Epoch 2807\n",
      "-------------------------------\n",
      "loss: 0.321758  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442726 \n",
      "\n",
      "Epoch 2808\n",
      "-------------------------------\n",
      "loss: 0.318632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443371 \n",
      "\n",
      "Epoch 2809\n",
      "-------------------------------\n",
      "loss: 0.316108  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443554 \n",
      "\n",
      "Epoch 2810\n",
      "-------------------------------\n",
      "loss: 0.318161  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442954 \n",
      "\n",
      "Epoch 2811\n",
      "-------------------------------\n",
      "loss: 0.314078  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443211 \n",
      "\n",
      "Epoch 2812\n",
      "-------------------------------\n",
      "loss: 0.314505  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443100 \n",
      "\n",
      "Epoch 2813\n",
      "-------------------------------\n",
      "loss: 0.314314  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443089 \n",
      "\n",
      "Epoch 2814\n",
      "-------------------------------\n",
      "loss: 0.307396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443722 \n",
      "\n",
      "Epoch 2815\n",
      "-------------------------------\n",
      "loss: 0.318358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443519 \n",
      "\n",
      "Epoch 2816\n",
      "-------------------------------\n",
      "loss: 0.308219  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442825 \n",
      "\n",
      "Epoch 2817\n",
      "-------------------------------\n",
      "loss: 0.314438  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441084 \n",
      "\n",
      "Epoch 2818\n",
      "-------------------------------\n",
      "loss: 0.318444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440970 \n",
      "\n",
      "Epoch 2819\n",
      "-------------------------------\n",
      "loss: 0.320453  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440994 \n",
      "\n",
      "Epoch 2820\n",
      "-------------------------------\n",
      "loss: 0.307583  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440321 \n",
      "\n",
      "Epoch 2821\n",
      "-------------------------------\n",
      "loss: 0.323697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440435 \n",
      "\n",
      "Epoch 2822\n",
      "-------------------------------\n",
      "loss: 0.313938  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440326 \n",
      "\n",
      "Epoch 2823\n",
      "-------------------------------\n",
      "loss: 0.318168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439988 \n",
      "\n",
      "Epoch 2824\n",
      "-------------------------------\n",
      "loss: 0.315016  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440618 \n",
      "\n",
      "Epoch 2825\n",
      "-------------------------------\n",
      "loss: 0.313122  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440572 \n",
      "\n",
      "Epoch 2826\n",
      "-------------------------------\n",
      "loss: 0.316019  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440272 \n",
      "\n",
      "Epoch 2827\n",
      "-------------------------------\n",
      "loss: 0.318368  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440135 \n",
      "\n",
      "Epoch 2828\n",
      "-------------------------------\n",
      "loss: 0.320275  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440960 \n",
      "\n",
      "Epoch 2829\n",
      "-------------------------------\n",
      "loss: 0.316554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440723 \n",
      "\n",
      "Epoch 2830\n",
      "-------------------------------\n",
      "loss: 0.313813  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441647 \n",
      "\n",
      "Epoch 2831\n",
      "-------------------------------\n",
      "loss: 0.319036  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441411 \n",
      "\n",
      "Epoch 2832\n",
      "-------------------------------\n",
      "loss: 0.314383  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442342 \n",
      "\n",
      "Epoch 2833\n",
      "-------------------------------\n",
      "loss: 0.316258  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442220 \n",
      "\n",
      "Epoch 2834\n",
      "-------------------------------\n",
      "loss: 0.319214  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442471 \n",
      "\n",
      "Epoch 2835\n",
      "-------------------------------\n",
      "loss: 0.314608  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442494 \n",
      "\n",
      "Epoch 2836\n",
      "-------------------------------\n",
      "loss: 0.315765  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441586 \n",
      "\n",
      "Epoch 2837\n",
      "-------------------------------\n",
      "loss: 0.318447  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441923 \n",
      "\n",
      "Epoch 2838\n",
      "-------------------------------\n",
      "loss: 0.319470  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441397 \n",
      "\n",
      "Epoch 2839\n",
      "-------------------------------\n",
      "loss: 0.323685  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441838 \n",
      "\n",
      "Epoch 2840\n",
      "-------------------------------\n",
      "loss: 0.302177  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441850 \n",
      "\n",
      "Epoch 2841\n",
      "-------------------------------\n",
      "loss: 0.311667  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441423 \n",
      "\n",
      "Epoch 2842\n",
      "-------------------------------\n",
      "loss: 0.309253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441809 \n",
      "\n",
      "Epoch 2843\n",
      "-------------------------------\n",
      "loss: 0.311554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441625 \n",
      "\n",
      "Epoch 2844\n",
      "-------------------------------\n",
      "loss: 0.313566  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441091 \n",
      "\n",
      "Epoch 2845\n",
      "-------------------------------\n",
      "loss: 0.314322  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440813 \n",
      "\n",
      "Epoch 2846\n",
      "-------------------------------\n",
      "loss: 0.307760  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440892 \n",
      "\n",
      "Epoch 2847\n",
      "-------------------------------\n",
      "loss: 0.319682  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441178 \n",
      "\n",
      "Epoch 2848\n",
      "-------------------------------\n",
      "loss: 0.314329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441877 \n",
      "\n",
      "Epoch 2849\n",
      "-------------------------------\n",
      "loss: 0.313843  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442842 \n",
      "\n",
      "Epoch 2850\n",
      "-------------------------------\n",
      "loss: 0.310294  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442252 \n",
      "\n",
      "Epoch 2851\n",
      "-------------------------------\n",
      "loss: 0.314306  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441859 \n",
      "\n",
      "Epoch 2852\n",
      "-------------------------------\n",
      "loss: 0.314377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440393 \n",
      "\n",
      "Epoch 2853\n",
      "-------------------------------\n",
      "loss: 0.309064  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439726 \n",
      "\n",
      "Epoch 2854\n",
      "-------------------------------\n",
      "loss: 0.318105  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438955 \n",
      "\n",
      "Epoch 2855\n",
      "-------------------------------\n",
      "loss: 0.311725  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438587 \n",
      "\n",
      "Epoch 2856\n",
      "-------------------------------\n",
      "loss: 0.320100  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438554 \n",
      "\n",
      "Epoch 2857\n",
      "-------------------------------\n",
      "loss: 0.319528  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439528 \n",
      "\n",
      "Epoch 2858\n",
      "-------------------------------\n",
      "loss: 0.315780  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.439452 \n",
      "\n",
      "Epoch 2859\n",
      "-------------------------------\n",
      "loss: 0.319330  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439626 \n",
      "\n",
      "Epoch 2860\n",
      "-------------------------------\n",
      "loss: 0.316755  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439913 \n",
      "\n",
      "Epoch 2861\n",
      "-------------------------------\n",
      "loss: 0.315562  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440383 \n",
      "\n",
      "Epoch 2862\n",
      "-------------------------------\n",
      "loss: 0.308138  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440251 \n",
      "\n",
      "Epoch 2863\n",
      "-------------------------------\n",
      "loss: 0.316046  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441285 \n",
      "\n",
      "Epoch 2864\n",
      "-------------------------------\n",
      "loss: 0.314120  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440752 \n",
      "\n",
      "Epoch 2865\n",
      "-------------------------------\n",
      "loss: 0.314652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441747 \n",
      "\n",
      "Epoch 2866\n",
      "-------------------------------\n",
      "loss: 0.315442  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441696 \n",
      "\n",
      "Epoch 2867\n",
      "-------------------------------\n",
      "loss: 0.319620  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442002 \n",
      "\n",
      "Epoch 2868\n",
      "-------------------------------\n",
      "loss: 0.317673  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442839 \n",
      "\n",
      "Epoch 2869\n",
      "-------------------------------\n",
      "loss: 0.312511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443367 \n",
      "\n",
      "Epoch 2870\n",
      "-------------------------------\n",
      "loss: 0.310898  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443168 \n",
      "\n",
      "Epoch 2871\n",
      "-------------------------------\n",
      "loss: 0.311357  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442442 \n",
      "\n",
      "Epoch 2872\n",
      "-------------------------------\n",
      "loss: 0.314876  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441005 \n",
      "\n",
      "Epoch 2873\n",
      "-------------------------------\n",
      "loss: 0.310730  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440267 \n",
      "\n",
      "Epoch 2874\n",
      "-------------------------------\n",
      "loss: 0.320863  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439834 \n",
      "\n",
      "Epoch 2875\n",
      "-------------------------------\n",
      "loss: 0.315475  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439015 \n",
      "\n",
      "Epoch 2876\n",
      "-------------------------------\n",
      "loss: 0.313643  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438881 \n",
      "\n",
      "Epoch 2877\n",
      "-------------------------------\n",
      "loss: 0.314715  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439255 \n",
      "\n",
      "Epoch 2878\n",
      "-------------------------------\n",
      "loss: 0.313473  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439384 \n",
      "\n",
      "Epoch 2879\n",
      "-------------------------------\n",
      "loss: 0.319474  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440178 \n",
      "\n",
      "Epoch 2880\n",
      "-------------------------------\n",
      "loss: 0.312756  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439828 \n",
      "\n",
      "Epoch 2881\n",
      "-------------------------------\n",
      "loss: 0.308543  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441442 \n",
      "\n",
      "Epoch 2882\n",
      "-------------------------------\n",
      "loss: 0.317330  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442215 \n",
      "\n",
      "Epoch 2883\n",
      "-------------------------------\n",
      "loss: 0.319053  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441794 \n",
      "\n",
      "Epoch 2884\n",
      "-------------------------------\n",
      "loss: 0.315471  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440880 \n",
      "\n",
      "Epoch 2885\n",
      "-------------------------------\n",
      "loss: 0.310381  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440601 \n",
      "\n",
      "Epoch 2886\n",
      "-------------------------------\n",
      "loss: 0.313260  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440897 \n",
      "\n",
      "Epoch 2887\n",
      "-------------------------------\n",
      "loss: 0.309211  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441157 \n",
      "\n",
      "Epoch 2888\n",
      "-------------------------------\n",
      "loss: 0.318436  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440893 \n",
      "\n",
      "Epoch 2889\n",
      "-------------------------------\n",
      "loss: 0.317548  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441512 \n",
      "\n",
      "Epoch 2890\n",
      "-------------------------------\n",
      "loss: 0.312604  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441209 \n",
      "\n",
      "Epoch 2891\n",
      "-------------------------------\n",
      "loss: 0.313224  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441303 \n",
      "\n",
      "Epoch 2892\n",
      "-------------------------------\n",
      "loss: 0.312488  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441947 \n",
      "\n",
      "Epoch 2893\n",
      "-------------------------------\n",
      "loss: 0.318161  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443185 \n",
      "\n",
      "Epoch 2894\n",
      "-------------------------------\n",
      "loss: 0.312981  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443160 \n",
      "\n",
      "Epoch 2895\n",
      "-------------------------------\n",
      "loss: 0.309713  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442905 \n",
      "\n",
      "Epoch 2896\n",
      "-------------------------------\n",
      "loss: 0.312112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444027 \n",
      "\n",
      "Epoch 2897\n",
      "-------------------------------\n",
      "loss: 0.310728  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443312 \n",
      "\n",
      "Epoch 2898\n",
      "-------------------------------\n",
      "loss: 0.310790  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443399 \n",
      "\n",
      "Epoch 2899\n",
      "-------------------------------\n",
      "loss: 0.310585  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442400 \n",
      "\n",
      "Epoch 2900\n",
      "-------------------------------\n",
      "loss: 0.311238  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442130 \n",
      "\n",
      "Epoch 2901\n",
      "-------------------------------\n",
      "loss: 0.319239  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442302 \n",
      "\n",
      "Epoch 2902\n",
      "-------------------------------\n",
      "loss: 0.314205  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442437 \n",
      "\n",
      "Epoch 2903\n",
      "-------------------------------\n",
      "loss: 0.315771  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441455 \n",
      "\n",
      "Epoch 2904\n",
      "-------------------------------\n",
      "loss: 0.313125  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441592 \n",
      "\n",
      "Epoch 2905\n",
      "-------------------------------\n",
      "loss: 0.304930  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441172 \n",
      "\n",
      "Epoch 2906\n",
      "-------------------------------\n",
      "loss: 0.304829  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441271 \n",
      "\n",
      "Epoch 2907\n",
      "-------------------------------\n",
      "loss: 0.318881  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441050 \n",
      "\n",
      "Epoch 2908\n",
      "-------------------------------\n",
      "loss: 0.318124  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440424 \n",
      "\n",
      "Epoch 2909\n",
      "-------------------------------\n",
      "loss: 0.313942  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440009 \n",
      "\n",
      "Epoch 2910\n",
      "-------------------------------\n",
      "loss: 0.319323  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439644 \n",
      "\n",
      "Epoch 2911\n",
      "-------------------------------\n",
      "loss: 0.304135  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439674 \n",
      "\n",
      "Epoch 2912\n",
      "-------------------------------\n",
      "loss: 0.318088  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439641 \n",
      "\n",
      "Epoch 2913\n",
      "-------------------------------\n",
      "loss: 0.323910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440470 \n",
      "\n",
      "Epoch 2914\n",
      "-------------------------------\n",
      "loss: 0.316912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441854 \n",
      "\n",
      "Epoch 2915\n",
      "-------------------------------\n",
      "loss: 0.313239  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441906 \n",
      "\n",
      "Epoch 2916\n",
      "-------------------------------\n",
      "loss: 0.313018  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442096 \n",
      "\n",
      "Epoch 2917\n",
      "-------------------------------\n",
      "loss: 0.308372  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442529 \n",
      "\n",
      "Epoch 2918\n",
      "-------------------------------\n",
      "loss: 0.319565  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442681 \n",
      "\n",
      "Epoch 2919\n",
      "-------------------------------\n",
      "loss: 0.318386  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442256 \n",
      "\n",
      "Epoch 2920\n",
      "-------------------------------\n",
      "loss: 0.321083  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441471 \n",
      "\n",
      "Epoch 2921\n",
      "-------------------------------\n",
      "loss: 0.319576  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441468 \n",
      "\n",
      "Epoch 2922\n",
      "-------------------------------\n",
      "loss: 0.309565  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442421 \n",
      "\n",
      "Epoch 2923\n",
      "-------------------------------\n",
      "loss: 0.316318  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440932 \n",
      "\n",
      "Epoch 2924\n",
      "-------------------------------\n",
      "loss: 0.309016  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440187 \n",
      "\n",
      "Epoch 2925\n",
      "-------------------------------\n",
      "loss: 0.306171  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439906 \n",
      "\n",
      "Epoch 2926\n",
      "-------------------------------\n",
      "loss: 0.311112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439644 \n",
      "\n",
      "Epoch 2927\n",
      "-------------------------------\n",
      "loss: 0.317512  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438630 \n",
      "\n",
      "Epoch 2928\n",
      "-------------------------------\n",
      "loss: 0.313736  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439151 \n",
      "\n",
      "Epoch 2929\n",
      "-------------------------------\n",
      "loss: 0.308848  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439509 \n",
      "\n",
      "Epoch 2930\n",
      "-------------------------------\n",
      "loss: 0.314011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440169 \n",
      "\n",
      "Epoch 2931\n",
      "-------------------------------\n",
      "loss: 0.317918  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440589 \n",
      "\n",
      "Epoch 2932\n",
      "-------------------------------\n",
      "loss: 0.313111  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440099 \n",
      "\n",
      "Epoch 2933\n",
      "-------------------------------\n",
      "loss: 0.317461  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441183 \n",
      "\n",
      "Epoch 2934\n",
      "-------------------------------\n",
      "loss: 0.316819  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440672 \n",
      "\n",
      "Epoch 2935\n",
      "-------------------------------\n",
      "loss: 0.308632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441773 \n",
      "\n",
      "Epoch 2936\n",
      "-------------------------------\n",
      "loss: 0.311244  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442124 \n",
      "\n",
      "Epoch 2937\n",
      "-------------------------------\n",
      "loss: 0.313850  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442152 \n",
      "\n",
      "Epoch 2938\n",
      "-------------------------------\n",
      "loss: 0.317634  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442693 \n",
      "\n",
      "Epoch 2939\n",
      "-------------------------------\n",
      "loss: 0.313445  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440887 \n",
      "\n",
      "Epoch 2940\n",
      "-------------------------------\n",
      "loss: 0.317347  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441059 \n",
      "\n",
      "Epoch 2941\n",
      "-------------------------------\n",
      "loss: 0.318873  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439989 \n",
      "\n",
      "Epoch 2942\n",
      "-------------------------------\n",
      "loss: 0.321272  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439547 \n",
      "\n",
      "Epoch 2943\n",
      "-------------------------------\n",
      "loss: 0.313565  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439077 \n",
      "\n",
      "Epoch 2944\n",
      "-------------------------------\n",
      "loss: 0.307662  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439261 \n",
      "\n",
      "Epoch 2945\n",
      "-------------------------------\n",
      "loss: 0.317160  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439953 \n",
      "\n",
      "Epoch 2946\n",
      "-------------------------------\n",
      "loss: 0.312825  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439950 \n",
      "\n",
      "Epoch 2947\n",
      "-------------------------------\n",
      "loss: 0.315706  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440378 \n",
      "\n",
      "Epoch 2948\n",
      "-------------------------------\n",
      "loss: 0.313080  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442021 \n",
      "\n",
      "Epoch 2949\n",
      "-------------------------------\n",
      "loss: 0.324233  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443247 \n",
      "\n",
      "Epoch 2950\n",
      "-------------------------------\n",
      "loss: 0.319389  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443386 \n",
      "\n",
      "Epoch 2951\n",
      "-------------------------------\n",
      "loss: 0.324806  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441127 \n",
      "\n",
      "Epoch 2952\n",
      "-------------------------------\n",
      "loss: 0.309963  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440043 \n",
      "\n",
      "Epoch 2953\n",
      "-------------------------------\n",
      "loss: 0.315033  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437953 \n",
      "\n",
      "Epoch 2954\n",
      "-------------------------------\n",
      "loss: 0.306619  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438662 \n",
      "\n",
      "Epoch 2955\n",
      "-------------------------------\n",
      "loss: 0.312479  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438749 \n",
      "\n",
      "Epoch 2956\n",
      "-------------------------------\n",
      "loss: 0.310439  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439537 \n",
      "\n",
      "Epoch 2957\n",
      "-------------------------------\n",
      "loss: 0.319891  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439583 \n",
      "\n",
      "Epoch 2958\n",
      "-------------------------------\n",
      "loss: 0.311203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440220 \n",
      "\n",
      "Epoch 2959\n",
      "-------------------------------\n",
      "loss: 0.312841  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440575 \n",
      "\n",
      "Epoch 2960\n",
      "-------------------------------\n",
      "loss: 0.314288  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440383 \n",
      "\n",
      "Epoch 2961\n",
      "-------------------------------\n",
      "loss: 0.312038  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439935 \n",
      "\n",
      "Epoch 2962\n",
      "-------------------------------\n",
      "loss: 0.310024  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439914 \n",
      "\n",
      "Epoch 2963\n",
      "-------------------------------\n",
      "loss: 0.311622  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440091 \n",
      "\n",
      "Epoch 2964\n",
      "-------------------------------\n",
      "loss: 0.307888  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439085 \n",
      "\n",
      "Epoch 2965\n",
      "-------------------------------\n",
      "loss: 0.308065  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439137 \n",
      "\n",
      "Epoch 2966\n",
      "-------------------------------\n",
      "loss: 0.312417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439274 \n",
      "\n",
      "Epoch 2967\n",
      "-------------------------------\n",
      "loss: 0.315595  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439266 \n",
      "\n",
      "Epoch 2968\n",
      "-------------------------------\n",
      "loss: 0.312225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440153 \n",
      "\n",
      "Epoch 2969\n",
      "-------------------------------\n",
      "loss: 0.313213  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439179 \n",
      "\n",
      "Epoch 2970\n",
      "-------------------------------\n",
      "loss: 0.313215  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439207 \n",
      "\n",
      "Epoch 2971\n",
      "-------------------------------\n",
      "loss: 0.311569  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440178 \n",
      "\n",
      "Epoch 2972\n",
      "-------------------------------\n",
      "loss: 0.307679  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440321 \n",
      "\n",
      "Epoch 2973\n",
      "-------------------------------\n",
      "loss: 0.311909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440437 \n",
      "\n",
      "Epoch 2974\n",
      "-------------------------------\n",
      "loss: 0.319180  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440280 \n",
      "\n",
      "Epoch 2975\n",
      "-------------------------------\n",
      "loss: 0.312300  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439825 \n",
      "\n",
      "Epoch 2976\n",
      "-------------------------------\n",
      "loss: 0.311452  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439576 \n",
      "\n",
      "Epoch 2977\n",
      "-------------------------------\n",
      "loss: 0.319715  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439774 \n",
      "\n",
      "Epoch 2978\n",
      "-------------------------------\n",
      "loss: 0.307388  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439758 \n",
      "\n",
      "Epoch 2979\n",
      "-------------------------------\n",
      "loss: 0.310532  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440094 \n",
      "\n",
      "Epoch 2980\n",
      "-------------------------------\n",
      "loss: 0.315398  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439404 \n",
      "\n",
      "Epoch 2981\n",
      "-------------------------------\n",
      "loss: 0.316247  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440251 \n",
      "\n",
      "Epoch 2982\n",
      "-------------------------------\n",
      "loss: 0.313004  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439403 \n",
      "\n",
      "Epoch 2983\n",
      "-------------------------------\n",
      "loss: 0.320299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439252 \n",
      "\n",
      "Epoch 2984\n",
      "-------------------------------\n",
      "loss: 0.314021  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438947 \n",
      "\n",
      "Epoch 2985\n",
      "-------------------------------\n",
      "loss: 0.327388  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438751 \n",
      "\n",
      "Epoch 2986\n",
      "-------------------------------\n",
      "loss: 0.311118  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439919 \n",
      "\n",
      "Epoch 2987\n",
      "-------------------------------\n",
      "loss: 0.301744  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440526 \n",
      "\n",
      "Epoch 2988\n",
      "-------------------------------\n",
      "loss: 0.311391  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441665 \n",
      "\n",
      "Epoch 2989\n",
      "-------------------------------\n",
      "loss: 0.306663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441250 \n",
      "\n",
      "Epoch 2990\n",
      "-------------------------------\n",
      "loss: 0.316461  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443281 \n",
      "\n",
      "Epoch 2991\n",
      "-------------------------------\n",
      "loss: 0.320958  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443606 \n",
      "\n",
      "Epoch 2992\n",
      "-------------------------------\n",
      "loss: 0.312453  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443082 \n",
      "\n",
      "Epoch 2993\n",
      "-------------------------------\n",
      "loss: 0.307957  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442186 \n",
      "\n",
      "Epoch 2994\n",
      "-------------------------------\n",
      "loss: 0.314443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441466 \n",
      "\n",
      "Epoch 2995\n",
      "-------------------------------\n",
      "loss: 0.313346  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441390 \n",
      "\n",
      "Epoch 2996\n",
      "-------------------------------\n",
      "loss: 0.312216  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440816 \n",
      "\n",
      "Epoch 2997\n",
      "-------------------------------\n",
      "loss: 0.304448  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440441 \n",
      "\n",
      "Epoch 2998\n",
      "-------------------------------\n",
      "loss: 0.305571  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439279 \n",
      "\n",
      "Epoch 2999\n",
      "-------------------------------\n",
      "loss: 0.309293  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439757 \n",
      "\n",
      "Epoch 3000\n",
      "-------------------------------\n",
      "loss: 0.306841  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440739 \n",
      "\n",
      "Epoch 3001\n",
      "-------------------------------\n",
      "loss: 0.313270  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441619 \n",
      "\n",
      "Epoch 3002\n",
      "-------------------------------\n",
      "loss: 0.311276  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441073 \n",
      "\n",
      "Epoch 3003\n",
      "-------------------------------\n",
      "loss: 0.315536  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440806 \n",
      "\n",
      "Epoch 3004\n",
      "-------------------------------\n",
      "loss: 0.319646  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441362 \n",
      "\n",
      "Epoch 3005\n",
      "-------------------------------\n",
      "loss: 0.312817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439411 \n",
      "\n",
      "Epoch 3006\n",
      "-------------------------------\n",
      "loss: 0.318199  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438669 \n",
      "\n",
      "Epoch 3007\n",
      "-------------------------------\n",
      "loss: 0.309483  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439333 \n",
      "\n",
      "Epoch 3008\n",
      "-------------------------------\n",
      "loss: 0.311456  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439927 \n",
      "\n",
      "Epoch 3009\n",
      "-------------------------------\n",
      "loss: 0.309460  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439877 \n",
      "\n",
      "Epoch 3010\n",
      "-------------------------------\n",
      "loss: 0.309823  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440541 \n",
      "\n",
      "Epoch 3011\n",
      "-------------------------------\n",
      "loss: 0.320642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441462 \n",
      "\n",
      "Epoch 3012\n",
      "-------------------------------\n",
      "loss: 0.319873  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441601 \n",
      "\n",
      "Epoch 3013\n",
      "-------------------------------\n",
      "loss: 0.305492  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441595 \n",
      "\n",
      "Epoch 3014\n",
      "-------------------------------\n",
      "loss: 0.316159  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440859 \n",
      "\n",
      "Epoch 3015\n",
      "-------------------------------\n",
      "loss: 0.314953  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440213 \n",
      "\n",
      "Epoch 3016\n",
      "-------------------------------\n",
      "loss: 0.306890  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440767 \n",
      "\n",
      "Epoch 3017\n",
      "-------------------------------\n",
      "loss: 0.315796  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438963 \n",
      "\n",
      "Epoch 3018\n",
      "-------------------------------\n",
      "loss: 0.316035  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439355 \n",
      "\n",
      "Epoch 3019\n",
      "-------------------------------\n",
      "loss: 0.309068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439163 \n",
      "\n",
      "Epoch 3020\n",
      "-------------------------------\n",
      "loss: 0.314114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440350 \n",
      "\n",
      "Epoch 3021\n",
      "-------------------------------\n",
      "loss: 0.318731  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440692 \n",
      "\n",
      "Epoch 3022\n",
      "-------------------------------\n",
      "loss: 0.313795  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440305 \n",
      "\n",
      "Epoch 3023\n",
      "-------------------------------\n",
      "loss: 0.316530  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440135 \n",
      "\n",
      "Epoch 3024\n",
      "-------------------------------\n",
      "loss: 0.310742  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440020 \n",
      "\n",
      "Epoch 3025\n",
      "-------------------------------\n",
      "loss: 0.310684  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440496 \n",
      "\n",
      "Epoch 3026\n",
      "-------------------------------\n",
      "loss: 0.301549  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441224 \n",
      "\n",
      "Epoch 3027\n",
      "-------------------------------\n",
      "loss: 0.305658  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440879 \n",
      "\n",
      "Epoch 3028\n",
      "-------------------------------\n",
      "loss: 0.315154  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440668 \n",
      "\n",
      "Epoch 3029\n",
      "-------------------------------\n",
      "loss: 0.319544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441327 \n",
      "\n",
      "Epoch 3030\n",
      "-------------------------------\n",
      "loss: 0.307529  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441407 \n",
      "\n",
      "Epoch 3031\n",
      "-------------------------------\n",
      "loss: 0.311556  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441580 \n",
      "\n",
      "Epoch 3032\n",
      "-------------------------------\n",
      "loss: 0.305164  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442359 \n",
      "\n",
      "Epoch 3033\n",
      "-------------------------------\n",
      "loss: 0.314012  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442800 \n",
      "\n",
      "Epoch 3034\n",
      "-------------------------------\n",
      "loss: 0.311856  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440885 \n",
      "\n",
      "Epoch 3035\n",
      "-------------------------------\n",
      "loss: 0.314861  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441171 \n",
      "\n",
      "Epoch 3036\n",
      "-------------------------------\n",
      "loss: 0.315182  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440165 \n",
      "\n",
      "Epoch 3037\n",
      "-------------------------------\n",
      "loss: 0.308472  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440495 \n",
      "\n",
      "Epoch 3038\n",
      "-------------------------------\n",
      "loss: 0.305721  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439924 \n",
      "\n",
      "Epoch 3039\n",
      "-------------------------------\n",
      "loss: 0.310761  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441161 \n",
      "\n",
      "Epoch 3040\n",
      "-------------------------------\n",
      "loss: 0.315278  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440841 \n",
      "\n",
      "Epoch 3041\n",
      "-------------------------------\n",
      "loss: 0.313191  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440900 \n",
      "\n",
      "Epoch 3042\n",
      "-------------------------------\n",
      "loss: 0.312699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441270 \n",
      "\n",
      "Epoch 3043\n",
      "-------------------------------\n",
      "loss: 0.315384  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442091 \n",
      "\n",
      "Epoch 3044\n",
      "-------------------------------\n",
      "loss: 0.317039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441783 \n",
      "\n",
      "Epoch 3045\n",
      "-------------------------------\n",
      "loss: 0.316975  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441857 \n",
      "\n",
      "Epoch 3046\n",
      "-------------------------------\n",
      "loss: 0.313621  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440614 \n",
      "\n",
      "Epoch 3047\n",
      "-------------------------------\n",
      "loss: 0.312912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439587 \n",
      "\n",
      "Epoch 3048\n",
      "-------------------------------\n",
      "loss: 0.308365  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439087 \n",
      "\n",
      "Epoch 3049\n",
      "-------------------------------\n",
      "loss: 0.307918  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439115 \n",
      "\n",
      "Epoch 3050\n",
      "-------------------------------\n",
      "loss: 0.310695  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439409 \n",
      "\n",
      "Epoch 3051\n",
      "-------------------------------\n",
      "loss: 0.309539  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440441 \n",
      "\n",
      "Epoch 3052\n",
      "-------------------------------\n",
      "loss: 0.310202  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441523 \n",
      "\n",
      "Epoch 3053\n",
      "-------------------------------\n",
      "loss: 0.306112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441695 \n",
      "\n",
      "Epoch 3054\n",
      "-------------------------------\n",
      "loss: 0.310097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442986 \n",
      "\n",
      "Epoch 3055\n",
      "-------------------------------\n",
      "loss: 0.313854  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442257 \n",
      "\n",
      "Epoch 3056\n",
      "-------------------------------\n",
      "loss: 0.309728  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443419 \n",
      "\n",
      "Epoch 3057\n",
      "-------------------------------\n",
      "loss: 0.312962  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441791 \n",
      "\n",
      "Epoch 3058\n",
      "-------------------------------\n",
      "loss: 0.305891  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441499 \n",
      "\n",
      "Epoch 3059\n",
      "-------------------------------\n",
      "loss: 0.307312  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441667 \n",
      "\n",
      "Epoch 3060\n",
      "-------------------------------\n",
      "loss: 0.308178  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440807 \n",
      "\n",
      "Epoch 3061\n",
      "-------------------------------\n",
      "loss: 0.310628  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440630 \n",
      "\n",
      "Epoch 3062\n",
      "-------------------------------\n",
      "loss: 0.306296  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440193 \n",
      "\n",
      "Epoch 3063\n",
      "-------------------------------\n",
      "loss: 0.319020  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440308 \n",
      "\n",
      "Epoch 3064\n",
      "-------------------------------\n",
      "loss: 0.314651  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440023 \n",
      "\n",
      "Epoch 3065\n",
      "-------------------------------\n",
      "loss: 0.313961  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439398 \n",
      "\n",
      "Epoch 3066\n",
      "-------------------------------\n",
      "loss: 0.312178  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439541 \n",
      "\n",
      "Epoch 3067\n",
      "-------------------------------\n",
      "loss: 0.313145  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439357 \n",
      "\n",
      "Epoch 3068\n",
      "-------------------------------\n",
      "loss: 0.308391  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438942 \n",
      "\n",
      "Epoch 3069\n",
      "-------------------------------\n",
      "loss: 0.318422  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439674 \n",
      "\n",
      "Epoch 3070\n",
      "-------------------------------\n",
      "loss: 0.309087  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440330 \n",
      "\n",
      "Epoch 3071\n",
      "-------------------------------\n",
      "loss: 0.311244  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441266 \n",
      "\n",
      "Epoch 3072\n",
      "-------------------------------\n",
      "loss: 0.314186  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441999 \n",
      "\n",
      "Epoch 3073\n",
      "-------------------------------\n",
      "loss: 0.310023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442895 \n",
      "\n",
      "Epoch 3074\n",
      "-------------------------------\n",
      "loss: 0.309377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442657 \n",
      "\n",
      "Epoch 3075\n",
      "-------------------------------\n",
      "loss: 0.313846  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442039 \n",
      "\n",
      "Epoch 3076\n",
      "-------------------------------\n",
      "loss: 0.303624  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441616 \n",
      "\n",
      "Epoch 3077\n",
      "-------------------------------\n",
      "loss: 0.307119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441564 \n",
      "\n",
      "Epoch 3078\n",
      "-------------------------------\n",
      "loss: 0.306002  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441081 \n",
      "\n",
      "Epoch 3079\n",
      "-------------------------------\n",
      "loss: 0.310299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439889 \n",
      "\n",
      "Epoch 3080\n",
      "-------------------------------\n",
      "loss: 0.311433  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439450 \n",
      "\n",
      "Epoch 3081\n",
      "-------------------------------\n",
      "loss: 0.317971  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439689 \n",
      "\n",
      "Epoch 3082\n",
      "-------------------------------\n",
      "loss: 0.310735  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439143 \n",
      "\n",
      "Epoch 3083\n",
      "-------------------------------\n",
      "loss: 0.313499  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440301 \n",
      "\n",
      "Epoch 3084\n",
      "-------------------------------\n",
      "loss: 0.312858  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440363 \n",
      "\n",
      "Epoch 3085\n",
      "-------------------------------\n",
      "loss: 0.307323  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440160 \n",
      "\n",
      "Epoch 3086\n",
      "-------------------------------\n",
      "loss: 0.317093  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440418 \n",
      "\n",
      "Epoch 3087\n",
      "-------------------------------\n",
      "loss: 0.322797  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439514 \n",
      "\n",
      "Epoch 3088\n",
      "-------------------------------\n",
      "loss: 0.317546  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438521 \n",
      "\n",
      "Epoch 3089\n",
      "-------------------------------\n",
      "loss: 0.316376  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438984 \n",
      "\n",
      "Epoch 3090\n",
      "-------------------------------\n",
      "loss: 0.308119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440586 \n",
      "\n",
      "Epoch 3091\n",
      "-------------------------------\n",
      "loss: 0.309469  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441440 \n",
      "\n",
      "Epoch 3092\n",
      "-------------------------------\n",
      "loss: 0.310241  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442041 \n",
      "\n",
      "Epoch 3093\n",
      "-------------------------------\n",
      "loss: 0.311451  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442386 \n",
      "\n",
      "Epoch 3094\n",
      "-------------------------------\n",
      "loss: 0.308762  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442431 \n",
      "\n",
      "Epoch 3095\n",
      "-------------------------------\n",
      "loss: 0.308479  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442431 \n",
      "\n",
      "Epoch 3096\n",
      "-------------------------------\n",
      "loss: 0.312039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442075 \n",
      "\n",
      "Epoch 3097\n",
      "-------------------------------\n",
      "loss: 0.306036  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441087 \n",
      "\n",
      "Epoch 3098\n",
      "-------------------------------\n",
      "loss: 0.321930  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439953 \n",
      "\n",
      "Epoch 3099\n",
      "-------------------------------\n",
      "loss: 0.310117  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439942 \n",
      "\n",
      "Epoch 3100\n",
      "-------------------------------\n",
      "loss: 0.315154  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438765 \n",
      "\n",
      "Epoch 3101\n",
      "-------------------------------\n",
      "loss: 0.310867  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438781 \n",
      "\n",
      "Epoch 3102\n",
      "-------------------------------\n",
      "loss: 0.316904  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439167 \n",
      "\n",
      "Epoch 3103\n",
      "-------------------------------\n",
      "loss: 0.313391  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439338 \n",
      "\n",
      "Epoch 3104\n",
      "-------------------------------\n",
      "loss: 0.299896  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439405 \n",
      "\n",
      "Epoch 3105\n",
      "-------------------------------\n",
      "loss: 0.308627  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439633 \n",
      "\n",
      "Epoch 3106\n",
      "-------------------------------\n",
      "loss: 0.309444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440879 \n",
      "\n",
      "Epoch 3107\n",
      "-------------------------------\n",
      "loss: 0.309222  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441644 \n",
      "\n",
      "Epoch 3108\n",
      "-------------------------------\n",
      "loss: 0.319806  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442993 \n",
      "\n",
      "Epoch 3109\n",
      "-------------------------------\n",
      "loss: 0.307622  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443289 \n",
      "\n",
      "Epoch 3110\n",
      "-------------------------------\n",
      "loss: 0.311363  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443009 \n",
      "\n",
      "Epoch 3111\n",
      "-------------------------------\n",
      "loss: 0.306643  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444174 \n",
      "\n",
      "Epoch 3112\n",
      "-------------------------------\n",
      "loss: 0.313665  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442156 \n",
      "\n",
      "Epoch 3113\n",
      "-------------------------------\n",
      "loss: 0.307733  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442533 \n",
      "\n",
      "Epoch 3114\n",
      "-------------------------------\n",
      "loss: 0.303288  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441892 \n",
      "\n",
      "Epoch 3115\n",
      "-------------------------------\n",
      "loss: 0.312520  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442367 \n",
      "\n",
      "Epoch 3116\n",
      "-------------------------------\n",
      "loss: 0.315033  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441840 \n",
      "\n",
      "Epoch 3117\n",
      "-------------------------------\n",
      "loss: 0.311532  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441634 \n",
      "\n",
      "Epoch 3118\n",
      "-------------------------------\n",
      "loss: 0.305357  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441313 \n",
      "\n",
      "Epoch 3119\n",
      "-------------------------------\n",
      "loss: 0.314951  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441545 \n",
      "\n",
      "Epoch 3120\n",
      "-------------------------------\n",
      "loss: 0.311302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441731 \n",
      "\n",
      "Epoch 3121\n",
      "-------------------------------\n",
      "loss: 0.313601  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442225 \n",
      "\n",
      "Epoch 3122\n",
      "-------------------------------\n",
      "loss: 0.316479  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441936 \n",
      "\n",
      "Epoch 3123\n",
      "-------------------------------\n",
      "loss: 0.313072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442099 \n",
      "\n",
      "Epoch 3124\n",
      "-------------------------------\n",
      "loss: 0.303148  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442675 \n",
      "\n",
      "Epoch 3125\n",
      "-------------------------------\n",
      "loss: 0.308386  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441738 \n",
      "\n",
      "Epoch 3126\n",
      "-------------------------------\n",
      "loss: 0.316938  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442137 \n",
      "\n",
      "Epoch 3127\n",
      "-------------------------------\n",
      "loss: 0.304016  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442897 \n",
      "\n",
      "Epoch 3128\n",
      "-------------------------------\n",
      "loss: 0.313501  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443039 \n",
      "\n",
      "Epoch 3129\n",
      "-------------------------------\n",
      "loss: 0.315278  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442546 \n",
      "\n",
      "Epoch 3130\n",
      "-------------------------------\n",
      "loss: 0.303324  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442660 \n",
      "\n",
      "Epoch 3131\n",
      "-------------------------------\n",
      "loss: 0.305636  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442612 \n",
      "\n",
      "Epoch 3132\n",
      "-------------------------------\n",
      "loss: 0.310286  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442471 \n",
      "\n",
      "Epoch 3133\n",
      "-------------------------------\n",
      "loss: 0.320126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442277 \n",
      "\n",
      "Epoch 3134\n",
      "-------------------------------\n",
      "loss: 0.316954  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441324 \n",
      "\n",
      "Epoch 3135\n",
      "-------------------------------\n",
      "loss: 0.316906  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441277 \n",
      "\n",
      "Epoch 3136\n",
      "-------------------------------\n",
      "loss: 0.305636  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440570 \n",
      "\n",
      "Epoch 3137\n",
      "-------------------------------\n",
      "loss: 0.311053  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439749 \n",
      "\n",
      "Epoch 3138\n",
      "-------------------------------\n",
      "loss: 0.311069  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440253 \n",
      "\n",
      "Epoch 3139\n",
      "-------------------------------\n",
      "loss: 0.311076  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441036 \n",
      "\n",
      "Epoch 3140\n",
      "-------------------------------\n",
      "loss: 0.308175  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441859 \n",
      "\n",
      "Epoch 3141\n",
      "-------------------------------\n",
      "loss: 0.305364  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441838 \n",
      "\n",
      "Epoch 3142\n",
      "-------------------------------\n",
      "loss: 0.308078  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441824 \n",
      "\n",
      "Epoch 3143\n",
      "-------------------------------\n",
      "loss: 0.311781  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441791 \n",
      "\n",
      "Epoch 3144\n",
      "-------------------------------\n",
      "loss: 0.318340  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441687 \n",
      "\n",
      "Epoch 3145\n",
      "-------------------------------\n",
      "loss: 0.318147  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441520 \n",
      "\n",
      "Epoch 3146\n",
      "-------------------------------\n",
      "loss: 0.313536  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442986 \n",
      "\n",
      "Epoch 3147\n",
      "-------------------------------\n",
      "loss: 0.305477  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443405 \n",
      "\n",
      "Epoch 3148\n",
      "-------------------------------\n",
      "loss: 0.304542  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445384 \n",
      "\n",
      "Epoch 3149\n",
      "-------------------------------\n",
      "loss: 0.304765  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445388 \n",
      "\n",
      "Epoch 3150\n",
      "-------------------------------\n",
      "loss: 0.312002  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444446 \n",
      "\n",
      "Epoch 3151\n",
      "-------------------------------\n",
      "loss: 0.307554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444049 \n",
      "\n",
      "Epoch 3152\n",
      "-------------------------------\n",
      "loss: 0.313817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443044 \n",
      "\n",
      "Epoch 3153\n",
      "-------------------------------\n",
      "loss: 0.306492  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441916 \n",
      "\n",
      "Epoch 3154\n",
      "-------------------------------\n",
      "loss: 0.320321  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441126 \n",
      "\n",
      "Epoch 3155\n",
      "-------------------------------\n",
      "loss: 0.310279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440365 \n",
      "\n",
      "Epoch 3156\n",
      "-------------------------------\n",
      "loss: 0.315784  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439627 \n",
      "\n",
      "Epoch 3157\n",
      "-------------------------------\n",
      "loss: 0.310506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440645 \n",
      "\n",
      "Epoch 3158\n",
      "-------------------------------\n",
      "loss: 0.317056  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440117 \n",
      "\n",
      "Epoch 3159\n",
      "-------------------------------\n",
      "loss: 0.312432  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440694 \n",
      "\n",
      "Epoch 3160\n",
      "-------------------------------\n",
      "loss: 0.305492  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440455 \n",
      "\n",
      "Epoch 3161\n",
      "-------------------------------\n",
      "loss: 0.303660  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441078 \n",
      "\n",
      "Epoch 3162\n",
      "-------------------------------\n",
      "loss: 0.309722  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440711 \n",
      "\n",
      "Epoch 3163\n",
      "-------------------------------\n",
      "loss: 0.303116  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442230 \n",
      "\n",
      "Epoch 3164\n",
      "-------------------------------\n",
      "loss: 0.312258  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442419 \n",
      "\n",
      "Epoch 3165\n",
      "-------------------------------\n",
      "loss: 0.317976  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442475 \n",
      "\n",
      "Epoch 3166\n",
      "-------------------------------\n",
      "loss: 0.315345  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442201 \n",
      "\n",
      "Epoch 3167\n",
      "-------------------------------\n",
      "loss: 0.314667  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442427 \n",
      "\n",
      "Epoch 3168\n",
      "-------------------------------\n",
      "loss: 0.314180  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442741 \n",
      "\n",
      "Epoch 3169\n",
      "-------------------------------\n",
      "loss: 0.315193  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441572 \n",
      "\n",
      "Epoch 3170\n",
      "-------------------------------\n",
      "loss: 0.322595  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441702 \n",
      "\n",
      "Epoch 3171\n",
      "-------------------------------\n",
      "loss: 0.318742  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440147 \n",
      "\n",
      "Epoch 3172\n",
      "-------------------------------\n",
      "loss: 0.308780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440769 \n",
      "\n",
      "Epoch 3173\n",
      "-------------------------------\n",
      "loss: 0.309692  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441666 \n",
      "\n",
      "Epoch 3174\n",
      "-------------------------------\n",
      "loss: 0.307757  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442248 \n",
      "\n",
      "Epoch 3175\n",
      "-------------------------------\n",
      "loss: 0.311544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442299 \n",
      "\n",
      "Epoch 3176\n",
      "-------------------------------\n",
      "loss: 0.313423  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442536 \n",
      "\n",
      "Epoch 3177\n",
      "-------------------------------\n",
      "loss: 0.316843  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441344 \n",
      "\n",
      "Epoch 3178\n",
      "-------------------------------\n",
      "loss: 0.310483  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441100 \n",
      "\n",
      "Epoch 3179\n",
      "-------------------------------\n",
      "loss: 0.310604  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440860 \n",
      "\n",
      "Epoch 3180\n",
      "-------------------------------\n",
      "loss: 0.306678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441006 \n",
      "\n",
      "Epoch 3181\n",
      "-------------------------------\n",
      "loss: 0.311612  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440931 \n",
      "\n",
      "Epoch 3182\n",
      "-------------------------------\n",
      "loss: 0.306286  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441992 \n",
      "\n",
      "Epoch 3183\n",
      "-------------------------------\n",
      "loss: 0.314145  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443176 \n",
      "\n",
      "Epoch 3184\n",
      "-------------------------------\n",
      "loss: 0.315553  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443910 \n",
      "\n",
      "Epoch 3185\n",
      "-------------------------------\n",
      "loss: 0.314485  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444905 \n",
      "\n",
      "Epoch 3186\n",
      "-------------------------------\n",
      "loss: 0.311214  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445391 \n",
      "\n",
      "Epoch 3187\n",
      "-------------------------------\n",
      "loss: 0.309121  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445693 \n",
      "\n",
      "Epoch 3188\n",
      "-------------------------------\n",
      "loss: 0.311717  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443902 \n",
      "\n",
      "Epoch 3189\n",
      "-------------------------------\n",
      "loss: 0.322366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443124 \n",
      "\n",
      "Epoch 3190\n",
      "-------------------------------\n",
      "loss: 0.314975  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440384 \n",
      "\n",
      "Epoch 3191\n",
      "-------------------------------\n",
      "loss: 0.304430  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440519 \n",
      "\n",
      "Epoch 3192\n",
      "-------------------------------\n",
      "loss: 0.306925  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440813 \n",
      "\n",
      "Epoch 3193\n",
      "-------------------------------\n",
      "loss: 0.306728  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440724 \n",
      "\n",
      "Epoch 3194\n",
      "-------------------------------\n",
      "loss: 0.313807  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440944 \n",
      "\n",
      "Epoch 3195\n",
      "-------------------------------\n",
      "loss: 0.321858  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441773 \n",
      "\n",
      "Epoch 3196\n",
      "-------------------------------\n",
      "loss: 0.309165  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442790 \n",
      "\n",
      "Epoch 3197\n",
      "-------------------------------\n",
      "loss: 0.316687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443577 \n",
      "\n",
      "Epoch 3198\n",
      "-------------------------------\n",
      "loss: 0.304706  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442988 \n",
      "\n",
      "Epoch 3199\n",
      "-------------------------------\n",
      "loss: 0.306581  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444145 \n",
      "\n",
      "Epoch 3200\n",
      "-------------------------------\n",
      "loss: 0.308054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442664 \n",
      "\n",
      "Epoch 3201\n",
      "-------------------------------\n",
      "loss: 0.304474  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443064 \n",
      "\n",
      "Epoch 3202\n",
      "-------------------------------\n",
      "loss: 0.319208  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442752 \n",
      "\n",
      "Epoch 3203\n",
      "-------------------------------\n",
      "loss: 0.314312  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441928 \n",
      "\n",
      "Epoch 3204\n",
      "-------------------------------\n",
      "loss: 0.306449  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441137 \n",
      "\n",
      "Epoch 3205\n",
      "-------------------------------\n",
      "loss: 0.307536  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440305 \n",
      "\n",
      "Epoch 3206\n",
      "-------------------------------\n",
      "loss: 0.311978  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439809 \n",
      "\n",
      "Epoch 3207\n",
      "-------------------------------\n",
      "loss: 0.310200  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438656 \n",
      "\n",
      "Epoch 3208\n",
      "-------------------------------\n",
      "loss: 0.312417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438477 \n",
      "\n",
      "Epoch 3209\n",
      "-------------------------------\n",
      "loss: 0.314838  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437988 \n",
      "\n",
      "Epoch 3210\n",
      "-------------------------------\n",
      "loss: 0.310829  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438836 \n",
      "\n",
      "Epoch 3211\n",
      "-------------------------------\n",
      "loss: 0.312605  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439357 \n",
      "\n",
      "Epoch 3212\n",
      "-------------------------------\n",
      "loss: 0.308417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439892 \n",
      "\n",
      "Epoch 3213\n",
      "-------------------------------\n",
      "loss: 0.307274  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439577 \n",
      "\n",
      "Epoch 3214\n",
      "-------------------------------\n",
      "loss: 0.318415  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438885 \n",
      "\n",
      "Epoch 3215\n",
      "-------------------------------\n",
      "loss: 0.310808  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438662 \n",
      "\n",
      "Epoch 3216\n",
      "-------------------------------\n",
      "loss: 0.306914  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438648 \n",
      "\n",
      "Epoch 3217\n",
      "-------------------------------\n",
      "loss: 0.317299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439717 \n",
      "\n",
      "Epoch 3218\n",
      "-------------------------------\n",
      "loss: 0.308964  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439608 \n",
      "\n",
      "Epoch 3219\n",
      "-------------------------------\n",
      "loss: 0.307711  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440694 \n",
      "\n",
      "Epoch 3220\n",
      "-------------------------------\n",
      "loss: 0.313748  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441868 \n",
      "\n",
      "Epoch 3221\n",
      "-------------------------------\n",
      "loss: 0.310962  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441314 \n",
      "\n",
      "Epoch 3222\n",
      "-------------------------------\n",
      "loss: 0.307659  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441724 \n",
      "\n",
      "Epoch 3223\n",
      "-------------------------------\n",
      "loss: 0.312394  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441490 \n",
      "\n",
      "Epoch 3224\n",
      "-------------------------------\n",
      "loss: 0.306885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440610 \n",
      "\n",
      "Epoch 3225\n",
      "-------------------------------\n",
      "loss: 0.307434  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439989 \n",
      "\n",
      "Epoch 3226\n",
      "-------------------------------\n",
      "loss: 0.307699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440193 \n",
      "\n",
      "Epoch 3227\n",
      "-------------------------------\n",
      "loss: 0.314999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439390 \n",
      "\n",
      "Epoch 3228\n",
      "-------------------------------\n",
      "loss: 0.304691  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440018 \n",
      "\n",
      "Epoch 3229\n",
      "-------------------------------\n",
      "loss: 0.311815  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439909 \n",
      "\n",
      "Epoch 3230\n",
      "-------------------------------\n",
      "loss: 0.315425  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440178 \n",
      "\n",
      "Epoch 3231\n",
      "-------------------------------\n",
      "loss: 0.308057  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440549 \n",
      "\n",
      "Epoch 3232\n",
      "-------------------------------\n",
      "loss: 0.310490  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441249 \n",
      "\n",
      "Epoch 3233\n",
      "-------------------------------\n",
      "loss: 0.309306  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441374 \n",
      "\n",
      "Epoch 3234\n",
      "-------------------------------\n",
      "loss: 0.309054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441549 \n",
      "\n",
      "Epoch 3235\n",
      "-------------------------------\n",
      "loss: 0.311999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441433 \n",
      "\n",
      "Epoch 3236\n",
      "-------------------------------\n",
      "loss: 0.312996  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442426 \n",
      "\n",
      "Epoch 3237\n",
      "-------------------------------\n",
      "loss: 0.305428  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442046 \n",
      "\n",
      "Epoch 3238\n",
      "-------------------------------\n",
      "loss: 0.315077  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442047 \n",
      "\n",
      "Epoch 3239\n",
      "-------------------------------\n",
      "loss: 0.312620  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441634 \n",
      "\n",
      "Epoch 3240\n",
      "-------------------------------\n",
      "loss: 0.309952  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441225 \n",
      "\n",
      "Epoch 3241\n",
      "-------------------------------\n",
      "loss: 0.309008  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441004 \n",
      "\n",
      "Epoch 3242\n",
      "-------------------------------\n",
      "loss: 0.300525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442227 \n",
      "\n",
      "Epoch 3243\n",
      "-------------------------------\n",
      "loss: 0.302489  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441927 \n",
      "\n",
      "Epoch 3244\n",
      "-------------------------------\n",
      "loss: 0.311224  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442788 \n",
      "\n",
      "Epoch 3245\n",
      "-------------------------------\n",
      "loss: 0.303437  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442147 \n",
      "\n",
      "Epoch 3246\n",
      "-------------------------------\n",
      "loss: 0.308801  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442756 \n",
      "\n",
      "Epoch 3247\n",
      "-------------------------------\n",
      "loss: 0.312753  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442291 \n",
      "\n",
      "Epoch 3248\n",
      "-------------------------------\n",
      "loss: 0.310170  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443037 \n",
      "\n",
      "Epoch 3249\n",
      "-------------------------------\n",
      "loss: 0.326909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442991 \n",
      "\n",
      "Epoch 3250\n",
      "-------------------------------\n",
      "loss: 0.306390  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443116 \n",
      "\n",
      "Epoch 3251\n",
      "-------------------------------\n",
      "loss: 0.302895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443136 \n",
      "\n",
      "Epoch 3252\n",
      "-------------------------------\n",
      "loss: 0.311231  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443038 \n",
      "\n",
      "Epoch 3253\n",
      "-------------------------------\n",
      "loss: 0.309530  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443190 \n",
      "\n",
      "Epoch 3254\n",
      "-------------------------------\n",
      "loss: 0.308829  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443135 \n",
      "\n",
      "Epoch 3255\n",
      "-------------------------------\n",
      "loss: 0.309167  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444300 \n",
      "\n",
      "Epoch 3256\n",
      "-------------------------------\n",
      "loss: 0.304478  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443971 \n",
      "\n",
      "Epoch 3257\n",
      "-------------------------------\n",
      "loss: 0.308932  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443799 \n",
      "\n",
      "Epoch 3258\n",
      "-------------------------------\n",
      "loss: 0.314078  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443404 \n",
      "\n",
      "Epoch 3259\n",
      "-------------------------------\n",
      "loss: 0.305913  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443540 \n",
      "\n",
      "Epoch 3260\n",
      "-------------------------------\n",
      "loss: 0.306206  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443691 \n",
      "\n",
      "Epoch 3261\n",
      "-------------------------------\n",
      "loss: 0.306813  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443200 \n",
      "\n",
      "Epoch 3262\n",
      "-------------------------------\n",
      "loss: 0.303215  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443146 \n",
      "\n",
      "Epoch 3263\n",
      "-------------------------------\n",
      "loss: 0.312818  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442377 \n",
      "\n",
      "Epoch 3264\n",
      "-------------------------------\n",
      "loss: 0.304301  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442017 \n",
      "\n",
      "Epoch 3265\n",
      "-------------------------------\n",
      "loss: 0.309269  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442062 \n",
      "\n",
      "Epoch 3266\n",
      "-------------------------------\n",
      "loss: 0.314657  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441834 \n",
      "\n",
      "Epoch 3267\n",
      "-------------------------------\n",
      "loss: 0.306247  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440557 \n",
      "\n",
      "Epoch 3268\n",
      "-------------------------------\n",
      "loss: 0.309093  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440390 \n",
      "\n",
      "Epoch 3269\n",
      "-------------------------------\n",
      "loss: 0.309866  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440689 \n",
      "\n",
      "Epoch 3270\n",
      "-------------------------------\n",
      "loss: 0.311181  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440965 \n",
      "\n",
      "Epoch 3271\n",
      "-------------------------------\n",
      "loss: 0.315652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441397 \n",
      "\n",
      "Epoch 3272\n",
      "-------------------------------\n",
      "loss: 0.314396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441981 \n",
      "\n",
      "Epoch 3273\n",
      "-------------------------------\n",
      "loss: 0.308240  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442194 \n",
      "\n",
      "Epoch 3274\n",
      "-------------------------------\n",
      "loss: 0.299528  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442721 \n",
      "\n",
      "Epoch 3275\n",
      "-------------------------------\n",
      "loss: 0.317144  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443533 \n",
      "\n",
      "Epoch 3276\n",
      "-------------------------------\n",
      "loss: 0.305040  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444385 \n",
      "\n",
      "Epoch 3277\n",
      "-------------------------------\n",
      "loss: 0.308552  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445510 \n",
      "\n",
      "Epoch 3278\n",
      "-------------------------------\n",
      "loss: 0.311810  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444873 \n",
      "\n",
      "Epoch 3279\n",
      "-------------------------------\n",
      "loss: 0.303856  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443308 \n",
      "\n",
      "Epoch 3280\n",
      "-------------------------------\n",
      "loss: 0.301332  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441862 \n",
      "\n",
      "Epoch 3281\n",
      "-------------------------------\n",
      "loss: 0.313129  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440576 \n",
      "\n",
      "Epoch 3282\n",
      "-------------------------------\n",
      "loss: 0.313274  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439740 \n",
      "\n",
      "Epoch 3283\n",
      "-------------------------------\n",
      "loss: 0.306562  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439081 \n",
      "\n",
      "Epoch 3284\n",
      "-------------------------------\n",
      "loss: 0.308233  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438168 \n",
      "\n",
      "Epoch 3285\n",
      "-------------------------------\n",
      "loss: 0.309390  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438945 \n",
      "\n",
      "Epoch 3286\n",
      "-------------------------------\n",
      "loss: 0.313568  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438549 \n",
      "\n",
      "Epoch 3287\n",
      "-------------------------------\n",
      "loss: 0.307349  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439277 \n",
      "\n",
      "Epoch 3288\n",
      "-------------------------------\n",
      "loss: 0.302718  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439679 \n",
      "\n",
      "Epoch 3289\n",
      "-------------------------------\n",
      "loss: 0.307544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440391 \n",
      "\n",
      "Epoch 3290\n",
      "-------------------------------\n",
      "loss: 0.309701  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440848 \n",
      "\n",
      "Epoch 3291\n",
      "-------------------------------\n",
      "loss: 0.315380  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441520 \n",
      "\n",
      "Epoch 3292\n",
      "-------------------------------\n",
      "loss: 0.312272  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440722 \n",
      "\n",
      "Epoch 3293\n",
      "-------------------------------\n",
      "loss: 0.301657  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440503 \n",
      "\n",
      "Epoch 3294\n",
      "-------------------------------\n",
      "loss: 0.312595  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440715 \n",
      "\n",
      "Epoch 3295\n",
      "-------------------------------\n",
      "loss: 0.311124  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440801 \n",
      "\n",
      "Epoch 3296\n",
      "-------------------------------\n",
      "loss: 0.303699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440602 \n",
      "\n",
      "Epoch 3297\n",
      "-------------------------------\n",
      "loss: 0.306773  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440029 \n",
      "\n",
      "Epoch 3298\n",
      "-------------------------------\n",
      "loss: 0.307869  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440529 \n",
      "\n",
      "Epoch 3299\n",
      "-------------------------------\n",
      "loss: 0.310455  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440746 \n",
      "\n",
      "Epoch 3300\n",
      "-------------------------------\n",
      "loss: 0.306543  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440324 \n",
      "\n",
      "Epoch 3301\n",
      "-------------------------------\n",
      "loss: 0.310676  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439975 \n",
      "\n",
      "Epoch 3302\n",
      "-------------------------------\n",
      "loss: 0.308203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440160 \n",
      "\n",
      "Epoch 3303\n",
      "-------------------------------\n",
      "loss: 0.310485  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441196 \n",
      "\n",
      "Epoch 3304\n",
      "-------------------------------\n",
      "loss: 0.313419  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441352 \n",
      "\n",
      "Epoch 3305\n",
      "-------------------------------\n",
      "loss: 0.301782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441357 \n",
      "\n",
      "Epoch 3306\n",
      "-------------------------------\n",
      "loss: 0.314316  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440053 \n",
      "\n",
      "Epoch 3307\n",
      "-------------------------------\n",
      "loss: 0.321339  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440330 \n",
      "\n",
      "Epoch 3308\n",
      "-------------------------------\n",
      "loss: 0.305760  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440103 \n",
      "\n",
      "Epoch 3309\n",
      "-------------------------------\n",
      "loss: 0.313973  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439379 \n",
      "\n",
      "Epoch 3310\n",
      "-------------------------------\n",
      "loss: 0.311722  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439666 \n",
      "\n",
      "Epoch 3311\n",
      "-------------------------------\n",
      "loss: 0.308737  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439958 \n",
      "\n",
      "Epoch 3312\n",
      "-------------------------------\n",
      "loss: 0.318203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440965 \n",
      "\n",
      "Epoch 3313\n",
      "-------------------------------\n",
      "loss: 0.312039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441379 \n",
      "\n",
      "Epoch 3314\n",
      "-------------------------------\n",
      "loss: 0.306672  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442238 \n",
      "\n",
      "Epoch 3315\n",
      "-------------------------------\n",
      "loss: 0.316256  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443003 \n",
      "\n",
      "Epoch 3316\n",
      "-------------------------------\n",
      "loss: 0.317315  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442303 \n",
      "\n",
      "Epoch 3317\n",
      "-------------------------------\n",
      "loss: 0.311533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441549 \n",
      "\n",
      "Epoch 3318\n",
      "-------------------------------\n",
      "loss: 0.313315  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441319 \n",
      "\n",
      "Epoch 3319\n",
      "-------------------------------\n",
      "loss: 0.309102  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441018 \n",
      "\n",
      "Epoch 3320\n",
      "-------------------------------\n",
      "loss: 0.308471  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442251 \n",
      "\n",
      "Epoch 3321\n",
      "-------------------------------\n",
      "loss: 0.306496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443308 \n",
      "\n",
      "Epoch 3322\n",
      "-------------------------------\n",
      "loss: 0.310602  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443024 \n",
      "\n",
      "Epoch 3323\n",
      "-------------------------------\n",
      "loss: 0.310674  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442368 \n",
      "\n",
      "Epoch 3324\n",
      "-------------------------------\n",
      "loss: 0.313753  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441885 \n",
      "\n",
      "Epoch 3325\n",
      "-------------------------------\n",
      "loss: 0.313640  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441052 \n",
      "\n",
      "Epoch 3326\n",
      "-------------------------------\n",
      "loss: 0.304961  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440646 \n",
      "\n",
      "Epoch 3327\n",
      "-------------------------------\n",
      "loss: 0.305228  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439488 \n",
      "\n",
      "Epoch 3328\n",
      "-------------------------------\n",
      "loss: 0.304293  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440407 \n",
      "\n",
      "Epoch 3329\n",
      "-------------------------------\n",
      "loss: 0.302193  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440448 \n",
      "\n",
      "Epoch 3330\n",
      "-------------------------------\n",
      "loss: 0.306518  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441855 \n",
      "\n",
      "Epoch 3331\n",
      "-------------------------------\n",
      "loss: 0.307374  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442406 \n",
      "\n",
      "Epoch 3332\n",
      "-------------------------------\n",
      "loss: 0.311890  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441633 \n",
      "\n",
      "Epoch 3333\n",
      "-------------------------------\n",
      "loss: 0.306486  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440474 \n",
      "\n",
      "Epoch 3334\n",
      "-------------------------------\n",
      "loss: 0.308598  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439567 \n",
      "\n",
      "Epoch 3335\n",
      "-------------------------------\n",
      "loss: 0.305372  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440199 \n",
      "\n",
      "Epoch 3336\n",
      "-------------------------------\n",
      "loss: 0.315536  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439554 \n",
      "\n",
      "Epoch 3337\n",
      "-------------------------------\n",
      "loss: 0.308659  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439669 \n",
      "\n",
      "Epoch 3338\n",
      "-------------------------------\n",
      "loss: 0.311449  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439642 \n",
      "\n",
      "Epoch 3339\n",
      "-------------------------------\n",
      "loss: 0.311674  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440127 \n",
      "\n",
      "Epoch 3340\n",
      "-------------------------------\n",
      "loss: 0.313089  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440246 \n",
      "\n",
      "Epoch 3341\n",
      "-------------------------------\n",
      "loss: 0.308816  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441278 \n",
      "\n",
      "Epoch 3342\n",
      "-------------------------------\n",
      "loss: 0.309935  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441568 \n",
      "\n",
      "Epoch 3343\n",
      "-------------------------------\n",
      "loss: 0.311448  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441149 \n",
      "\n",
      "Epoch 3344\n",
      "-------------------------------\n",
      "loss: 0.313554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441854 \n",
      "\n",
      "Epoch 3345\n",
      "-------------------------------\n",
      "loss: 0.315430  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441436 \n",
      "\n",
      "Epoch 3346\n",
      "-------------------------------\n",
      "loss: 0.306092  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442029 \n",
      "\n",
      "Epoch 3347\n",
      "-------------------------------\n",
      "loss: 0.313221  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440911 \n",
      "\n",
      "Epoch 3348\n",
      "-------------------------------\n",
      "loss: 0.307338  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440579 \n",
      "\n",
      "Epoch 3349\n",
      "-------------------------------\n",
      "loss: 0.309480  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440148 \n",
      "\n",
      "Epoch 3350\n",
      "-------------------------------\n",
      "loss: 0.312229  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439098 \n",
      "\n",
      "Epoch 3351\n",
      "-------------------------------\n",
      "loss: 0.312620  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439511 \n",
      "\n",
      "Epoch 3352\n",
      "-------------------------------\n",
      "loss: 0.308747  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440175 \n",
      "\n",
      "Epoch 3353\n",
      "-------------------------------\n",
      "loss: 0.299045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439758 \n",
      "\n",
      "Epoch 3354\n",
      "-------------------------------\n",
      "loss: 0.309537  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439836 \n",
      "\n",
      "Epoch 3355\n",
      "-------------------------------\n",
      "loss: 0.307431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440666 \n",
      "\n",
      "Epoch 3356\n",
      "-------------------------------\n",
      "loss: 0.304194  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440177 \n",
      "\n",
      "Epoch 3357\n",
      "-------------------------------\n",
      "loss: 0.306688  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440949 \n",
      "\n",
      "Epoch 3358\n",
      "-------------------------------\n",
      "loss: 0.310513  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440804 \n",
      "\n",
      "Epoch 3359\n",
      "-------------------------------\n",
      "loss: 0.305396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440974 \n",
      "\n",
      "Epoch 3360\n",
      "-------------------------------\n",
      "loss: 0.306792  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440911 \n",
      "\n",
      "Epoch 3361\n",
      "-------------------------------\n",
      "loss: 0.305224  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440089 \n",
      "\n",
      "Epoch 3362\n",
      "-------------------------------\n",
      "loss: 0.306343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439508 \n",
      "\n",
      "Epoch 3363\n",
      "-------------------------------\n",
      "loss: 0.303584  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439997 \n",
      "\n",
      "Epoch 3364\n",
      "-------------------------------\n",
      "loss: 0.301920  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440282 \n",
      "\n",
      "Epoch 3365\n",
      "-------------------------------\n",
      "loss: 0.302041  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440329 \n",
      "\n",
      "Epoch 3366\n",
      "-------------------------------\n",
      "loss: 0.309489  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440811 \n",
      "\n",
      "Epoch 3367\n",
      "-------------------------------\n",
      "loss: 0.313092  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441555 \n",
      "\n",
      "Epoch 3368\n",
      "-------------------------------\n",
      "loss: 0.317053  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441713 \n",
      "\n",
      "Epoch 3369\n",
      "-------------------------------\n",
      "loss: 0.312863  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442481 \n",
      "\n",
      "Epoch 3370\n",
      "-------------------------------\n",
      "loss: 0.303506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442263 \n",
      "\n",
      "Epoch 3371\n",
      "-------------------------------\n",
      "loss: 0.310091  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442247 \n",
      "\n",
      "Epoch 3372\n",
      "-------------------------------\n",
      "loss: 0.312727  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441432 \n",
      "\n",
      "Epoch 3373\n",
      "-------------------------------\n",
      "loss: 0.312948  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441280 \n",
      "\n",
      "Epoch 3374\n",
      "-------------------------------\n",
      "loss: 0.308543  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440477 \n",
      "\n",
      "Epoch 3375\n",
      "-------------------------------\n",
      "loss: 0.309046  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440485 \n",
      "\n",
      "Epoch 3376\n",
      "-------------------------------\n",
      "loss: 0.310384  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440144 \n",
      "\n",
      "Epoch 3377\n",
      "-------------------------------\n",
      "loss: 0.314281  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440654 \n",
      "\n",
      "Epoch 3378\n",
      "-------------------------------\n",
      "loss: 0.311909  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441196 \n",
      "\n",
      "Epoch 3379\n",
      "-------------------------------\n",
      "loss: 0.320525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442042 \n",
      "\n",
      "Epoch 3380\n",
      "-------------------------------\n",
      "loss: 0.306274  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442074 \n",
      "\n",
      "Epoch 3381\n",
      "-------------------------------\n",
      "loss: 0.312011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443038 \n",
      "\n",
      "Epoch 3382\n",
      "-------------------------------\n",
      "loss: 0.311444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444463 \n",
      "\n",
      "Epoch 3383\n",
      "-------------------------------\n",
      "loss: 0.311818  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444417 \n",
      "\n",
      "Epoch 3384\n",
      "-------------------------------\n",
      "loss: 0.307768  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443969 \n",
      "\n",
      "Epoch 3385\n",
      "-------------------------------\n",
      "loss: 0.307513  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442672 \n",
      "\n",
      "Epoch 3386\n",
      "-------------------------------\n",
      "loss: 0.305912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441391 \n",
      "\n",
      "Epoch 3387\n",
      "-------------------------------\n",
      "loss: 0.308446  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441132 \n",
      "\n",
      "Epoch 3388\n",
      "-------------------------------\n",
      "loss: 0.313826  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440809 \n",
      "\n",
      "Epoch 3389\n",
      "-------------------------------\n",
      "loss: 0.306077  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440599 \n",
      "\n",
      "Epoch 3390\n",
      "-------------------------------\n",
      "loss: 0.305533  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440426 \n",
      "\n",
      "Epoch 3391\n",
      "-------------------------------\n",
      "loss: 0.299408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442301 \n",
      "\n",
      "Epoch 3392\n",
      "-------------------------------\n",
      "loss: 0.301751  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442437 \n",
      "\n",
      "Epoch 3393\n",
      "-------------------------------\n",
      "loss: 0.314910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443994 \n",
      "\n",
      "Epoch 3394\n",
      "-------------------------------\n",
      "loss: 0.310078  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443238 \n",
      "\n",
      "Epoch 3395\n",
      "-------------------------------\n",
      "loss: 0.302875  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442502 \n",
      "\n",
      "Epoch 3396\n",
      "-------------------------------\n",
      "loss: 0.307496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442209 \n",
      "\n",
      "Epoch 3397\n",
      "-------------------------------\n",
      "loss: 0.314216  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442066 \n",
      "\n",
      "Epoch 3398\n",
      "-------------------------------\n",
      "loss: 0.310458  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440796 \n",
      "\n",
      "Epoch 3399\n",
      "-------------------------------\n",
      "loss: 0.310126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440381 \n",
      "\n",
      "Epoch 3400\n",
      "-------------------------------\n",
      "loss: 0.309949  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440060 \n",
      "\n",
      "Epoch 3401\n",
      "-------------------------------\n",
      "loss: 0.303721  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440234 \n",
      "\n",
      "Epoch 3402\n",
      "-------------------------------\n",
      "loss: 0.312297  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440495 \n",
      "\n",
      "Epoch 3403\n",
      "-------------------------------\n",
      "loss: 0.315657  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440783 \n",
      "\n",
      "Epoch 3404\n",
      "-------------------------------\n",
      "loss: 0.313999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441621 \n",
      "\n",
      "Epoch 3405\n",
      "-------------------------------\n",
      "loss: 0.318032  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442512 \n",
      "\n",
      "Epoch 3406\n",
      "-------------------------------\n",
      "loss: 0.306932  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441681 \n",
      "\n",
      "Epoch 3407\n",
      "-------------------------------\n",
      "loss: 0.316466  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441754 \n",
      "\n",
      "Epoch 3408\n",
      "-------------------------------\n",
      "loss: 0.310758  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440533 \n",
      "\n",
      "Epoch 3409\n",
      "-------------------------------\n",
      "loss: 0.310983  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440734 \n",
      "\n",
      "Epoch 3410\n",
      "-------------------------------\n",
      "loss: 0.308885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439664 \n",
      "\n",
      "Epoch 3411\n",
      "-------------------------------\n",
      "loss: 0.309361  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439148 \n",
      "\n",
      "Epoch 3412\n",
      "-------------------------------\n",
      "loss: 0.313100  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440009 \n",
      "\n",
      "Epoch 3413\n",
      "-------------------------------\n",
      "loss: 0.314046  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439669 \n",
      "\n",
      "Epoch 3414\n",
      "-------------------------------\n",
      "loss: 0.319820  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439822 \n",
      "\n",
      "Epoch 3415\n",
      "-------------------------------\n",
      "loss: 0.310358  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440600 \n",
      "\n",
      "Epoch 3416\n",
      "-------------------------------\n",
      "loss: 0.308232  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440832 \n",
      "\n",
      "Epoch 3417\n",
      "-------------------------------\n",
      "loss: 0.310190  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440995 \n",
      "\n",
      "Epoch 3418\n",
      "-------------------------------\n",
      "loss: 0.308757  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441530 \n",
      "\n",
      "Epoch 3419\n",
      "-------------------------------\n",
      "loss: 0.302875  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442222 \n",
      "\n",
      "Epoch 3420\n",
      "-------------------------------\n",
      "loss: 0.314425  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441739 \n",
      "\n",
      "Epoch 3421\n",
      "-------------------------------\n",
      "loss: 0.315149  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441779 \n",
      "\n",
      "Epoch 3422\n",
      "-------------------------------\n",
      "loss: 0.302088  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442314 \n",
      "\n",
      "Epoch 3423\n",
      "-------------------------------\n",
      "loss: 0.308150  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441112 \n",
      "\n",
      "Epoch 3424\n",
      "-------------------------------\n",
      "loss: 0.306763  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440869 \n",
      "\n",
      "Epoch 3425\n",
      "-------------------------------\n",
      "loss: 0.305654  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440528 \n",
      "\n",
      "Epoch 3426\n",
      "-------------------------------\n",
      "loss: 0.308632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439040 \n",
      "\n",
      "Epoch 3427\n",
      "-------------------------------\n",
      "loss: 0.315177  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438746 \n",
      "\n",
      "Epoch 3428\n",
      "-------------------------------\n",
      "loss: 0.307413  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438882 \n",
      "\n",
      "Epoch 3429\n",
      "-------------------------------\n",
      "loss: 0.307690  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440195 \n",
      "\n",
      "Epoch 3430\n",
      "-------------------------------\n",
      "loss: 0.310991  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440274 \n",
      "\n",
      "Epoch 3431\n",
      "-------------------------------\n",
      "loss: 0.307567  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440811 \n",
      "\n",
      "Epoch 3432\n",
      "-------------------------------\n",
      "loss: 0.306589  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440892 \n",
      "\n",
      "Epoch 3433\n",
      "-------------------------------\n",
      "loss: 0.310878  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441703 \n",
      "\n",
      "Epoch 3434\n",
      "-------------------------------\n",
      "loss: 0.307103  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442511 \n",
      "\n",
      "Epoch 3435\n",
      "-------------------------------\n",
      "loss: 0.312215  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442239 \n",
      "\n",
      "Epoch 3436\n",
      "-------------------------------\n",
      "loss: 0.303053  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441546 \n",
      "\n",
      "Epoch 3437\n",
      "-------------------------------\n",
      "loss: 0.313366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442587 \n",
      "\n",
      "Epoch 3438\n",
      "-------------------------------\n",
      "loss: 0.311774  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442448 \n",
      "\n",
      "Epoch 3439\n",
      "-------------------------------\n",
      "loss: 0.312890  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441333 \n",
      "\n",
      "Epoch 3440\n",
      "-------------------------------\n",
      "loss: 0.306917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441663 \n",
      "\n",
      "Epoch 3441\n",
      "-------------------------------\n",
      "loss: 0.307169  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440882 \n",
      "\n",
      "Epoch 3442\n",
      "-------------------------------\n",
      "loss: 0.302294  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441512 \n",
      "\n",
      "Epoch 3443\n",
      "-------------------------------\n",
      "loss: 0.311891  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441707 \n",
      "\n",
      "Epoch 3444\n",
      "-------------------------------\n",
      "loss: 0.300388  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442937 \n",
      "\n",
      "Epoch 3445\n",
      "-------------------------------\n",
      "loss: 0.313970  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443267 \n",
      "\n",
      "Epoch 3446\n",
      "-------------------------------\n",
      "loss: 0.307047  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442606 \n",
      "\n",
      "Epoch 3447\n",
      "-------------------------------\n",
      "loss: 0.314228  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442760 \n",
      "\n",
      "Epoch 3448\n",
      "-------------------------------\n",
      "loss: 0.306688  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441478 \n",
      "\n",
      "Epoch 3449\n",
      "-------------------------------\n",
      "loss: 0.310478  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440381 \n",
      "\n",
      "Epoch 3450\n",
      "-------------------------------\n",
      "loss: 0.307691  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440792 \n",
      "\n",
      "Epoch 3451\n",
      "-------------------------------\n",
      "loss: 0.310474  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440595 \n",
      "\n",
      "Epoch 3452\n",
      "-------------------------------\n",
      "loss: 0.317472  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439689 \n",
      "\n",
      "Epoch 3453\n",
      "-------------------------------\n",
      "loss: 0.309210  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440857 \n",
      "\n",
      "Epoch 3454\n",
      "-------------------------------\n",
      "loss: 0.310635  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441196 \n",
      "\n",
      "Epoch 3455\n",
      "-------------------------------\n",
      "loss: 0.306250  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442051 \n",
      "\n",
      "Epoch 3456\n",
      "-------------------------------\n",
      "loss: 0.315611  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443745 \n",
      "\n",
      "Epoch 3457\n",
      "-------------------------------\n",
      "loss: 0.306435  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443524 \n",
      "\n",
      "Epoch 3458\n",
      "-------------------------------\n",
      "loss: 0.315259  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443747 \n",
      "\n",
      "Epoch 3459\n",
      "-------------------------------\n",
      "loss: 0.310402  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442647 \n",
      "\n",
      "Epoch 3460\n",
      "-------------------------------\n",
      "loss: 0.311917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441824 \n",
      "\n",
      "Epoch 3461\n",
      "-------------------------------\n",
      "loss: 0.309173  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440882 \n",
      "\n",
      "Epoch 3462\n",
      "-------------------------------\n",
      "loss: 0.306534  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440399 \n",
      "\n",
      "Epoch 3463\n",
      "-------------------------------\n",
      "loss: 0.311171  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440070 \n",
      "\n",
      "Epoch 3464\n",
      "-------------------------------\n",
      "loss: 0.315228  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440772 \n",
      "\n",
      "Epoch 3465\n",
      "-------------------------------\n",
      "loss: 0.309964  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441007 \n",
      "\n",
      "Epoch 3466\n",
      "-------------------------------\n",
      "loss: 0.308520  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440557 \n",
      "\n",
      "Epoch 3467\n",
      "-------------------------------\n",
      "loss: 0.311957  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441295 \n",
      "\n",
      "Epoch 3468\n",
      "-------------------------------\n",
      "loss: 0.306396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443032 \n",
      "\n",
      "Epoch 3469\n",
      "-------------------------------\n",
      "loss: 0.303987  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443427 \n",
      "\n",
      "Epoch 3470\n",
      "-------------------------------\n",
      "loss: 0.305081  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444019 \n",
      "\n",
      "Epoch 3471\n",
      "-------------------------------\n",
      "loss: 0.313259  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443945 \n",
      "\n",
      "Epoch 3472\n",
      "-------------------------------\n",
      "loss: 0.306299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442461 \n",
      "\n",
      "Epoch 3473\n",
      "-------------------------------\n",
      "loss: 0.302974  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442143 \n",
      "\n",
      "Epoch 3474\n",
      "-------------------------------\n",
      "loss: 0.309379  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443001 \n",
      "\n",
      "Epoch 3475\n",
      "-------------------------------\n",
      "loss: 0.314208  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441669 \n",
      "\n",
      "Epoch 3476\n",
      "-------------------------------\n",
      "loss: 0.301252  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440856 \n",
      "\n",
      "Epoch 3477\n",
      "-------------------------------\n",
      "loss: 0.315248  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440789 \n",
      "\n",
      "Epoch 3478\n",
      "-------------------------------\n",
      "loss: 0.306170  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440569 \n",
      "\n",
      "Epoch 3479\n",
      "-------------------------------\n",
      "loss: 0.310204  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440699 \n",
      "\n",
      "Epoch 3480\n",
      "-------------------------------\n",
      "loss: 0.312148  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440997 \n",
      "\n",
      "Epoch 3481\n",
      "-------------------------------\n",
      "loss: 0.303373  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440490 \n",
      "\n",
      "Epoch 3482\n",
      "-------------------------------\n",
      "loss: 0.313966  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441900 \n",
      "\n",
      "Epoch 3483\n",
      "-------------------------------\n",
      "loss: 0.307641  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441226 \n",
      "\n",
      "Epoch 3484\n",
      "-------------------------------\n",
      "loss: 0.306649  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440702 \n",
      "\n",
      "Epoch 3485\n",
      "-------------------------------\n",
      "loss: 0.313915  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441324 \n",
      "\n",
      "Epoch 3486\n",
      "-------------------------------\n",
      "loss: 0.313455  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441982 \n",
      "\n",
      "Epoch 3487\n",
      "-------------------------------\n",
      "loss: 0.310666  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441787 \n",
      "\n",
      "Epoch 3488\n",
      "-------------------------------\n",
      "loss: 0.310206  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441983 \n",
      "\n",
      "Epoch 3489\n",
      "-------------------------------\n",
      "loss: 0.306016  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441825 \n",
      "\n",
      "Epoch 3490\n",
      "-------------------------------\n",
      "loss: 0.310197  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442271 \n",
      "\n",
      "Epoch 3491\n",
      "-------------------------------\n",
      "loss: 0.307739  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442036 \n",
      "\n",
      "Epoch 3492\n",
      "-------------------------------\n",
      "loss: 0.313752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441775 \n",
      "\n",
      "Epoch 3493\n",
      "-------------------------------\n",
      "loss: 0.309016  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441739 \n",
      "\n",
      "Epoch 3494\n",
      "-------------------------------\n",
      "loss: 0.306186  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441744 \n",
      "\n",
      "Epoch 3495\n",
      "-------------------------------\n",
      "loss: 0.313243  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441348 \n",
      "\n",
      "Epoch 3496\n",
      "-------------------------------\n",
      "loss: 0.317291  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442236 \n",
      "\n",
      "Epoch 3497\n",
      "-------------------------------\n",
      "loss: 0.306073  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443088 \n",
      "\n",
      "Epoch 3498\n",
      "-------------------------------\n",
      "loss: 0.303554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442783 \n",
      "\n",
      "Epoch 3499\n",
      "-------------------------------\n",
      "loss: 0.312986  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443027 \n",
      "\n",
      "Epoch 3500\n",
      "-------------------------------\n",
      "loss: 0.308434  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442366 \n",
      "\n",
      "Epoch 3501\n",
      "-------------------------------\n",
      "loss: 0.304262  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442167 \n",
      "\n",
      "Epoch 3502\n",
      "-------------------------------\n",
      "loss: 0.313434  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441509 \n",
      "\n",
      "Epoch 3503\n",
      "-------------------------------\n",
      "loss: 0.304332  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440850 \n",
      "\n",
      "Epoch 3504\n",
      "-------------------------------\n",
      "loss: 0.309376  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441549 \n",
      "\n",
      "Epoch 3505\n",
      "-------------------------------\n",
      "loss: 0.301943  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442512 \n",
      "\n",
      "Epoch 3506\n",
      "-------------------------------\n",
      "loss: 0.314119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442860 \n",
      "\n",
      "Epoch 3507\n",
      "-------------------------------\n",
      "loss: 0.313112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442433 \n",
      "\n",
      "Epoch 3508\n",
      "-------------------------------\n",
      "loss: 0.307615  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442194 \n",
      "\n",
      "Epoch 3509\n",
      "-------------------------------\n",
      "loss: 0.312239  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442224 \n",
      "\n",
      "Epoch 3510\n",
      "-------------------------------\n",
      "loss: 0.310455  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442144 \n",
      "\n",
      "Epoch 3511\n",
      "-------------------------------\n",
      "loss: 0.301986  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442651 \n",
      "\n",
      "Epoch 3512\n",
      "-------------------------------\n",
      "loss: 0.307223  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443058 \n",
      "\n",
      "Epoch 3513\n",
      "-------------------------------\n",
      "loss: 0.306761  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443489 \n",
      "\n",
      "Epoch 3514\n",
      "-------------------------------\n",
      "loss: 0.315569  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443022 \n",
      "\n",
      "Epoch 3515\n",
      "-------------------------------\n",
      "loss: 0.311479  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443162 \n",
      "\n",
      "Epoch 3516\n",
      "-------------------------------\n",
      "loss: 0.296826  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443056 \n",
      "\n",
      "Epoch 3517\n",
      "-------------------------------\n",
      "loss: 0.301718  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442710 \n",
      "\n",
      "Epoch 3518\n",
      "-------------------------------\n",
      "loss: 0.309947  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442955 \n",
      "\n",
      "Epoch 3519\n",
      "-------------------------------\n",
      "loss: 0.311420  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442727 \n",
      "\n",
      "Epoch 3520\n",
      "-------------------------------\n",
      "loss: 0.314850  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442770 \n",
      "\n",
      "Epoch 3521\n",
      "-------------------------------\n",
      "loss: 0.309121  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442624 \n",
      "\n",
      "Epoch 3522\n",
      "-------------------------------\n",
      "loss: 0.311819  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441415 \n",
      "\n",
      "Epoch 3523\n",
      "-------------------------------\n",
      "loss: 0.303022  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441759 \n",
      "\n",
      "Epoch 3524\n",
      "-------------------------------\n",
      "loss: 0.304375  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441125 \n",
      "\n",
      "Epoch 3525\n",
      "-------------------------------\n",
      "loss: 0.306923  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441173 \n",
      "\n",
      "Epoch 3526\n",
      "-------------------------------\n",
      "loss: 0.302075  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441036 \n",
      "\n",
      "Epoch 3527\n",
      "-------------------------------\n",
      "loss: 0.310713  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441232 \n",
      "\n",
      "Epoch 3528\n",
      "-------------------------------\n",
      "loss: 0.311850  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441545 \n",
      "\n",
      "Epoch 3529\n",
      "-------------------------------\n",
      "loss: 0.304638  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440924 \n",
      "\n",
      "Epoch 3530\n",
      "-------------------------------\n",
      "loss: 0.299154  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440311 \n",
      "\n",
      "Epoch 3531\n",
      "-------------------------------\n",
      "loss: 0.303360  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440724 \n",
      "\n",
      "Epoch 3532\n",
      "-------------------------------\n",
      "loss: 0.313953  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440578 \n",
      "\n",
      "Epoch 3533\n",
      "-------------------------------\n",
      "loss: 0.303753  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441477 \n",
      "\n",
      "Epoch 3534\n",
      "-------------------------------\n",
      "loss: 0.313994  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441747 \n",
      "\n",
      "Epoch 3535\n",
      "-------------------------------\n",
      "loss: 0.308303  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441338 \n",
      "\n",
      "Epoch 3536\n",
      "-------------------------------\n",
      "loss: 0.308999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440972 \n",
      "\n",
      "Epoch 3537\n",
      "-------------------------------\n",
      "loss: 0.309038  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441315 \n",
      "\n",
      "Epoch 3538\n",
      "-------------------------------\n",
      "loss: 0.303552  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441892 \n",
      "\n",
      "Epoch 3539\n",
      "-------------------------------\n",
      "loss: 0.310650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441658 \n",
      "\n",
      "Epoch 3540\n",
      "-------------------------------\n",
      "loss: 0.310674  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441628 \n",
      "\n",
      "Epoch 3541\n",
      "-------------------------------\n",
      "loss: 0.308032  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442643 \n",
      "\n",
      "Epoch 3542\n",
      "-------------------------------\n",
      "loss: 0.305349  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442939 \n",
      "\n",
      "Epoch 3543\n",
      "-------------------------------\n",
      "loss: 0.305943  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442495 \n",
      "\n",
      "Epoch 3544\n",
      "-------------------------------\n",
      "loss: 0.312690  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442595 \n",
      "\n",
      "Epoch 3545\n",
      "-------------------------------\n",
      "loss: 0.314819  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442047 \n",
      "\n",
      "Epoch 3546\n",
      "-------------------------------\n",
      "loss: 0.316138  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441559 \n",
      "\n",
      "Epoch 3547\n",
      "-------------------------------\n",
      "loss: 0.302671  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441709 \n",
      "\n",
      "Epoch 3548\n",
      "-------------------------------\n",
      "loss: 0.306145  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441120 \n",
      "\n",
      "Epoch 3549\n",
      "-------------------------------\n",
      "loss: 0.307526  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441498 \n",
      "\n",
      "Epoch 3550\n",
      "-------------------------------\n",
      "loss: 0.310453  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440586 \n",
      "\n",
      "Epoch 3551\n",
      "-------------------------------\n",
      "loss: 0.308774  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440660 \n",
      "\n",
      "Epoch 3552\n",
      "-------------------------------\n",
      "loss: 0.304134  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440209 \n",
      "\n",
      "Epoch 3553\n",
      "-------------------------------\n",
      "loss: 0.311513  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440323 \n",
      "\n",
      "Epoch 3554\n",
      "-------------------------------\n",
      "loss: 0.312454  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440425 \n",
      "\n",
      "Epoch 3555\n",
      "-------------------------------\n",
      "loss: 0.306135  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440845 \n",
      "\n",
      "Epoch 3556\n",
      "-------------------------------\n",
      "loss: 0.301273  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441562 \n",
      "\n",
      "Epoch 3557\n",
      "-------------------------------\n",
      "loss: 0.307894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441980 \n",
      "\n",
      "Epoch 3558\n",
      "-------------------------------\n",
      "loss: 0.315577  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441774 \n",
      "\n",
      "Epoch 3559\n",
      "-------------------------------\n",
      "loss: 0.303446  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442023 \n",
      "\n",
      "Epoch 3560\n",
      "-------------------------------\n",
      "loss: 0.303473  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442037 \n",
      "\n",
      "Epoch 3561\n",
      "-------------------------------\n",
      "loss: 0.298375  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442255 \n",
      "\n",
      "Epoch 3562\n",
      "-------------------------------\n",
      "loss: 0.308802  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442080 \n",
      "\n",
      "Epoch 3563\n",
      "-------------------------------\n",
      "loss: 0.310224  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442301 \n",
      "\n",
      "Epoch 3564\n",
      "-------------------------------\n",
      "loss: 0.306290  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442986 \n",
      "\n",
      "Epoch 3565\n",
      "-------------------------------\n",
      "loss: 0.314940  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442345 \n",
      "\n",
      "Epoch 3566\n",
      "-------------------------------\n",
      "loss: 0.305343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442042 \n",
      "\n",
      "Epoch 3567\n",
      "-------------------------------\n",
      "loss: 0.308700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442904 \n",
      "\n",
      "Epoch 3568\n",
      "-------------------------------\n",
      "loss: 0.319773  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442805 \n",
      "\n",
      "Epoch 3569\n",
      "-------------------------------\n",
      "loss: 0.310343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441791 \n",
      "\n",
      "Epoch 3570\n",
      "-------------------------------\n",
      "loss: 0.319746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440640 \n",
      "\n",
      "Epoch 3571\n",
      "-------------------------------\n",
      "loss: 0.305561  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441374 \n",
      "\n",
      "Epoch 3572\n",
      "-------------------------------\n",
      "loss: 0.303861  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440341 \n",
      "\n",
      "Epoch 3573\n",
      "-------------------------------\n",
      "loss: 0.307647  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440354 \n",
      "\n",
      "Epoch 3574\n",
      "-------------------------------\n",
      "loss: 0.314674  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440452 \n",
      "\n",
      "Epoch 3575\n",
      "-------------------------------\n",
      "loss: 0.305115  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440201 \n",
      "\n",
      "Epoch 3576\n",
      "-------------------------------\n",
      "loss: 0.299542  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440198 \n",
      "\n",
      "Epoch 3577\n",
      "-------------------------------\n",
      "loss: 0.303102  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441084 \n",
      "\n",
      "Epoch 3578\n",
      "-------------------------------\n",
      "loss: 0.305714  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441089 \n",
      "\n",
      "Epoch 3579\n",
      "-------------------------------\n",
      "loss: 0.308967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440936 \n",
      "\n",
      "Epoch 3580\n",
      "-------------------------------\n",
      "loss: 0.298873  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441052 \n",
      "\n",
      "Epoch 3581\n",
      "-------------------------------\n",
      "loss: 0.306128  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441539 \n",
      "\n",
      "Epoch 3582\n",
      "-------------------------------\n",
      "loss: 0.310567  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442125 \n",
      "\n",
      "Epoch 3583\n",
      "-------------------------------\n",
      "loss: 0.299730  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442363 \n",
      "\n",
      "Epoch 3584\n",
      "-------------------------------\n",
      "loss: 0.298160  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442033 \n",
      "\n",
      "Epoch 3585\n",
      "-------------------------------\n",
      "loss: 0.308886  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441614 \n",
      "\n",
      "Epoch 3586\n",
      "-------------------------------\n",
      "loss: 0.305523  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442343 \n",
      "\n",
      "Epoch 3587\n",
      "-------------------------------\n",
      "loss: 0.309742  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442822 \n",
      "\n",
      "Epoch 3588\n",
      "-------------------------------\n",
      "loss: 0.303443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443012 \n",
      "\n",
      "Epoch 3589\n",
      "-------------------------------\n",
      "loss: 0.310056  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443193 \n",
      "\n",
      "Epoch 3590\n",
      "-------------------------------\n",
      "loss: 0.303980  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442879 \n",
      "\n",
      "Epoch 3591\n",
      "-------------------------------\n",
      "loss: 0.306807  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442062 \n",
      "\n",
      "Epoch 3592\n",
      "-------------------------------\n",
      "loss: 0.306745  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441858 \n",
      "\n",
      "Epoch 3593\n",
      "-------------------------------\n",
      "loss: 0.303524  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442230 \n",
      "\n",
      "Epoch 3594\n",
      "-------------------------------\n",
      "loss: 0.306179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441632 \n",
      "\n",
      "Epoch 3595\n",
      "-------------------------------\n",
      "loss: 0.310459  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442424 \n",
      "\n",
      "Epoch 3596\n",
      "-------------------------------\n",
      "loss: 0.310007  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442981 \n",
      "\n",
      "Epoch 3597\n",
      "-------------------------------\n",
      "loss: 0.303444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442822 \n",
      "\n",
      "Epoch 3598\n",
      "-------------------------------\n",
      "loss: 0.308699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442860 \n",
      "\n",
      "Epoch 3599\n",
      "-------------------------------\n",
      "loss: 0.309999  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441358 \n",
      "\n",
      "Epoch 3600\n",
      "-------------------------------\n",
      "loss: 0.303792  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441517 \n",
      "\n",
      "Epoch 3601\n",
      "-------------------------------\n",
      "loss: 0.308609  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440213 \n",
      "\n",
      "Epoch 3602\n",
      "-------------------------------\n",
      "loss: 0.301928  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441092 \n",
      "\n",
      "Epoch 3603\n",
      "-------------------------------\n",
      "loss: 0.309895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440743 \n",
      "\n",
      "Epoch 3604\n",
      "-------------------------------\n",
      "loss: 0.308054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441884 \n",
      "\n",
      "Epoch 3605\n",
      "-------------------------------\n",
      "loss: 0.307704  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442296 \n",
      "\n",
      "Epoch 3606\n",
      "-------------------------------\n",
      "loss: 0.306542  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442768 \n",
      "\n",
      "Epoch 3607\n",
      "-------------------------------\n",
      "loss: 0.307445  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443359 \n",
      "\n",
      "Epoch 3608\n",
      "-------------------------------\n",
      "loss: 0.301452  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443026 \n",
      "\n",
      "Epoch 3609\n",
      "-------------------------------\n",
      "loss: 0.303753  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443225 \n",
      "\n",
      "Epoch 3610\n",
      "-------------------------------\n",
      "loss: 0.308980  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442538 \n",
      "\n",
      "Epoch 3611\n",
      "-------------------------------\n",
      "loss: 0.309337  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442139 \n",
      "\n",
      "Epoch 3612\n",
      "-------------------------------\n",
      "loss: 0.308751  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442365 \n",
      "\n",
      "Epoch 3613\n",
      "-------------------------------\n",
      "loss: 0.303840  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442280 \n",
      "\n",
      "Epoch 3614\n",
      "-------------------------------\n",
      "loss: 0.312894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441961 \n",
      "\n",
      "Epoch 3615\n",
      "-------------------------------\n",
      "loss: 0.303172  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442423 \n",
      "\n",
      "Epoch 3616\n",
      "-------------------------------\n",
      "loss: 0.307130  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442131 \n",
      "\n",
      "Epoch 3617\n",
      "-------------------------------\n",
      "loss: 0.302779  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442522 \n",
      "\n",
      "Epoch 3618\n",
      "-------------------------------\n",
      "loss: 0.306702  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442058 \n",
      "\n",
      "Epoch 3619\n",
      "-------------------------------\n",
      "loss: 0.313622  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441304 \n",
      "\n",
      "Epoch 3620\n",
      "-------------------------------\n",
      "loss: 0.313111  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440770 \n",
      "\n",
      "Epoch 3621\n",
      "-------------------------------\n",
      "loss: 0.308338  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440377 \n",
      "\n",
      "Epoch 3622\n",
      "-------------------------------\n",
      "loss: 0.301887  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440053 \n",
      "\n",
      "Epoch 3623\n",
      "-------------------------------\n",
      "loss: 0.312007  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440130 \n",
      "\n",
      "Epoch 3624\n",
      "-------------------------------\n",
      "loss: 0.310411  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439195 \n",
      "\n",
      "Epoch 3625\n",
      "-------------------------------\n",
      "loss: 0.302490  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439321 \n",
      "\n",
      "Epoch 3626\n",
      "-------------------------------\n",
      "loss: 0.300519  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438941 \n",
      "\n",
      "Epoch 3627\n",
      "-------------------------------\n",
      "loss: 0.308242  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438209 \n",
      "\n",
      "Epoch 3628\n",
      "-------------------------------\n",
      "loss: 0.304032  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438791 \n",
      "\n",
      "Epoch 3629\n",
      "-------------------------------\n",
      "loss: 0.296876  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438960 \n",
      "\n",
      "Epoch 3630\n",
      "-------------------------------\n",
      "loss: 0.302332  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440471 \n",
      "\n",
      "Epoch 3631\n",
      "-------------------------------\n",
      "loss: 0.314555  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441684 \n",
      "\n",
      "Epoch 3632\n",
      "-------------------------------\n",
      "loss: 0.311950  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442977 \n",
      "\n",
      "Epoch 3633\n",
      "-------------------------------\n",
      "loss: 0.305160  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442673 \n",
      "\n",
      "Epoch 3634\n",
      "-------------------------------\n",
      "loss: 0.302166  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443408 \n",
      "\n",
      "Epoch 3635\n",
      "-------------------------------\n",
      "loss: 0.306201  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443567 \n",
      "\n",
      "Epoch 3636\n",
      "-------------------------------\n",
      "loss: 0.297645  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443612 \n",
      "\n",
      "Epoch 3637\n",
      "-------------------------------\n",
      "loss: 0.304706  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443566 \n",
      "\n",
      "Epoch 3638\n",
      "-------------------------------\n",
      "loss: 0.313626  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442727 \n",
      "\n",
      "Epoch 3639\n",
      "-------------------------------\n",
      "loss: 0.301261  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442007 \n",
      "\n",
      "Epoch 3640\n",
      "-------------------------------\n",
      "loss: 0.311346  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441080 \n",
      "\n",
      "Epoch 3641\n",
      "-------------------------------\n",
      "loss: 0.307444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441038 \n",
      "\n",
      "Epoch 3642\n",
      "-------------------------------\n",
      "loss: 0.304076  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440330 \n",
      "\n",
      "Epoch 3643\n",
      "-------------------------------\n",
      "loss: 0.307606  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440099 \n",
      "\n",
      "Epoch 3644\n",
      "-------------------------------\n",
      "loss: 0.305653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440141 \n",
      "\n",
      "Epoch 3645\n",
      "-------------------------------\n",
      "loss: 0.307810  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439717 \n",
      "\n",
      "Epoch 3646\n",
      "-------------------------------\n",
      "loss: 0.305179  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439356 \n",
      "\n",
      "Epoch 3647\n",
      "-------------------------------\n",
      "loss: 0.302651  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440034 \n",
      "\n",
      "Epoch 3648\n",
      "-------------------------------\n",
      "loss: 0.300232  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440861 \n",
      "\n",
      "Epoch 3649\n",
      "-------------------------------\n",
      "loss: 0.310088  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441758 \n",
      "\n",
      "Epoch 3650\n",
      "-------------------------------\n",
      "loss: 0.305899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441836 \n",
      "\n",
      "Epoch 3651\n",
      "-------------------------------\n",
      "loss: 0.299579  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441731 \n",
      "\n",
      "Epoch 3652\n",
      "-------------------------------\n",
      "loss: 0.304630  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441854 \n",
      "\n",
      "Epoch 3653\n",
      "-------------------------------\n",
      "loss: 0.309413  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440972 \n",
      "\n",
      "Epoch 3654\n",
      "-------------------------------\n",
      "loss: 0.303800  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440427 \n",
      "\n",
      "Epoch 3655\n",
      "-------------------------------\n",
      "loss: 0.302184  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440009 \n",
      "\n",
      "Epoch 3656\n",
      "-------------------------------\n",
      "loss: 0.306906  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439110 \n",
      "\n",
      "Epoch 3657\n",
      "-------------------------------\n",
      "loss: 0.309450  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438718 \n",
      "\n",
      "Epoch 3658\n",
      "-------------------------------\n",
      "loss: 0.306465  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438594 \n",
      "\n",
      "Epoch 3659\n",
      "-------------------------------\n",
      "loss: 0.302862  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438478 \n",
      "\n",
      "Epoch 3660\n",
      "-------------------------------\n",
      "loss: 0.307569  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438948 \n",
      "\n",
      "Epoch 3661\n",
      "-------------------------------\n",
      "loss: 0.300316  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438882 \n",
      "\n",
      "Epoch 3662\n",
      "-------------------------------\n",
      "loss: 0.312816  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440201 \n",
      "\n",
      "Epoch 3663\n",
      "-------------------------------\n",
      "loss: 0.307178  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441164 \n",
      "\n",
      "Epoch 3664\n",
      "-------------------------------\n",
      "loss: 0.301072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442172 \n",
      "\n",
      "Epoch 3665\n",
      "-------------------------------\n",
      "loss: 0.304644  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443755 \n",
      "\n",
      "Epoch 3666\n",
      "-------------------------------\n",
      "loss: 0.309089  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444120 \n",
      "\n",
      "Epoch 3667\n",
      "-------------------------------\n",
      "loss: 0.305256  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445134 \n",
      "\n",
      "Epoch 3668\n",
      "-------------------------------\n",
      "loss: 0.308396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444937 \n",
      "\n",
      "Epoch 3669\n",
      "-------------------------------\n",
      "loss: 0.306878  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443743 \n",
      "\n",
      "Epoch 3670\n",
      "-------------------------------\n",
      "loss: 0.307118  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442858 \n",
      "\n",
      "Epoch 3671\n",
      "-------------------------------\n",
      "loss: 0.301487  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442629 \n",
      "\n",
      "Epoch 3672\n",
      "-------------------------------\n",
      "loss: 0.310000  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442079 \n",
      "\n",
      "Epoch 3673\n",
      "-------------------------------\n",
      "loss: 0.308900  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442037 \n",
      "\n",
      "Epoch 3674\n",
      "-------------------------------\n",
      "loss: 0.301474  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441401 \n",
      "\n",
      "Epoch 3675\n",
      "-------------------------------\n",
      "loss: 0.304951  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441912 \n",
      "\n",
      "Epoch 3676\n",
      "-------------------------------\n",
      "loss: 0.314314  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442352 \n",
      "\n",
      "Epoch 3677\n",
      "-------------------------------\n",
      "loss: 0.310620  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442141 \n",
      "\n",
      "Epoch 3678\n",
      "-------------------------------\n",
      "loss: 0.307020  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442388 \n",
      "\n",
      "Epoch 3679\n",
      "-------------------------------\n",
      "loss: 0.311899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441774 \n",
      "\n",
      "Epoch 3680\n",
      "-------------------------------\n",
      "loss: 0.304868  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441560 \n",
      "\n",
      "Epoch 3681\n",
      "-------------------------------\n",
      "loss: 0.307417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441337 \n",
      "\n",
      "Epoch 3682\n",
      "-------------------------------\n",
      "loss: 0.303639  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440419 \n",
      "\n",
      "Epoch 3683\n",
      "-------------------------------\n",
      "loss: 0.307617  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440221 \n",
      "\n",
      "Epoch 3684\n",
      "-------------------------------\n",
      "loss: 0.305354  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439750 \n",
      "\n",
      "Epoch 3685\n",
      "-------------------------------\n",
      "loss: 0.307692  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439988 \n",
      "\n",
      "Epoch 3686\n",
      "-------------------------------\n",
      "loss: 0.307250  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440296 \n",
      "\n",
      "Epoch 3687\n",
      "-------------------------------\n",
      "loss: 0.305484  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441480 \n",
      "\n",
      "Epoch 3688\n",
      "-------------------------------\n",
      "loss: 0.307193  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441977 \n",
      "\n",
      "Epoch 3689\n",
      "-------------------------------\n",
      "loss: 0.314979  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442419 \n",
      "\n",
      "Epoch 3690\n",
      "-------------------------------\n",
      "loss: 0.301272  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441759 \n",
      "\n",
      "Epoch 3691\n",
      "-------------------------------\n",
      "loss: 0.314774  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441522 \n",
      "\n",
      "Epoch 3692\n",
      "-------------------------------\n",
      "loss: 0.307527  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439797 \n",
      "\n",
      "Epoch 3693\n",
      "-------------------------------\n",
      "loss: 0.306556  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438836 \n",
      "\n",
      "Epoch 3694\n",
      "-------------------------------\n",
      "loss: 0.307510  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.438360 \n",
      "\n",
      "Epoch 3695\n",
      "-------------------------------\n",
      "loss: 0.304255  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438920 \n",
      "\n",
      "Epoch 3696\n",
      "-------------------------------\n",
      "loss: 0.311045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438555 \n",
      "\n",
      "Epoch 3697\n",
      "-------------------------------\n",
      "loss: 0.300817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438419 \n",
      "\n",
      "Epoch 3698\n",
      "-------------------------------\n",
      "loss: 0.304787  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438330 \n",
      "\n",
      "Epoch 3699\n",
      "-------------------------------\n",
      "loss: 0.307960  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440961 \n",
      "\n",
      "Epoch 3700\n",
      "-------------------------------\n",
      "loss: 0.302826  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441959 \n",
      "\n",
      "Epoch 3701\n",
      "-------------------------------\n",
      "loss: 0.309384  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441930 \n",
      "\n",
      "Epoch 3702\n",
      "-------------------------------\n",
      "loss: 0.313291  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442384 \n",
      "\n",
      "Epoch 3703\n",
      "-------------------------------\n",
      "loss: 0.309963  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441204 \n",
      "\n",
      "Epoch 3704\n",
      "-------------------------------\n",
      "loss: 0.304364  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439683 \n",
      "\n",
      "Epoch 3705\n",
      "-------------------------------\n",
      "loss: 0.304499  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438373 \n",
      "\n",
      "Epoch 3706\n",
      "-------------------------------\n",
      "loss: 0.305857  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437834 \n",
      "\n",
      "Epoch 3707\n",
      "-------------------------------\n",
      "loss: 0.312791  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439261 \n",
      "\n",
      "Epoch 3708\n",
      "-------------------------------\n",
      "loss: 0.303173  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438318 \n",
      "\n",
      "Epoch 3709\n",
      "-------------------------------\n",
      "loss: 0.306950  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439213 \n",
      "\n",
      "Epoch 3710\n",
      "-------------------------------\n",
      "loss: 0.305876  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439104 \n",
      "\n",
      "Epoch 3711\n",
      "-------------------------------\n",
      "loss: 0.305858  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440139 \n",
      "\n",
      "Epoch 3712\n",
      "-------------------------------\n",
      "loss: 0.301469  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441151 \n",
      "\n",
      "Epoch 3713\n",
      "-------------------------------\n",
      "loss: 0.307752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442205 \n",
      "\n",
      "Epoch 3714\n",
      "-------------------------------\n",
      "loss: 0.308209  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443088 \n",
      "\n",
      "Epoch 3715\n",
      "-------------------------------\n",
      "loss: 0.305246  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442236 \n",
      "\n",
      "Epoch 3716\n",
      "-------------------------------\n",
      "loss: 0.309391  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441944 \n",
      "\n",
      "Epoch 3717\n",
      "-------------------------------\n",
      "loss: 0.308232  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441179 \n",
      "\n",
      "Epoch 3718\n",
      "-------------------------------\n",
      "loss: 0.302168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441801 \n",
      "\n",
      "Epoch 3719\n",
      "-------------------------------\n",
      "loss: 0.303951  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442227 \n",
      "\n",
      "Epoch 3720\n",
      "-------------------------------\n",
      "loss: 0.306153  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442396 \n",
      "\n",
      "Epoch 3721\n",
      "-------------------------------\n",
      "loss: 0.301281  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443267 \n",
      "\n",
      "Epoch 3722\n",
      "-------------------------------\n",
      "loss: 0.308319  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443320 \n",
      "\n",
      "Epoch 3723\n",
      "-------------------------------\n",
      "loss: 0.305014  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442711 \n",
      "\n",
      "Epoch 3724\n",
      "-------------------------------\n",
      "loss: 0.308047  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443158 \n",
      "\n",
      "Epoch 3725\n",
      "-------------------------------\n",
      "loss: 0.306812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443472 \n",
      "\n",
      "Epoch 3726\n",
      "-------------------------------\n",
      "loss: 0.311042  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443396 \n",
      "\n",
      "Epoch 3727\n",
      "-------------------------------\n",
      "loss: 0.312391  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442907 \n",
      "\n",
      "Epoch 3728\n",
      "-------------------------------\n",
      "loss: 0.315609  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442994 \n",
      "\n",
      "Epoch 3729\n",
      "-------------------------------\n",
      "loss: 0.308940  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442265 \n",
      "\n",
      "Epoch 3730\n",
      "-------------------------------\n",
      "loss: 0.304566  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441849 \n",
      "\n",
      "Epoch 3731\n",
      "-------------------------------\n",
      "loss: 0.313295  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440806 \n",
      "\n",
      "Epoch 3732\n",
      "-------------------------------\n",
      "loss: 0.299958  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441022 \n",
      "\n",
      "Epoch 3733\n",
      "-------------------------------\n",
      "loss: 0.307477  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440392 \n",
      "\n",
      "Epoch 3734\n",
      "-------------------------------\n",
      "loss: 0.310867  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440211 \n",
      "\n",
      "Epoch 3735\n",
      "-------------------------------\n",
      "loss: 0.303686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440301 \n",
      "\n",
      "Epoch 3736\n",
      "-------------------------------\n",
      "loss: 0.304467  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440251 \n",
      "\n",
      "Epoch 3737\n",
      "-------------------------------\n",
      "loss: 0.305762  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441507 \n",
      "\n",
      "Epoch 3738\n",
      "-------------------------------\n",
      "loss: 0.311669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442184 \n",
      "\n",
      "Epoch 3739\n",
      "-------------------------------\n",
      "loss: 0.303447  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443134 \n",
      "\n",
      "Epoch 3740\n",
      "-------------------------------\n",
      "loss: 0.323207  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443417 \n",
      "\n",
      "Epoch 3741\n",
      "-------------------------------\n",
      "loss: 0.300231  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442990 \n",
      "\n",
      "Epoch 3742\n",
      "-------------------------------\n",
      "loss: 0.309846  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442749 \n",
      "\n",
      "Epoch 3743\n",
      "-------------------------------\n",
      "loss: 0.302879  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441910 \n",
      "\n",
      "Epoch 3744\n",
      "-------------------------------\n",
      "loss: 0.299970  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440906 \n",
      "\n",
      "Epoch 3745\n",
      "-------------------------------\n",
      "loss: 0.305673  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441184 \n",
      "\n",
      "Epoch 3746\n",
      "-------------------------------\n",
      "loss: 0.303486  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441260 \n",
      "\n",
      "Epoch 3747\n",
      "-------------------------------\n",
      "loss: 0.309803  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441447 \n",
      "\n",
      "Epoch 3748\n",
      "-------------------------------\n",
      "loss: 0.309791  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442280 \n",
      "\n",
      "Epoch 3749\n",
      "-------------------------------\n",
      "loss: 0.308024  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443458 \n",
      "\n",
      "Epoch 3750\n",
      "-------------------------------\n",
      "loss: 0.301233  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444742 \n",
      "\n",
      "Epoch 3751\n",
      "-------------------------------\n",
      "loss: 0.306289  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444172 \n",
      "\n",
      "Epoch 3752\n",
      "-------------------------------\n",
      "loss: 0.308132  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444317 \n",
      "\n",
      "Epoch 3753\n",
      "-------------------------------\n",
      "loss: 0.310418  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444049 \n",
      "\n",
      "Epoch 3754\n",
      "-------------------------------\n",
      "loss: 0.302495  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442197 \n",
      "\n",
      "Epoch 3755\n",
      "-------------------------------\n",
      "loss: 0.301463  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441105 \n",
      "\n",
      "Epoch 3756\n",
      "-------------------------------\n",
      "loss: 0.305850  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440679 \n",
      "\n",
      "Epoch 3757\n",
      "-------------------------------\n",
      "loss: 0.307735  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439654 \n",
      "\n",
      "Epoch 3758\n",
      "-------------------------------\n",
      "loss: 0.309220  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439718 \n",
      "\n",
      "Epoch 3759\n",
      "-------------------------------\n",
      "loss: 0.318712  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439807 \n",
      "\n",
      "Epoch 3760\n",
      "-------------------------------\n",
      "loss: 0.308112  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440132 \n",
      "\n",
      "Epoch 3761\n",
      "-------------------------------\n",
      "loss: 0.313628  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440111 \n",
      "\n",
      "Epoch 3762\n",
      "-------------------------------\n",
      "loss: 0.310748  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439627 \n",
      "\n",
      "Epoch 3763\n",
      "-------------------------------\n",
      "loss: 0.309047  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440139 \n",
      "\n",
      "Epoch 3764\n",
      "-------------------------------\n",
      "loss: 0.295417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441635 \n",
      "\n",
      "Epoch 3765\n",
      "-------------------------------\n",
      "loss: 0.302629  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442277 \n",
      "\n",
      "Epoch 3766\n",
      "-------------------------------\n",
      "loss: 0.307408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442619 \n",
      "\n",
      "Epoch 3767\n",
      "-------------------------------\n",
      "loss: 0.308211  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443456 \n",
      "\n",
      "Epoch 3768\n",
      "-------------------------------\n",
      "loss: 0.302476  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442513 \n",
      "\n",
      "Epoch 3769\n",
      "-------------------------------\n",
      "loss: 0.304486  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441854 \n",
      "\n",
      "Epoch 3770\n",
      "-------------------------------\n",
      "loss: 0.298492  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440990 \n",
      "\n",
      "Epoch 3771\n",
      "-------------------------------\n",
      "loss: 0.302548  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440957 \n",
      "\n",
      "Epoch 3772\n",
      "-------------------------------\n",
      "loss: 0.308926  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439996 \n",
      "\n",
      "Epoch 3773\n",
      "-------------------------------\n",
      "loss: 0.310882  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441376 \n",
      "\n",
      "Epoch 3774\n",
      "-------------------------------\n",
      "loss: 0.308668  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441488 \n",
      "\n",
      "Epoch 3775\n",
      "-------------------------------\n",
      "loss: 0.300165  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441815 \n",
      "\n",
      "Epoch 3776\n",
      "-------------------------------\n",
      "loss: 0.297998  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441286 \n",
      "\n",
      "Epoch 3777\n",
      "-------------------------------\n",
      "loss: 0.302136  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440826 \n",
      "\n",
      "Epoch 3778\n",
      "-------------------------------\n",
      "loss: 0.300237  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441494 \n",
      "\n",
      "Epoch 3779\n",
      "-------------------------------\n",
      "loss: 0.306947  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442044 \n",
      "\n",
      "Epoch 3780\n",
      "-------------------------------\n",
      "loss: 0.316625  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441094 \n",
      "\n",
      "Epoch 3781\n",
      "-------------------------------\n",
      "loss: 0.302678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440216 \n",
      "\n",
      "Epoch 3782\n",
      "-------------------------------\n",
      "loss: 0.302493  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439153 \n",
      "\n",
      "Epoch 3783\n",
      "-------------------------------\n",
      "loss: 0.298313  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439614 \n",
      "\n",
      "Epoch 3784\n",
      "-------------------------------\n",
      "loss: 0.306817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439666 \n",
      "\n",
      "Epoch 3785\n",
      "-------------------------------\n",
      "loss: 0.304661  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440465 \n",
      "\n",
      "Epoch 3786\n",
      "-------------------------------\n",
      "loss: 0.302497  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439940 \n",
      "\n",
      "Epoch 3787\n",
      "-------------------------------\n",
      "loss: 0.304243  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440803 \n",
      "\n",
      "Epoch 3788\n",
      "-------------------------------\n",
      "loss: 0.305203  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442430 \n",
      "\n",
      "Epoch 3789\n",
      "-------------------------------\n",
      "loss: 0.303818  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442257 \n",
      "\n",
      "Epoch 3790\n",
      "-------------------------------\n",
      "loss: 0.296039  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442954 \n",
      "\n",
      "Epoch 3791\n",
      "-------------------------------\n",
      "loss: 0.307079  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442969 \n",
      "\n",
      "Epoch 3792\n",
      "-------------------------------\n",
      "loss: 0.312159  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443318 \n",
      "\n",
      "Epoch 3793\n",
      "-------------------------------\n",
      "loss: 0.311780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443085 \n",
      "\n",
      "Epoch 3794\n",
      "-------------------------------\n",
      "loss: 0.307012  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442202 \n",
      "\n",
      "Epoch 3795\n",
      "-------------------------------\n",
      "loss: 0.308275  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441984 \n",
      "\n",
      "Epoch 3796\n",
      "-------------------------------\n",
      "loss: 0.307110  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440968 \n",
      "\n",
      "Epoch 3797\n",
      "-------------------------------\n",
      "loss: 0.307941  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440403 \n",
      "\n",
      "Epoch 3798\n",
      "-------------------------------\n",
      "loss: 0.310482  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440895 \n",
      "\n",
      "Epoch 3799\n",
      "-------------------------------\n",
      "loss: 0.302580  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440244 \n",
      "\n",
      "Epoch 3800\n",
      "-------------------------------\n",
      "loss: 0.305711  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439958 \n",
      "\n",
      "Epoch 3801\n",
      "-------------------------------\n",
      "loss: 0.309630  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439816 \n",
      "\n",
      "Epoch 3802\n",
      "-------------------------------\n",
      "loss: 0.303272  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440239 \n",
      "\n",
      "Epoch 3803\n",
      "-------------------------------\n",
      "loss: 0.301771  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442010 \n",
      "\n",
      "Epoch 3804\n",
      "-------------------------------\n",
      "loss: 0.308077  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443133 \n",
      "\n",
      "Epoch 3805\n",
      "-------------------------------\n",
      "loss: 0.305547  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442790 \n",
      "\n",
      "Epoch 3806\n",
      "-------------------------------\n",
      "loss: 0.311011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442779 \n",
      "\n",
      "Epoch 3807\n",
      "-------------------------------\n",
      "loss: 0.303369  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442000 \n",
      "\n",
      "Epoch 3808\n",
      "-------------------------------\n",
      "loss: 0.305058  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442626 \n",
      "\n",
      "Epoch 3809\n",
      "-------------------------------\n",
      "loss: 0.298782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441656 \n",
      "\n",
      "Epoch 3810\n",
      "-------------------------------\n",
      "loss: 0.312241  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441241 \n",
      "\n",
      "Epoch 3811\n",
      "-------------------------------\n",
      "loss: 0.309188  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440301 \n",
      "\n",
      "Epoch 3812\n",
      "-------------------------------\n",
      "loss: 0.306752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440502 \n",
      "\n",
      "Epoch 3813\n",
      "-------------------------------\n",
      "loss: 0.312865  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439558 \n",
      "\n",
      "Epoch 3814\n",
      "-------------------------------\n",
      "loss: 0.300689  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439186 \n",
      "\n",
      "Epoch 3815\n",
      "-------------------------------\n",
      "loss: 0.311642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439479 \n",
      "\n",
      "Epoch 3816\n",
      "-------------------------------\n",
      "loss: 0.309418  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438947 \n",
      "\n",
      "Epoch 3817\n",
      "-------------------------------\n",
      "loss: 0.302723  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438678 \n",
      "\n",
      "Epoch 3818\n",
      "-------------------------------\n",
      "loss: 0.301167  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439889 \n",
      "\n",
      "Epoch 3819\n",
      "-------------------------------\n",
      "loss: 0.307636  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439920 \n",
      "\n",
      "Epoch 3820\n",
      "-------------------------------\n",
      "loss: 0.308808  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440036 \n",
      "\n",
      "Epoch 3821\n",
      "-------------------------------\n",
      "loss: 0.302895  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440830 \n",
      "\n",
      "Epoch 3822\n",
      "-------------------------------\n",
      "loss: 0.294151  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441083 \n",
      "\n",
      "Epoch 3823\n",
      "-------------------------------\n",
      "loss: 0.310142  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441717 \n",
      "\n",
      "Epoch 3824\n",
      "-------------------------------\n",
      "loss: 0.304964  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440879 \n",
      "\n",
      "Epoch 3825\n",
      "-------------------------------\n",
      "loss: 0.305996  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441172 \n",
      "\n",
      "Epoch 3826\n",
      "-------------------------------\n",
      "loss: 0.315880  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440201 \n",
      "\n",
      "Epoch 3827\n",
      "-------------------------------\n",
      "loss: 0.301511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441043 \n",
      "\n",
      "Epoch 3828\n",
      "-------------------------------\n",
      "loss: 0.303653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440039 \n",
      "\n",
      "Epoch 3829\n",
      "-------------------------------\n",
      "loss: 0.309170  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439977 \n",
      "\n",
      "Epoch 3830\n",
      "-------------------------------\n",
      "loss: 0.308769  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439637 \n",
      "\n",
      "Epoch 3831\n",
      "-------------------------------\n",
      "loss: 0.309687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438974 \n",
      "\n",
      "Epoch 3832\n",
      "-------------------------------\n",
      "loss: 0.308378  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440334 \n",
      "\n",
      "Epoch 3833\n",
      "-------------------------------\n",
      "loss: 0.304415  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440539 \n",
      "\n",
      "Epoch 3834\n",
      "-------------------------------\n",
      "loss: 0.303965  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440590 \n",
      "\n",
      "Epoch 3835\n",
      "-------------------------------\n",
      "loss: 0.303599  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440636 \n",
      "\n",
      "Epoch 3836\n",
      "-------------------------------\n",
      "loss: 0.307165  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441427 \n",
      "\n",
      "Epoch 3837\n",
      "-------------------------------\n",
      "loss: 0.299811  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440563 \n",
      "\n",
      "Epoch 3838\n",
      "-------------------------------\n",
      "loss: 0.304394  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440786 \n",
      "\n",
      "Epoch 3839\n",
      "-------------------------------\n",
      "loss: 0.308587  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440755 \n",
      "\n",
      "Epoch 3840\n",
      "-------------------------------\n",
      "loss: 0.304111  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441222 \n",
      "\n",
      "Epoch 3841\n",
      "-------------------------------\n",
      "loss: 0.300494  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440708 \n",
      "\n",
      "Epoch 3842\n",
      "-------------------------------\n",
      "loss: 0.303507  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439932 \n",
      "\n",
      "Epoch 3843\n",
      "-------------------------------\n",
      "loss: 0.301556  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439368 \n",
      "\n",
      "Epoch 3844\n",
      "-------------------------------\n",
      "loss: 0.302413  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439024 \n",
      "\n",
      "Epoch 3845\n",
      "-------------------------------\n",
      "loss: 0.305887  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439057 \n",
      "\n",
      "Epoch 3846\n",
      "-------------------------------\n",
      "loss: 0.306832  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.438405 \n",
      "\n",
      "Epoch 3847\n",
      "-------------------------------\n",
      "loss: 0.303432  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438530 \n",
      "\n",
      "Epoch 3848\n",
      "-------------------------------\n",
      "loss: 0.299404  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438469 \n",
      "\n",
      "Epoch 3849\n",
      "-------------------------------\n",
      "loss: 0.302459  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438902 \n",
      "\n",
      "Epoch 3850\n",
      "-------------------------------\n",
      "loss: 0.301190  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438303 \n",
      "\n",
      "Epoch 3851\n",
      "-------------------------------\n",
      "loss: 0.304009  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439905 \n",
      "\n",
      "Epoch 3852\n",
      "-------------------------------\n",
      "loss: 0.305789  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439375 \n",
      "\n",
      "Epoch 3853\n",
      "-------------------------------\n",
      "loss: 0.305859  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439285 \n",
      "\n",
      "Epoch 3854\n",
      "-------------------------------\n",
      "loss: 0.306065  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439167 \n",
      "\n",
      "Epoch 3855\n",
      "-------------------------------\n",
      "loss: 0.303016  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438187 \n",
      "\n",
      "Epoch 3856\n",
      "-------------------------------\n",
      "loss: 0.312788  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439366 \n",
      "\n",
      "Epoch 3857\n",
      "-------------------------------\n",
      "loss: 0.298572  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440113 \n",
      "\n",
      "Epoch 3858\n",
      "-------------------------------\n",
      "loss: 0.305570  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439874 \n",
      "\n",
      "Epoch 3859\n",
      "-------------------------------\n",
      "loss: 0.306983  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440472 \n",
      "\n",
      "Epoch 3860\n",
      "-------------------------------\n",
      "loss: 0.309853  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440184 \n",
      "\n",
      "Epoch 3861\n",
      "-------------------------------\n",
      "loss: 0.299431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440199 \n",
      "\n",
      "Epoch 3862\n",
      "-------------------------------\n",
      "loss: 0.301282  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440461 \n",
      "\n",
      "Epoch 3863\n",
      "-------------------------------\n",
      "loss: 0.308568  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440591 \n",
      "\n",
      "Epoch 3864\n",
      "-------------------------------\n",
      "loss: 0.300930  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442653 \n",
      "\n",
      "Epoch 3865\n",
      "-------------------------------\n",
      "loss: 0.310752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442715 \n",
      "\n",
      "Epoch 3866\n",
      "-------------------------------\n",
      "loss: 0.312300  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443059 \n",
      "\n",
      "Epoch 3867\n",
      "-------------------------------\n",
      "loss: 0.302817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441447 \n",
      "\n",
      "Epoch 3868\n",
      "-------------------------------\n",
      "loss: 0.297262  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440804 \n",
      "\n",
      "Epoch 3869\n",
      "-------------------------------\n",
      "loss: 0.301268  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440621 \n",
      "\n",
      "Epoch 3870\n",
      "-------------------------------\n",
      "loss: 0.307918  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439986 \n",
      "\n",
      "Epoch 3871\n",
      "-------------------------------\n",
      "loss: 0.307701  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439243 \n",
      "\n",
      "Epoch 3872\n",
      "-------------------------------\n",
      "loss: 0.300550  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439306 \n",
      "\n",
      "Epoch 3873\n",
      "-------------------------------\n",
      "loss: 0.308014  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439662 \n",
      "\n",
      "Epoch 3874\n",
      "-------------------------------\n",
      "loss: 0.306476  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439656 \n",
      "\n",
      "Epoch 3875\n",
      "-------------------------------\n",
      "loss: 0.301533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439859 \n",
      "\n",
      "Epoch 3876\n",
      "-------------------------------\n",
      "loss: 0.309986  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439904 \n",
      "\n",
      "Epoch 3877\n",
      "-------------------------------\n",
      "loss: 0.314063  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440468 \n",
      "\n",
      "Epoch 3878\n",
      "-------------------------------\n",
      "loss: 0.302024  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441310 \n",
      "\n",
      "Epoch 3879\n",
      "-------------------------------\n",
      "loss: 0.303538  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441837 \n",
      "\n",
      "Epoch 3880\n",
      "-------------------------------\n",
      "loss: 0.303303  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440556 \n",
      "\n",
      "Epoch 3881\n",
      "-------------------------------\n",
      "loss: 0.302535  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440961 \n",
      "\n",
      "Epoch 3882\n",
      "-------------------------------\n",
      "loss: 0.315336  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440353 \n",
      "\n",
      "Epoch 3883\n",
      "-------------------------------\n",
      "loss: 0.310341  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440718 \n",
      "\n",
      "Epoch 3884\n",
      "-------------------------------\n",
      "loss: 0.302383  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439921 \n",
      "\n",
      "Epoch 3885\n",
      "-------------------------------\n",
      "loss: 0.309654  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440103 \n",
      "\n",
      "Epoch 3886\n",
      "-------------------------------\n",
      "loss: 0.304686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440448 \n",
      "\n",
      "Epoch 3887\n",
      "-------------------------------\n",
      "loss: 0.302612  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439986 \n",
      "\n",
      "Epoch 3888\n",
      "-------------------------------\n",
      "loss: 0.302576  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440478 \n",
      "\n",
      "Epoch 3889\n",
      "-------------------------------\n",
      "loss: 0.295456  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440216 \n",
      "\n",
      "Epoch 3890\n",
      "-------------------------------\n",
      "loss: 0.303778  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441610 \n",
      "\n",
      "Epoch 3891\n",
      "-------------------------------\n",
      "loss: 0.302513  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441891 \n",
      "\n",
      "Epoch 3892\n",
      "-------------------------------\n",
      "loss: 0.300686  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443011 \n",
      "\n",
      "Epoch 3893\n",
      "-------------------------------\n",
      "loss: 0.307707  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442875 \n",
      "\n",
      "Epoch 3894\n",
      "-------------------------------\n",
      "loss: 0.306301  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441431 \n",
      "\n",
      "Epoch 3895\n",
      "-------------------------------\n",
      "loss: 0.310440  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440973 \n",
      "\n",
      "Epoch 3896\n",
      "-------------------------------\n",
      "loss: 0.309273  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441524 \n",
      "\n",
      "Epoch 3897\n",
      "-------------------------------\n",
      "loss: 0.307476  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441142 \n",
      "\n",
      "Epoch 3898\n",
      "-------------------------------\n",
      "loss: 0.301172  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441212 \n",
      "\n",
      "Epoch 3899\n",
      "-------------------------------\n",
      "loss: 0.305442  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441476 \n",
      "\n",
      "Epoch 3900\n",
      "-------------------------------\n",
      "loss: 0.313382  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441611 \n",
      "\n",
      "Epoch 3901\n",
      "-------------------------------\n",
      "loss: 0.308663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442298 \n",
      "\n",
      "Epoch 3902\n",
      "-------------------------------\n",
      "loss: 0.307055  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442753 \n",
      "\n",
      "Epoch 3903\n",
      "-------------------------------\n",
      "loss: 0.302549  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444001 \n",
      "\n",
      "Epoch 3904\n",
      "-------------------------------\n",
      "loss: 0.309432  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444082 \n",
      "\n",
      "Epoch 3905\n",
      "-------------------------------\n",
      "loss: 0.299820  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443605 \n",
      "\n",
      "Epoch 3906\n",
      "-------------------------------\n",
      "loss: 0.306499  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442579 \n",
      "\n",
      "Epoch 3907\n",
      "-------------------------------\n",
      "loss: 0.311229  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441598 \n",
      "\n",
      "Epoch 3908\n",
      "-------------------------------\n",
      "loss: 0.307874  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440171 \n",
      "\n",
      "Epoch 3909\n",
      "-------------------------------\n",
      "loss: 0.304794  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440781 \n",
      "\n",
      "Epoch 3910\n",
      "-------------------------------\n",
      "loss: 0.304031  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440270 \n",
      "\n",
      "Epoch 3911\n",
      "-------------------------------\n",
      "loss: 0.300152  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440295 \n",
      "\n",
      "Epoch 3912\n",
      "-------------------------------\n",
      "loss: 0.304468  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440900 \n",
      "\n",
      "Epoch 3913\n",
      "-------------------------------\n",
      "loss: 0.293877  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440916 \n",
      "\n",
      "Epoch 3914\n",
      "-------------------------------\n",
      "loss: 0.312941  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441607 \n",
      "\n",
      "Epoch 3915\n",
      "-------------------------------\n",
      "loss: 0.300478  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441269 \n",
      "\n",
      "Epoch 3916\n",
      "-------------------------------\n",
      "loss: 0.306677  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440925 \n",
      "\n",
      "Epoch 3917\n",
      "-------------------------------\n",
      "loss: 0.301994  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441039 \n",
      "\n",
      "Epoch 3918\n",
      "-------------------------------\n",
      "loss: 0.306868  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440444 \n",
      "\n",
      "Epoch 3919\n",
      "-------------------------------\n",
      "loss: 0.300306  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440840 \n",
      "\n",
      "Epoch 3920\n",
      "-------------------------------\n",
      "loss: 0.298160  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442100 \n",
      "\n",
      "Epoch 3921\n",
      "-------------------------------\n",
      "loss: 0.306701  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441242 \n",
      "\n",
      "Epoch 3922\n",
      "-------------------------------\n",
      "loss: 0.306442  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441834 \n",
      "\n",
      "Epoch 3923\n",
      "-------------------------------\n",
      "loss: 0.307253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440404 \n",
      "\n",
      "Epoch 3924\n",
      "-------------------------------\n",
      "loss: 0.301526  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439488 \n",
      "\n",
      "Epoch 3925\n",
      "-------------------------------\n",
      "loss: 0.307350  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439207 \n",
      "\n",
      "Epoch 3926\n",
      "-------------------------------\n",
      "loss: 0.305594  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438581 \n",
      "\n",
      "Epoch 3927\n",
      "-------------------------------\n",
      "loss: 0.312570  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439402 \n",
      "\n",
      "Epoch 3928\n",
      "-------------------------------\n",
      "loss: 0.304446  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440299 \n",
      "\n",
      "Epoch 3929\n",
      "-------------------------------\n",
      "loss: 0.314604  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441752 \n",
      "\n",
      "Epoch 3930\n",
      "-------------------------------\n",
      "loss: 0.303941  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442062 \n",
      "\n",
      "Epoch 3931\n",
      "-------------------------------\n",
      "loss: 0.300904  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442297 \n",
      "\n",
      "Epoch 3932\n",
      "-------------------------------\n",
      "loss: 0.302065  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442277 \n",
      "\n",
      "Epoch 3933\n",
      "-------------------------------\n",
      "loss: 0.304842  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442403 \n",
      "\n",
      "Epoch 3934\n",
      "-------------------------------\n",
      "loss: 0.313738  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442626 \n",
      "\n",
      "Epoch 3935\n",
      "-------------------------------\n",
      "loss: 0.299975  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442067 \n",
      "\n",
      "Epoch 3936\n",
      "-------------------------------\n",
      "loss: 0.305185  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442014 \n",
      "\n",
      "Epoch 3937\n",
      "-------------------------------\n",
      "loss: 0.311201  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441486 \n",
      "\n",
      "Epoch 3938\n",
      "-------------------------------\n",
      "loss: 0.303838  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440896 \n",
      "\n",
      "Epoch 3939\n",
      "-------------------------------\n",
      "loss: 0.302779  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440840 \n",
      "\n",
      "Epoch 3940\n",
      "-------------------------------\n",
      "loss: 0.312043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440078 \n",
      "\n",
      "Epoch 3941\n",
      "-------------------------------\n",
      "loss: 0.298192  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439492 \n",
      "\n",
      "Epoch 3942\n",
      "-------------------------------\n",
      "loss: 0.307936  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439031 \n",
      "\n",
      "Epoch 3943\n",
      "-------------------------------\n",
      "loss: 0.300121  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439226 \n",
      "\n",
      "Epoch 3944\n",
      "-------------------------------\n",
      "loss: 0.301011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439710 \n",
      "\n",
      "Epoch 3945\n",
      "-------------------------------\n",
      "loss: 0.299585  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440549 \n",
      "\n",
      "Epoch 3946\n",
      "-------------------------------\n",
      "loss: 0.306927  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441175 \n",
      "\n",
      "Epoch 3947\n",
      "-------------------------------\n",
      "loss: 0.309748  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441538 \n",
      "\n",
      "Epoch 3948\n",
      "-------------------------------\n",
      "loss: 0.304569  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440974 \n",
      "\n",
      "Epoch 3949\n",
      "-------------------------------\n",
      "loss: 0.302444  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440879 \n",
      "\n",
      "Epoch 3950\n",
      "-------------------------------\n",
      "loss: 0.301667  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440129 \n",
      "\n",
      "Epoch 3951\n",
      "-------------------------------\n",
      "loss: 0.302947  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440089 \n",
      "\n",
      "Epoch 3952\n",
      "-------------------------------\n",
      "loss: 0.307293  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439474 \n",
      "\n",
      "Epoch 3953\n",
      "-------------------------------\n",
      "loss: 0.307057  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438876 \n",
      "\n",
      "Epoch 3954\n",
      "-------------------------------\n",
      "loss: 0.308020  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438613 \n",
      "\n",
      "Epoch 3955\n",
      "-------------------------------\n",
      "loss: 0.298945  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438549 \n",
      "\n",
      "Epoch 3956\n",
      "-------------------------------\n",
      "loss: 0.305678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439759 \n",
      "\n",
      "Epoch 3957\n",
      "-------------------------------\n",
      "loss: 0.308811  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439644 \n",
      "\n",
      "Epoch 3958\n",
      "-------------------------------\n",
      "loss: 0.306269  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440311 \n",
      "\n",
      "Epoch 3959\n",
      "-------------------------------\n",
      "loss: 0.301912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441122 \n",
      "\n",
      "Epoch 3960\n",
      "-------------------------------\n",
      "loss: 0.293893  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441853 \n",
      "\n",
      "Epoch 3961\n",
      "-------------------------------\n",
      "loss: 0.308690  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442506 \n",
      "\n",
      "Epoch 3962\n",
      "-------------------------------\n",
      "loss: 0.301616  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442800 \n",
      "\n",
      "Epoch 3963\n",
      "-------------------------------\n",
      "loss: 0.304716  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441626 \n",
      "\n",
      "Epoch 3964\n",
      "-------------------------------\n",
      "loss: 0.310758  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441213 \n",
      "\n",
      "Epoch 3965\n",
      "-------------------------------\n",
      "loss: 0.306283  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441418 \n",
      "\n",
      "Epoch 3966\n",
      "-------------------------------\n",
      "loss: 0.304902  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440857 \n",
      "\n",
      "Epoch 3967\n",
      "-------------------------------\n",
      "loss: 0.301471  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441167 \n",
      "\n",
      "Epoch 3968\n",
      "-------------------------------\n",
      "loss: 0.312922  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441159 \n",
      "\n",
      "Epoch 3969\n",
      "-------------------------------\n",
      "loss: 0.306653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440620 \n",
      "\n",
      "Epoch 3970\n",
      "-------------------------------\n",
      "loss: 0.299161  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440997 \n",
      "\n",
      "Epoch 3971\n",
      "-------------------------------\n",
      "loss: 0.309021  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440637 \n",
      "\n",
      "Epoch 3972\n",
      "-------------------------------\n",
      "loss: 0.298166  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441424 \n",
      "\n",
      "Epoch 3973\n",
      "-------------------------------\n",
      "loss: 0.310113  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441300 \n",
      "\n",
      "Epoch 3974\n",
      "-------------------------------\n",
      "loss: 0.302329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441588 \n",
      "\n",
      "Epoch 3975\n",
      "-------------------------------\n",
      "loss: 0.299669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440677 \n",
      "\n",
      "Epoch 3976\n",
      "-------------------------------\n",
      "loss: 0.310473  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439920 \n",
      "\n",
      "Epoch 3977\n",
      "-------------------------------\n",
      "loss: 0.306697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439479 \n",
      "\n",
      "Epoch 3978\n",
      "-------------------------------\n",
      "loss: 0.303043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439072 \n",
      "\n",
      "Epoch 3979\n",
      "-------------------------------\n",
      "loss: 0.304319  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439505 \n",
      "\n",
      "Epoch 3980\n",
      "-------------------------------\n",
      "loss: 0.300005  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439830 \n",
      "\n",
      "Epoch 3981\n",
      "-------------------------------\n",
      "loss: 0.308148  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440000 \n",
      "\n",
      "Epoch 3982\n",
      "-------------------------------\n",
      "loss: 0.311085  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439935 \n",
      "\n",
      "Epoch 3983\n",
      "-------------------------------\n",
      "loss: 0.305128  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439719 \n",
      "\n",
      "Epoch 3984\n",
      "-------------------------------\n",
      "loss: 0.311508  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440155 \n",
      "\n",
      "Epoch 3985\n",
      "-------------------------------\n",
      "loss: 0.309427  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440315 \n",
      "\n",
      "Epoch 3986\n",
      "-------------------------------\n",
      "loss: 0.302562  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440135 \n",
      "\n",
      "Epoch 3987\n",
      "-------------------------------\n",
      "loss: 0.300894  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440542 \n",
      "\n",
      "Epoch 3988\n",
      "-------------------------------\n",
      "loss: 0.310888  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440476 \n",
      "\n",
      "Epoch 3989\n",
      "-------------------------------\n",
      "loss: 0.300926  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440079 \n",
      "\n",
      "Epoch 3990\n",
      "-------------------------------\n",
      "loss: 0.301566  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441148 \n",
      "\n",
      "Epoch 3991\n",
      "-------------------------------\n",
      "loss: 0.304974  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441476 \n",
      "\n",
      "Epoch 3992\n",
      "-------------------------------\n",
      "loss: 0.301351  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442077 \n",
      "\n",
      "Epoch 3993\n",
      "-------------------------------\n",
      "loss: 0.297819  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441819 \n",
      "\n",
      "Epoch 3994\n",
      "-------------------------------\n",
      "loss: 0.300710  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442153 \n",
      "\n",
      "Epoch 3995\n",
      "-------------------------------\n",
      "loss: 0.311462  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441449 \n",
      "\n",
      "Epoch 3996\n",
      "-------------------------------\n",
      "loss: 0.300693  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440391 \n",
      "\n",
      "Epoch 3997\n",
      "-------------------------------\n",
      "loss: 0.308352  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440000 \n",
      "\n",
      "Epoch 3998\n",
      "-------------------------------\n",
      "loss: 0.310237  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.439440 \n",
      "\n",
      "Epoch 3999\n",
      "-------------------------------\n",
      "loss: 0.311443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438947 \n",
      "\n",
      "Epoch 4000\n",
      "-------------------------------\n",
      "loss: 0.300289  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438883 \n",
      "\n",
      "Epoch 4001\n",
      "-------------------------------\n",
      "loss: 0.298256  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439574 \n",
      "\n",
      "Epoch 4002\n",
      "-------------------------------\n",
      "loss: 0.310934  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439518 \n",
      "\n",
      "Epoch 4003\n",
      "-------------------------------\n",
      "loss: 0.306678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440013 \n",
      "\n",
      "Epoch 4004\n",
      "-------------------------------\n",
      "loss: 0.306587  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440051 \n",
      "\n",
      "Epoch 4005\n",
      "-------------------------------\n",
      "loss: 0.304421  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441913 \n",
      "\n",
      "Epoch 4006\n",
      "-------------------------------\n",
      "loss: 0.309173  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442311 \n",
      "\n",
      "Epoch 4007\n",
      "-------------------------------\n",
      "loss: 0.302698  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443541 \n",
      "\n",
      "Epoch 4008\n",
      "-------------------------------\n",
      "loss: 0.304247  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443141 \n",
      "\n",
      "Epoch 4009\n",
      "-------------------------------\n",
      "loss: 0.309508  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442085 \n",
      "\n",
      "Epoch 4010\n",
      "-------------------------------\n",
      "loss: 0.304925  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441013 \n",
      "\n",
      "Epoch 4011\n",
      "-------------------------------\n",
      "loss: 0.306027  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440346 \n",
      "\n",
      "Epoch 4012\n",
      "-------------------------------\n",
      "loss: 0.303683  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439231 \n",
      "\n",
      "Epoch 4013\n",
      "-------------------------------\n",
      "loss: 0.302546  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440169 \n",
      "\n",
      "Epoch 4014\n",
      "-------------------------------\n",
      "loss: 0.307383  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440759 \n",
      "\n",
      "Epoch 4015\n",
      "-------------------------------\n",
      "loss: 0.307137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440097 \n",
      "\n",
      "Epoch 4016\n",
      "-------------------------------\n",
      "loss: 0.310055  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440681 \n",
      "\n",
      "Epoch 4017\n",
      "-------------------------------\n",
      "loss: 0.301887  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440508 \n",
      "\n",
      "Epoch 4018\n",
      "-------------------------------\n",
      "loss: 0.301354  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440516 \n",
      "\n",
      "Epoch 4019\n",
      "-------------------------------\n",
      "loss: 0.300220  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440806 \n",
      "\n",
      "Epoch 4020\n",
      "-------------------------------\n",
      "loss: 0.300072  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441324 \n",
      "\n",
      "Epoch 4021\n",
      "-------------------------------\n",
      "loss: 0.301899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440058 \n",
      "\n",
      "Epoch 4022\n",
      "-------------------------------\n",
      "loss: 0.312795  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439642 \n",
      "\n",
      "Epoch 4023\n",
      "-------------------------------\n",
      "loss: 0.302167  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439551 \n",
      "\n",
      "Epoch 4024\n",
      "-------------------------------\n",
      "loss: 0.305851  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439437 \n",
      "\n",
      "Epoch 4025\n",
      "-------------------------------\n",
      "loss: 0.300611  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440392 \n",
      "\n",
      "Epoch 4026\n",
      "-------------------------------\n",
      "loss: 0.306518  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441101 \n",
      "\n",
      "Epoch 4027\n",
      "-------------------------------\n",
      "loss: 0.304097  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441775 \n",
      "\n",
      "Epoch 4028\n",
      "-------------------------------\n",
      "loss: 0.304468  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442141 \n",
      "\n",
      "Epoch 4029\n",
      "-------------------------------\n",
      "loss: 0.304664  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442042 \n",
      "\n",
      "Epoch 4030\n",
      "-------------------------------\n",
      "loss: 0.303828  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442359 \n",
      "\n",
      "Epoch 4031\n",
      "-------------------------------\n",
      "loss: 0.307175  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441665 \n",
      "\n",
      "Epoch 4032\n",
      "-------------------------------\n",
      "loss: 0.303049  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441519 \n",
      "\n",
      "Epoch 4033\n",
      "-------------------------------\n",
      "loss: 0.299006  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441737 \n",
      "\n",
      "Epoch 4034\n",
      "-------------------------------\n",
      "loss: 0.303184  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441733 \n",
      "\n",
      "Epoch 4035\n",
      "-------------------------------\n",
      "loss: 0.307226  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441970 \n",
      "\n",
      "Epoch 4036\n",
      "-------------------------------\n",
      "loss: 0.310142  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442608 \n",
      "\n",
      "Epoch 4037\n",
      "-------------------------------\n",
      "loss: 0.301055  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442801 \n",
      "\n",
      "Epoch 4038\n",
      "-------------------------------\n",
      "loss: 0.301341  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443440 \n",
      "\n",
      "Epoch 4039\n",
      "-------------------------------\n",
      "loss: 0.296671  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443808 \n",
      "\n",
      "Epoch 4040\n",
      "-------------------------------\n",
      "loss: 0.304780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444507 \n",
      "\n",
      "Epoch 4041\n",
      "-------------------------------\n",
      "loss: 0.309540  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444113 \n",
      "\n",
      "Epoch 4042\n",
      "-------------------------------\n",
      "loss: 0.307773  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442334 \n",
      "\n",
      "Epoch 4043\n",
      "-------------------------------\n",
      "loss: 0.301472  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441615 \n",
      "\n",
      "Epoch 4044\n",
      "-------------------------------\n",
      "loss: 0.308355  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441201 \n",
      "\n",
      "Epoch 4045\n",
      "-------------------------------\n",
      "loss: 0.298564  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440884 \n",
      "\n",
      "Epoch 4046\n",
      "-------------------------------\n",
      "loss: 0.305136  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441024 \n",
      "\n",
      "Epoch 4047\n",
      "-------------------------------\n",
      "loss: 0.303837  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440706 \n",
      "\n",
      "Epoch 4048\n",
      "-------------------------------\n",
      "loss: 0.306849  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440866 \n",
      "\n",
      "Epoch 4049\n",
      "-------------------------------\n",
      "loss: 0.303017  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440767 \n",
      "\n",
      "Epoch 4050\n",
      "-------------------------------\n",
      "loss: 0.298119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440517 \n",
      "\n",
      "Epoch 4051\n",
      "-------------------------------\n",
      "loss: 0.306917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440737 \n",
      "\n",
      "Epoch 4052\n",
      "-------------------------------\n",
      "loss: 0.303160  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440202 \n",
      "\n",
      "Epoch 4053\n",
      "-------------------------------\n",
      "loss: 0.303085  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441170 \n",
      "\n",
      "Epoch 4054\n",
      "-------------------------------\n",
      "loss: 0.312892  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441163 \n",
      "\n",
      "Epoch 4055\n",
      "-------------------------------\n",
      "loss: 0.301238  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440736 \n",
      "\n",
      "Epoch 4056\n",
      "-------------------------------\n",
      "loss: 0.306352  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440475 \n",
      "\n",
      "Epoch 4057\n",
      "-------------------------------\n",
      "loss: 0.300411  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440371 \n",
      "\n",
      "Epoch 4058\n",
      "-------------------------------\n",
      "loss: 0.306195  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440912 \n",
      "\n",
      "Epoch 4059\n",
      "-------------------------------\n",
      "loss: 0.307153  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440349 \n",
      "\n",
      "Epoch 4060\n",
      "-------------------------------\n",
      "loss: 0.307501  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441664 \n",
      "\n",
      "Epoch 4061\n",
      "-------------------------------\n",
      "loss: 0.305552  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441590 \n",
      "\n",
      "Epoch 4062\n",
      "-------------------------------\n",
      "loss: 0.300169  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440428 \n",
      "\n",
      "Epoch 4063\n",
      "-------------------------------\n",
      "loss: 0.309331  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440695 \n",
      "\n",
      "Epoch 4064\n",
      "-------------------------------\n",
      "loss: 0.296511  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440394 \n",
      "\n",
      "Epoch 4065\n",
      "-------------------------------\n",
      "loss: 0.302127  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441311 \n",
      "\n",
      "Epoch 4066\n",
      "-------------------------------\n",
      "loss: 0.310649  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440564 \n",
      "\n",
      "Epoch 4067\n",
      "-------------------------------\n",
      "loss: 0.307427  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441748 \n",
      "\n",
      "Epoch 4068\n",
      "-------------------------------\n",
      "loss: 0.306554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441467 \n",
      "\n",
      "Epoch 4069\n",
      "-------------------------------\n",
      "loss: 0.302059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440991 \n",
      "\n",
      "Epoch 4070\n",
      "-------------------------------\n",
      "loss: 0.304561  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441065 \n",
      "\n",
      "Epoch 4071\n",
      "-------------------------------\n",
      "loss: 0.303354  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440174 \n",
      "\n",
      "Epoch 4072\n",
      "-------------------------------\n",
      "loss: 0.307049  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440366 \n",
      "\n",
      "Epoch 4073\n",
      "-------------------------------\n",
      "loss: 0.299376  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441227 \n",
      "\n",
      "Epoch 4074\n",
      "-------------------------------\n",
      "loss: 0.303972  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440670 \n",
      "\n",
      "Epoch 4075\n",
      "-------------------------------\n",
      "loss: 0.304565  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440573 \n",
      "\n",
      "Epoch 4076\n",
      "-------------------------------\n",
      "loss: 0.304632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440376 \n",
      "\n",
      "Epoch 4077\n",
      "-------------------------------\n",
      "loss: 0.302318  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440952 \n",
      "\n",
      "Epoch 4078\n",
      "-------------------------------\n",
      "loss: 0.302347  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440061 \n",
      "\n",
      "Epoch 4079\n",
      "-------------------------------\n",
      "loss: 0.302093  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439500 \n",
      "\n",
      "Epoch 4080\n",
      "-------------------------------\n",
      "loss: 0.303123  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438777 \n",
      "\n",
      "Epoch 4081\n",
      "-------------------------------\n",
      "loss: 0.303683  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439452 \n",
      "\n",
      "Epoch 4082\n",
      "-------------------------------\n",
      "loss: 0.301740  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439332 \n",
      "\n",
      "Epoch 4083\n",
      "-------------------------------\n",
      "loss: 0.304509  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440520 \n",
      "\n",
      "Epoch 4084\n",
      "-------------------------------\n",
      "loss: 0.308299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440454 \n",
      "\n",
      "Epoch 4085\n",
      "-------------------------------\n",
      "loss: 0.303440  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439984 \n",
      "\n",
      "Epoch 4086\n",
      "-------------------------------\n",
      "loss: 0.304454  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440920 \n",
      "\n",
      "Epoch 4087\n",
      "-------------------------------\n",
      "loss: 0.304666  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440558 \n",
      "\n",
      "Epoch 4088\n",
      "-------------------------------\n",
      "loss: 0.306126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440037 \n",
      "\n",
      "Epoch 4089\n",
      "-------------------------------\n",
      "loss: 0.305758  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440250 \n",
      "\n",
      "Epoch 4090\n",
      "-------------------------------\n",
      "loss: 0.300648  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440181 \n",
      "\n",
      "Epoch 4091\n",
      "-------------------------------\n",
      "loss: 0.310778  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441653 \n",
      "\n",
      "Epoch 4092\n",
      "-------------------------------\n",
      "loss: 0.305991  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442433 \n",
      "\n",
      "Epoch 4093\n",
      "-------------------------------\n",
      "loss: 0.303252  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443247 \n",
      "\n",
      "Epoch 4094\n",
      "-------------------------------\n",
      "loss: 0.297907  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443233 \n",
      "\n",
      "Epoch 4095\n",
      "-------------------------------\n",
      "loss: 0.298992  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443428 \n",
      "\n",
      "Epoch 4096\n",
      "-------------------------------\n",
      "loss: 0.306402  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443133 \n",
      "\n",
      "Epoch 4097\n",
      "-------------------------------\n",
      "loss: 0.309960  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441846 \n",
      "\n",
      "Epoch 4098\n",
      "-------------------------------\n",
      "loss: 0.301202  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440639 \n",
      "\n",
      "Epoch 4099\n",
      "-------------------------------\n",
      "loss: 0.304099  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440163 \n",
      "\n",
      "Epoch 4100\n",
      "-------------------------------\n",
      "loss: 0.306460  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439548 \n",
      "\n",
      "Epoch 4101\n",
      "-------------------------------\n",
      "loss: 0.301462  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439441 \n",
      "\n",
      "Epoch 4102\n",
      "-------------------------------\n",
      "loss: 0.305470  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439231 \n",
      "\n",
      "Epoch 4103\n",
      "-------------------------------\n",
      "loss: 0.303277  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439287 \n",
      "\n",
      "Epoch 4104\n",
      "-------------------------------\n",
      "loss: 0.307142  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439830 \n",
      "\n",
      "Epoch 4105\n",
      "-------------------------------\n",
      "loss: 0.303720  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439014 \n",
      "\n",
      "Epoch 4106\n",
      "-------------------------------\n",
      "loss: 0.303697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439988 \n",
      "\n",
      "Epoch 4107\n",
      "-------------------------------\n",
      "loss: 0.303706  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440181 \n",
      "\n",
      "Epoch 4108\n",
      "-------------------------------\n",
      "loss: 0.303931  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440123 \n",
      "\n",
      "Epoch 4109\n",
      "-------------------------------\n",
      "loss: 0.297207  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440831 \n",
      "\n",
      "Epoch 4110\n",
      "-------------------------------\n",
      "loss: 0.307883  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440933 \n",
      "\n",
      "Epoch 4111\n",
      "-------------------------------\n",
      "loss: 0.300218  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440615 \n",
      "\n",
      "Epoch 4112\n",
      "-------------------------------\n",
      "loss: 0.306520  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440300 \n",
      "\n",
      "Epoch 4113\n",
      "-------------------------------\n",
      "loss: 0.301448  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439726 \n",
      "\n",
      "Epoch 4114\n",
      "-------------------------------\n",
      "loss: 0.310761  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438268 \n",
      "\n",
      "Epoch 4115\n",
      "-------------------------------\n",
      "loss: 0.299889  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439618 \n",
      "\n",
      "Epoch 4116\n",
      "-------------------------------\n",
      "loss: 0.296577  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439303 \n",
      "\n",
      "Epoch 4117\n",
      "-------------------------------\n",
      "loss: 0.297776  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440479 \n",
      "\n",
      "Epoch 4118\n",
      "-------------------------------\n",
      "loss: 0.311757  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440918 \n",
      "\n",
      "Epoch 4119\n",
      "-------------------------------\n",
      "loss: 0.302053  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442239 \n",
      "\n",
      "Epoch 4120\n",
      "-------------------------------\n",
      "loss: 0.302820  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442292 \n",
      "\n",
      "Epoch 4121\n",
      "-------------------------------\n",
      "loss: 0.301069  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443439 \n",
      "\n",
      "Epoch 4122\n",
      "-------------------------------\n",
      "loss: 0.308545  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443161 \n",
      "\n",
      "Epoch 4123\n",
      "-------------------------------\n",
      "loss: 0.307058  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442669 \n",
      "\n",
      "Epoch 4124\n",
      "-------------------------------\n",
      "loss: 0.304443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442307 \n",
      "\n",
      "Epoch 4125\n",
      "-------------------------------\n",
      "loss: 0.306150  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442108 \n",
      "\n",
      "Epoch 4126\n",
      "-------------------------------\n",
      "loss: 0.305788  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441783 \n",
      "\n",
      "Epoch 4127\n",
      "-------------------------------\n",
      "loss: 0.302023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441117 \n",
      "\n",
      "Epoch 4128\n",
      "-------------------------------\n",
      "loss: 0.302633  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441281 \n",
      "\n",
      "Epoch 4129\n",
      "-------------------------------\n",
      "loss: 0.306497  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440922 \n",
      "\n",
      "Epoch 4130\n",
      "-------------------------------\n",
      "loss: 0.300016  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440814 \n",
      "\n",
      "Epoch 4131\n",
      "-------------------------------\n",
      "loss: 0.306707  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441825 \n",
      "\n",
      "Epoch 4132\n",
      "-------------------------------\n",
      "loss: 0.298552  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442478 \n",
      "\n",
      "Epoch 4133\n",
      "-------------------------------\n",
      "loss: 0.297936  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442580 \n",
      "\n",
      "Epoch 4134\n",
      "-------------------------------\n",
      "loss: 0.301561  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443588 \n",
      "\n",
      "Epoch 4135\n",
      "-------------------------------\n",
      "loss: 0.305058  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443027 \n",
      "\n",
      "Epoch 4136\n",
      "-------------------------------\n",
      "loss: 0.306431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441375 \n",
      "\n",
      "Epoch 4137\n",
      "-------------------------------\n",
      "loss: 0.304951  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441040 \n",
      "\n",
      "Epoch 4138\n",
      "-------------------------------\n",
      "loss: 0.296828  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440300 \n",
      "\n",
      "Epoch 4139\n",
      "-------------------------------\n",
      "loss: 0.298607  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440416 \n",
      "\n",
      "Epoch 4140\n",
      "-------------------------------\n",
      "loss: 0.292653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439907 \n",
      "\n",
      "Epoch 4141\n",
      "-------------------------------\n",
      "loss: 0.293043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440246 \n",
      "\n",
      "Epoch 4142\n",
      "-------------------------------\n",
      "loss: 0.307443  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440287 \n",
      "\n",
      "Epoch 4143\n",
      "-------------------------------\n",
      "loss: 0.300336  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440611 \n",
      "\n",
      "Epoch 4144\n",
      "-------------------------------\n",
      "loss: 0.299582  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440959 \n",
      "\n",
      "Epoch 4145\n",
      "-------------------------------\n",
      "loss: 0.296008  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441032 \n",
      "\n",
      "Epoch 4146\n",
      "-------------------------------\n",
      "loss: 0.309983  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440680 \n",
      "\n",
      "Epoch 4147\n",
      "-------------------------------\n",
      "loss: 0.295593  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439851 \n",
      "\n",
      "Epoch 4148\n",
      "-------------------------------\n",
      "loss: 0.299618  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439745 \n",
      "\n",
      "Epoch 4149\n",
      "-------------------------------\n",
      "loss: 0.300943  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440366 \n",
      "\n",
      "Epoch 4150\n",
      "-------------------------------\n",
      "loss: 0.306067  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440272 \n",
      "\n",
      "Epoch 4151\n",
      "-------------------------------\n",
      "loss: 0.303584  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440138 \n",
      "\n",
      "Epoch 4152\n",
      "-------------------------------\n",
      "loss: 0.305799  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439737 \n",
      "\n",
      "Epoch 4153\n",
      "-------------------------------\n",
      "loss: 0.308353  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439634 \n",
      "\n",
      "Epoch 4154\n",
      "-------------------------------\n",
      "loss: 0.306907  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439551 \n",
      "\n",
      "Epoch 4155\n",
      "-------------------------------\n",
      "loss: 0.300080  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439050 \n",
      "\n",
      "Epoch 4156\n",
      "-------------------------------\n",
      "loss: 0.301225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438926 \n",
      "\n",
      "Epoch 4157\n",
      "-------------------------------\n",
      "loss: 0.304968  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439019 \n",
      "\n",
      "Epoch 4158\n",
      "-------------------------------\n",
      "loss: 0.300577  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439041 \n",
      "\n",
      "Epoch 4159\n",
      "-------------------------------\n",
      "loss: 0.307725  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439410 \n",
      "\n",
      "Epoch 4160\n",
      "-------------------------------\n",
      "loss: 0.301837  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439904 \n",
      "\n",
      "Epoch 4161\n",
      "-------------------------------\n",
      "loss: 0.306148  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439977 \n",
      "\n",
      "Epoch 4162\n",
      "-------------------------------\n",
      "loss: 0.308612  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439964 \n",
      "\n",
      "Epoch 4163\n",
      "-------------------------------\n",
      "loss: 0.297275  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440473 \n",
      "\n",
      "Epoch 4164\n",
      "-------------------------------\n",
      "loss: 0.299739  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441512 \n",
      "\n",
      "Epoch 4165\n",
      "-------------------------------\n",
      "loss: 0.305483  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441577 \n",
      "\n",
      "Epoch 4166\n",
      "-------------------------------\n",
      "loss: 0.302916  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441182 \n",
      "\n",
      "Epoch 4167\n",
      "-------------------------------\n",
      "loss: 0.299527  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440798 \n",
      "\n",
      "Epoch 4168\n",
      "-------------------------------\n",
      "loss: 0.311108  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441302 \n",
      "\n",
      "Epoch 4169\n",
      "-------------------------------\n",
      "loss: 0.301811  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440360 \n",
      "\n",
      "Epoch 4170\n",
      "-------------------------------\n",
      "loss: 0.300918  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440408 \n",
      "\n",
      "Epoch 4171\n",
      "-------------------------------\n",
      "loss: 0.307144  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441357 \n",
      "\n",
      "Epoch 4172\n",
      "-------------------------------\n",
      "loss: 0.304396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441913 \n",
      "\n",
      "Epoch 4173\n",
      "-------------------------------\n",
      "loss: 0.299793  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441965 \n",
      "\n",
      "Epoch 4174\n",
      "-------------------------------\n",
      "loss: 0.296921  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441514 \n",
      "\n",
      "Epoch 4175\n",
      "-------------------------------\n",
      "loss: 0.299884  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441931 \n",
      "\n",
      "Epoch 4176\n",
      "-------------------------------\n",
      "loss: 0.304507  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442425 \n",
      "\n",
      "Epoch 4177\n",
      "-------------------------------\n",
      "loss: 0.309282  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443183 \n",
      "\n",
      "Epoch 4178\n",
      "-------------------------------\n",
      "loss: 0.305630  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443939 \n",
      "\n",
      "Epoch 4179\n",
      "-------------------------------\n",
      "loss: 0.304804  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443924 \n",
      "\n",
      "Epoch 4180\n",
      "-------------------------------\n",
      "loss: 0.302817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443721 \n",
      "\n",
      "Epoch 4181\n",
      "-------------------------------\n",
      "loss: 0.297340  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443160 \n",
      "\n",
      "Epoch 4182\n",
      "-------------------------------\n",
      "loss: 0.304041  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442366 \n",
      "\n",
      "Epoch 4183\n",
      "-------------------------------\n",
      "loss: 0.306104  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442122 \n",
      "\n",
      "Epoch 4184\n",
      "-------------------------------\n",
      "loss: 0.303879  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441126 \n",
      "\n",
      "Epoch 4185\n",
      "-------------------------------\n",
      "loss: 0.298287  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441575 \n",
      "\n",
      "Epoch 4186\n",
      "-------------------------------\n",
      "loss: 0.299570  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440762 \n",
      "\n",
      "Epoch 4187\n",
      "-------------------------------\n",
      "loss: 0.307564  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441148 \n",
      "\n",
      "Epoch 4188\n",
      "-------------------------------\n",
      "loss: 0.298245  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441841 \n",
      "\n",
      "Epoch 4189\n",
      "-------------------------------\n",
      "loss: 0.301941  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441991 \n",
      "\n",
      "Epoch 4190\n",
      "-------------------------------\n",
      "loss: 0.295276  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441244 \n",
      "\n",
      "Epoch 4191\n",
      "-------------------------------\n",
      "loss: 0.303457  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441660 \n",
      "\n",
      "Epoch 4192\n",
      "-------------------------------\n",
      "loss: 0.304989  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442294 \n",
      "\n",
      "Epoch 4193\n",
      "-------------------------------\n",
      "loss: 0.296314  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441848 \n",
      "\n",
      "Epoch 4194\n",
      "-------------------------------\n",
      "loss: 0.302899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441198 \n",
      "\n",
      "Epoch 4195\n",
      "-------------------------------\n",
      "loss: 0.302189  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440785 \n",
      "\n",
      "Epoch 4196\n",
      "-------------------------------\n",
      "loss: 0.314279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440858 \n",
      "\n",
      "Epoch 4197\n",
      "-------------------------------\n",
      "loss: 0.301393  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439769 \n",
      "\n",
      "Epoch 4198\n",
      "-------------------------------\n",
      "loss: 0.301772  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439407 \n",
      "\n",
      "Epoch 4199\n",
      "-------------------------------\n",
      "loss: 0.300803  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439459 \n",
      "\n",
      "Epoch 4200\n",
      "-------------------------------\n",
      "loss: 0.305986  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439277 \n",
      "\n",
      "Epoch 4201\n",
      "-------------------------------\n",
      "loss: 0.309951  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438622 \n",
      "\n",
      "Epoch 4202\n",
      "-------------------------------\n",
      "loss: 0.297634  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438893 \n",
      "\n",
      "Epoch 4203\n",
      "-------------------------------\n",
      "loss: 0.302652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438883 \n",
      "\n",
      "Epoch 4204\n",
      "-------------------------------\n",
      "loss: 0.295899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438551 \n",
      "\n",
      "Epoch 4205\n",
      "-------------------------------\n",
      "loss: 0.296757  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439245 \n",
      "\n",
      "Epoch 4206\n",
      "-------------------------------\n",
      "loss: 0.307810  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439537 \n",
      "\n",
      "Epoch 4207\n",
      "-------------------------------\n",
      "loss: 0.308299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440534 \n",
      "\n",
      "Epoch 4208\n",
      "-------------------------------\n",
      "loss: 0.296899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440400 \n",
      "\n",
      "Epoch 4209\n",
      "-------------------------------\n",
      "loss: 0.304428  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440450 \n",
      "\n",
      "Epoch 4210\n",
      "-------------------------------\n",
      "loss: 0.302245  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439700 \n",
      "\n",
      "Epoch 4211\n",
      "-------------------------------\n",
      "loss: 0.293023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439437 \n",
      "\n",
      "Epoch 4212\n",
      "-------------------------------\n",
      "loss: 0.294501  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439469 \n",
      "\n",
      "Epoch 4213\n",
      "-------------------------------\n",
      "loss: 0.298776  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438682 \n",
      "\n",
      "Epoch 4214\n",
      "-------------------------------\n",
      "loss: 0.298385  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438519 \n",
      "\n",
      "Epoch 4215\n",
      "-------------------------------\n",
      "loss: 0.307306  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438347 \n",
      "\n",
      "Epoch 4216\n",
      "-------------------------------\n",
      "loss: 0.303299  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438215 \n",
      "\n",
      "Epoch 4217\n",
      "-------------------------------\n",
      "loss: 0.293808  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437915 \n",
      "\n",
      "Epoch 4218\n",
      "-------------------------------\n",
      "loss: 0.305169  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438095 \n",
      "\n",
      "Epoch 4219\n",
      "-------------------------------\n",
      "loss: 0.297359  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438171 \n",
      "\n",
      "Epoch 4220\n",
      "-------------------------------\n",
      "loss: 0.305240  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438677 \n",
      "\n",
      "Epoch 4221\n",
      "-------------------------------\n",
      "loss: 0.306961  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439090 \n",
      "\n",
      "Epoch 4222\n",
      "-------------------------------\n",
      "loss: 0.304874  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438623 \n",
      "\n",
      "Epoch 4223\n",
      "-------------------------------\n",
      "loss: 0.300669  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438709 \n",
      "\n",
      "Epoch 4224\n",
      "-------------------------------\n",
      "loss: 0.301983  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439348 \n",
      "\n",
      "Epoch 4225\n",
      "-------------------------------\n",
      "loss: 0.301303  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439706 \n",
      "\n",
      "Epoch 4226\n",
      "-------------------------------\n",
      "loss: 0.297783  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440383 \n",
      "\n",
      "Epoch 4227\n",
      "-------------------------------\n",
      "loss: 0.296967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440667 \n",
      "\n",
      "Epoch 4228\n",
      "-------------------------------\n",
      "loss: 0.301159  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441660 \n",
      "\n",
      "Epoch 4229\n",
      "-------------------------------\n",
      "loss: 0.301544  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441850 \n",
      "\n",
      "Epoch 4230\n",
      "-------------------------------\n",
      "loss: 0.302130  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442208 \n",
      "\n",
      "Epoch 4231\n",
      "-------------------------------\n",
      "loss: 0.295898  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441441 \n",
      "\n",
      "Epoch 4232\n",
      "-------------------------------\n",
      "loss: 0.300379  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441348 \n",
      "\n",
      "Epoch 4233\n",
      "-------------------------------\n",
      "loss: 0.296236  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440780 \n",
      "\n",
      "Epoch 4234\n",
      "-------------------------------\n",
      "loss: 0.302268  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440418 \n",
      "\n",
      "Epoch 4235\n",
      "-------------------------------\n",
      "loss: 0.293498  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440018 \n",
      "\n",
      "Epoch 4236\n",
      "-------------------------------\n",
      "loss: 0.308487  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440455 \n",
      "\n",
      "Epoch 4237\n",
      "-------------------------------\n",
      "loss: 0.309629  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439631 \n",
      "\n",
      "Epoch 4238\n",
      "-------------------------------\n",
      "loss: 0.299456  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439847 \n",
      "\n",
      "Epoch 4239\n",
      "-------------------------------\n",
      "loss: 0.305239  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439729 \n",
      "\n",
      "Epoch 4240\n",
      "-------------------------------\n",
      "loss: 0.292417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439520 \n",
      "\n",
      "Epoch 4241\n",
      "-------------------------------\n",
      "loss: 0.302770  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440629 \n",
      "\n",
      "Epoch 4242\n",
      "-------------------------------\n",
      "loss: 0.295181  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441199 \n",
      "\n",
      "Epoch 4243\n",
      "-------------------------------\n",
      "loss: 0.303231  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441732 \n",
      "\n",
      "Epoch 4244\n",
      "-------------------------------\n",
      "loss: 0.296641  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441213 \n",
      "\n",
      "Epoch 4245\n",
      "-------------------------------\n",
      "loss: 0.302950  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440922 \n",
      "\n",
      "Epoch 4246\n",
      "-------------------------------\n",
      "loss: 0.300471  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440262 \n",
      "\n",
      "Epoch 4247\n",
      "-------------------------------\n",
      "loss: 0.306493  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439795 \n",
      "\n",
      "Epoch 4248\n",
      "-------------------------------\n",
      "loss: 0.299683  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438853 \n",
      "\n",
      "Epoch 4249\n",
      "-------------------------------\n",
      "loss: 0.306816  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440139 \n",
      "\n",
      "Epoch 4250\n",
      "-------------------------------\n",
      "loss: 0.307287  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438724 \n",
      "\n",
      "Epoch 4251\n",
      "-------------------------------\n",
      "loss: 0.299486  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439104 \n",
      "\n",
      "Epoch 4252\n",
      "-------------------------------\n",
      "loss: 0.299799  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439424 \n",
      "\n",
      "Epoch 4253\n",
      "-------------------------------\n",
      "loss: 0.302248  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439095 \n",
      "\n",
      "Epoch 4254\n",
      "-------------------------------\n",
      "loss: 0.300576  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440337 \n",
      "\n",
      "Epoch 4255\n",
      "-------------------------------\n",
      "loss: 0.303741  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441929 \n",
      "\n",
      "Epoch 4256\n",
      "-------------------------------\n",
      "loss: 0.296334  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442206 \n",
      "\n",
      "Epoch 4257\n",
      "-------------------------------\n",
      "loss: 0.304401  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443689 \n",
      "\n",
      "Epoch 4258\n",
      "-------------------------------\n",
      "loss: 0.306849  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444100 \n",
      "\n",
      "Epoch 4259\n",
      "-------------------------------\n",
      "loss: 0.309939  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442500 \n",
      "\n",
      "Epoch 4260\n",
      "-------------------------------\n",
      "loss: 0.304529  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442240 \n",
      "\n",
      "Epoch 4261\n",
      "-------------------------------\n",
      "loss: 0.300852  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441585 \n",
      "\n",
      "Epoch 4262\n",
      "-------------------------------\n",
      "loss: 0.301792  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440710 \n",
      "\n",
      "Epoch 4263\n",
      "-------------------------------\n",
      "loss: 0.302606  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440953 \n",
      "\n",
      "Epoch 4264\n",
      "-------------------------------\n",
      "loss: 0.300401  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441150 \n",
      "\n",
      "Epoch 4265\n",
      "-------------------------------\n",
      "loss: 0.302740  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440655 \n",
      "\n",
      "Epoch 4266\n",
      "-------------------------------\n",
      "loss: 0.295972  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440939 \n",
      "\n",
      "Epoch 4267\n",
      "-------------------------------\n",
      "loss: 0.300084  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442005 \n",
      "\n",
      "Epoch 4268\n",
      "-------------------------------\n",
      "loss: 0.298180  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443782 \n",
      "\n",
      "Epoch 4269\n",
      "-------------------------------\n",
      "loss: 0.307236  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443402 \n",
      "\n",
      "Epoch 4270\n",
      "-------------------------------\n",
      "loss: 0.298702  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443996 \n",
      "\n",
      "Epoch 4271\n",
      "-------------------------------\n",
      "loss: 0.304597  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442605 \n",
      "\n",
      "Epoch 4272\n",
      "-------------------------------\n",
      "loss: 0.302399  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440636 \n",
      "\n",
      "Epoch 4273\n",
      "-------------------------------\n",
      "loss: 0.300082  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440265 \n",
      "\n",
      "Epoch 4274\n",
      "-------------------------------\n",
      "loss: 0.302094  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440469 \n",
      "\n",
      "Epoch 4275\n",
      "-------------------------------\n",
      "loss: 0.304940  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439570 \n",
      "\n",
      "Epoch 4276\n",
      "-------------------------------\n",
      "loss: 0.299710  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439658 \n",
      "\n",
      "Epoch 4277\n",
      "-------------------------------\n",
      "loss: 0.300741  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439933 \n",
      "\n",
      "Epoch 4278\n",
      "-------------------------------\n",
      "loss: 0.307004  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440191 \n",
      "\n",
      "Epoch 4279\n",
      "-------------------------------\n",
      "loss: 0.296798  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440620 \n",
      "\n",
      "Epoch 4280\n",
      "-------------------------------\n",
      "loss: 0.296547  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441240 \n",
      "\n",
      "Epoch 4281\n",
      "-------------------------------\n",
      "loss: 0.308315  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441074 \n",
      "\n",
      "Epoch 4282\n",
      "-------------------------------\n",
      "loss: 0.306668  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441759 \n",
      "\n",
      "Epoch 4283\n",
      "-------------------------------\n",
      "loss: 0.301278  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440817 \n",
      "\n",
      "Epoch 4284\n",
      "-------------------------------\n",
      "loss: 0.306177  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439660 \n",
      "\n",
      "Epoch 4285\n",
      "-------------------------------\n",
      "loss: 0.302272  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439205 \n",
      "\n",
      "Epoch 4286\n",
      "-------------------------------\n",
      "loss: 0.297642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438342 \n",
      "\n",
      "Epoch 4287\n",
      "-------------------------------\n",
      "loss: 0.301653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437942 \n",
      "\n",
      "Epoch 4288\n",
      "-------------------------------\n",
      "loss: 0.309513  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438149 \n",
      "\n",
      "Epoch 4289\n",
      "-------------------------------\n",
      "loss: 0.307386  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438793 \n",
      "\n",
      "Epoch 4290\n",
      "-------------------------------\n",
      "loss: 0.309321  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439144 \n",
      "\n",
      "Epoch 4291\n",
      "-------------------------------\n",
      "loss: 0.303079  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440220 \n",
      "\n",
      "Epoch 4292\n",
      "-------------------------------\n",
      "loss: 0.294926  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440835 \n",
      "\n",
      "Epoch 4293\n",
      "-------------------------------\n",
      "loss: 0.301242  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441452 \n",
      "\n",
      "Epoch 4294\n",
      "-------------------------------\n",
      "loss: 0.297182  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441338 \n",
      "\n",
      "Epoch 4295\n",
      "-------------------------------\n",
      "loss: 0.304991  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441510 \n",
      "\n",
      "Epoch 4296\n",
      "-------------------------------\n",
      "loss: 0.300050  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441789 \n",
      "\n",
      "Epoch 4297\n",
      "-------------------------------\n",
      "loss: 0.302262  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441793 \n",
      "\n",
      "Epoch 4298\n",
      "-------------------------------\n",
      "loss: 0.292137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440773 \n",
      "\n",
      "Epoch 4299\n",
      "-------------------------------\n",
      "loss: 0.306853  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440465 \n",
      "\n",
      "Epoch 4300\n",
      "-------------------------------\n",
      "loss: 0.300014  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440978 \n",
      "\n",
      "Epoch 4301\n",
      "-------------------------------\n",
      "loss: 0.305500  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441116 \n",
      "\n",
      "Epoch 4302\n",
      "-------------------------------\n",
      "loss: 0.295570  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441090 \n",
      "\n",
      "Epoch 4303\n",
      "-------------------------------\n",
      "loss: 0.300930  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441474 \n",
      "\n",
      "Epoch 4304\n",
      "-------------------------------\n",
      "loss: 0.307508  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441366 \n",
      "\n",
      "Epoch 4305\n",
      "-------------------------------\n",
      "loss: 0.298177  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441933 \n",
      "\n",
      "Epoch 4306\n",
      "-------------------------------\n",
      "loss: 0.299213  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441392 \n",
      "\n",
      "Epoch 4307\n",
      "-------------------------------\n",
      "loss: 0.300175  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441072 \n",
      "\n",
      "Epoch 4308\n",
      "-------------------------------\n",
      "loss: 0.296788  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441636 \n",
      "\n",
      "Epoch 4309\n",
      "-------------------------------\n",
      "loss: 0.310906  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440805 \n",
      "\n",
      "Epoch 4310\n",
      "-------------------------------\n",
      "loss: 0.310363  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440463 \n",
      "\n",
      "Epoch 4311\n",
      "-------------------------------\n",
      "loss: 0.294969  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441308 \n",
      "\n",
      "Epoch 4312\n",
      "-------------------------------\n",
      "loss: 0.301956  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441111 \n",
      "\n",
      "Epoch 4313\n",
      "-------------------------------\n",
      "loss: 0.309664  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442948 \n",
      "\n",
      "Epoch 4314\n",
      "-------------------------------\n",
      "loss: 0.306776  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441157 \n",
      "\n",
      "Epoch 4315\n",
      "-------------------------------\n",
      "loss: 0.297397  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441107 \n",
      "\n",
      "Epoch 4316\n",
      "-------------------------------\n",
      "loss: 0.301552  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441047 \n",
      "\n",
      "Epoch 4317\n",
      "-------------------------------\n",
      "loss: 0.297781  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440982 \n",
      "\n",
      "Epoch 4318\n",
      "-------------------------------\n",
      "loss: 0.308766  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440460 \n",
      "\n",
      "Epoch 4319\n",
      "-------------------------------\n",
      "loss: 0.300678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440229 \n",
      "\n",
      "Epoch 4320\n",
      "-------------------------------\n",
      "loss: 0.298561  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439995 \n",
      "\n",
      "Epoch 4321\n",
      "-------------------------------\n",
      "loss: 0.300054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439295 \n",
      "\n",
      "Epoch 4322\n",
      "-------------------------------\n",
      "loss: 0.301558  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440278 \n",
      "\n",
      "Epoch 4323\n",
      "-------------------------------\n",
      "loss: 0.301155  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440609 \n",
      "\n",
      "Epoch 4324\n",
      "-------------------------------\n",
      "loss: 0.300911  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441540 \n",
      "\n",
      "Epoch 4325\n",
      "-------------------------------\n",
      "loss: 0.301381  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442688 \n",
      "\n",
      "Epoch 4326\n",
      "-------------------------------\n",
      "loss: 0.298279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442298 \n",
      "\n",
      "Epoch 4327\n",
      "-------------------------------\n",
      "loss: 0.305431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442428 \n",
      "\n",
      "Epoch 4328\n",
      "-------------------------------\n",
      "loss: 0.302572  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440937 \n",
      "\n",
      "Epoch 4329\n",
      "-------------------------------\n",
      "loss: 0.297554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439765 \n",
      "\n",
      "Epoch 4330\n",
      "-------------------------------\n",
      "loss: 0.307678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440369 \n",
      "\n",
      "Epoch 4331\n",
      "-------------------------------\n",
      "loss: 0.304251  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440428 \n",
      "\n",
      "Epoch 4332\n",
      "-------------------------------\n",
      "loss: 0.297623  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440028 \n",
      "\n",
      "Epoch 4333\n",
      "-------------------------------\n",
      "loss: 0.308221  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440425 \n",
      "\n",
      "Epoch 4334\n",
      "-------------------------------\n",
      "loss: 0.305928  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440386 \n",
      "\n",
      "Epoch 4335\n",
      "-------------------------------\n",
      "loss: 0.296618  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441453 \n",
      "\n",
      "Epoch 4336\n",
      "-------------------------------\n",
      "loss: 0.300509  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441404 \n",
      "\n",
      "Epoch 4337\n",
      "-------------------------------\n",
      "loss: 0.306780  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443257 \n",
      "\n",
      "Epoch 4338\n",
      "-------------------------------\n",
      "loss: 0.303485  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442143 \n",
      "\n",
      "Epoch 4339\n",
      "-------------------------------\n",
      "loss: 0.298089  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442261 \n",
      "\n",
      "Epoch 4340\n",
      "-------------------------------\n",
      "loss: 0.298617  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441531 \n",
      "\n",
      "Epoch 4341\n",
      "-------------------------------\n",
      "loss: 0.297554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441962 \n",
      "\n",
      "Epoch 4342\n",
      "-------------------------------\n",
      "loss: 0.304034  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441946 \n",
      "\n",
      "Epoch 4343\n",
      "-------------------------------\n",
      "loss: 0.308968  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441411 \n",
      "\n",
      "Epoch 4344\n",
      "-------------------------------\n",
      "loss: 0.304558  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441553 \n",
      "\n",
      "Epoch 4345\n",
      "-------------------------------\n",
      "loss: 0.296722  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441242 \n",
      "\n",
      "Epoch 4346\n",
      "-------------------------------\n",
      "loss: 0.303149  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440852 \n",
      "\n",
      "Epoch 4347\n",
      "-------------------------------\n",
      "loss: 0.296164  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440231 \n",
      "\n",
      "Epoch 4348\n",
      "-------------------------------\n",
      "loss: 0.308433  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439554 \n",
      "\n",
      "Epoch 4349\n",
      "-------------------------------\n",
      "loss: 0.300316  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440026 \n",
      "\n",
      "Epoch 4350\n",
      "-------------------------------\n",
      "loss: 0.304830  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439914 \n",
      "\n",
      "Epoch 4351\n",
      "-------------------------------\n",
      "loss: 0.304824  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440219 \n",
      "\n",
      "Epoch 4352\n",
      "-------------------------------\n",
      "loss: 0.299841  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440344 \n",
      "\n",
      "Epoch 4353\n",
      "-------------------------------\n",
      "loss: 0.299929  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441371 \n",
      "\n",
      "Epoch 4354\n",
      "-------------------------------\n",
      "loss: 0.299658  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440782 \n",
      "\n",
      "Epoch 4355\n",
      "-------------------------------\n",
      "loss: 0.305050  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441059 \n",
      "\n",
      "Epoch 4356\n",
      "-------------------------------\n",
      "loss: 0.295256  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440137 \n",
      "\n",
      "Epoch 4357\n",
      "-------------------------------\n",
      "loss: 0.294433  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440450 \n",
      "\n",
      "Epoch 4358\n",
      "-------------------------------\n",
      "loss: 0.310955  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440855 \n",
      "\n",
      "Epoch 4359\n",
      "-------------------------------\n",
      "loss: 0.305326  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440458 \n",
      "\n",
      "Epoch 4360\n",
      "-------------------------------\n",
      "loss: 0.297980  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441067 \n",
      "\n",
      "Epoch 4361\n",
      "-------------------------------\n",
      "loss: 0.300749  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441560 \n",
      "\n",
      "Epoch 4362\n",
      "-------------------------------\n",
      "loss: 0.301046  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441549 \n",
      "\n",
      "Epoch 4363\n",
      "-------------------------------\n",
      "loss: 0.301453  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441216 \n",
      "\n",
      "Epoch 4364\n",
      "-------------------------------\n",
      "loss: 0.298989  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441441 \n",
      "\n",
      "Epoch 4365\n",
      "-------------------------------\n",
      "loss: 0.295680  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441244 \n",
      "\n",
      "Epoch 4366\n",
      "-------------------------------\n",
      "loss: 0.296866  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440795 \n",
      "\n",
      "Epoch 4367\n",
      "-------------------------------\n",
      "loss: 0.305849  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440587 \n",
      "\n",
      "Epoch 4368\n",
      "-------------------------------\n",
      "loss: 0.306198  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440601 \n",
      "\n",
      "Epoch 4369\n",
      "-------------------------------\n",
      "loss: 0.301965  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440657 \n",
      "\n",
      "Epoch 4370\n",
      "-------------------------------\n",
      "loss: 0.301974  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440655 \n",
      "\n",
      "Epoch 4371\n",
      "-------------------------------\n",
      "loss: 0.298437  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440620 \n",
      "\n",
      "Epoch 4372\n",
      "-------------------------------\n",
      "loss: 0.303792  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441122 \n",
      "\n",
      "Epoch 4373\n",
      "-------------------------------\n",
      "loss: 0.300357  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441874 \n",
      "\n",
      "Epoch 4374\n",
      "-------------------------------\n",
      "loss: 0.298727  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441630 \n",
      "\n",
      "Epoch 4375\n",
      "-------------------------------\n",
      "loss: 0.301699  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441617 \n",
      "\n",
      "Epoch 4376\n",
      "-------------------------------\n",
      "loss: 0.303510  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441100 \n",
      "\n",
      "Epoch 4377\n",
      "-------------------------------\n",
      "loss: 0.298769  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441148 \n",
      "\n",
      "Epoch 4378\n",
      "-------------------------------\n",
      "loss: 0.303545  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440974 \n",
      "\n",
      "Epoch 4379\n",
      "-------------------------------\n",
      "loss: 0.304719  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440481 \n",
      "\n",
      "Epoch 4380\n",
      "-------------------------------\n",
      "loss: 0.305574  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440774 \n",
      "\n",
      "Epoch 4381\n",
      "-------------------------------\n",
      "loss: 0.302064  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440721 \n",
      "\n",
      "Epoch 4382\n",
      "-------------------------------\n",
      "loss: 0.292979  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441280 \n",
      "\n",
      "Epoch 4383\n",
      "-------------------------------\n",
      "loss: 0.293018  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441341 \n",
      "\n",
      "Epoch 4384\n",
      "-------------------------------\n",
      "loss: 0.298253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440357 \n",
      "\n",
      "Epoch 4385\n",
      "-------------------------------\n",
      "loss: 0.308275  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440455 \n",
      "\n",
      "Epoch 4386\n",
      "-------------------------------\n",
      "loss: 0.298242  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440591 \n",
      "\n",
      "Epoch 4387\n",
      "-------------------------------\n",
      "loss: 0.300707  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439782 \n",
      "\n",
      "Epoch 4388\n",
      "-------------------------------\n",
      "loss: 0.302950  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440573 \n",
      "\n",
      "Epoch 4389\n",
      "-------------------------------\n",
      "loss: 0.308226  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440390 \n",
      "\n",
      "Epoch 4390\n",
      "-------------------------------\n",
      "loss: 0.303491  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440352 \n",
      "\n",
      "Epoch 4391\n",
      "-------------------------------\n",
      "loss: 0.302522  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440799 \n",
      "\n",
      "Epoch 4392\n",
      "-------------------------------\n",
      "loss: 0.296410  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440645 \n",
      "\n",
      "Epoch 4393\n",
      "-------------------------------\n",
      "loss: 0.296830  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440924 \n",
      "\n",
      "Epoch 4394\n",
      "-------------------------------\n",
      "loss: 0.304576  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441122 \n",
      "\n",
      "Epoch 4395\n",
      "-------------------------------\n",
      "loss: 0.306253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441624 \n",
      "\n",
      "Epoch 4396\n",
      "-------------------------------\n",
      "loss: 0.298782  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442000 \n",
      "\n",
      "Epoch 4397\n",
      "-------------------------------\n",
      "loss: 0.305524  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440842 \n",
      "\n",
      "Epoch 4398\n",
      "-------------------------------\n",
      "loss: 0.300732  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439782 \n",
      "\n",
      "Epoch 4399\n",
      "-------------------------------\n",
      "loss: 0.297521  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438989 \n",
      "\n",
      "Epoch 4400\n",
      "-------------------------------\n",
      "loss: 0.308290  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438772 \n",
      "\n",
      "Epoch 4401\n",
      "-------------------------------\n",
      "loss: 0.307318  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438693 \n",
      "\n",
      "Epoch 4402\n",
      "-------------------------------\n",
      "loss: 0.303232  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437885 \n",
      "\n",
      "Epoch 4403\n",
      "-------------------------------\n",
      "loss: 0.306672  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438016 \n",
      "\n",
      "Epoch 4404\n",
      "-------------------------------\n",
      "loss: 0.306433  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437314 \n",
      "\n",
      "Epoch 4405\n",
      "-------------------------------\n",
      "loss: 0.308068  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438351 \n",
      "\n",
      "Epoch 4406\n",
      "-------------------------------\n",
      "loss: 0.303185  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439205 \n",
      "\n",
      "Epoch 4407\n",
      "-------------------------------\n",
      "loss: 0.294181  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441023 \n",
      "\n",
      "Epoch 4408\n",
      "-------------------------------\n",
      "loss: 0.307610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441908 \n",
      "\n",
      "Epoch 4409\n",
      "-------------------------------\n",
      "loss: 0.305653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441950 \n",
      "\n",
      "Epoch 4410\n",
      "-------------------------------\n",
      "loss: 0.306293  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442308 \n",
      "\n",
      "Epoch 4411\n",
      "-------------------------------\n",
      "loss: 0.306827  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440987 \n",
      "\n",
      "Epoch 4412\n",
      "-------------------------------\n",
      "loss: 0.295344  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439791 \n",
      "\n",
      "Epoch 4413\n",
      "-------------------------------\n",
      "loss: 0.302990  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437924 \n",
      "\n",
      "Epoch 4414\n",
      "-------------------------------\n",
      "loss: 0.289415  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438267 \n",
      "\n",
      "Epoch 4415\n",
      "-------------------------------\n",
      "loss: 0.302265  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439097 \n",
      "\n",
      "Epoch 4416\n",
      "-------------------------------\n",
      "loss: 0.300254  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440166 \n",
      "\n",
      "Epoch 4417\n",
      "-------------------------------\n",
      "loss: 0.294316  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440122 \n",
      "\n",
      "Epoch 4418\n",
      "-------------------------------\n",
      "loss: 0.306036  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440427 \n",
      "\n",
      "Epoch 4419\n",
      "-------------------------------\n",
      "loss: 0.298014  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441114 \n",
      "\n",
      "Epoch 4420\n",
      "-------------------------------\n",
      "loss: 0.298809  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442178 \n",
      "\n",
      "Epoch 4421\n",
      "-------------------------------\n",
      "loss: 0.299663  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442515 \n",
      "\n",
      "Epoch 4422\n",
      "-------------------------------\n",
      "loss: 0.302073  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442545 \n",
      "\n",
      "Epoch 4423\n",
      "-------------------------------\n",
      "loss: 0.304647  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442302 \n",
      "\n",
      "Epoch 4424\n",
      "-------------------------------\n",
      "loss: 0.299104  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440792 \n",
      "\n",
      "Epoch 4425\n",
      "-------------------------------\n",
      "loss: 0.302722  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439731 \n",
      "\n",
      "Epoch 4426\n",
      "-------------------------------\n",
      "loss: 0.304232  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439260 \n",
      "\n",
      "Epoch 4427\n",
      "-------------------------------\n",
      "loss: 0.300033  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440129 \n",
      "\n",
      "Epoch 4428\n",
      "-------------------------------\n",
      "loss: 0.300419  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439903 \n",
      "\n",
      "Epoch 4429\n",
      "-------------------------------\n",
      "loss: 0.304044  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439965 \n",
      "\n",
      "Epoch 4430\n",
      "-------------------------------\n",
      "loss: 0.299533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440614 \n",
      "\n",
      "Epoch 4431\n",
      "-------------------------------\n",
      "loss: 0.300460  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440437 \n",
      "\n",
      "Epoch 4432\n",
      "-------------------------------\n",
      "loss: 0.307924  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440778 \n",
      "\n",
      "Epoch 4433\n",
      "-------------------------------\n",
      "loss: 0.302440  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440761 \n",
      "\n",
      "Epoch 4434\n",
      "-------------------------------\n",
      "loss: 0.311095  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441392 \n",
      "\n",
      "Epoch 4435\n",
      "-------------------------------\n",
      "loss: 0.307011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441074 \n",
      "\n",
      "Epoch 4436\n",
      "-------------------------------\n",
      "loss: 0.305503  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440236 \n",
      "\n",
      "Epoch 4437\n",
      "-------------------------------\n",
      "loss: 0.295324  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440675 \n",
      "\n",
      "Epoch 4438\n",
      "-------------------------------\n",
      "loss: 0.299872  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440691 \n",
      "\n",
      "Epoch 4439\n",
      "-------------------------------\n",
      "loss: 0.295649  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439640 \n",
      "\n",
      "Epoch 4440\n",
      "-------------------------------\n",
      "loss: 0.297822  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441114 \n",
      "\n",
      "Epoch 4441\n",
      "-------------------------------\n",
      "loss: 0.298210  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441498 \n",
      "\n",
      "Epoch 4442\n",
      "-------------------------------\n",
      "loss: 0.299804  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441317 \n",
      "\n",
      "Epoch 4443\n",
      "-------------------------------\n",
      "loss: 0.303919  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442544 \n",
      "\n",
      "Epoch 4444\n",
      "-------------------------------\n",
      "loss: 0.296408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442383 \n",
      "\n",
      "Epoch 4445\n",
      "-------------------------------\n",
      "loss: 0.307820  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441002 \n",
      "\n",
      "Epoch 4446\n",
      "-------------------------------\n",
      "loss: 0.296625  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441124 \n",
      "\n",
      "Epoch 4447\n",
      "-------------------------------\n",
      "loss: 0.295201  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440142 \n",
      "\n",
      "Epoch 4448\n",
      "-------------------------------\n",
      "loss: 0.308897  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440143 \n",
      "\n",
      "Epoch 4449\n",
      "-------------------------------\n",
      "loss: 0.304196  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438745 \n",
      "\n",
      "Epoch 4450\n",
      "-------------------------------\n",
      "loss: 0.300835  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439554 \n",
      "\n",
      "Epoch 4451\n",
      "-------------------------------\n",
      "loss: 0.302281  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439637 \n",
      "\n",
      "Epoch 4452\n",
      "-------------------------------\n",
      "loss: 0.298632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439640 \n",
      "\n",
      "Epoch 4453\n",
      "-------------------------------\n",
      "loss: 0.302278  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440416 \n",
      "\n",
      "Epoch 4454\n",
      "-------------------------------\n",
      "loss: 0.302418  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440144 \n",
      "\n",
      "Epoch 4455\n",
      "-------------------------------\n",
      "loss: 0.297629  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439875 \n",
      "\n",
      "Epoch 4456\n",
      "-------------------------------\n",
      "loss: 0.306173  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440600 \n",
      "\n",
      "Epoch 4457\n",
      "-------------------------------\n",
      "loss: 0.298858  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440712 \n",
      "\n",
      "Epoch 4458\n",
      "-------------------------------\n",
      "loss: 0.297158  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440976 \n",
      "\n",
      "Epoch 4459\n",
      "-------------------------------\n",
      "loss: 0.295720  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441547 \n",
      "\n",
      "Epoch 4460\n",
      "-------------------------------\n",
      "loss: 0.299412  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442058 \n",
      "\n",
      "Epoch 4461\n",
      "-------------------------------\n",
      "loss: 0.300934  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442341 \n",
      "\n",
      "Epoch 4462\n",
      "-------------------------------\n",
      "loss: 0.306877  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442352 \n",
      "\n",
      "Epoch 4463\n",
      "-------------------------------\n",
      "loss: 0.301928  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441991 \n",
      "\n",
      "Epoch 4464\n",
      "-------------------------------\n",
      "loss: 0.305603  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442029 \n",
      "\n",
      "Epoch 4465\n",
      "-------------------------------\n",
      "loss: 0.300185  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440818 \n",
      "\n",
      "Epoch 4466\n",
      "-------------------------------\n",
      "loss: 0.297798  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441191 \n",
      "\n",
      "Epoch 4467\n",
      "-------------------------------\n",
      "loss: 0.304966  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440711 \n",
      "\n",
      "Epoch 4468\n",
      "-------------------------------\n",
      "loss: 0.305489  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439941 \n",
      "\n",
      "Epoch 4469\n",
      "-------------------------------\n",
      "loss: 0.295086  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440309 \n",
      "\n",
      "Epoch 4470\n",
      "-------------------------------\n",
      "loss: 0.299115  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441098 \n",
      "\n",
      "Epoch 4471\n",
      "-------------------------------\n",
      "loss: 0.301655  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441620 \n",
      "\n",
      "Epoch 4472\n",
      "-------------------------------\n",
      "loss: 0.301540  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441796 \n",
      "\n",
      "Epoch 4473\n",
      "-------------------------------\n",
      "loss: 0.298860  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442332 \n",
      "\n",
      "Epoch 4474\n",
      "-------------------------------\n",
      "loss: 0.297525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442733 \n",
      "\n",
      "Epoch 4475\n",
      "-------------------------------\n",
      "loss: 0.301641  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442396 \n",
      "\n",
      "Epoch 4476\n",
      "-------------------------------\n",
      "loss: 0.304118  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441691 \n",
      "\n",
      "Epoch 4477\n",
      "-------------------------------\n",
      "loss: 0.306847  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442002 \n",
      "\n",
      "Epoch 4478\n",
      "-------------------------------\n",
      "loss: 0.302432  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441660 \n",
      "\n",
      "Epoch 4479\n",
      "-------------------------------\n",
      "loss: 0.303119  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441372 \n",
      "\n",
      "Epoch 4480\n",
      "-------------------------------\n",
      "loss: 0.306601  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440917 \n",
      "\n",
      "Epoch 4481\n",
      "-------------------------------\n",
      "loss: 0.298822  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441332 \n",
      "\n",
      "Epoch 4482\n",
      "-------------------------------\n",
      "loss: 0.294693  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441454 \n",
      "\n",
      "Epoch 4483\n",
      "-------------------------------\n",
      "loss: 0.295680  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441457 \n",
      "\n",
      "Epoch 4484\n",
      "-------------------------------\n",
      "loss: 0.302849  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441678 \n",
      "\n",
      "Epoch 4485\n",
      "-------------------------------\n",
      "loss: 0.294670  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442359 \n",
      "\n",
      "Epoch 4486\n",
      "-------------------------------\n",
      "loss: 0.299401  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442029 \n",
      "\n",
      "Epoch 4487\n",
      "-------------------------------\n",
      "loss: 0.298408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442590 \n",
      "\n",
      "Epoch 4488\n",
      "-------------------------------\n",
      "loss: 0.301970  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442181 \n",
      "\n",
      "Epoch 4489\n",
      "-------------------------------\n",
      "loss: 0.300817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441117 \n",
      "\n",
      "Epoch 4490\n",
      "-------------------------------\n",
      "loss: 0.307113  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440311 \n",
      "\n",
      "Epoch 4491\n",
      "-------------------------------\n",
      "loss: 0.306955  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439056 \n",
      "\n",
      "Epoch 4492\n",
      "-------------------------------\n",
      "loss: 0.302956  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439240 \n",
      "\n",
      "Epoch 4493\n",
      "-------------------------------\n",
      "loss: 0.297294  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439129 \n",
      "\n",
      "Epoch 4494\n",
      "-------------------------------\n",
      "loss: 0.307933  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439053 \n",
      "\n",
      "Epoch 4495\n",
      "-------------------------------\n",
      "loss: 0.301257  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438299 \n",
      "\n",
      "Epoch 4496\n",
      "-------------------------------\n",
      "loss: 0.307223  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439357 \n",
      "\n",
      "Epoch 4497\n",
      "-------------------------------\n",
      "loss: 0.304366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439820 \n",
      "\n",
      "Epoch 4498\n",
      "-------------------------------\n",
      "loss: 0.298817  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441178 \n",
      "\n",
      "Epoch 4499\n",
      "-------------------------------\n",
      "loss: 0.304614  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441448 \n",
      "\n",
      "Epoch 4500\n",
      "-------------------------------\n",
      "loss: 0.295841  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442574 \n",
      "\n",
      "Epoch 4501\n",
      "-------------------------------\n",
      "loss: 0.299590  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443347 \n",
      "\n",
      "Epoch 4502\n",
      "-------------------------------\n",
      "loss: 0.299937  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443553 \n",
      "\n",
      "Epoch 4503\n",
      "-------------------------------\n",
      "loss: 0.306270  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442068 \n",
      "\n",
      "Epoch 4504\n",
      "-------------------------------\n",
      "loss: 0.297251  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440725 \n",
      "\n",
      "Epoch 4505\n",
      "-------------------------------\n",
      "loss: 0.297875  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439626 \n",
      "\n",
      "Epoch 4506\n",
      "-------------------------------\n",
      "loss: 0.292740  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438227 \n",
      "\n",
      "Epoch 4507\n",
      "-------------------------------\n",
      "loss: 0.303997  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.437944 \n",
      "\n",
      "Epoch 4508\n",
      "-------------------------------\n",
      "loss: 0.301967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438174 \n",
      "\n",
      "Epoch 4509\n",
      "-------------------------------\n",
      "loss: 0.297271  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438388 \n",
      "\n",
      "Epoch 4510\n",
      "-------------------------------\n",
      "loss: 0.298245  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438071 \n",
      "\n",
      "Epoch 4511\n",
      "-------------------------------\n",
      "loss: 0.302105  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438530 \n",
      "\n",
      "Epoch 4512\n",
      "-------------------------------\n",
      "loss: 0.307399  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438822 \n",
      "\n",
      "Epoch 4513\n",
      "-------------------------------\n",
      "loss: 0.301634  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439404 \n",
      "\n",
      "Epoch 4514\n",
      "-------------------------------\n",
      "loss: 0.300885  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439663 \n",
      "\n",
      "Epoch 4515\n",
      "-------------------------------\n",
      "loss: 0.295984  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439665 \n",
      "\n",
      "Epoch 4516\n",
      "-------------------------------\n",
      "loss: 0.304368  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439804 \n",
      "\n",
      "Epoch 4517\n",
      "-------------------------------\n",
      "loss: 0.298142  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439811 \n",
      "\n",
      "Epoch 4518\n",
      "-------------------------------\n",
      "loss: 0.302661  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439997 \n",
      "\n",
      "Epoch 4519\n",
      "-------------------------------\n",
      "loss: 0.299013  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440648 \n",
      "\n",
      "Epoch 4520\n",
      "-------------------------------\n",
      "loss: 0.302740  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440563 \n",
      "\n",
      "Epoch 4521\n",
      "-------------------------------\n",
      "loss: 0.300916  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439728 \n",
      "\n",
      "Epoch 4522\n",
      "-------------------------------\n",
      "loss: 0.301313  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440137 \n",
      "\n",
      "Epoch 4523\n",
      "-------------------------------\n",
      "loss: 0.298278  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440130 \n",
      "\n",
      "Epoch 4524\n",
      "-------------------------------\n",
      "loss: 0.295023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441360 \n",
      "\n",
      "Epoch 4525\n",
      "-------------------------------\n",
      "loss: 0.301429  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441509 \n",
      "\n",
      "Epoch 4526\n",
      "-------------------------------\n",
      "loss: 0.305302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441589 \n",
      "\n",
      "Epoch 4527\n",
      "-------------------------------\n",
      "loss: 0.296392  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441394 \n",
      "\n",
      "Epoch 4528\n",
      "-------------------------------\n",
      "loss: 0.294438  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441523 \n",
      "\n",
      "Epoch 4529\n",
      "-------------------------------\n",
      "loss: 0.293754  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442126 \n",
      "\n",
      "Epoch 4530\n",
      "-------------------------------\n",
      "loss: 0.303016  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442154 \n",
      "\n",
      "Epoch 4531\n",
      "-------------------------------\n",
      "loss: 0.300816  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442011 \n",
      "\n",
      "Epoch 4532\n",
      "-------------------------------\n",
      "loss: 0.298472  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441440 \n",
      "\n",
      "Epoch 4533\n",
      "-------------------------------\n",
      "loss: 0.305080  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441779 \n",
      "\n",
      "Epoch 4534\n",
      "-------------------------------\n",
      "loss: 0.295181  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441649 \n",
      "\n",
      "Epoch 4535\n",
      "-------------------------------\n",
      "loss: 0.292453  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442070 \n",
      "\n",
      "Epoch 4536\n",
      "-------------------------------\n",
      "loss: 0.300064  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442375 \n",
      "\n",
      "Epoch 4537\n",
      "-------------------------------\n",
      "loss: 0.299730  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443400 \n",
      "\n",
      "Epoch 4538\n",
      "-------------------------------\n",
      "loss: 0.302267  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443799 \n",
      "\n",
      "Epoch 4539\n",
      "-------------------------------\n",
      "loss: 0.305693  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443558 \n",
      "\n",
      "Epoch 4540\n",
      "-------------------------------\n",
      "loss: 0.305232  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443792 \n",
      "\n",
      "Epoch 4541\n",
      "-------------------------------\n",
      "loss: 0.300824  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443067 \n",
      "\n",
      "Epoch 4542\n",
      "-------------------------------\n",
      "loss: 0.293289  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443029 \n",
      "\n",
      "Epoch 4543\n",
      "-------------------------------\n",
      "loss: 0.296554  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442109 \n",
      "\n",
      "Epoch 4544\n",
      "-------------------------------\n",
      "loss: 0.304585  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441958 \n",
      "\n",
      "Epoch 4545\n",
      "-------------------------------\n",
      "loss: 0.300917  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441730 \n",
      "\n",
      "Epoch 4546\n",
      "-------------------------------\n",
      "loss: 0.302610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441888 \n",
      "\n",
      "Epoch 4547\n",
      "-------------------------------\n",
      "loss: 0.304126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441025 \n",
      "\n",
      "Epoch 4548\n",
      "-------------------------------\n",
      "loss: 0.301113  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440903 \n",
      "\n",
      "Epoch 4549\n",
      "-------------------------------\n",
      "loss: 0.304941  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441770 \n",
      "\n",
      "Epoch 4550\n",
      "-------------------------------\n",
      "loss: 0.293148  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441843 \n",
      "\n",
      "Epoch 4551\n",
      "-------------------------------\n",
      "loss: 0.296481  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441204 \n",
      "\n",
      "Epoch 4552\n",
      "-------------------------------\n",
      "loss: 0.299420  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441008 \n",
      "\n",
      "Epoch 4553\n",
      "-------------------------------\n",
      "loss: 0.307502  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441878 \n",
      "\n",
      "Epoch 4554\n",
      "-------------------------------\n",
      "loss: 0.295261  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441319 \n",
      "\n",
      "Epoch 4555\n",
      "-------------------------------\n",
      "loss: 0.294819  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441604 \n",
      "\n",
      "Epoch 4556\n",
      "-------------------------------\n",
      "loss: 0.300532  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441751 \n",
      "\n",
      "Epoch 4557\n",
      "-------------------------------\n",
      "loss: 0.299344  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441821 \n",
      "\n",
      "Epoch 4558\n",
      "-------------------------------\n",
      "loss: 0.300472  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441626 \n",
      "\n",
      "Epoch 4559\n",
      "-------------------------------\n",
      "loss: 0.300524  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441728 \n",
      "\n",
      "Epoch 4560\n",
      "-------------------------------\n",
      "loss: 0.302023  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441648 \n",
      "\n",
      "Epoch 4561\n",
      "-------------------------------\n",
      "loss: 0.300634  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441782 \n",
      "\n",
      "Epoch 4562\n",
      "-------------------------------\n",
      "loss: 0.301324  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441220 \n",
      "\n",
      "Epoch 4563\n",
      "-------------------------------\n",
      "loss: 0.296537  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441643 \n",
      "\n",
      "Epoch 4564\n",
      "-------------------------------\n",
      "loss: 0.302126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440839 \n",
      "\n",
      "Epoch 4565\n",
      "-------------------------------\n",
      "loss: 0.300295  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440577 \n",
      "\n",
      "Epoch 4566\n",
      "-------------------------------\n",
      "loss: 0.298253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440351 \n",
      "\n",
      "Epoch 4567\n",
      "-------------------------------\n",
      "loss: 0.297923  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440575 \n",
      "\n",
      "Epoch 4568\n",
      "-------------------------------\n",
      "loss: 0.305314  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440615 \n",
      "\n",
      "Epoch 4569\n",
      "-------------------------------\n",
      "loss: 0.297184  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440874 \n",
      "\n",
      "Epoch 4570\n",
      "-------------------------------\n",
      "loss: 0.301109  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440152 \n",
      "\n",
      "Epoch 4571\n",
      "-------------------------------\n",
      "loss: 0.298910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441319 \n",
      "\n",
      "Epoch 4572\n",
      "-------------------------------\n",
      "loss: 0.294174  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441514 \n",
      "\n",
      "Epoch 4573\n",
      "-------------------------------\n",
      "loss: 0.306643  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442565 \n",
      "\n",
      "Epoch 4574\n",
      "-------------------------------\n",
      "loss: 0.300994  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442281 \n",
      "\n",
      "Epoch 4575\n",
      "-------------------------------\n",
      "loss: 0.299221  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442603 \n",
      "\n",
      "Epoch 4576\n",
      "-------------------------------\n",
      "loss: 0.302383  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442878 \n",
      "\n",
      "Epoch 4577\n",
      "-------------------------------\n",
      "loss: 0.303056  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442477 \n",
      "\n",
      "Epoch 4578\n",
      "-------------------------------\n",
      "loss: 0.297667  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441636 \n",
      "\n",
      "Epoch 4579\n",
      "-------------------------------\n",
      "loss: 0.299858  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440511 \n",
      "\n",
      "Epoch 4580\n",
      "-------------------------------\n",
      "loss: 0.301700  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439750 \n",
      "\n",
      "Epoch 4581\n",
      "-------------------------------\n",
      "loss: 0.294286  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439676 \n",
      "\n",
      "Epoch 4582\n",
      "-------------------------------\n",
      "loss: 0.305225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439751 \n",
      "\n",
      "Epoch 4583\n",
      "-------------------------------\n",
      "loss: 0.300794  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440193 \n",
      "\n",
      "Epoch 4584\n",
      "-------------------------------\n",
      "loss: 0.296805  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440598 \n",
      "\n",
      "Epoch 4585\n",
      "-------------------------------\n",
      "loss: 0.295283  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440124 \n",
      "\n",
      "Epoch 4586\n",
      "-------------------------------\n",
      "loss: 0.295193  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439987 \n",
      "\n",
      "Epoch 4587\n",
      "-------------------------------\n",
      "loss: 0.296318  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440338 \n",
      "\n",
      "Epoch 4588\n",
      "-------------------------------\n",
      "loss: 0.303049  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440422 \n",
      "\n",
      "Epoch 4589\n",
      "-------------------------------\n",
      "loss: 0.308834  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440995 \n",
      "\n",
      "Epoch 4590\n",
      "-------------------------------\n",
      "loss: 0.297915  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440859 \n",
      "\n",
      "Epoch 4591\n",
      "-------------------------------\n",
      "loss: 0.304910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441274 \n",
      "\n",
      "Epoch 4592\n",
      "-------------------------------\n",
      "loss: 0.301921  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442154 \n",
      "\n",
      "Epoch 4593\n",
      "-------------------------------\n",
      "loss: 0.296819  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441740 \n",
      "\n",
      "Epoch 4594\n",
      "-------------------------------\n",
      "loss: 0.301653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441247 \n",
      "\n",
      "Epoch 4595\n",
      "-------------------------------\n",
      "loss: 0.297718  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441979 \n",
      "\n",
      "Epoch 4596\n",
      "-------------------------------\n",
      "loss: 0.301496  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441435 \n",
      "\n",
      "Epoch 4597\n",
      "-------------------------------\n",
      "loss: 0.301146  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442076 \n",
      "\n",
      "Epoch 4598\n",
      "-------------------------------\n",
      "loss: 0.297503  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441583 \n",
      "\n",
      "Epoch 4599\n",
      "-------------------------------\n",
      "loss: 0.302571  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441717 \n",
      "\n",
      "Epoch 4600\n",
      "-------------------------------\n",
      "loss: 0.300054  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442648 \n",
      "\n",
      "Epoch 4601\n",
      "-------------------------------\n",
      "loss: 0.305523  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442921 \n",
      "\n",
      "Epoch 4602\n",
      "-------------------------------\n",
      "loss: 0.299062  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442443 \n",
      "\n",
      "Epoch 4603\n",
      "-------------------------------\n",
      "loss: 0.298035  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441531 \n",
      "\n",
      "Epoch 4604\n",
      "-------------------------------\n",
      "loss: 0.301071  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441149 \n",
      "\n",
      "Epoch 4605\n",
      "-------------------------------\n",
      "loss: 0.300276  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440585 \n",
      "\n",
      "Epoch 4606\n",
      "-------------------------------\n",
      "loss: 0.294709  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440285 \n",
      "\n",
      "Epoch 4607\n",
      "-------------------------------\n",
      "loss: 0.300141  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440578 \n",
      "\n",
      "Epoch 4608\n",
      "-------------------------------\n",
      "loss: 0.296983  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440499 \n",
      "\n",
      "Epoch 4609\n",
      "-------------------------------\n",
      "loss: 0.302344  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441233 \n",
      "\n",
      "Epoch 4610\n",
      "-------------------------------\n",
      "loss: 0.299932  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441192 \n",
      "\n",
      "Epoch 4611\n",
      "-------------------------------\n",
      "loss: 0.297749  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440839 \n",
      "\n",
      "Epoch 4612\n",
      "-------------------------------\n",
      "loss: 0.295732  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440026 \n",
      "\n",
      "Epoch 4613\n",
      "-------------------------------\n",
      "loss: 0.297302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439454 \n",
      "\n",
      "Epoch 4614\n",
      "-------------------------------\n",
      "loss: 0.300296  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439360 \n",
      "\n",
      "Epoch 4615\n",
      "-------------------------------\n",
      "loss: 0.301807  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439818 \n",
      "\n",
      "Epoch 4616\n",
      "-------------------------------\n",
      "loss: 0.302878  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439830 \n",
      "\n",
      "Epoch 4617\n",
      "-------------------------------\n",
      "loss: 0.300589  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439838 \n",
      "\n",
      "Epoch 4618\n",
      "-------------------------------\n",
      "loss: 0.297213  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439634 \n",
      "\n",
      "Epoch 4619\n",
      "-------------------------------\n",
      "loss: 0.301880  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440089 \n",
      "\n",
      "Epoch 4620\n",
      "-------------------------------\n",
      "loss: 0.297116  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439836 \n",
      "\n",
      "Epoch 4621\n",
      "-------------------------------\n",
      "loss: 0.295131  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439159 \n",
      "\n",
      "Epoch 4622\n",
      "-------------------------------\n",
      "loss: 0.303555  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439167 \n",
      "\n",
      "Epoch 4623\n",
      "-------------------------------\n",
      "loss: 0.301392  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439219 \n",
      "\n",
      "Epoch 4624\n",
      "-------------------------------\n",
      "loss: 0.300218  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439531 \n",
      "\n",
      "Epoch 4625\n",
      "-------------------------------\n",
      "loss: 0.301913  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440438 \n",
      "\n",
      "Epoch 4626\n",
      "-------------------------------\n",
      "loss: 0.297196  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441333 \n",
      "\n",
      "Epoch 4627\n",
      "-------------------------------\n",
      "loss: 0.295589  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441270 \n",
      "\n",
      "Epoch 4628\n",
      "-------------------------------\n",
      "loss: 0.297381  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441373 \n",
      "\n",
      "Epoch 4629\n",
      "-------------------------------\n",
      "loss: 0.299254  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440715 \n",
      "\n",
      "Epoch 4630\n",
      "-------------------------------\n",
      "loss: 0.309576  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439564 \n",
      "\n",
      "Epoch 4631\n",
      "-------------------------------\n",
      "loss: 0.301720  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439616 \n",
      "\n",
      "Epoch 4632\n",
      "-------------------------------\n",
      "loss: 0.299449  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438674 \n",
      "\n",
      "Epoch 4633\n",
      "-------------------------------\n",
      "loss: 0.298731  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439271 \n",
      "\n",
      "Epoch 4634\n",
      "-------------------------------\n",
      "loss: 0.306650  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438838 \n",
      "\n",
      "Epoch 4635\n",
      "-------------------------------\n",
      "loss: 0.300625  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439179 \n",
      "\n",
      "Epoch 4636\n",
      "-------------------------------\n",
      "loss: 0.300436  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440057 \n",
      "\n",
      "Epoch 4637\n",
      "-------------------------------\n",
      "loss: 0.304380  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440324 \n",
      "\n",
      "Epoch 4638\n",
      "-------------------------------\n",
      "loss: 0.299550  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441183 \n",
      "\n",
      "Epoch 4639\n",
      "-------------------------------\n",
      "loss: 0.290637  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441995 \n",
      "\n",
      "Epoch 4640\n",
      "-------------------------------\n",
      "loss: 0.299037  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441875 \n",
      "\n",
      "Epoch 4641\n",
      "-------------------------------\n",
      "loss: 0.294975  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442149 \n",
      "\n",
      "Epoch 4642\n",
      "-------------------------------\n",
      "loss: 0.301482  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441782 \n",
      "\n",
      "Epoch 4643\n",
      "-------------------------------\n",
      "loss: 0.295898  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441101 \n",
      "\n",
      "Epoch 4644\n",
      "-------------------------------\n",
      "loss: 0.298929  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440238 \n",
      "\n",
      "Epoch 4645\n",
      "-------------------------------\n",
      "loss: 0.304246  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440378 \n",
      "\n",
      "Epoch 4646\n",
      "-------------------------------\n",
      "loss: 0.306287  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440719 \n",
      "\n",
      "Epoch 4647\n",
      "-------------------------------\n",
      "loss: 0.299137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440933 \n",
      "\n",
      "Epoch 4648\n",
      "-------------------------------\n",
      "loss: 0.304520  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440378 \n",
      "\n",
      "Epoch 4649\n",
      "-------------------------------\n",
      "loss: 0.299239  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441030 \n",
      "\n",
      "Epoch 4650\n",
      "-------------------------------\n",
      "loss: 0.302298  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441265 \n",
      "\n",
      "Epoch 4651\n",
      "-------------------------------\n",
      "loss: 0.304915  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441532 \n",
      "\n",
      "Epoch 4652\n",
      "-------------------------------\n",
      "loss: 0.300165  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441866 \n",
      "\n",
      "Epoch 4653\n",
      "-------------------------------\n",
      "loss: 0.290374  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441926 \n",
      "\n",
      "Epoch 4654\n",
      "-------------------------------\n",
      "loss: 0.300647  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442137 \n",
      "\n",
      "Epoch 4655\n",
      "-------------------------------\n",
      "loss: 0.291776  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441609 \n",
      "\n",
      "Epoch 4656\n",
      "-------------------------------\n",
      "loss: 0.297871  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442253 \n",
      "\n",
      "Epoch 4657\n",
      "-------------------------------\n",
      "loss: 0.300830  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442678 \n",
      "\n",
      "Epoch 4658\n",
      "-------------------------------\n",
      "loss: 0.295463  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442486 \n",
      "\n",
      "Epoch 4659\n",
      "-------------------------------\n",
      "loss: 0.300353  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442359 \n",
      "\n",
      "Epoch 4660\n",
      "-------------------------------\n",
      "loss: 0.297559  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442261 \n",
      "\n",
      "Epoch 4661\n",
      "-------------------------------\n",
      "loss: 0.296810  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441859 \n",
      "\n",
      "Epoch 4662\n",
      "-------------------------------\n",
      "loss: 0.301090  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442780 \n",
      "\n",
      "Epoch 4663\n",
      "-------------------------------\n",
      "loss: 0.292349  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442290 \n",
      "\n",
      "Epoch 4664\n",
      "-------------------------------\n",
      "loss: 0.302083  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442281 \n",
      "\n",
      "Epoch 4665\n",
      "-------------------------------\n",
      "loss: 0.308407  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443423 \n",
      "\n",
      "Epoch 4666\n",
      "-------------------------------\n",
      "loss: 0.298187  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444036 \n",
      "\n",
      "Epoch 4667\n",
      "-------------------------------\n",
      "loss: 0.300556  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444239 \n",
      "\n",
      "Epoch 4668\n",
      "-------------------------------\n",
      "loss: 0.296296  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442855 \n",
      "\n",
      "Epoch 4669\n",
      "-------------------------------\n",
      "loss: 0.297019  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442434 \n",
      "\n",
      "Epoch 4670\n",
      "-------------------------------\n",
      "loss: 0.303366  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441793 \n",
      "\n",
      "Epoch 4671\n",
      "-------------------------------\n",
      "loss: 0.293157  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441465 \n",
      "\n",
      "Epoch 4672\n",
      "-------------------------------\n",
      "loss: 0.293761  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440420 \n",
      "\n",
      "Epoch 4673\n",
      "-------------------------------\n",
      "loss: 0.299687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440518 \n",
      "\n",
      "Epoch 4674\n",
      "-------------------------------\n",
      "loss: 0.299983  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440835 \n",
      "\n",
      "Epoch 4675\n",
      "-------------------------------\n",
      "loss: 0.300555  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440229 \n",
      "\n",
      "Epoch 4676\n",
      "-------------------------------\n",
      "loss: 0.301733  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440305 \n",
      "\n",
      "Epoch 4677\n",
      "-------------------------------\n",
      "loss: 0.305931  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440150 \n",
      "\n",
      "Epoch 4678\n",
      "-------------------------------\n",
      "loss: 0.298092  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439528 \n",
      "\n",
      "Epoch 4679\n",
      "-------------------------------\n",
      "loss: 0.299336  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439835 \n",
      "\n",
      "Epoch 4680\n",
      "-------------------------------\n",
      "loss: 0.297476  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439498 \n",
      "\n",
      "Epoch 4681\n",
      "-------------------------------\n",
      "loss: 0.297902  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439580 \n",
      "\n",
      "Epoch 4682\n",
      "-------------------------------\n",
      "loss: 0.295305  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.440827 \n",
      "\n",
      "Epoch 4683\n",
      "-------------------------------\n",
      "loss: 0.300500  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441041 \n",
      "\n",
      "Epoch 4684\n",
      "-------------------------------\n",
      "loss: 0.299514  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441099 \n",
      "\n",
      "Epoch 4685\n",
      "-------------------------------\n",
      "loss: 0.296448  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440929 \n",
      "\n",
      "Epoch 4686\n",
      "-------------------------------\n",
      "loss: 0.297201  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440830 \n",
      "\n",
      "Epoch 4687\n",
      "-------------------------------\n",
      "loss: 0.294329  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441464 \n",
      "\n",
      "Epoch 4688\n",
      "-------------------------------\n",
      "loss: 0.297648  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441014 \n",
      "\n",
      "Epoch 4689\n",
      "-------------------------------\n",
      "loss: 0.291615  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441266 \n",
      "\n",
      "Epoch 4690\n",
      "-------------------------------\n",
      "loss: 0.288838  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440825 \n",
      "\n",
      "Epoch 4691\n",
      "-------------------------------\n",
      "loss: 0.308451  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440972 \n",
      "\n",
      "Epoch 4692\n",
      "-------------------------------\n",
      "loss: 0.301006  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440171 \n",
      "\n",
      "Epoch 4693\n",
      "-------------------------------\n",
      "loss: 0.298640  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439636 \n",
      "\n",
      "Epoch 4694\n",
      "-------------------------------\n",
      "loss: 0.307253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439578 \n",
      "\n",
      "Epoch 4695\n",
      "-------------------------------\n",
      "loss: 0.296178  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439728 \n",
      "\n",
      "Epoch 4696\n",
      "-------------------------------\n",
      "loss: 0.307049  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439965 \n",
      "\n",
      "Epoch 4697\n",
      "-------------------------------\n",
      "loss: 0.299833  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440037 \n",
      "\n",
      "Epoch 4698\n",
      "-------------------------------\n",
      "loss: 0.300985  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440742 \n",
      "\n",
      "Epoch 4699\n",
      "-------------------------------\n",
      "loss: 0.302530  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439971 \n",
      "\n",
      "Epoch 4700\n",
      "-------------------------------\n",
      "loss: 0.296322  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440438 \n",
      "\n",
      "Epoch 4701\n",
      "-------------------------------\n",
      "loss: 0.299687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440274 \n",
      "\n",
      "Epoch 4702\n",
      "-------------------------------\n",
      "loss: 0.299652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440580 \n",
      "\n",
      "Epoch 4703\n",
      "-------------------------------\n",
      "loss: 0.298940  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440602 \n",
      "\n",
      "Epoch 4704\n",
      "-------------------------------\n",
      "loss: 0.295834  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440304 \n",
      "\n",
      "Epoch 4705\n",
      "-------------------------------\n",
      "loss: 0.300962  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440224 \n",
      "\n",
      "Epoch 4706\n",
      "-------------------------------\n",
      "loss: 0.293711  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440499 \n",
      "\n",
      "Epoch 4707\n",
      "-------------------------------\n",
      "loss: 0.299195  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440737 \n",
      "\n",
      "Epoch 4708\n",
      "-------------------------------\n",
      "loss: 0.299390  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440806 \n",
      "\n",
      "Epoch 4709\n",
      "-------------------------------\n",
      "loss: 0.298045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440942 \n",
      "\n",
      "Epoch 4710\n",
      "-------------------------------\n",
      "loss: 0.296517  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441962 \n",
      "\n",
      "Epoch 4711\n",
      "-------------------------------\n",
      "loss: 0.300001  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441776 \n",
      "\n",
      "Epoch 4712\n",
      "-------------------------------\n",
      "loss: 0.297574  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441683 \n",
      "\n",
      "Epoch 4713\n",
      "-------------------------------\n",
      "loss: 0.300577  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440876 \n",
      "\n",
      "Epoch 4714\n",
      "-------------------------------\n",
      "loss: 0.294652  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440685 \n",
      "\n",
      "Epoch 4715\n",
      "-------------------------------\n",
      "loss: 0.295599  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440673 \n",
      "\n",
      "Epoch 4716\n",
      "-------------------------------\n",
      "loss: 0.299846  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440450 \n",
      "\n",
      "Epoch 4717\n",
      "-------------------------------\n",
      "loss: 0.297186  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439816 \n",
      "\n",
      "Epoch 4718\n",
      "-------------------------------\n",
      "loss: 0.299981  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439837 \n",
      "\n",
      "Epoch 4719\n",
      "-------------------------------\n",
      "loss: 0.299864  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439438 \n",
      "\n",
      "Epoch 4720\n",
      "-------------------------------\n",
      "loss: 0.303642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440839 \n",
      "\n",
      "Epoch 4721\n",
      "-------------------------------\n",
      "loss: 0.307904  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440209 \n",
      "\n",
      "Epoch 4722\n",
      "-------------------------------\n",
      "loss: 0.297910  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441261 \n",
      "\n",
      "Epoch 4723\n",
      "-------------------------------\n",
      "loss: 0.305685  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441455 \n",
      "\n",
      "Epoch 4724\n",
      "-------------------------------\n",
      "loss: 0.306173  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441601 \n",
      "\n",
      "Epoch 4725\n",
      "-------------------------------\n",
      "loss: 0.301415  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441877 \n",
      "\n",
      "Epoch 4726\n",
      "-------------------------------\n",
      "loss: 0.298213  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441640 \n",
      "\n",
      "Epoch 4727\n",
      "-------------------------------\n",
      "loss: 0.302480  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441082 \n",
      "\n",
      "Epoch 4728\n",
      "-------------------------------\n",
      "loss: 0.304852  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441634 \n",
      "\n",
      "Epoch 4729\n",
      "-------------------------------\n",
      "loss: 0.302245  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441267 \n",
      "\n",
      "Epoch 4730\n",
      "-------------------------------\n",
      "loss: 0.294642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441119 \n",
      "\n",
      "Epoch 4731\n",
      "-------------------------------\n",
      "loss: 0.294362  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441451 \n",
      "\n",
      "Epoch 4732\n",
      "-------------------------------\n",
      "loss: 0.300696  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441953 \n",
      "\n",
      "Epoch 4733\n",
      "-------------------------------\n",
      "loss: 0.297537  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442000 \n",
      "\n",
      "Epoch 4734\n",
      "-------------------------------\n",
      "loss: 0.295345  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442881 \n",
      "\n",
      "Epoch 4735\n",
      "-------------------------------\n",
      "loss: 0.297770  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442548 \n",
      "\n",
      "Epoch 4736\n",
      "-------------------------------\n",
      "loss: 0.294343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442478 \n",
      "\n",
      "Epoch 4737\n",
      "-------------------------------\n",
      "loss: 0.294970  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441324 \n",
      "\n",
      "Epoch 4738\n",
      "-------------------------------\n",
      "loss: 0.303983  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440802 \n",
      "\n",
      "Epoch 4739\n",
      "-------------------------------\n",
      "loss: 0.297692  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439699 \n",
      "\n",
      "Epoch 4740\n",
      "-------------------------------\n",
      "loss: 0.295988  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440075 \n",
      "\n",
      "Epoch 4741\n",
      "-------------------------------\n",
      "loss: 0.295930  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440441 \n",
      "\n",
      "Epoch 4742\n",
      "-------------------------------\n",
      "loss: 0.292548  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440877 \n",
      "\n",
      "Epoch 4743\n",
      "-------------------------------\n",
      "loss: 0.291557  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441987 \n",
      "\n",
      "Epoch 4744\n",
      "-------------------------------\n",
      "loss: 0.309466  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442446 \n",
      "\n",
      "Epoch 4745\n",
      "-------------------------------\n",
      "loss: 0.310442  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442206 \n",
      "\n",
      "Epoch 4746\n",
      "-------------------------------\n",
      "loss: 0.305146  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443650 \n",
      "\n",
      "Epoch 4747\n",
      "-------------------------------\n",
      "loss: 0.299408  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443154 \n",
      "\n",
      "Epoch 4748\n",
      "-------------------------------\n",
      "loss: 0.301013  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443803 \n",
      "\n",
      "Epoch 4749\n",
      "-------------------------------\n",
      "loss: 0.297888  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444469 \n",
      "\n",
      "Epoch 4750\n",
      "-------------------------------\n",
      "loss: 0.305668  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444669 \n",
      "\n",
      "Epoch 4751\n",
      "-------------------------------\n",
      "loss: 0.299832  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443988 \n",
      "\n",
      "Epoch 4752\n",
      "-------------------------------\n",
      "loss: 0.299632  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445022 \n",
      "\n",
      "Epoch 4753\n",
      "-------------------------------\n",
      "loss: 0.304392  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445173 \n",
      "\n",
      "Epoch 4754\n",
      "-------------------------------\n",
      "loss: 0.307495  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444829 \n",
      "\n",
      "Epoch 4755\n",
      "-------------------------------\n",
      "loss: 0.302455  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442862 \n",
      "\n",
      "Epoch 4756\n",
      "-------------------------------\n",
      "loss: 0.295458  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442551 \n",
      "\n",
      "Epoch 4757\n",
      "-------------------------------\n",
      "loss: 0.298033  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441863 \n",
      "\n",
      "Epoch 4758\n",
      "-------------------------------\n",
      "loss: 0.292520  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441051 \n",
      "\n",
      "Epoch 4759\n",
      "-------------------------------\n",
      "loss: 0.301497  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440740 \n",
      "\n",
      "Epoch 4760\n",
      "-------------------------------\n",
      "loss: 0.297771  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440128 \n",
      "\n",
      "Epoch 4761\n",
      "-------------------------------\n",
      "loss: 0.298484  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439222 \n",
      "\n",
      "Epoch 4762\n",
      "-------------------------------\n",
      "loss: 0.300452  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439257 \n",
      "\n",
      "Epoch 4763\n",
      "-------------------------------\n",
      "loss: 0.301095  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439332 \n",
      "\n",
      "Epoch 4764\n",
      "-------------------------------\n",
      "loss: 0.305313  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439381 \n",
      "\n",
      "Epoch 4765\n",
      "-------------------------------\n",
      "loss: 0.295866  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439693 \n",
      "\n",
      "Epoch 4766\n",
      "-------------------------------\n",
      "loss: 0.297660  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440214 \n",
      "\n",
      "Epoch 4767\n",
      "-------------------------------\n",
      "loss: 0.304024  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439852 \n",
      "\n",
      "Epoch 4768\n",
      "-------------------------------\n",
      "loss: 0.295132  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440769 \n",
      "\n",
      "Epoch 4769\n",
      "-------------------------------\n",
      "loss: 0.302643  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440287 \n",
      "\n",
      "Epoch 4770\n",
      "-------------------------------\n",
      "loss: 0.302223  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441269 \n",
      "\n",
      "Epoch 4771\n",
      "-------------------------------\n",
      "loss: 0.298266  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441348 \n",
      "\n",
      "Epoch 4772\n",
      "-------------------------------\n",
      "loss: 0.293275  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441400 \n",
      "\n",
      "Epoch 4773\n",
      "-------------------------------\n",
      "loss: 0.295263  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441059 \n",
      "\n",
      "Epoch 4774\n",
      "-------------------------------\n",
      "loss: 0.299928  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440569 \n",
      "\n",
      "Epoch 4775\n",
      "-------------------------------\n",
      "loss: 0.300207  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440567 \n",
      "\n",
      "Epoch 4776\n",
      "-------------------------------\n",
      "loss: 0.290912  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440503 \n",
      "\n",
      "Epoch 4777\n",
      "-------------------------------\n",
      "loss: 0.291036  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439690 \n",
      "\n",
      "Epoch 4778\n",
      "-------------------------------\n",
      "loss: 0.294770  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439869 \n",
      "\n",
      "Epoch 4779\n",
      "-------------------------------\n",
      "loss: 0.295614  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439630 \n",
      "\n",
      "Epoch 4780\n",
      "-------------------------------\n",
      "loss: 0.297099  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439766 \n",
      "\n",
      "Epoch 4781\n",
      "-------------------------------\n",
      "loss: 0.300881  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440089 \n",
      "\n",
      "Epoch 4782\n",
      "-------------------------------\n",
      "loss: 0.303747  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439671 \n",
      "\n",
      "Epoch 4783\n",
      "-------------------------------\n",
      "loss: 0.306416  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439332 \n",
      "\n",
      "Epoch 4784\n",
      "-------------------------------\n",
      "loss: 0.308979  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439628 \n",
      "\n",
      "Epoch 4785\n",
      "-------------------------------\n",
      "loss: 0.305666  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439579 \n",
      "\n",
      "Epoch 4786\n",
      "-------------------------------\n",
      "loss: 0.298517  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439655 \n",
      "\n",
      "Epoch 4787\n",
      "-------------------------------\n",
      "loss: 0.297045  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440066 \n",
      "\n",
      "Epoch 4788\n",
      "-------------------------------\n",
      "loss: 0.297498  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440693 \n",
      "\n",
      "Epoch 4789\n",
      "-------------------------------\n",
      "loss: 0.303168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440839 \n",
      "\n",
      "Epoch 4790\n",
      "-------------------------------\n",
      "loss: 0.296883  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441399 \n",
      "\n",
      "Epoch 4791\n",
      "-------------------------------\n",
      "loss: 0.301668  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442788 \n",
      "\n",
      "Epoch 4792\n",
      "-------------------------------\n",
      "loss: 0.301387  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443541 \n",
      "\n",
      "Epoch 4793\n",
      "-------------------------------\n",
      "loss: 0.305566  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443630 \n",
      "\n",
      "Epoch 4794\n",
      "-------------------------------\n",
      "loss: 0.300219  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442077 \n",
      "\n",
      "Epoch 4795\n",
      "-------------------------------\n",
      "loss: 0.293170  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442531 \n",
      "\n",
      "Epoch 4796\n",
      "-------------------------------\n",
      "loss: 0.292737  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442168 \n",
      "\n",
      "Epoch 4797\n",
      "-------------------------------\n",
      "loss: 0.304114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441798 \n",
      "\n",
      "Epoch 4798\n",
      "-------------------------------\n",
      "loss: 0.298790  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441448 \n",
      "\n",
      "Epoch 4799\n",
      "-------------------------------\n",
      "loss: 0.305868  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441344 \n",
      "\n",
      "Epoch 4800\n",
      "-------------------------------\n",
      "loss: 0.292619  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441668 \n",
      "\n",
      "Epoch 4801\n",
      "-------------------------------\n",
      "loss: 0.302279  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441404 \n",
      "\n",
      "Epoch 4802\n",
      "-------------------------------\n",
      "loss: 0.296897  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441048 \n",
      "\n",
      "Epoch 4803\n",
      "-------------------------------\n",
      "loss: 0.298133  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442275 \n",
      "\n",
      "Epoch 4804\n",
      "-------------------------------\n",
      "loss: 0.295530  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442876 \n",
      "\n",
      "Epoch 4805\n",
      "-------------------------------\n",
      "loss: 0.301114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441892 \n",
      "\n",
      "Epoch 4806\n",
      "-------------------------------\n",
      "loss: 0.296101  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441891 \n",
      "\n",
      "Epoch 4807\n",
      "-------------------------------\n",
      "loss: 0.300938  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441794 \n",
      "\n",
      "Epoch 4808\n",
      "-------------------------------\n",
      "loss: 0.297152  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442301 \n",
      "\n",
      "Epoch 4809\n",
      "-------------------------------\n",
      "loss: 0.295505  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441589 \n",
      "\n",
      "Epoch 4810\n",
      "-------------------------------\n",
      "loss: 0.296613  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441918 \n",
      "\n",
      "Epoch 4811\n",
      "-------------------------------\n",
      "loss: 0.295989  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441247 \n",
      "\n",
      "Epoch 4812\n",
      "-------------------------------\n",
      "loss: 0.294678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441363 \n",
      "\n",
      "Epoch 4813\n",
      "-------------------------------\n",
      "loss: 0.300032  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441529 \n",
      "\n",
      "Epoch 4814\n",
      "-------------------------------\n",
      "loss: 0.301214  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441009 \n",
      "\n",
      "Epoch 4815\n",
      "-------------------------------\n",
      "loss: 0.296337  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440747 \n",
      "\n",
      "Epoch 4816\n",
      "-------------------------------\n",
      "loss: 0.295302  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440237 \n",
      "\n",
      "Epoch 4817\n",
      "-------------------------------\n",
      "loss: 0.288848  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439302 \n",
      "\n",
      "Epoch 4818\n",
      "-------------------------------\n",
      "loss: 0.298474  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439321 \n",
      "\n",
      "Epoch 4819\n",
      "-------------------------------\n",
      "loss: 0.301059  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440809 \n",
      "\n",
      "Epoch 4820\n",
      "-------------------------------\n",
      "loss: 0.311938  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440576 \n",
      "\n",
      "Epoch 4821\n",
      "-------------------------------\n",
      "loss: 0.306982  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441270 \n",
      "\n",
      "Epoch 4822\n",
      "-------------------------------\n",
      "loss: 0.298409  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441331 \n",
      "\n",
      "Epoch 4823\n",
      "-------------------------------\n",
      "loss: 0.301492  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441140 \n",
      "\n",
      "Epoch 4824\n",
      "-------------------------------\n",
      "loss: 0.298182  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441465 \n",
      "\n",
      "Epoch 4825\n",
      "-------------------------------\n",
      "loss: 0.297535  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441185 \n",
      "\n",
      "Epoch 4826\n",
      "-------------------------------\n",
      "loss: 0.309060  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441955 \n",
      "\n",
      "Epoch 4827\n",
      "-------------------------------\n",
      "loss: 0.304497  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442315 \n",
      "\n",
      "Epoch 4828\n",
      "-------------------------------\n",
      "loss: 0.294935  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442770 \n",
      "\n",
      "Epoch 4829\n",
      "-------------------------------\n",
      "loss: 0.299524  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443125 \n",
      "\n",
      "Epoch 4830\n",
      "-------------------------------\n",
      "loss: 0.298931  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443109 \n",
      "\n",
      "Epoch 4831\n",
      "-------------------------------\n",
      "loss: 0.299598  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443206 \n",
      "\n",
      "Epoch 4832\n",
      "-------------------------------\n",
      "loss: 0.300924  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443408 \n",
      "\n",
      "Epoch 4833\n",
      "-------------------------------\n",
      "loss: 0.295914  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444630 \n",
      "\n",
      "Epoch 4834\n",
      "-------------------------------\n",
      "loss: 0.307802  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.444170 \n",
      "\n",
      "Epoch 4835\n",
      "-------------------------------\n",
      "loss: 0.295504  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444096 \n",
      "\n",
      "Epoch 4836\n",
      "-------------------------------\n",
      "loss: 0.298716  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443261 \n",
      "\n",
      "Epoch 4837\n",
      "-------------------------------\n",
      "loss: 0.301070  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442536 \n",
      "\n",
      "Epoch 4838\n",
      "-------------------------------\n",
      "loss: 0.298345  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442398 \n",
      "\n",
      "Epoch 4839\n",
      "-------------------------------\n",
      "loss: 0.296892  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441640 \n",
      "\n",
      "Epoch 4840\n",
      "-------------------------------\n",
      "loss: 0.297850  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439706 \n",
      "\n",
      "Epoch 4841\n",
      "-------------------------------\n",
      "loss: 0.305157  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439476 \n",
      "\n",
      "Epoch 4842\n",
      "-------------------------------\n",
      "loss: 0.296320  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440414 \n",
      "\n",
      "Epoch 4843\n",
      "-------------------------------\n",
      "loss: 0.299342  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440875 \n",
      "\n",
      "Epoch 4844\n",
      "-------------------------------\n",
      "loss: 0.301273  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440762 \n",
      "\n",
      "Epoch 4845\n",
      "-------------------------------\n",
      "loss: 0.306958  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441016 \n",
      "\n",
      "Epoch 4846\n",
      "-------------------------------\n",
      "loss: 0.294645  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440974 \n",
      "\n",
      "Epoch 4847\n",
      "-------------------------------\n",
      "loss: 0.297748  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441252 \n",
      "\n",
      "Epoch 4848\n",
      "-------------------------------\n",
      "loss: 0.295046  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440927 \n",
      "\n",
      "Epoch 4849\n",
      "-------------------------------\n",
      "loss: 0.300359  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441198 \n",
      "\n",
      "Epoch 4850\n",
      "-------------------------------\n",
      "loss: 0.299801  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441134 \n",
      "\n",
      "Epoch 4851\n",
      "-------------------------------\n",
      "loss: 0.299341  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440876 \n",
      "\n",
      "Epoch 4852\n",
      "-------------------------------\n",
      "loss: 0.304224  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440232 \n",
      "\n",
      "Epoch 4853\n",
      "-------------------------------\n",
      "loss: 0.295156  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440423 \n",
      "\n",
      "Epoch 4854\n",
      "-------------------------------\n",
      "loss: 0.290456  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440567 \n",
      "\n",
      "Epoch 4855\n",
      "-------------------------------\n",
      "loss: 0.290862  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441454 \n",
      "\n",
      "Epoch 4856\n",
      "-------------------------------\n",
      "loss: 0.296929  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442123 \n",
      "\n",
      "Epoch 4857\n",
      "-------------------------------\n",
      "loss: 0.300070  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442447 \n",
      "\n",
      "Epoch 4858\n",
      "-------------------------------\n",
      "loss: 0.296653  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441444 \n",
      "\n",
      "Epoch 4859\n",
      "-------------------------------\n",
      "loss: 0.294398  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439524 \n",
      "\n",
      "Epoch 4860\n",
      "-------------------------------\n",
      "loss: 0.296011  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439028 \n",
      "\n",
      "Epoch 4861\n",
      "-------------------------------\n",
      "loss: 0.297351  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439305 \n",
      "\n",
      "Epoch 4862\n",
      "-------------------------------\n",
      "loss: 0.298031  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438380 \n",
      "\n",
      "Epoch 4863\n",
      "-------------------------------\n",
      "loss: 0.297259  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438306 \n",
      "\n",
      "Epoch 4864\n",
      "-------------------------------\n",
      "loss: 0.308417  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438319 \n",
      "\n",
      "Epoch 4865\n",
      "-------------------------------\n",
      "loss: 0.302924  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438748 \n",
      "\n",
      "Epoch 4866\n",
      "-------------------------------\n",
      "loss: 0.302810  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438002 \n",
      "\n",
      "Epoch 4867\n",
      "-------------------------------\n",
      "loss: 0.297428  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439260 \n",
      "\n",
      "Epoch 4868\n",
      "-------------------------------\n",
      "loss: 0.300761  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439999 \n",
      "\n",
      "Epoch 4869\n",
      "-------------------------------\n",
      "loss: 0.300502  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440843 \n",
      "\n",
      "Epoch 4870\n",
      "-------------------------------\n",
      "loss: 0.291196  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441307 \n",
      "\n",
      "Epoch 4871\n",
      "-------------------------------\n",
      "loss: 0.300022  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441518 \n",
      "\n",
      "Epoch 4872\n",
      "-------------------------------\n",
      "loss: 0.296103  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441654 \n",
      "\n",
      "Epoch 4873\n",
      "-------------------------------\n",
      "loss: 0.304697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441329 \n",
      "\n",
      "Epoch 4874\n",
      "-------------------------------\n",
      "loss: 0.300014  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440349 \n",
      "\n",
      "Epoch 4875\n",
      "-------------------------------\n",
      "loss: 0.301512  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440051 \n",
      "\n",
      "Epoch 4876\n",
      "-------------------------------\n",
      "loss: 0.303678  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439647 \n",
      "\n",
      "Epoch 4877\n",
      "-------------------------------\n",
      "loss: 0.300343  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438309 \n",
      "\n",
      "Epoch 4878\n",
      "-------------------------------\n",
      "loss: 0.293102  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438809 \n",
      "\n",
      "Epoch 4879\n",
      "-------------------------------\n",
      "loss: 0.296649  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438542 \n",
      "\n",
      "Epoch 4880\n",
      "-------------------------------\n",
      "loss: 0.292188  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439942 \n",
      "\n",
      "Epoch 4881\n",
      "-------------------------------\n",
      "loss: 0.298230  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439952 \n",
      "\n",
      "Epoch 4882\n",
      "-------------------------------\n",
      "loss: 0.297704  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440426 \n",
      "\n",
      "Epoch 4883\n",
      "-------------------------------\n",
      "loss: 0.304361  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441124 \n",
      "\n",
      "Epoch 4884\n",
      "-------------------------------\n",
      "loss: 0.292590  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441449 \n",
      "\n",
      "Epoch 4885\n",
      "-------------------------------\n",
      "loss: 0.300900  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441917 \n",
      "\n",
      "Epoch 4886\n",
      "-------------------------------\n",
      "loss: 0.301104  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441240 \n",
      "\n",
      "Epoch 4887\n",
      "-------------------------------\n",
      "loss: 0.295114  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440483 \n",
      "\n",
      "Epoch 4888\n",
      "-------------------------------\n",
      "loss: 0.294746  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440044 \n",
      "\n",
      "Epoch 4889\n",
      "-------------------------------\n",
      "loss: 0.302725  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439819 \n",
      "\n",
      "Epoch 4890\n",
      "-------------------------------\n",
      "loss: 0.289846  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440248 \n",
      "\n",
      "Epoch 4891\n",
      "-------------------------------\n",
      "loss: 0.299130  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440588 \n",
      "\n",
      "Epoch 4892\n",
      "-------------------------------\n",
      "loss: 0.301606  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440527 \n",
      "\n",
      "Epoch 4893\n",
      "-------------------------------\n",
      "loss: 0.293342  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439561 \n",
      "\n",
      "Epoch 4894\n",
      "-------------------------------\n",
      "loss: 0.291014  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439331 \n",
      "\n",
      "Epoch 4895\n",
      "-------------------------------\n",
      "loss: 0.297722  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439758 \n",
      "\n",
      "Epoch 4896\n",
      "-------------------------------\n",
      "loss: 0.296812  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440880 \n",
      "\n",
      "Epoch 4897\n",
      "-------------------------------\n",
      "loss: 0.301783  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441604 \n",
      "\n",
      "Epoch 4898\n",
      "-------------------------------\n",
      "loss: 0.304835  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441894 \n",
      "\n",
      "Epoch 4899\n",
      "-------------------------------\n",
      "loss: 0.302825  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441575 \n",
      "\n",
      "Epoch 4900\n",
      "-------------------------------\n",
      "loss: 0.303610  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441221 \n",
      "\n",
      "Epoch 4901\n",
      "-------------------------------\n",
      "loss: 0.300145  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440472 \n",
      "\n",
      "Epoch 4902\n",
      "-------------------------------\n",
      "loss: 0.288403  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440281 \n",
      "\n",
      "Epoch 4903\n",
      "-------------------------------\n",
      "loss: 0.292996  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440731 \n",
      "\n",
      "Epoch 4904\n",
      "-------------------------------\n",
      "loss: 0.290253  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441026 \n",
      "\n",
      "Epoch 4905\n",
      "-------------------------------\n",
      "loss: 0.294250  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441922 \n",
      "\n",
      "Epoch 4906\n",
      "-------------------------------\n",
      "loss: 0.295636  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441878 \n",
      "\n",
      "Epoch 4907\n",
      "-------------------------------\n",
      "loss: 0.293377  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442483 \n",
      "\n",
      "Epoch 4908\n",
      "-------------------------------\n",
      "loss: 0.297440  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442615 \n",
      "\n",
      "Epoch 4909\n",
      "-------------------------------\n",
      "loss: 0.296328  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441215 \n",
      "\n",
      "Epoch 4910\n",
      "-------------------------------\n",
      "loss: 0.296912  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441729 \n",
      "\n",
      "Epoch 4911\n",
      "-------------------------------\n",
      "loss: 0.299778  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441865 \n",
      "\n",
      "Epoch 4912\n",
      "-------------------------------\n",
      "loss: 0.294492  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441637 \n",
      "\n",
      "Epoch 4913\n",
      "-------------------------------\n",
      "loss: 0.293986  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441481 \n",
      "\n",
      "Epoch 4914\n",
      "-------------------------------\n",
      "loss: 0.297147  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441911 \n",
      "\n",
      "Epoch 4915\n",
      "-------------------------------\n",
      "loss: 0.299704  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441252 \n",
      "\n",
      "Epoch 4916\n",
      "-------------------------------\n",
      "loss: 0.292001  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441451 \n",
      "\n",
      "Epoch 4917\n",
      "-------------------------------\n",
      "loss: 0.299235  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442034 \n",
      "\n",
      "Epoch 4918\n",
      "-------------------------------\n",
      "loss: 0.295043  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441808 \n",
      "\n",
      "Epoch 4919\n",
      "-------------------------------\n",
      "loss: 0.293997  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442223 \n",
      "\n",
      "Epoch 4920\n",
      "-------------------------------\n",
      "loss: 0.299396  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443338 \n",
      "\n",
      "Epoch 4921\n",
      "-------------------------------\n",
      "loss: 0.295562  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442724 \n",
      "\n",
      "Epoch 4922\n",
      "-------------------------------\n",
      "loss: 0.299674  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442261 \n",
      "\n",
      "Epoch 4923\n",
      "-------------------------------\n",
      "loss: 0.291047  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441148 \n",
      "\n",
      "Epoch 4924\n",
      "-------------------------------\n",
      "loss: 0.297029  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441370 \n",
      "\n",
      "Epoch 4925\n",
      "-------------------------------\n",
      "loss: 0.293129  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441100 \n",
      "\n",
      "Epoch 4926\n",
      "-------------------------------\n",
      "loss: 0.291248  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441004 \n",
      "\n",
      "Epoch 4927\n",
      "-------------------------------\n",
      "loss: 0.297954  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440736 \n",
      "\n",
      "Epoch 4928\n",
      "-------------------------------\n",
      "loss: 0.299100  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441337 \n",
      "\n",
      "Epoch 4929\n",
      "-------------------------------\n",
      "loss: 0.301961  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441230 \n",
      "\n",
      "Epoch 4930\n",
      "-------------------------------\n",
      "loss: 0.293436  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441777 \n",
      "\n",
      "Epoch 4931\n",
      "-------------------------------\n",
      "loss: 0.292304  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441970 \n",
      "\n",
      "Epoch 4932\n",
      "-------------------------------\n",
      "loss: 0.293553  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442551 \n",
      "\n",
      "Epoch 4933\n",
      "-------------------------------\n",
      "loss: 0.296507  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443994 \n",
      "\n",
      "Epoch 4934\n",
      "-------------------------------\n",
      "loss: 0.298425  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445439 \n",
      "\n",
      "Epoch 4935\n",
      "-------------------------------\n",
      "loss: 0.292799  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445279 \n",
      "\n",
      "Epoch 4936\n",
      "-------------------------------\n",
      "loss: 0.300960  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445711 \n",
      "\n",
      "Epoch 4937\n",
      "-------------------------------\n",
      "loss: 0.298837  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.445038 \n",
      "\n",
      "Epoch 4938\n",
      "-------------------------------\n",
      "loss: 0.300085  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.444306 \n",
      "\n",
      "Epoch 4939\n",
      "-------------------------------\n",
      "loss: 0.295208  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442868 \n",
      "\n",
      "Epoch 4940\n",
      "-------------------------------\n",
      "loss: 0.298507  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442020 \n",
      "\n",
      "Epoch 4941\n",
      "-------------------------------\n",
      "loss: 0.301225  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441165 \n",
      "\n",
      "Epoch 4942\n",
      "-------------------------------\n",
      "loss: 0.300546  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442046 \n",
      "\n",
      "Epoch 4943\n",
      "-------------------------------\n",
      "loss: 0.294281  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440949 \n",
      "\n",
      "Epoch 4944\n",
      "-------------------------------\n",
      "loss: 0.307823  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440724 \n",
      "\n",
      "Epoch 4945\n",
      "-------------------------------\n",
      "loss: 0.292126  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440148 \n",
      "\n",
      "Epoch 4946\n",
      "-------------------------------\n",
      "loss: 0.293078  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440839 \n",
      "\n",
      "Epoch 4947\n",
      "-------------------------------\n",
      "loss: 0.299500  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441697 \n",
      "\n",
      "Epoch 4948\n",
      "-------------------------------\n",
      "loss: 0.297656  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441485 \n",
      "\n",
      "Epoch 4949\n",
      "-------------------------------\n",
      "loss: 0.302752  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441862 \n",
      "\n",
      "Epoch 4950\n",
      "-------------------------------\n",
      "loss: 0.297710  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441137 \n",
      "\n",
      "Epoch 4951\n",
      "-------------------------------\n",
      "loss: 0.301331  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441088 \n",
      "\n",
      "Epoch 4952\n",
      "-------------------------------\n",
      "loss: 0.296713  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440329 \n",
      "\n",
      "Epoch 4953\n",
      "-------------------------------\n",
      "loss: 0.297458  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440362 \n",
      "\n",
      "Epoch 4954\n",
      "-------------------------------\n",
      "loss: 0.294967  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440972 \n",
      "\n",
      "Epoch 4955\n",
      "-------------------------------\n",
      "loss: 0.297939  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441466 \n",
      "\n",
      "Epoch 4956\n",
      "-------------------------------\n",
      "loss: 0.299506  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441962 \n",
      "\n",
      "Epoch 4957\n",
      "-------------------------------\n",
      "loss: 0.291332  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441590 \n",
      "\n",
      "Epoch 4958\n",
      "-------------------------------\n",
      "loss: 0.299852  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442495 \n",
      "\n",
      "Epoch 4959\n",
      "-------------------------------\n",
      "loss: 0.295525  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442473 \n",
      "\n",
      "Epoch 4960\n",
      "-------------------------------\n",
      "loss: 0.298899  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443118 \n",
      "\n",
      "Epoch 4961\n",
      "-------------------------------\n",
      "loss: 0.295813  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442483 \n",
      "\n",
      "Epoch 4962\n",
      "-------------------------------\n",
      "loss: 0.294415  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442144 \n",
      "\n",
      "Epoch 4963\n",
      "-------------------------------\n",
      "loss: 0.290220  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441178 \n",
      "\n",
      "Epoch 4964\n",
      "-------------------------------\n",
      "loss: 0.299438  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439895 \n",
      "\n",
      "Epoch 4965\n",
      "-------------------------------\n",
      "loss: 0.291642  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439791 \n",
      "\n",
      "Epoch 4966\n",
      "-------------------------------\n",
      "loss: 0.302041  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439882 \n",
      "\n",
      "Epoch 4967\n",
      "-------------------------------\n",
      "loss: 0.296042  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439830 \n",
      "\n",
      "Epoch 4968\n",
      "-------------------------------\n",
      "loss: 0.301687  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438923 \n",
      "\n",
      "Epoch 4969\n",
      "-------------------------------\n",
      "loss: 0.293416  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438000 \n",
      "\n",
      "Epoch 4970\n",
      "-------------------------------\n",
      "loss: 0.296703  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438431 \n",
      "\n",
      "Epoch 4971\n",
      "-------------------------------\n",
      "loss: 0.299697  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438732 \n",
      "\n",
      "Epoch 4972\n",
      "-------------------------------\n",
      "loss: 0.304319  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438007 \n",
      "\n",
      "Epoch 4973\n",
      "-------------------------------\n",
      "loss: 0.302127  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438492 \n",
      "\n",
      "Epoch 4974\n",
      "-------------------------------\n",
      "loss: 0.292189  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438637 \n",
      "\n",
      "Epoch 4975\n",
      "-------------------------------\n",
      "loss: 0.296168  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438986 \n",
      "\n",
      "Epoch 4976\n",
      "-------------------------------\n",
      "loss: 0.291137  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440771 \n",
      "\n",
      "Epoch 4977\n",
      "-------------------------------\n",
      "loss: 0.296961  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440991 \n",
      "\n",
      "Epoch 4978\n",
      "-------------------------------\n",
      "loss: 0.298004  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440815 \n",
      "\n",
      "Epoch 4979\n",
      "-------------------------------\n",
      "loss: 0.300533  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441273 \n",
      "\n",
      "Epoch 4980\n",
      "-------------------------------\n",
      "loss: 0.306022  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441787 \n",
      "\n",
      "Epoch 4981\n",
      "-------------------------------\n",
      "loss: 0.291431  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441117 \n",
      "\n",
      "Epoch 4982\n",
      "-------------------------------\n",
      "loss: 0.293657  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441488 \n",
      "\n",
      "Epoch 4983\n",
      "-------------------------------\n",
      "loss: 0.296679  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441267 \n",
      "\n",
      "Epoch 4984\n",
      "-------------------------------\n",
      "loss: 0.296146  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441619 \n",
      "\n",
      "Epoch 4985\n",
      "-------------------------------\n",
      "loss: 0.291841  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441525 \n",
      "\n",
      "Epoch 4986\n",
      "-------------------------------\n",
      "loss: 0.307657  [ 1024/132096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.441377 \n",
      "\n",
      "Epoch 4987\n",
      "-------------------------------\n",
      "loss: 0.298154  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439930 \n",
      "\n",
      "Epoch 4988\n",
      "-------------------------------\n",
      "loss: 0.300406  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438831 \n",
      "\n",
      "Epoch 4989\n",
      "-------------------------------\n",
      "loss: 0.291781  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438327 \n",
      "\n",
      "Epoch 4990\n",
      "-------------------------------\n",
      "loss: 0.302681  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438555 \n",
      "\n",
      "Epoch 4991\n",
      "-------------------------------\n",
      "loss: 0.294185  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.438870 \n",
      "\n",
      "Epoch 4992\n",
      "-------------------------------\n",
      "loss: 0.299347  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.439535 \n",
      "\n",
      "Epoch 4993\n",
      "-------------------------------\n",
      "loss: 0.304115  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440000 \n",
      "\n",
      "Epoch 4994\n",
      "-------------------------------\n",
      "loss: 0.294088  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.440853 \n",
      "\n",
      "Epoch 4995\n",
      "-------------------------------\n",
      "loss: 0.287731  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.441322 \n",
      "\n",
      "Epoch 4996\n",
      "-------------------------------\n",
      "loss: 0.306183  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442521 \n",
      "\n",
      "Epoch 4997\n",
      "-------------------------------\n",
      "loss: 0.297911  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443064 \n",
      "\n",
      "Epoch 4998\n",
      "-------------------------------\n",
      "loss: 0.304350  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442793 \n",
      "\n",
      "Epoch 4999\n",
      "-------------------------------\n",
      "loss: 0.296767  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.443116 \n",
      "\n",
      "Epoch 5000\n",
      "-------------------------------\n",
      "loss: 0.292980  [ 1024/132096]\n",
      "Test Error: \n",
      " Avg loss: 0.442510 \n",
      "\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 27 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 27 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-68/metadata\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if optChoice == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "elif optChoice == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "else:\n",
    "    optimizer = None\n",
    "    print('no optimizer chosen...')\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=neptuneProject,\n",
    "    api_token=api_token,  \n",
    "    capture_hardware_metrics=True,\n",
    "    capture_stderr=True,\n",
    "    capture_stdout=True,\n",
    ")\n",
    "\n",
    "PARAMS = {\n",
    "    \"modelID\": modelID,\n",
    "    \"targetScalpElectrodes\": str(targetScalpElectrodes),\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": learningRate,\n",
    "    \"optimizer\": optChoice,\n",
    "    \"patience\": patience,\n",
    "    \"subsampleFreq\": subsampleFreq,\n",
    "    \"secondsInWindow\": secondsInWindow,\n",
    "    \"nperseg\": nperseg,\n",
    "    \"noverlap\": noverlap,\n",
    "    \"window\": stringify_unsupported(window),\n",
    "    \"loss_fn\": stringify_unsupported(loss_fn),\n",
    "    \"architectureString\": str(model),\n",
    "    \"numParameters\": sdm.count_parameters(model)\n",
    "}\n",
    "run[\"parameters\"] = PARAMS\n",
    "\n",
    "noImprovementCount = 0\n",
    "\n",
    "#epochs = 2\n",
    "\n",
    "try:\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = sdm.train(trainDataLoader, model, loss_fn, optimizer, device)\n",
    "        test_loss = sdm.test(validDataLoader, model, loss_fn, device)\n",
    "\n",
    "        if test_loss < bestTestLoss:\n",
    "            noImprovementCount = 0\n",
    "            bestTestLoss = test_loss\n",
    "            \n",
    "            model_scripted = torch.jit.script(model) \n",
    "            model_scripted.save(modelPath + 'model_%s.pt' % str(modelID))\n",
    "    \n",
    "            run[\"best_test_loss\"] =  bestTestLoss\n",
    "            run[\"best_test_epoch\"] = t\n",
    "            print(\"\\nSaved a new best model!\\n\")\n",
    "        else:\n",
    "            noImprovementCount = noImprovementCount + 1\n",
    "\n",
    "        run[\"train/loss\"].append(train_loss)\n",
    "        run[\"test/loss\"].append(test_loss)\n",
    "\n",
    "        if noImprovementCount >= patience:   \n",
    "            print(\"Early stopping invoked....\")\n",
    "            break\n",
    "\n",
    "    run.stop()\n",
    "    print(\"Done!\")\n",
    "except:\n",
    "    run.stop()\n",
    "    print(\"Training aborted...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12a577",
   "metadata": {},
   "source": [
    "# LOAD SAVED MODEL (TORCHSCRIPT) FOR INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afe26a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.437126 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelID = '59169'\n",
    "\n",
    "model = torch.jit.load(modelPath + 'model_%s.pt' % str(modelID))\n",
    "if validFlag:\n",
    "    bestTestLoss = sdm.test(validDataLoader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3474b",
   "metadata": {},
   "source": [
    "# PLOT RESULTS OF FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a858773f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT PREDICTION VERSUS TRUTH\n",
    "\n",
    "trainPlotFlag = False\n",
    "scalpElectrodeName = 'F7'\n",
    "\n",
    "scalpIndex = targetScalpElectrodes.index(scalpElectrodeName)\n",
    "if trainPlotFlag:\n",
    "    x = trainXTensor\n",
    "    trainTitle = 'train'\n",
    "else:\n",
    "    x = validXTensor\n",
    "    trainTitle = 'valididation'\n",
    "\n",
    "model.to('cpu')\n",
    "predict = model(x).cpu().detach().numpy()\n",
    "model.to(device)\n",
    "\n",
    "yPred = predict[:,scalpIndex]\n",
    "if trainPlotFlag:\n",
    "    yTrue = yTrainTimeDomain[:,scalpIndex]\n",
    "else:\n",
    "    yTrue = yValidTimeDomain[:,scalpIndex]\n",
    "\n",
    "lossTemp = loss_fn(torch.tensor(yPred), torch.tensor(yTrue)).item()\n",
    "title = 'Data: ' + trainTitle + ' (loss: %s)' % str(lossTemp)\n",
    "plt.figure()\n",
    "plt.plot(yPred, label='predict')\n",
    "plt.plot(yTrue, label='true')\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1901be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE yTRUE and yPRED for conversion to EDF\n",
    "\n",
    "arraySavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/predictionResults/numpy/results_31_Wake_ME1.npz'\n",
    "np.savez(arraySavePath, yTrue=yTrue, yPred=yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc1e38",
   "metadata": {},
   "source": [
    "# GET BEST MODEL DATA FROM NEPTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2888482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys/id</th>\n",
       "      <th>best_test_loss</th>\n",
       "      <th>parameters/modelID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRED-68</td>\n",
       "      <td>0.436742</td>\n",
       "      <td>59169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRED-67</td>\n",
       "      <td>0.508105</td>\n",
       "      <td>279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRED-66</td>\n",
       "      <td>0.389803</td>\n",
       "      <td>982815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRED-65</td>\n",
       "      <td>0.677281</td>\n",
       "      <td>228338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRED-64</td>\n",
       "      <td>0.648604</td>\n",
       "      <td>64693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRED-63</td>\n",
       "      <td>0.665345</td>\n",
       "      <td>64693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRED-62</td>\n",
       "      <td>0.676881</td>\n",
       "      <td>64693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRED-61</td>\n",
       "      <td>0.666001</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRED-60</td>\n",
       "      <td>0.674732</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRED-59</td>\n",
       "      <td>0.391365</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRED-54</td>\n",
       "      <td>0.391573</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRED-53</td>\n",
       "      <td>0.423721</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PRED-46</td>\n",
       "      <td>0.40543</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRED-43</td>\n",
       "      <td>0.390877</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRED-38</td>\n",
       "      <td>0.398955</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRED-35</td>\n",
       "      <td>0.403722</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRED-34</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRED-32</td>\n",
       "      <td>0.408214</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PRED-31</td>\n",
       "      <td>0.40969</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRED-58</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRED-57</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRED-56</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRED-55</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sys/id best_test_loss  parameters/modelID\n",
       "0   PRED-68       0.436742               59169\n",
       "1   PRED-67       0.508105              279144\n",
       "2   PRED-66       0.389803              982815\n",
       "3   PRED-65       0.677281              228338\n",
       "4   PRED-64       0.648604               64693\n",
       "5   PRED-63       0.665345               64693\n",
       "6   PRED-62       0.676881               64693\n",
       "7   PRED-61       0.666001                  -1\n",
       "8   PRED-60       0.674732                  -1\n",
       "9   PRED-59       0.391365                  -1\n",
       "14  PRED-54       0.391573                  -1\n",
       "15  PRED-53       0.423721                  -1\n",
       "16  PRED-46        0.40543                  -1\n",
       "17  PRED-43       0.390877                  -1\n",
       "18  PRED-38       0.398955                  -1\n",
       "19  PRED-35       0.403722                  -1\n",
       "20  PRED-34       0.417772                  -1\n",
       "21  PRED-32       0.408214                  -1\n",
       "22  PRED-31        0.40969                  -1\n",
       "10  PRED-58             -1                  -1\n",
       "11  PRED-57             -1                  -1\n",
       "12  PRED-56             -1                  -1\n",
       "13  PRED-55             -1                  -1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdm.neptuneBestRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671c8d3",
   "metadata": {},
   "source": [
    "# SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict.shape[1] == 1:\n",
    "    yPred = predict[:,0]\n",
    "    if trainPlotFlag:\n",
    "        yTrue = yTrainTimeDomain[:,0]\n",
    "    else:\n",
    "        yTrue = yValidTimeDomain[:,0]\n",
    "else:\n",
    "    _, yPred = realSTFTtoTimeSeries(predict)\n",
    "    if trainPlotFlag:\n",
    "        y = y_trainRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "    else:\n",
    "        y = y_validRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c14b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "fs = 1\n",
    "nperseg = 32\n",
    "noverlap = 31\n",
    "#windowType = ('tukey', .25)\n",
    "windowType = np.ones(nperseg)\n",
    "\n",
    "\n",
    "a = np.random.rand(100)\n",
    "f, t, S = stft(a, fs=fs, window=windowType, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "b = torch.stft(torch.tensor(a), \n",
    "               n_fft = nperseg, \n",
    "               hop_length = 1, \n",
    "               return_complex=True, \n",
    "               normalized=False, \n",
    "               onesided=True, \n",
    "               pad_mode='constant').numpy()\n",
    "\n",
    "np.abs(np.divide(b,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d95ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import get_window\n",
    "a = get_window(('tukey', .25), nperseg)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        return loss\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, layerOrderedDict):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(layerOrderedDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# GIVEN A LIST OF LAYER SIZES MAKE AN ORDERED DICTIONARY FOR INITIALIZING A PYTORCH NET\n",
    "\n",
    "def listToOrderedDict(sizeList):\n",
    "    n = len(sizeList)\n",
    "    tupleList = []\n",
    "    for i in range(n - 1):\n",
    "        tupleList.append(('bn%s' % str(i), nn.BatchNorm1d(sizeList[i])))\n",
    "        tupleList.append(('l%s' % str(i), nn.Linear(sizeList[i], sizeList[i+1])))\n",
    "        tupleList.append(('r%s' % str(i), nn.ReLU()))\n",
    "    return OrderedDict(tupleList[:-1])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "'''\n",
    "\n",
    "'''\n",
    "    layerSizeList = [trainXTensor.shape[1]] + hiddenLayerSizes + [trainYTensor.shape[1]]\n",
    "    layerOrderedDict = sdm.listToOrderedDict(layerSizeList)\n",
    "    model = sdm.NeuralNetwork(layerOrderedDict)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.13",
   "language": "python",
   "name": "pytorch-1.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
