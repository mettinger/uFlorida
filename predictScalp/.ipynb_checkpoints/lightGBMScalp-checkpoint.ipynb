{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d3475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 14:28:47,296\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import ray\n",
    "ray.init(include_dashboard=True, num_cpus = 8, dashboard_host='0.0.0.0')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6db8c0",
   "metadata": {},
   "source": [
    "# UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0d0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampleFreq = 64   # FINAL FREQUENCY IN HERTZ AFTER SUBSAMPLING\n",
    "secondsInWindow = 1.\n",
    "nperseg = subsampleFreq * secondsInWindow\n",
    "noverlap = nperseg - 1\n",
    "window = ('tukey', .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7e2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT STFT FROM R,THETA TO COMPLEX\n",
    "# dim(z) = (# timesteps, # freq bins x 2 (2 reals = 1 complex))\n",
    "\n",
    "def rThetaToComplex(z):\n",
    "    rows, cols = z.shape\n",
    "    shortTermFourier = np.zeros((rows, cols // 2), dtype=np.csingle)\n",
    "    for i in range(rows):\n",
    "        for k in range(cols // 2):\n",
    "            r = z[i,k]\n",
    "            theta = z[i, (k + cols // 2)]\n",
    "            shortTermFourier[i,k] =  r * np.exp(complex(0, theta))\n",
    "    return shortTermFourier.transpose() # dim = (# freq bins, # timepoints)\n",
    "\n",
    "# CONVERT REAL STFT TO COMPLEX STFT, INVERT TO GET THE ISTFT (I.E. TIME SERIES), THEN PLOT\n",
    "\n",
    "def realSTFTtoTimeSeries(realSTFT):\n",
    "    shortTermFourierComplex = rThetaToComplex(realSTFT)\n",
    "    times, inverseShortFourier = istft(shortTermFourierComplex, \n",
    "                                       fs=subsampleFreq, \n",
    "                                       window=window, \n",
    "                                       nperseg=nperseg, \n",
    "                                       noverlap=noverlap)\n",
    "    return times, inverseShortFourier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2e3a2",
   "metadata": {},
   "source": [
    "# LOAD NUMPY ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69309e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "arraySavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/trainTestRTheta.npz'\n",
    "npzfile = np.load(arraySavePath)\n",
    "x_trainRTheta = npzfile['x_trainRTheta']\n",
    "x_validRTheta = npzfile['x_validRTheta'] \n",
    "y_trainRTheta = npzfile['y_trainRTheta'] \n",
    "y_validRTheta = npzfile['y_validRTheta']\n",
    "\n",
    "_,nY = y_validRTheta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb960c9",
   "metadata": {},
   "source": [
    "# LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb49d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATIVE LIGHTGBM API VERSION\n",
    "\n",
    "modelDirectory = '/blue/gkalamangalam/jmark.ettinger/predictScalp/lgbModels/'\n",
    "\n",
    "@ray.remote\n",
    "def train_index(x_trainRTheta, y_trainRTheta, x_validRTheta, y_validRTheta, index, init_model, num_iterations):\n",
    "    metric = 'mse'\n",
    "    early_stopping_rounds = 5\n",
    "\n",
    "    param = {'metric': metric, \n",
    "             'num_iterations': num_iterations,\n",
    "             'early_stopping_rounds': early_stopping_rounds,\n",
    "             'first_metric_only': True}\n",
    "\n",
    "    lgbTrain = lgb.Dataset(x_trainRTheta, label=y_trainRTheta[:,index], free_raw_data=False)\n",
    "    lgbValid = lgbTrain.create_valid(x_validRTheta, label=y_validRTheta[:,index])\n",
    "\n",
    "    bst = lgb.train(param, \n",
    "                    lgbTrain, \n",
    "                    valid_sets=[lgbValid, lgbTrain],\n",
    "                    init_model=init_model)\n",
    "    \n",
    "    bst.save_model(modelDirectory + 'lgbModel_%s.txt' % str(index), num_iteration=bst.best_iteration)\n",
    "    return bst\n",
    "\n",
    "def lgbPredictIndex(x, index):\n",
    "    bst = lgb.Booster(model_file=modelDirectory + 'lgbModel_%s.txt' % str(index))\n",
    "    ypred = bst.predict(x, num_iteration=bst.best_iteration)\n",
    "    return ypred\n",
    "\n",
    "def lgbPredict(x):\n",
    "    return np.array([lgbPredictIndex(x, index) for index in range(nY)]).transpose()\n",
    "\n",
    "xTrainRay = ray.put(x_trainRTheta)\n",
    "yTrainRay = ray.put(y_trainRTheta) \n",
    "xValidRay = ray.put(x_validRTheta)\n",
    "yValidRay = ray.put(y_validRTheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124090a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_index pid=11088)\u001b[0m /home/jmark.ettinger/.local/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "\u001b[2m\u001b[36m(train_index pid=11088)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m /home/jmark.ettinger/.local/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\u001b[2m\u001b[36m(train_index pid=11091)\u001b[0m /home/jmark.ettinger/.local/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "\u001b[2m\u001b[36m(train_index pid=11091)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m /home/jmark.ettinger/.local/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\u001b[2m\u001b[36m(train_index pid=11092)\u001b[0m /home/jmark.ettinger/.local/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "\u001b[2m\u001b[36m(train_index pid=11092)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m /home/jmark.ettinger/.local/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\u001b[2m\u001b[36m(train_index pid=11096)\u001b[0m /home/jmark.ettinger/.local/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "\u001b[2m\u001b[36m(train_index pid=11096)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\u001b[2m\u001b[36m(train_index pid=11090)\u001b[0m /home/jmark.ettinger/.local/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "\u001b[2m\u001b[36m(train_index pid=11090)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 21.707213 seconds.\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [LightGBM] [Info] Total Bins 1420188\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [LightGBM] [Info] Number of data points in the train set: 89440, number of used features: 5742\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [123]\ttraining's l2: 0.869031\tvalid_0's l2: 1.49517\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [124]\ttraining's l2: 0.864248\tvalid_0's l2: 1.49324\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [125]\ttraining's l2: 0.859888\tvalid_0's l2: 1.49094\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [126]\ttraining's l2: 0.855595\tvalid_0's l2: 1.48887\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [127]\ttraining's l2: 0.850603\tvalid_0's l2: 1.48765\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [128]\ttraining's l2: 0.845403\tvalid_0's l2: 1.48229\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [129]\ttraining's l2: 0.840988\tvalid_0's l2: 1.47943\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [130]\ttraining's l2: 0.836338\tvalid_0's l2: 1.4766\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [131]\ttraining's l2: 0.832636\tvalid_0's l2: 1.4746\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [132]\ttraining's l2: 0.828811\tvalid_0's l2: 1.47381\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [133]\ttraining's l2: 0.825397\tvalid_0's l2: 1.47299\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [134]\ttraining's l2: 0.821973\tvalid_0's l2: 1.47069\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [135]\ttraining's l2: 0.817419\tvalid_0's l2: 1.46981\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [136]\ttraining's l2: 0.814003\tvalid_0's l2: 1.46853\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [137]\ttraining's l2: 0.809977\tvalid_0's l2: 1.46743\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [138]\ttraining's l2: 0.806475\tvalid_0's l2: 1.46571\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [139]\ttraining's l2: 0.802547\tvalid_0's l2: 1.46334\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [140]\ttraining's l2: 0.798539\tvalid_0's l2: 1.46163\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [141]\ttraining's l2: 0.794729\tvalid_0's l2: 1.45935\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [142]\ttraining's l2: 0.790452\tvalid_0's l2: 1.45689\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [143]\ttraining's l2: 0.786141\tvalid_0's l2: 1.45461\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [144]\ttraining's l2: 0.782375\tvalid_0's l2: 1.45264\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.352760 seconds.\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [LightGBM] [Info] Total Bins 1420188\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [LightGBM] [Info] Number of data points in the train set: 89440, number of used features: 5742\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [145]\ttraining's l2: 0.778863\tvalid_0's l2: 1.45142\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [146]\ttraining's l2: 0.77492\tvalid_0's l2: 1.45028\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [147]\ttraining's l2: 0.770881\tvalid_0's l2: 1.44911\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [148]\ttraining's l2: 0.766949\tvalid_0's l2: 1.44697\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [149]\ttraining's l2: 0.763441\tvalid_0's l2: 1.4465\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [150]\ttraining's l2: 0.75992\tvalid_0's l2: 1.44485\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [151]\ttraining's l2: 0.755997\tvalid_0's l2: 1.44287\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [152]\ttraining's l2: 0.752444\tvalid_0's l2: 1.44142\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [153]\ttraining's l2: 0.748555\tvalid_0's l2: 1.43922\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [154]\ttraining's l2: 0.745592\tvalid_0's l2: 1.43742\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [155]\ttraining's l2: 0.74189\tvalid_0's l2: 1.43505\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [123]\ttraining's l2: 5.00852\tvalid_0's l2: 10.3089\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [156]\ttraining's l2: 0.738555\tvalid_0's l2: 1.43376\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [124]\ttraining's l2: 4.97654\tvalid_0's l2: 10.2922\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [157]\ttraining's l2: 0.734971\tvalid_0's l2: 1.43238\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [158]\ttraining's l2: 0.73153\tvalid_0's l2: 1.43119\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [125]\ttraining's l2: 4.93747\tvalid_0's l2: 10.2728\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [159]\ttraining's l2: 0.728216\tvalid_0's l2: 1.4303\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [126]\ttraining's l2: 4.90327\tvalid_0's l2: 10.2552\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [160]\ttraining's l2: 0.722957\tvalid_0's l2: 1.42394\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [127]\ttraining's l2: 4.87136\tvalid_0's l2: 10.2358\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [161]\ttraining's l2: 0.719773\tvalid_0's l2: 1.42226\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [128]\ttraining's l2: 4.83809\tvalid_0's l2: 10.2161\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [162]\ttraining's l2: 0.716396\tvalid_0's l2: 1.42071\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [129]\ttraining's l2: 4.80651\tvalid_0's l2: 10.2019\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [163]\ttraining's l2: 0.713011\tvalid_0's l2: 1.4189\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [164]\ttraining's l2: 0.709973\tvalid_0's l2: 1.41809\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [130]\ttraining's l2: 4.7715\tvalid_0's l2: 10.1798\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [165]\ttraining's l2: 0.706945\tvalid_0's l2: 1.41724\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [131]\ttraining's l2: 4.74348\tvalid_0's l2: 10.162\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.602884 seconds.\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m [LightGBM] [Info] Total Bins 1420188\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m [LightGBM] [Info] Number of data points in the train set: 89440, number of used features: 5742\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [166]\ttraining's l2: 0.703082\tvalid_0's l2: 1.41571\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [132]\ttraining's l2: 4.71135\tvalid_0's l2: 10.1416\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [167]\ttraining's l2: 0.700044\tvalid_0's l2: 1.41438\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [168]\ttraining's l2: 0.697039\tvalid_0's l2: 1.41321\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [133]\ttraining's l2: 4.68219\tvalid_0's l2: 10.1259\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [134]\ttraining's l2: 4.65234\tvalid_0's l2: 10.1134\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [169]\ttraining's l2: 0.693597\tvalid_0's l2: 1.4112\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [170]\ttraining's l2: 0.69093\tvalid_0's l2: 1.40993\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [135]\ttraining's l2: 4.62406\tvalid_0's l2: 10.1011\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [171]\ttraining's l2: 0.688259\tvalid_0's l2: 1.40873\n",
      "\u001b[2m\u001b[36m(train_index pid=11090)\u001b[0m [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.724213 seconds.\n",
      "\u001b[2m\u001b[36m(train_index pid=11090)\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[2m\u001b[36m(train_index pid=11090)\u001b[0m [LightGBM] [Info] Total Bins 1420188\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [136]\ttraining's l2: 4.58912\tvalid_0's l2: 10.0739\n",
      "\u001b[2m\u001b[36m(train_index pid=11090)\u001b[0m [LightGBM] [Info] Number of data points in the train set: 89440, number of used features: 5742\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [172]\ttraining's l2: 0.685227\tvalid_0's l2: 1.40811\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m [172]\ttraining's l2: 0.685227\tvalid_0's l2: 1.40811\n",
      "\u001b[2m\u001b[36m(train_index pid=11089)\u001b[0m Evaluated only: l2\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [137]\ttraining's l2: 4.55589\tvalid_0's l2: 10.0556\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [138]\ttraining's l2: 4.52944\tvalid_0's l2: 10.0468\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [139]\ttraining's l2: 4.49978\tvalid_0's l2: 10.0249\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [140]\ttraining's l2: 4.46942\tvalid_0's l2: 10.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [141]\ttraining's l2: 4.44166\tvalid_0's l2: 9.98233\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [142]\ttraining's l2: 4.41486\tvalid_0's l2: 9.97302\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [143]\ttraining's l2: 4.38915\tvalid_0's l2: 9.95043\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m [123]\ttraining's l2: 0.643763\tvalid_0's l2: 1.23309\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [144]\ttraining's l2: 4.36059\tvalid_0's l2: 9.9324\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m [124]\ttraining's l2: 0.640163\tvalid_0's l2: 1.23115\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [145]\ttraining's l2: 4.33738\tvalid_0's l2: 9.91886\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m [125]\ttraining's l2: 0.636347\tvalid_0's l2: 1.22948\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [146]\ttraining's l2: 4.31172\tvalid_0's l2: 9.90747\n",
      "\u001b[2m\u001b[36m(train_index pid=11093)\u001b[0m [126]\ttraining's l2: 0.632379\tvalid_0's l2: 1.22695\n",
      "\u001b[2m\u001b[36m(train_index pid=11094)\u001b[0m [147]\ttraining's l2: 4.28275\tvalid_0's l2: 9.88912\n"
     ]
    }
   ],
   "source": [
    "# TRAIN LIGHTGBM MODEL\n",
    "\n",
    "continueFlag = True\n",
    "num_iterations = 50\n",
    "\n",
    "result_ids = []\n",
    "for index in range(nY):\n",
    "    if continueFlag:\n",
    "        init_model = modelDirectory + 'lgbModel_%s.txt' % str(index)\n",
    "    else:\n",
    "        init_model = None\n",
    "        \n",
    "    result_ids.append(train_index.remote(xTrainRay, \n",
    "                                         yTrainRay, \n",
    "                                         xValidRay, \n",
    "                                         yValidRay, \n",
    "                                         index, \n",
    "                                         init_model, \n",
    "                                         num_iterations))\n",
    "#results = ray.get(result_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49094c64",
   "metadata": {},
   "source": [
    "# Plot results of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT PREDICTION VERSUS TRUTH\n",
    "\n",
    "trainPlotFlag = False\n",
    "    \n",
    "if trainPlotFlag:\n",
    "    x = x_trainRTheta\n",
    "    y = y_trainRTheta\n",
    "    trainTitle = 'train'\n",
    "else:\n",
    "    x = x_validRTheta\n",
    "    y = y_validRTheta\n",
    "    trainTitle = 'valididation'\n",
    "    \n",
    "freqPredict = lgbPredict(x)\n",
    "title = 'LightGBM: ' + trainTitle\n",
    "\n",
    "_, yPred = realSTFTtoTimeSeries(freqPredict)\n",
    "_, yTrue = realSTFTtoTimeSeries(y)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(yPred, label='predict')\n",
    "plt.plot(yTrue, label='true')\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8176a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNEtools-0.22.0",
   "language": "python",
   "name": "mnetools-0.22.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
