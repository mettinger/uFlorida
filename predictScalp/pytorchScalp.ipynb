{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d3475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scalpDeepModels as sdm\n",
    "\n",
    "import importlib\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef38d8",
   "metadata": {},
   "source": [
    "# PARAMETERS - GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f63db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "patient = 'UFSEEG031'\n",
    "targetScalpElectrodes = ['F7', 'F8', 'F3', 'F4', 'C3', 'C4', 'P7', 'P8', 'P3', 'P4']\n",
    "mode = 'Wake'\n",
    "\n",
    "stftSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/freqRTheta_%s_%s_%s.npz' % (patient, targetScalpElectrodes, mode)\n",
    "timeDomainSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeDomain_%s_%s_%s.npz' % (patient, targetScalpElectrodes, mode)\n",
    "timeFreqSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeFreqRTheta_%s_%s_%s.npz' % (patient, targetScalpElectrodes, mode)\n",
    "\n",
    "modelPath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/'\n",
    "\n",
    "neptuneProject = 'jettinger35/predictScalp'\n",
    "api_token = os.environ.get('NEPTUNE_API_TOKEN')\n",
    "\n",
    "subsampleFreq = 128   # FINAL FREQUENCY IN HERTZ AFTER SUBSAMPLING\n",
    "secondsInWindow = 1\n",
    "nperseg = subsampleFreq * secondsInWindow\n",
    "noverlap = nperseg - 1\n",
    "window = ('tukey', .25)\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7fce9",
   "metadata": {},
   "source": [
    "# PARAMETERS - TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224077ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 1024\n",
    "learningRate = 1e-3\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "optChoice = 'adam'\n",
    "\n",
    "patience = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6db8c0",
   "metadata": {},
   "source": [
    "# UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7e2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT STFT FROM R,THETA TO COMPLEX\n",
    "# dim(z) = (# timesteps, # freq bins x 2 (2 reals = 1 complex))\n",
    "\n",
    "def rThetaToComplex(z):\n",
    "    rows, cols = z.shape\n",
    "    shortTermFourier = np.zeros((rows, cols // 2), dtype=np.csingle)\n",
    "    for i in range(rows):\n",
    "        for k in range(cols // 2):\n",
    "            r = z[i,k]\n",
    "            theta = z[i, (k + cols // 2)]\n",
    "            shortTermFourier[i,k] =  r * np.exp(complex(0, theta))\n",
    "    return shortTermFourier.transpose() # dim = (# freq bins, # timepoints)\n",
    "\n",
    "# CONVERT REAL STFT TO COMPLEX STFT, INVERT TO GET THE ISTFT (I.E. TIME SERIES), THEN PLOT\n",
    "\n",
    "def realSTFTtoTimeSeries(realSTFT):\n",
    "    shortTermFourierComplex = rThetaToComplex(realSTFT)\n",
    "    times, inverseShortFourier = istft(shortTermFourierComplex, \n",
    "                                       fs=subsampleFreq, \n",
    "                                       window=window, \n",
    "                                       nperseg=nperseg, \n",
    "                                       noverlap=noverlap)\n",
    "    return times, inverseShortFourier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbd749",
   "metadata": {},
   "source": [
    "# LOAD NUMPY DATA ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba4b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSwitch = 'time'\n",
    "\n",
    "if dataSwitch == 'freq':\n",
    "    # STFT DATA\n",
    "\n",
    "    npzfile = np.load(stftSavePath)\n",
    "    x_trainRTheta = npzfile['x_trainRTheta']\n",
    "    x_validRTheta = npzfile['x_validRTheta'] \n",
    "    y_trainRTheta = npzfile['y_trainRTheta'] \n",
    "    y_validRTheta = npzfile['y_validRTheta']\n",
    "\n",
    "    trainXTensor = torch.Tensor(x_trainRTheta)\n",
    "    trainYTensor = torch.Tensor(y_trainRTheta)\n",
    "    validXTensor = torch.Tensor(x_validRTheta)\n",
    "    validYTensor = torch.Tensor(y_validRTheta)\n",
    "\n",
    "elif dataSwitch == 'time':\n",
    "    # TIME DOMAIN DATA\n",
    "\n",
    "    npzfile = np.load(timeDomainSavePath)\n",
    "    xTrainTimeDomain = npzfile['xTrainTimeDomain']\n",
    "    xValidTimeDomain = npzfile['xValidTimeDomain'] \n",
    "    yTrainTimeDomain = npzfile['yTrainTimeDomain'] \n",
    "    yValidTimeDomain = npzfile['yValidTimeDomain']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrainTimeDomain)\n",
    "    trainYTensor = torch.Tensor(yTrainTimeDomain)\n",
    "    validXTensor = torch.Tensor(xValidTimeDomain)\n",
    "    validYTensor = torch.Tensor(yValidTimeDomain)\n",
    "    \n",
    "elif dataSwitch == 'timeFreq':\n",
    "    \n",
    "    npzfile = np.load(timeFreqSavePath)\n",
    "    xTrain = npzfile['x_trainTimeFreq']\n",
    "    xValid = npzfile['x_validTimeFreq'] \n",
    "    yTrain = npzfile['y_trainTimeFreq'] \n",
    "    yValid = npzfile['y_validTimeFreq']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrain)\n",
    "    trainYTensor = torch.Tensor(yTrain)\n",
    "    validXTensor = torch.Tensor(xValid)\n",
    "    validYTensor = torch.Tensor(yValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedd53c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 1]) torch.float32\n",
      "No validation dataset...\n"
     ]
    }
   ],
   "source": [
    "# CREATE PYTORCH DATALOADERS\n",
    "\n",
    "trainDataset = TensorDataset(trainXTensor,trainYTensor)\n",
    "trainDataLoader = DataLoader(trainDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"train: \")\n",
    "for X, y in trainDataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "try:    \n",
    "    validDataset = TensorDataset(validXTensor,validYTensor)\n",
    "    validDataLoader = DataLoader(validDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    print(\"\\ntest: \")\n",
    "    for X, y in validDataLoader:\n",
    "        print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "        break\n",
    "        \n",
    "    validFlag = True\n",
    "except:\n",
    "    validFlag = False\n",
    "    print(\"No validation dataset...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243c05c",
   "metadata": {},
   "source": [
    "# DEFINE THE MODEL FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeaad9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: 279144\n",
      "Number of parameters:  3963439\n",
      "Sequential(\n",
      "  (bn0): BatchNorm1d(5655, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l0): Linear(in_features=5655, out_features=512, bias=True)\n",
      "  (r0): ReLU()\n",
      "  (d0): Dropout(p=0.5, inplace=False)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r1): ReLU()\n",
      "  (d1): Dropout(p=0.5, inplace=False)\n",
      "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r2): ReLU()\n",
      "  (d2): Dropout(p=0.5, inplace=False)\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r3): ReLU()\n",
      "  (d3): Dropout(p=0.5, inplace=False)\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r4): ReLU()\n",
      "  (d4): Dropout(p=0.5, inplace=False)\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "importlib.reload(sdm) # reload in case we've made any architecture changes\n",
    "\n",
    "modelID = np.random.randint(0, 10**6)\n",
    "\n",
    "# DEFINE ARCHITECTURE HERE\n",
    "inputSize = trainXTensor.shape[1]\n",
    "hiddenLayerSizes = [512,512,512,512,512,512]\n",
    "\n",
    "layerDict = sdm.listToOrderedDict_1([inputSize] + hiddenLayerSizes)\n",
    "#layerDict = sdm.residualAddDict(inputSize, 512, 5)\n",
    "#layerDict = sdm.residualConcatDict(inputSize, hiddenLayerSizes)\n",
    "\n",
    "model = nn.Sequential(layerDict)\n",
    "bestTestLoss = float('inf')\n",
    "    \n",
    "print(\"Model ID: \" + str(modelID))\n",
    "print(\"Number of parameters: \", sdm.count_parameters(model))\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68e5ed",
   "metadata": {},
   "source": [
    "# TRAIN (LOG DATA TO NEPTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c6012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-67\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.823489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.667046 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.736638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.661986 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.737005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.658080 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.762069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.652616 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.751433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.644410 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.726495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.638026 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.686783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.634307 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.723344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.631846 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.711882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.628698 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.757450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.627227 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.708596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.628135 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.708474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.628789 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.675154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.626686 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.691304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.623156 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.690322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.619896 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.669430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.617482 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.661720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.614174 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.706124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.611475 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.660430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.609195 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.673802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.608218 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.679841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.609440 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.632441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.611522 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.667479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.613547 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.657354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.612670 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.628613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.607758 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.663525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.601627 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.618269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.598038 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.656251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.594671 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.626343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.589087 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.629713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.586732 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.620460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.584556 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.643671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.582426 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.607651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.579901 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.646985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.579169 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.595276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.577087 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.592133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.574523 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.621033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.571556 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.589209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.570470 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.555911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.568869 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.620635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.565014 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.594227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.561817 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.617416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.559541 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.570324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.558210 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.577624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.556851 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.572212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.555800 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.595679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.554564 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.593548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.553200 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.604044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.550822 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.581908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.550363 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.591139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.548653 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.596065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.547996 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.588735  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.546979 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.572721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.546976 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.554158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.546805 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.577191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.546880 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.571523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.546114 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.541400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.545863 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.552904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.545759 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.567939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.545314 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.553379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.546845 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.569373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.548759 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.523425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.551000 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.543955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.551895 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.565673  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.552662 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.563705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.550558 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.567732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.548418 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.561354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.543383 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.547267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.539543 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.553309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536668 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.511027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535632 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.526483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535790 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.539025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536188 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.545664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535858 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.563296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.534971 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.545493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.534962 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.560392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535632 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.547203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536495 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.551139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.538788 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.508110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.543058 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.542894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.548284 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.543833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.548026 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.555635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.546423 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.529916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.545787 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.545689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.541956 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.542330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.538267 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.549606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.534598 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.523505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533569 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.516630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532977 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.517484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532238 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.548969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531548 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.554140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530765 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.519258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530635 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.520699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530858 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.545514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531577 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.517507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532927 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.527135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535075 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.530518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536061 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.534245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535460 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.527618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533418 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.528099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531181 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.552764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529621 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.532371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528853 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.530613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528602 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.536413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528226 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.529273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528369 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.511004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528598 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.516950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527939 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.522979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526770 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.530326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526217 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.544486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526772 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.530521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529423 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.535699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532760 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.522326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536186 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.539998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.539144 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.537870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.538727 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.494232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.539410 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.529387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.538451 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.543042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535004 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.505137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530049 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.535185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527195 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.505646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525786 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.518957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525065 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.499694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525266 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.520693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526659 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.527101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530234 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.505968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532809 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.517247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531225 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.524531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528019 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.521536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524355 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.512091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523891 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.487893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524245 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.513067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523752 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.512751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522110 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.528774  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.520985 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.500605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522968 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.532088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526838 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.533931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530153 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.509920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529764 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.507664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527061 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.526592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522791 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.509924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520383 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.523566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520585 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.512722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522721 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.501328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525732 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.488954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528659 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.521492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530370 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.519310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529601 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.523377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527521 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.517587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525710 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.488880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525044 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.490593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525437 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.548397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525806 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.510770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526677 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.529256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526382 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.516234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525487 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.507537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524296 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.506753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524047 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.503461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524675 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.535085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525493 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.504385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524814 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.503231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524340 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.513473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523559 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.502205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524346 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.512888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525771 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.512981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526842 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.503908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525786 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.504560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522125 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.515809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519094 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.523709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518141 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.517826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518359 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.494236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519631 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.502633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521477 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.496965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523355 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.518159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526261 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.504700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526949 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.489431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526870 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.525481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526295 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.503170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525347 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.516408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525114 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.480188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525067 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.502501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524346 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.488077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523372 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.510304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523092 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.514007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523619 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.501545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524376 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.503911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524435 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.518670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522333 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.502439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519759 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.501661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517925 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.535280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517803 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.510450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518097 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.508016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517635 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.501111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516943 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.513609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516562 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.533185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516044 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.501996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516213 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.497058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516361 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.512533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517174 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.492546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517581 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.476255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518696 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.501178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520078 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.479577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520803 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.503945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519667 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.505800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520006 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.494564  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519953 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.492531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519257 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.518468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518214 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.477404  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.517170 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.512249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516920 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.479695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517202 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.501183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517350 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.529793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517175 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.500886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518485 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.468123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521703 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.488656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526542 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.498602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530860 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.509279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529706 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.501847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524375 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.496907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519365 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.512115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517709 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.518015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518082 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.476613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518743 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.481457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519746 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.525246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520288 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.490860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521748 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.497103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522433 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.495325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525271 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.495816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526535 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.475859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525111 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.507113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522544 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.478407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520548 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.529532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519059 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.508368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518587 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.492473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518860 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.515278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519107 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.490715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519013 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.503655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519726 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.502720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521226 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.511805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522213 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.489169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524326 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.492267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524469 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.498853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522482 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.496769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521386 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.469368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521775 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.510810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521870 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.481804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522203 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.493277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522872 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.485407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522426 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.492954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521696 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.472830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521767 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.494965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522353 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.500399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522788 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.498985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523207 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.512409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522212 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.493314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521203 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.470298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520820 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.504924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519986 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.512057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519838 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.458815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519690 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.493057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519253 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.501473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519902 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.479693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520524 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.472741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519039 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.467253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516912 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.496591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515675 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.477658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515809 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.455880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517091 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.474940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518701 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.488381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521687 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.510899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524704 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.501482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523560 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.485675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519673 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.484776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516513 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.476498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515687 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.473883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517262 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.499240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519524 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.494565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518732 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.478842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515446 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.484467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514150 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.496352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515492 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.503198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517468 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.468262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517578 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.488748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519137 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.495439  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.520488 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.478250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523015 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.471122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523241 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.504478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520721 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.488237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518117 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.509239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515892 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.496487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514516 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.474087  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513908 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.484210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513631 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.498259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514582 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.497786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517455 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.503874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520177 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.499222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520191 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.497765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519467 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.473505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517597 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.483226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515729 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.487520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513883 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.501759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512794 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.470414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512085 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.486420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512791 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.466766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512994 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.490473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513250 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.496264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513828 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.488671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515498 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.471408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517358 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.490833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519504 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.480958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517669 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.470876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514089 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.465701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511885 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.466360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511948 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.499039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511979 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.483425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511251 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.487993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.510451 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.472692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.509989 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.491084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511139 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.494383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513095 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.482446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514901 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.480734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514260 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.502878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512509 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.445096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512348 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.481151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513400 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.471183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514835 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.495484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516104 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.470542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517369 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.491914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518460 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.486507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520831 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.482055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521880 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.487059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523224 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.469133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522091 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.491948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521165 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.483671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520203 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.480340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519593 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.487834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519046 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.494594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518048 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.471955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517334 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.499999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516938 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.486851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515141 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.466006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513281 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.472372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511245 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.451181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.510829 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.469493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511915 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.473173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513107 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.485209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515515 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.494453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517418 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.481307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516781 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.501421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517254 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.483408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521475 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.486724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525126 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.508190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525464 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.469688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523204 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.506326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518913 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.459764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513843 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.498522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.510922 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.466170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.508811 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.472561  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.508105 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.464010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.508669 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.468113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511107 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.490507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.509578 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.490627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.510537 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.451058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514661 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.481576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516111 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.458772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515196 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.470923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514011 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.496697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513144 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.478449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516821 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.472640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524200 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.478585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530720 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.493670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532411 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.462843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529874 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.481331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525793 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.459499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520622 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.476966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516989 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.484561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515967 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.478486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516847 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.483728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517674 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.492805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515074 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.477132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511642 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.484138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513062 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.468579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518637 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.475254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523182 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.473246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521974 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.467407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518916 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.491482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514088 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.466174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512115 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.505668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512318 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.470539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512579 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.464292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512887 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.468489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513544 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.497463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514335 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.479973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513683 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.501057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513816 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.474349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514143 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.477726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515887 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.455983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516796 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.462020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516230 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.480180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514971 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.478752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515366 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.474517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516545 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.441734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516814 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.476892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516003 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.477943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515745 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.494135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514993 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.471209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514873 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.456670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515410 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.485333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515559 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.464005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516797 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.443463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515079 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.463642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513454 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.473169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513798 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.463581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515638 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.474320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517598 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.468780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519599 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.427727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522274 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.448655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523126 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.453628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520536 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.482588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515640 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.479173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513636 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.465508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514544 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.453152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515893 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.461030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514986 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.491042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512915 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.456562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511301 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.478513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.510858 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.486132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512566 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.445416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514113 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.438703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517213 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.462232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519267 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.457552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521490 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.441191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522787 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.458514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523582 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.491823  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521290 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.436436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519232 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.465092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517108 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.446240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514890 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.454667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513550 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.484221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512494 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.449880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512589 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.462145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512302 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.476760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511980 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.484468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512654 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.462405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517218 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.472850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523275 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.430895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527266 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.471622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524157 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.512948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518989 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.447068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516316 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.469558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515807 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.466085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515364 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.461146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514883 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.468631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513701 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.472148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514660 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.444668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517132 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.468878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520719 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.473465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524232 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.446557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526647 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.486426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526077 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.440909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523035 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.468233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520096 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.451213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518250 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.465471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517666 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.461351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519146 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.455220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519415 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.446485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519216 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.435818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519957 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.462634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519951 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.443558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517087 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.457366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514939 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.469955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513539 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.479053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513785 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.443562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513871 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.453517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514092 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.475904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514374 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.459145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514565 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.461685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515800 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.464283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516431 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.458248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519069 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.466614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522788 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.466037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524447 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.484731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523168 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.450778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519614 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.471369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517324 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.455657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517465 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.470256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519114 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.443903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520062 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.475380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519549 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.471066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517410 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.448078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516335 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.481172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515583 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.451785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515422 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.459485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515852 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.469552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516998 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.457922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516939 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.456504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516240 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.449566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516623 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.463747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519448 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.434366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522140 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.490844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520908 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.468987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520156 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.448978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518188 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.447113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516563 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.451232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516951 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.463556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517459 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.448848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518349 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.453426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518304 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.459434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515692 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.446357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515721 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.469829  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.516447 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.444536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517964 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.444763  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517016 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.466753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516417 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.464811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515212 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.463743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514576 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.453064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516359 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.464055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519232 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.460347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523284 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.456567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527407 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.439078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530159 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.427287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525441 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.461903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519236 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.458459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519223 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.440492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521343 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.447372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520478 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.463619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518627 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.461476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517486 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.456314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516821 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.444637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516676 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.450920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518859 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.448731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521608 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.471997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523581 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.469773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523690 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.473926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521673 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.469840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519803 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.452045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518593 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.432805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518566 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.454650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518937 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.447564  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518772 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.432561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517091 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.449563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516379 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.449847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516810 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.438784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517556 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.487403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517745 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.435178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518973 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.473090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521119 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.451049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522119 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.454213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520121 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.432537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518174 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.465680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517929 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.469115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517479 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.451404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516513 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.453102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516986 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.457509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519359 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.449073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522091 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.455239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523554 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.456350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522679 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.457033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521854 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.485127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520928 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.467412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523230 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.458560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526059 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.462565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525115 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.466816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521304 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.474463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516861 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.452792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514460 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.436798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515733 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.457773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518173 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.455002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519654 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.424069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520957 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.469910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521515 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.440286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520846 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.467882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517606 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.424262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515382 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.454821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514489 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.460627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513997 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.470443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513723 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.424156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515665 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.471790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517397 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.456501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516837 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.447234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516346 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.462975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516871 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.462416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517953 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.448668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518679 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.467511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521062 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.463040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523464 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.437451  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521751 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.447803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518008 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.460398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516644 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.476207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516528 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.429581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517130 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.454515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516950 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.447265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517091 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.428494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517999 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.475320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519586 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.446710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522181 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.445798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523140 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.451933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523261 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.432350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522132 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.441726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521161 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.453222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520802 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.442942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519579 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.427803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519842 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.442041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520271 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.445611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521528 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.454426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523608 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.441640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524195 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.445000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518770 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.432106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516498 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.443235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514980 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.447184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514027 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.446516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514854 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.430615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516575 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.446011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516564 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.466628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516404 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.451833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516350 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.426987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516777 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.459058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518129 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.392312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521542 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.475314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525633 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.425571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527545 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.441245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525447 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.415244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523108 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.434354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520298 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.433755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518089 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.452915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517540 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.459646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518461 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.472996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519833 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.440610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519095 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.442538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517848 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.447964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518575 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.420963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519501 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.457207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520509 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.425459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519626 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.475353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517165 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.436103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515446 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.445949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515329 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.437757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514771 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.442943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515087 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.434877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516581 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.429139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518954 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.438540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521460 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.453631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522445 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.449836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521369 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.455957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521187 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.442318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521831 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.437360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520801 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.432751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519085 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.434010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516641 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.423753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515410 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.428364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515782 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.427974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516208 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.453189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516909 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.445685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518090 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.446223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520270 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.453365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521865 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.436292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522771 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.472052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521826 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.446318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520962 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.440122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520221 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.430982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519397 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.434882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518634 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.413906  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.518811 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.420997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521463 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.461426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524047 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.461743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526808 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.449972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525655 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.425820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523418 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.432086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522012 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.452404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522177 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.435628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523385 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.426136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523973 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.440947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521952 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.429059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521072 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.457447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520707 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.416670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523197 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.450206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527370 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.455517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528620 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.444014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524955 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.456234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519469 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.413722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515921 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.458509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515919 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.428273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517291 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.422383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517791 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.472114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518328 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.415908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519484 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.443094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522425 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.426338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524743 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.428228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522067 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.434637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519331 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.437962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518927 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.454380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520344 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.430213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521941 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.428415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522302 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.453764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520505 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.411247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518717 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.447696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518375 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.427034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519754 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.440316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521777 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.430955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522218 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.453959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521048 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.417279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520110 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.414058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519457 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.419063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519225 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.456932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519413 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.442426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519758 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.445337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520059 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.438971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520647 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.430708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521874 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.425072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522517 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.436961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523704 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.430771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524271 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.424269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523557 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.437118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521286 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.446737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520628 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.431872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520767 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.431636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520953 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.428594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520509 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.438677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519479 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.430662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519747 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.439416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521653 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.460011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522572 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.438657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522870 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.438952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523125 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.439641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524786 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.433261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528224 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.447969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531784 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.474921  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532800 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.457427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530883 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.422246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528980 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.433971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528389 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.444895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526868 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.413881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527310 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.422308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525913 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.439850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522406 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.437190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519369 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.437521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518228 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.434663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517355 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.445039  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.516293 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.414714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515808 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.420466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515282 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.423653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515191 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.407924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515717 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.435300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516794 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.431793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516886 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.445458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517172 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.418018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517465 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.411366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518787 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.411691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520141 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.433601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521643 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.418646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521399 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.426594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521223 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.433498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520827 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.428176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520135 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.425106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519650 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.438657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519880 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.462978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520127 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.398190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520162 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.451270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519297 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.423016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518784 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.410476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518178 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.441195  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519007 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.418541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520456 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.417274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521392 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.447005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523073 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.450118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522267 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.450685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520669 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.432990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519943 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.404288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520289 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.438903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521569 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.430946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521916 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.418348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521621 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.430436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522529 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.428293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524689 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.416936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526775 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.428787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528710 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.430304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527839 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.430530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525035 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.414576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521540 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.414718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520119 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.415950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522103 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.412658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525606 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.424383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527650 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.423074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525902 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.430218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522776 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.423482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522660 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.423242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525439 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.422811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525899 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.442354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527036 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.425738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525933 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.423326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523586 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.416552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522036 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.408153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520398 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.420749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519694 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.446336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518288 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.416740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517756 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.404940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516886 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.423370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517816 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.431328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517507 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.403173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517217 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.414098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516435 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.436840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516860 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.442716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518334 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.424190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520057 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.413670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521070 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.411735  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522248 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.426198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522656 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.438856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523538 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.422881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524352 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.416981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526183 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.409041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525859 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.409351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523932 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.412398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524631 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.422776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525881 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.414490  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.525770 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.400253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524362 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.393101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522897 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.409543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522032 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.422362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523412 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.410007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523734 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.434929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522552 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.402822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522940 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.403262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526367 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.425686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532934 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.417764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536801 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.413121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.538647 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.470928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536694 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.427119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531528 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.423613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527504 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.413002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525285 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.414379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525026 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.399762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525433 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.401594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525156 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.438689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523664 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.419826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523528 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.417715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524118 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.406229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525912 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.406410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527904 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.402645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528509 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.417711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527805 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.428080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525812 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.437762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523247 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.432925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520547 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.414157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518665 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.441598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518935 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.405139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521748 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.433999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525911 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.408950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527969 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.436814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527256 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.424082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524403 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.429399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524217 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.419045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526404 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.421954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526304 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.394635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525007 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.442616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523575 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.417283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523906 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.419655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526060 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.414014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527329 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.407093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526408 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.407974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525198 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.416116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523843 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.401146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524781 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.411068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526784 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.391339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527132 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.422121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525601 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.413520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526134 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.406755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528297 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.417773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529090 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.425976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527401 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.431397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524048 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.392589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521398 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.415077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521142 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.427055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522731 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.425099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523537 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.417488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522975 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.396648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522447 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.426138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522996 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.423015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522821 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.428249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522645 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.423061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522871 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.396944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521090 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.423660  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519742 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.406105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519616 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.420346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520568 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.412611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521062 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.398078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521268 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.381059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521935 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.416789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522377 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.425640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522462 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.401292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521970 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.417463  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.520495 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.406017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519404 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.407513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519112 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.411636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519190 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.417392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519520 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.420863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520238 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.431660  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521751 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.407062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524749 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.411711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526725 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.405494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526764 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.413012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525305 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.405571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524576 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.406052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523007 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.432564  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522232 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.401653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522266 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.430611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522715 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.396743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523679 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.426665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522977 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.416401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521676 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.411618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520082 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.416682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520367 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.434701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523581 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.396007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526140 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.385850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527963 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.407912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527383 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.426347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526292 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.435878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526831 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.403856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526759 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.393588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526841 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.418994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524750 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.384889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523794 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.421392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523356 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.406425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523244 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.398043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524213 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.398824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527114 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.415680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530045 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.400916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530358 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.386255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529893 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.391888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529068 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.392166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526745 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.393830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524031 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.427555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523051 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.395931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523235 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.403456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524271 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.406756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524677 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.398125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524405 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.424079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524999 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.422428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523991 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.410893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524117 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.405468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525565 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.395862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528384 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.422398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530882 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.412473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529684 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.422759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527857 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.398748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526133 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.407725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524712 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.391574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524258 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.400370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525218 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.404140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525405 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.403668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524773 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.416993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523858 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.384119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525385 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.399457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528288 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.395587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531353 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.423652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532720 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.422058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530661 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.411041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526709 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.426898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522953 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.420842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521711 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.433037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521315 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.450494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520786 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.411486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520276 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.402924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520688 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.390016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523072 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.377878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525600 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.418828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526241 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.405946  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.524891 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.419302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522184 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.418748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519235 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.408508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518902 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.398847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520681 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.396401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522499 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.423434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524759 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.427760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524589 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.383566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526513 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.412140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528714 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.416524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530536 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.416571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529691 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.379703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525452 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.419829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523343 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.429073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522378 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.403504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522332 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.399856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523981 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.425510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525167 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.432183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526397 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.401094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525463 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.402601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525465 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.416155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525002 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.402150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525738 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.390644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526647 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.399529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527620 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.426161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527582 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.411860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525836 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.390244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524755 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.383959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524537 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.403026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526098 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.411586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529650 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.402604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530532 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.385883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529898 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.394460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527524 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.400979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524668 \n",
      "\n",
      "Epoch 1001\n",
      "-------------------------------\n",
      "loss: 0.404588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522813 \n",
      "\n",
      "Epoch 1002\n",
      "-------------------------------\n",
      "loss: 0.404842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521275 \n",
      "\n",
      "Epoch 1003\n",
      "-------------------------------\n",
      "loss: 0.402707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520544 \n",
      "\n",
      "Epoch 1004\n",
      "-------------------------------\n",
      "loss: 0.420991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521939 \n",
      "\n",
      "Epoch 1005\n",
      "-------------------------------\n",
      "loss: 0.392767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524464 \n",
      "\n",
      "Epoch 1006\n",
      "-------------------------------\n",
      "loss: 0.405255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523455 \n",
      "\n",
      "Epoch 1007\n",
      "-------------------------------\n",
      "loss: 0.406570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522431 \n",
      "\n",
      "Epoch 1008\n",
      "-------------------------------\n",
      "loss: 0.405514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522023 \n",
      "\n",
      "Epoch 1009\n",
      "-------------------------------\n",
      "loss: 0.396504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522056 \n",
      "\n",
      "Epoch 1010\n",
      "-------------------------------\n",
      "loss: 0.388742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521353 \n",
      "\n",
      "Epoch 1011\n",
      "-------------------------------\n",
      "loss: 0.408162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519814 \n",
      "\n",
      "Epoch 1012\n",
      "-------------------------------\n",
      "loss: 0.414750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518527 \n",
      "\n",
      "Epoch 1013\n",
      "-------------------------------\n",
      "loss: 0.397268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518578 \n",
      "\n",
      "Epoch 1014\n",
      "-------------------------------\n",
      "loss: 0.398923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518296 \n",
      "\n",
      "Epoch 1015\n",
      "-------------------------------\n",
      "loss: 0.402455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518012 \n",
      "\n",
      "Epoch 1016\n",
      "-------------------------------\n",
      "loss: 0.399492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518415 \n",
      "\n",
      "Epoch 1017\n",
      "-------------------------------\n",
      "loss: 0.399025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518391 \n",
      "\n",
      "Epoch 1018\n",
      "-------------------------------\n",
      "loss: 0.414274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517593 \n",
      "\n",
      "Epoch 1019\n",
      "-------------------------------\n",
      "loss: 0.388787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517360 \n",
      "\n",
      "Epoch 1020\n",
      "-------------------------------\n",
      "loss: 0.395825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517503 \n",
      "\n",
      "Epoch 1021\n",
      "-------------------------------\n",
      "loss: 0.382491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517917 \n",
      "\n",
      "Epoch 1022\n",
      "-------------------------------\n",
      "loss: 0.404766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519166 \n",
      "\n",
      "Epoch 1023\n",
      "-------------------------------\n",
      "loss: 0.405463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519531 \n",
      "\n",
      "Epoch 1024\n",
      "-------------------------------\n",
      "loss: 0.397396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521302 \n",
      "\n",
      "Epoch 1025\n",
      "-------------------------------\n",
      "loss: 0.408970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524173 \n",
      "\n",
      "Epoch 1026\n",
      "-------------------------------\n",
      "loss: 0.386346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526557 \n",
      "\n",
      "Epoch 1027\n",
      "-------------------------------\n",
      "loss: 0.383864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526403 \n",
      "\n",
      "Epoch 1028\n",
      "-------------------------------\n",
      "loss: 0.410288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523203 \n",
      "\n",
      "Epoch 1029\n",
      "-------------------------------\n",
      "loss: 0.406082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522101 \n",
      "\n",
      "Epoch 1030\n",
      "-------------------------------\n",
      "loss: 0.376778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522061 \n",
      "\n",
      "Epoch 1031\n",
      "-------------------------------\n",
      "loss: 0.402264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522491 \n",
      "\n",
      "Epoch 1032\n",
      "-------------------------------\n",
      "loss: 0.410800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522629 \n",
      "\n",
      "Epoch 1033\n",
      "-------------------------------\n",
      "loss: 0.408742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522354 \n",
      "\n",
      "Epoch 1034\n",
      "-------------------------------\n",
      "loss: 0.408033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521767 \n",
      "\n",
      "Epoch 1035\n",
      "-------------------------------\n",
      "loss: 0.416791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521404 \n",
      "\n",
      "Epoch 1036\n",
      "-------------------------------\n",
      "loss: 0.389453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522527 \n",
      "\n",
      "Epoch 1037\n",
      "-------------------------------\n",
      "loss: 0.398589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523131 \n",
      "\n",
      "Epoch 1038\n",
      "-------------------------------\n",
      "loss: 0.405559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521803 \n",
      "\n",
      "Epoch 1039\n",
      "-------------------------------\n",
      "loss: 0.394923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520211 \n",
      "\n",
      "Epoch 1040\n",
      "-------------------------------\n",
      "loss: 0.385231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520661 \n",
      "\n",
      "Epoch 1041\n",
      "-------------------------------\n",
      "loss: 0.402936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519875 \n",
      "\n",
      "Epoch 1042\n",
      "-------------------------------\n",
      "loss: 0.397408  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.519674 \n",
      "\n",
      "Epoch 1043\n",
      "-------------------------------\n",
      "loss: 0.397592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520501 \n",
      "\n",
      "Epoch 1044\n",
      "-------------------------------\n",
      "loss: 0.383561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521622 \n",
      "\n",
      "Epoch 1045\n",
      "-------------------------------\n",
      "loss: 0.406372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523289 \n",
      "\n",
      "Epoch 1046\n",
      "-------------------------------\n",
      "loss: 0.395375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524758 \n",
      "\n",
      "Epoch 1047\n",
      "-------------------------------\n",
      "loss: 0.405695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524778 \n",
      "\n",
      "Epoch 1048\n",
      "-------------------------------\n",
      "loss: 0.387779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524177 \n",
      "\n",
      "Epoch 1049\n",
      "-------------------------------\n",
      "loss: 0.413680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522964 \n",
      "\n",
      "Epoch 1050\n",
      "-------------------------------\n",
      "loss: 0.410606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522805 \n",
      "\n",
      "Epoch 1051\n",
      "-------------------------------\n",
      "loss: 0.384365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524063 \n",
      "\n",
      "Epoch 1052\n",
      "-------------------------------\n",
      "loss: 0.391745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525532 \n",
      "\n",
      "Epoch 1053\n",
      "-------------------------------\n",
      "loss: 0.382268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524599 \n",
      "\n",
      "Epoch 1054\n",
      "-------------------------------\n",
      "loss: 0.385764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523781 \n",
      "\n",
      "Epoch 1055\n",
      "-------------------------------\n",
      "loss: 0.402056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523327 \n",
      "\n",
      "Epoch 1056\n",
      "-------------------------------\n",
      "loss: 0.382448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523664 \n",
      "\n",
      "Epoch 1057\n",
      "-------------------------------\n",
      "loss: 0.377259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524767 \n",
      "\n",
      "Epoch 1058\n",
      "-------------------------------\n",
      "loss: 0.394932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525300 \n",
      "\n",
      "Epoch 1059\n",
      "-------------------------------\n",
      "loss: 0.387590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524068 \n",
      "\n",
      "Epoch 1060\n",
      "-------------------------------\n",
      "loss: 0.392629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522903 \n",
      "\n",
      "Epoch 1061\n",
      "-------------------------------\n",
      "loss: 0.376849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521331 \n",
      "\n",
      "Epoch 1062\n",
      "-------------------------------\n",
      "loss: 0.382992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521421 \n",
      "\n",
      "Epoch 1063\n",
      "-------------------------------\n",
      "loss: 0.409606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522866 \n",
      "\n",
      "Epoch 1064\n",
      "-------------------------------\n",
      "loss: 0.382211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523282 \n",
      "\n",
      "Epoch 1065\n",
      "-------------------------------\n",
      "loss: 0.399265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523145 \n",
      "\n",
      "Epoch 1066\n",
      "-------------------------------\n",
      "loss: 0.390657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522099 \n",
      "\n",
      "Epoch 1067\n",
      "-------------------------------\n",
      "loss: 0.359250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521005 \n",
      "\n",
      "Epoch 1068\n",
      "-------------------------------\n",
      "loss: 0.368493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520505 \n",
      "\n",
      "Epoch 1069\n",
      "-------------------------------\n",
      "loss: 0.417164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521268 \n",
      "\n",
      "Epoch 1070\n",
      "-------------------------------\n",
      "loss: 0.396118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522189 \n",
      "\n",
      "Epoch 1071\n",
      "-------------------------------\n",
      "loss: 0.378161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523990 \n",
      "\n",
      "Epoch 1072\n",
      "-------------------------------\n",
      "loss: 0.388290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525938 \n",
      "\n",
      "Epoch 1073\n",
      "-------------------------------\n",
      "loss: 0.399689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529151 \n",
      "\n",
      "Epoch 1074\n",
      "-------------------------------\n",
      "loss: 0.403054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532105 \n",
      "\n",
      "Epoch 1075\n",
      "-------------------------------\n",
      "loss: 0.406983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531270 \n",
      "\n",
      "Epoch 1076\n",
      "-------------------------------\n",
      "loss: 0.406257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527068 \n",
      "\n",
      "Epoch 1077\n",
      "-------------------------------\n",
      "loss: 0.368248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522828 \n",
      "\n",
      "Epoch 1078\n",
      "-------------------------------\n",
      "loss: 0.387551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520325 \n",
      "\n",
      "Epoch 1079\n",
      "-------------------------------\n",
      "loss: 0.394622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518904 \n",
      "\n",
      "Epoch 1080\n",
      "-------------------------------\n",
      "loss: 0.412085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517718 \n",
      "\n",
      "Epoch 1081\n",
      "-------------------------------\n",
      "loss: 0.389330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516956 \n",
      "\n",
      "Epoch 1082\n",
      "-------------------------------\n",
      "loss: 0.384030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516474 \n",
      "\n",
      "Epoch 1083\n",
      "-------------------------------\n",
      "loss: 0.399635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517658 \n",
      "\n",
      "Epoch 1084\n",
      "-------------------------------\n",
      "loss: 0.405218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518971 \n",
      "\n",
      "Epoch 1085\n",
      "-------------------------------\n",
      "loss: 0.416012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521032 \n",
      "\n",
      "Epoch 1086\n",
      "-------------------------------\n",
      "loss: 0.396706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522593 \n",
      "\n",
      "Epoch 1087\n",
      "-------------------------------\n",
      "loss: 0.402719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523552 \n",
      "\n",
      "Epoch 1088\n",
      "-------------------------------\n",
      "loss: 0.382840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522588 \n",
      "\n",
      "Epoch 1089\n",
      "-------------------------------\n",
      "loss: 0.403402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520156 \n",
      "\n",
      "Epoch 1090\n",
      "-------------------------------\n",
      "loss: 0.403874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518432 \n",
      "\n",
      "Epoch 1091\n",
      "-------------------------------\n",
      "loss: 0.409458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518875 \n",
      "\n",
      "Epoch 1092\n",
      "-------------------------------\n",
      "loss: 0.397164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520790 \n",
      "\n",
      "Epoch 1093\n",
      "-------------------------------\n",
      "loss: 0.396751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522021 \n",
      "\n",
      "Epoch 1094\n",
      "-------------------------------\n",
      "loss: 0.411371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522612 \n",
      "\n",
      "Epoch 1095\n",
      "-------------------------------\n",
      "loss: 0.379179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524326 \n",
      "\n",
      "Epoch 1096\n",
      "-------------------------------\n",
      "loss: 0.386996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527572 \n",
      "\n",
      "Epoch 1097\n",
      "-------------------------------\n",
      "loss: 0.369769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531786 \n",
      "\n",
      "Epoch 1098\n",
      "-------------------------------\n",
      "loss: 0.402782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533175 \n",
      "\n",
      "Epoch 1099\n",
      "-------------------------------\n",
      "loss: 0.401437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533316 \n",
      "\n",
      "Epoch 1100\n",
      "-------------------------------\n",
      "loss: 0.401186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530746 \n",
      "\n",
      "Epoch 1101\n",
      "-------------------------------\n",
      "loss: 0.406061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527697 \n",
      "\n",
      "Epoch 1102\n",
      "-------------------------------\n",
      "loss: 0.383480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524938 \n",
      "\n",
      "Epoch 1103\n",
      "-------------------------------\n",
      "loss: 0.373341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522523 \n",
      "\n",
      "Epoch 1104\n",
      "-------------------------------\n",
      "loss: 0.387328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522045 \n",
      "\n",
      "Epoch 1105\n",
      "-------------------------------\n",
      "loss: 0.383757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521317 \n",
      "\n",
      "Epoch 1106\n",
      "-------------------------------\n",
      "loss: 0.395698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520603 \n",
      "\n",
      "Epoch 1107\n",
      "-------------------------------\n",
      "loss: 0.391872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522406 \n",
      "\n",
      "Epoch 1108\n",
      "-------------------------------\n",
      "loss: 0.396040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527449 \n",
      "\n",
      "Epoch 1109\n",
      "-------------------------------\n",
      "loss: 0.371406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530591 \n",
      "\n",
      "Epoch 1110\n",
      "-------------------------------\n",
      "loss: 0.386954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527988 \n",
      "\n",
      "Epoch 1111\n",
      "-------------------------------\n",
      "loss: 0.370602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524004 \n",
      "\n",
      "Epoch 1112\n",
      "-------------------------------\n",
      "loss: 0.398357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521665 \n",
      "\n",
      "Epoch 1113\n",
      "-------------------------------\n",
      "loss: 0.395184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519665 \n",
      "\n",
      "Epoch 1114\n",
      "-------------------------------\n",
      "loss: 0.401371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519104 \n",
      "\n",
      "Epoch 1115\n",
      "-------------------------------\n",
      "loss: 0.390961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518918 \n",
      "\n",
      "Epoch 1116\n",
      "-------------------------------\n",
      "loss: 0.376310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521069 \n",
      "\n",
      "Epoch 1117\n",
      "-------------------------------\n",
      "loss: 0.403675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524677 \n",
      "\n",
      "Epoch 1118\n",
      "-------------------------------\n",
      "loss: 0.408408  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.524710 \n",
      "\n",
      "Epoch 1119\n",
      "-------------------------------\n",
      "loss: 0.388933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523128 \n",
      "\n",
      "Epoch 1120\n",
      "-------------------------------\n",
      "loss: 0.407798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521280 \n",
      "\n",
      "Epoch 1121\n",
      "-------------------------------\n",
      "loss: 0.390048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521364 \n",
      "\n",
      "Epoch 1122\n",
      "-------------------------------\n",
      "loss: 0.379679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522485 \n",
      "\n",
      "Epoch 1123\n",
      "-------------------------------\n",
      "loss: 0.421186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524305 \n",
      "\n",
      "Epoch 1124\n",
      "-------------------------------\n",
      "loss: 0.382865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526324 \n",
      "\n",
      "Epoch 1125\n",
      "-------------------------------\n",
      "loss: 0.386005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526855 \n",
      "\n",
      "Epoch 1126\n",
      "-------------------------------\n",
      "loss: 0.381999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526891 \n",
      "\n",
      "Epoch 1127\n",
      "-------------------------------\n",
      "loss: 0.363706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526458 \n",
      "\n",
      "Epoch 1128\n",
      "-------------------------------\n",
      "loss: 0.383734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524604 \n",
      "\n",
      "Epoch 1129\n",
      "-------------------------------\n",
      "loss: 0.380039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522623 \n",
      "\n",
      "Epoch 1130\n",
      "-------------------------------\n",
      "loss: 0.382244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522643 \n",
      "\n",
      "Epoch 1131\n",
      "-------------------------------\n",
      "loss: 0.376148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521704 \n",
      "\n",
      "Epoch 1132\n",
      "-------------------------------\n",
      "loss: 0.392789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521372 \n",
      "\n",
      "Epoch 1133\n",
      "-------------------------------\n",
      "loss: 0.396448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521953 \n",
      "\n",
      "Epoch 1134\n",
      "-------------------------------\n",
      "loss: 0.378127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524635 \n",
      "\n",
      "Epoch 1135\n",
      "-------------------------------\n",
      "loss: 0.379322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527389 \n",
      "\n",
      "Epoch 1136\n",
      "-------------------------------\n",
      "loss: 0.385139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527506 \n",
      "\n",
      "Epoch 1137\n",
      "-------------------------------\n",
      "loss: 0.355532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526187 \n",
      "\n",
      "Epoch 1138\n",
      "-------------------------------\n",
      "loss: 0.372397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525073 \n",
      "\n",
      "Epoch 1139\n",
      "-------------------------------\n",
      "loss: 0.379344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524833 \n",
      "\n",
      "Epoch 1140\n",
      "-------------------------------\n",
      "loss: 0.373412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524871 \n",
      "\n",
      "Epoch 1141\n",
      "-------------------------------\n",
      "loss: 0.380301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524466 \n",
      "\n",
      "Epoch 1142\n",
      "-------------------------------\n",
      "loss: 0.397740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523373 \n",
      "\n",
      "Epoch 1143\n",
      "-------------------------------\n",
      "loss: 0.395336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523461 \n",
      "\n",
      "Epoch 1144\n",
      "-------------------------------\n",
      "loss: 0.381062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525407 \n",
      "\n",
      "Epoch 1145\n",
      "-------------------------------\n",
      "loss: 0.386725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525609 \n",
      "\n",
      "Epoch 1146\n",
      "-------------------------------\n",
      "loss: 0.397949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525510 \n",
      "\n",
      "Epoch 1147\n",
      "-------------------------------\n",
      "loss: 0.389081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525893 \n",
      "\n",
      "Epoch 1148\n",
      "-------------------------------\n",
      "loss: 0.381380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527975 \n",
      "\n",
      "Epoch 1149\n",
      "-------------------------------\n",
      "loss: 0.390304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528264 \n",
      "\n",
      "Epoch 1150\n",
      "-------------------------------\n",
      "loss: 0.376882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526553 \n",
      "\n",
      "Epoch 1151\n",
      "-------------------------------\n",
      "loss: 0.369668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524720 \n",
      "\n",
      "Epoch 1152\n",
      "-------------------------------\n",
      "loss: 0.383617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523151 \n",
      "\n",
      "Epoch 1153\n",
      "-------------------------------\n",
      "loss: 0.409237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522983 \n",
      "\n",
      "Epoch 1154\n",
      "-------------------------------\n",
      "loss: 0.369994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522536 \n",
      "\n",
      "Epoch 1155\n",
      "-------------------------------\n",
      "loss: 0.380171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521769 \n",
      "\n",
      "Epoch 1156\n",
      "-------------------------------\n",
      "loss: 0.415614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521081 \n",
      "\n",
      "Epoch 1157\n",
      "-------------------------------\n",
      "loss: 0.399257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522134 \n",
      "\n",
      "Epoch 1158\n",
      "-------------------------------\n",
      "loss: 0.381870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523275 \n",
      "\n",
      "Epoch 1159\n",
      "-------------------------------\n",
      "loss: 0.377328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523438 \n",
      "\n",
      "Epoch 1160\n",
      "-------------------------------\n",
      "loss: 0.378923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523596 \n",
      "\n",
      "Epoch 1161\n",
      "-------------------------------\n",
      "loss: 0.379602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522969 \n",
      "\n",
      "Epoch 1162\n",
      "-------------------------------\n",
      "loss: 0.387398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523273 \n",
      "\n",
      "Epoch 1163\n",
      "-------------------------------\n",
      "loss: 0.350687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524089 \n",
      "\n",
      "Epoch 1164\n",
      "-------------------------------\n",
      "loss: 0.383161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526263 \n",
      "\n",
      "Epoch 1165\n",
      "-------------------------------\n",
      "loss: 0.379257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528925 \n",
      "\n",
      "Epoch 1166\n",
      "-------------------------------\n",
      "loss: 0.369758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531294 \n",
      "\n",
      "Epoch 1167\n",
      "-------------------------------\n",
      "loss: 0.382496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531392 \n",
      "\n",
      "Epoch 1168\n",
      "-------------------------------\n",
      "loss: 0.383101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530122 \n",
      "\n",
      "Epoch 1169\n",
      "-------------------------------\n",
      "loss: 0.400799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529647 \n",
      "\n",
      "Epoch 1170\n",
      "-------------------------------\n",
      "loss: 0.375686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528434 \n",
      "\n",
      "Epoch 1171\n",
      "-------------------------------\n",
      "loss: 0.392999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527828 \n",
      "\n",
      "Epoch 1172\n",
      "-------------------------------\n",
      "loss: 0.393896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526340 \n",
      "\n",
      "Epoch 1173\n",
      "-------------------------------\n",
      "loss: 0.394685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524899 \n",
      "\n",
      "Epoch 1174\n",
      "-------------------------------\n",
      "loss: 0.394098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524624 \n",
      "\n",
      "Epoch 1175\n",
      "-------------------------------\n",
      "loss: 0.363132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524682 \n",
      "\n",
      "Epoch 1176\n",
      "-------------------------------\n",
      "loss: 0.392586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524026 \n",
      "\n",
      "Epoch 1177\n",
      "-------------------------------\n",
      "loss: 0.378586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523990 \n",
      "\n",
      "Epoch 1178\n",
      "-------------------------------\n",
      "loss: 0.411469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525002 \n",
      "\n",
      "Epoch 1179\n",
      "-------------------------------\n",
      "loss: 0.382370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527304 \n",
      "\n",
      "Epoch 1180\n",
      "-------------------------------\n",
      "loss: 0.391042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529154 \n",
      "\n",
      "Epoch 1181\n",
      "-------------------------------\n",
      "loss: 0.386820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527091 \n",
      "\n",
      "Epoch 1182\n",
      "-------------------------------\n",
      "loss: 0.374511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523611 \n",
      "\n",
      "Epoch 1183\n",
      "-------------------------------\n",
      "loss: 0.374721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522254 \n",
      "\n",
      "Epoch 1184\n",
      "-------------------------------\n",
      "loss: 0.384719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523430 \n",
      "\n",
      "Epoch 1185\n",
      "-------------------------------\n",
      "loss: 0.371566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524368 \n",
      "\n",
      "Epoch 1186\n",
      "-------------------------------\n",
      "loss: 0.386701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523845 \n",
      "\n",
      "Epoch 1187\n",
      "-------------------------------\n",
      "loss: 0.384553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524105 \n",
      "\n",
      "Epoch 1188\n",
      "-------------------------------\n",
      "loss: 0.367111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525974 \n",
      "\n",
      "Epoch 1189\n",
      "-------------------------------\n",
      "loss: 0.370043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529133 \n",
      "\n",
      "Epoch 1190\n",
      "-------------------------------\n",
      "loss: 0.387691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530425 \n",
      "\n",
      "Epoch 1191\n",
      "-------------------------------\n",
      "loss: 0.381837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527840 \n",
      "\n",
      "Epoch 1192\n",
      "-------------------------------\n",
      "loss: 0.377661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525069 \n",
      "\n",
      "Epoch 1193\n",
      "-------------------------------\n",
      "loss: 0.366502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523515 \n",
      "\n",
      "Epoch 1194\n",
      "-------------------------------\n",
      "loss: 0.359241  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.524211 \n",
      "\n",
      "Epoch 1195\n",
      "-------------------------------\n",
      "loss: 0.364708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525589 \n",
      "\n",
      "Epoch 1196\n",
      "-------------------------------\n",
      "loss: 0.346431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526793 \n",
      "\n",
      "Epoch 1197\n",
      "-------------------------------\n",
      "loss: 0.376122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528228 \n",
      "\n",
      "Epoch 1198\n",
      "-------------------------------\n",
      "loss: 0.386506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528951 \n",
      "\n",
      "Epoch 1199\n",
      "-------------------------------\n",
      "loss: 0.394197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528365 \n",
      "\n",
      "Epoch 1200\n",
      "-------------------------------\n",
      "loss: 0.390251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527745 \n",
      "\n",
      "Epoch 1201\n",
      "-------------------------------\n",
      "loss: 0.381770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527724 \n",
      "\n",
      "Epoch 1202\n",
      "-------------------------------\n",
      "loss: 0.386802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525761 \n",
      "\n",
      "Epoch 1203\n",
      "-------------------------------\n",
      "loss: 0.385126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522893 \n",
      "\n",
      "Epoch 1204\n",
      "-------------------------------\n",
      "loss: 0.366341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521085 \n",
      "\n",
      "Epoch 1205\n",
      "-------------------------------\n",
      "loss: 0.378728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521494 \n",
      "\n",
      "Epoch 1206\n",
      "-------------------------------\n",
      "loss: 0.411580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522469 \n",
      "\n",
      "Epoch 1207\n",
      "-------------------------------\n",
      "loss: 0.383201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522778 \n",
      "\n",
      "Epoch 1208\n",
      "-------------------------------\n",
      "loss: 0.361075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523771 \n",
      "\n",
      "Epoch 1209\n",
      "-------------------------------\n",
      "loss: 0.373655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526282 \n",
      "\n",
      "Epoch 1210\n",
      "-------------------------------\n",
      "loss: 0.376481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528978 \n",
      "\n",
      "Epoch 1211\n",
      "-------------------------------\n",
      "loss: 0.371293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530878 \n",
      "\n",
      "Epoch 1212\n",
      "-------------------------------\n",
      "loss: 0.377476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530510 \n",
      "\n",
      "Epoch 1213\n",
      "-------------------------------\n",
      "loss: 0.388551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527029 \n",
      "\n",
      "Epoch 1214\n",
      "-------------------------------\n",
      "loss: 0.387873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524669 \n",
      "\n",
      "Epoch 1215\n",
      "-------------------------------\n",
      "loss: 0.397928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522933 \n",
      "\n",
      "Epoch 1216\n",
      "-------------------------------\n",
      "loss: 0.380279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521888 \n",
      "\n",
      "Epoch 1217\n",
      "-------------------------------\n",
      "loss: 0.385134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521384 \n",
      "\n",
      "Epoch 1218\n",
      "-------------------------------\n",
      "loss: 0.382460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521543 \n",
      "\n",
      "Epoch 1219\n",
      "-------------------------------\n",
      "loss: 0.371098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522619 \n",
      "\n",
      "Epoch 1220\n",
      "-------------------------------\n",
      "loss: 0.381113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524845 \n",
      "\n",
      "Epoch 1221\n",
      "-------------------------------\n",
      "loss: 0.390462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526570 \n",
      "\n",
      "Epoch 1222\n",
      "-------------------------------\n",
      "loss: 0.378377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525887 \n",
      "\n",
      "Epoch 1223\n",
      "-------------------------------\n",
      "loss: 0.386399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523497 \n",
      "\n",
      "Epoch 1224\n",
      "-------------------------------\n",
      "loss: 0.365924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522144 \n",
      "\n",
      "Epoch 1225\n",
      "-------------------------------\n",
      "loss: 0.382017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521503 \n",
      "\n",
      "Epoch 1226\n",
      "-------------------------------\n",
      "loss: 0.370504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523387 \n",
      "\n",
      "Epoch 1227\n",
      "-------------------------------\n",
      "loss: 0.372065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526074 \n",
      "\n",
      "Epoch 1228\n",
      "-------------------------------\n",
      "loss: 0.398906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526583 \n",
      "\n",
      "Epoch 1229\n",
      "-------------------------------\n",
      "loss: 0.392290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524504 \n",
      "\n",
      "Epoch 1230\n",
      "-------------------------------\n",
      "loss: 0.405476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523952 \n",
      "\n",
      "Epoch 1231\n",
      "-------------------------------\n",
      "loss: 0.400031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527130 \n",
      "\n",
      "Epoch 1232\n",
      "-------------------------------\n",
      "loss: 0.404561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530005 \n",
      "\n",
      "Epoch 1233\n",
      "-------------------------------\n",
      "loss: 0.385134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529291 \n",
      "\n",
      "Epoch 1234\n",
      "-------------------------------\n",
      "loss: 0.379541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526322 \n",
      "\n",
      "Epoch 1235\n",
      "-------------------------------\n",
      "loss: 0.372562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521944 \n",
      "\n",
      "Epoch 1236\n",
      "-------------------------------\n",
      "loss: 0.392778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521196 \n",
      "\n",
      "Epoch 1237\n",
      "-------------------------------\n",
      "loss: 0.384707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521163 \n",
      "\n",
      "Epoch 1238\n",
      "-------------------------------\n",
      "loss: 0.402954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520103 \n",
      "\n",
      "Epoch 1239\n",
      "-------------------------------\n",
      "loss: 0.404713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518932 \n",
      "\n",
      "Epoch 1240\n",
      "-------------------------------\n",
      "loss: 0.376955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519817 \n",
      "\n",
      "Epoch 1241\n",
      "-------------------------------\n",
      "loss: 0.372514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521579 \n",
      "\n",
      "Epoch 1242\n",
      "-------------------------------\n",
      "loss: 0.383073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522428 \n",
      "\n",
      "Epoch 1243\n",
      "-------------------------------\n",
      "loss: 0.388694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523566 \n",
      "\n",
      "Epoch 1244\n",
      "-------------------------------\n",
      "loss: 0.381113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522683 \n",
      "\n",
      "Epoch 1245\n",
      "-------------------------------\n",
      "loss: 0.381695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520669 \n",
      "\n",
      "Epoch 1246\n",
      "-------------------------------\n",
      "loss: 0.393169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519533 \n",
      "\n",
      "Epoch 1247\n",
      "-------------------------------\n",
      "loss: 0.400458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519279 \n",
      "\n",
      "Epoch 1248\n",
      "-------------------------------\n",
      "loss: 0.390365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519743 \n",
      "\n",
      "Epoch 1249\n",
      "-------------------------------\n",
      "loss: 0.372766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520451 \n",
      "\n",
      "Epoch 1250\n",
      "-------------------------------\n",
      "loss: 0.362536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522227 \n",
      "\n",
      "Epoch 1251\n",
      "-------------------------------\n",
      "loss: 0.377803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521346 \n",
      "\n",
      "Epoch 1252\n",
      "-------------------------------\n",
      "loss: 0.392240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520385 \n",
      "\n",
      "Epoch 1253\n",
      "-------------------------------\n",
      "loss: 0.376968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519409 \n",
      "\n",
      "Epoch 1254\n",
      "-------------------------------\n",
      "loss: 0.382477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519536 \n",
      "\n",
      "Epoch 1255\n",
      "-------------------------------\n",
      "loss: 0.367643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520121 \n",
      "\n",
      "Epoch 1256\n",
      "-------------------------------\n",
      "loss: 0.394415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520087 \n",
      "\n",
      "Epoch 1257\n",
      "-------------------------------\n",
      "loss: 0.382910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520080 \n",
      "\n",
      "Epoch 1258\n",
      "-------------------------------\n",
      "loss: 0.397182  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521604 \n",
      "\n",
      "Epoch 1259\n",
      "-------------------------------\n",
      "loss: 0.363218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524423 \n",
      "\n",
      "Epoch 1260\n",
      "-------------------------------\n",
      "loss: 0.393033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525676 \n",
      "\n",
      "Epoch 1261\n",
      "-------------------------------\n",
      "loss: 0.389186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524234 \n",
      "\n",
      "Epoch 1262\n",
      "-------------------------------\n",
      "loss: 0.369548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522745 \n",
      "\n",
      "Epoch 1263\n",
      "-------------------------------\n",
      "loss: 0.381722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523139 \n",
      "\n",
      "Epoch 1264\n",
      "-------------------------------\n",
      "loss: 0.391526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524649 \n",
      "\n",
      "Epoch 1265\n",
      "-------------------------------\n",
      "loss: 0.385699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525810 \n",
      "\n",
      "Epoch 1266\n",
      "-------------------------------\n",
      "loss: 0.388419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526705 \n",
      "\n",
      "Epoch 1267\n",
      "-------------------------------\n",
      "loss: 0.379376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528502 \n",
      "\n",
      "Epoch 1268\n",
      "-------------------------------\n",
      "loss: 0.388872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530377 \n",
      "\n",
      "Epoch 1269\n",
      "-------------------------------\n",
      "loss: 0.386128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528165 \n",
      "\n",
      "Epoch 1270\n",
      "-------------------------------\n",
      "loss: 0.374570  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.525469 \n",
      "\n",
      "Epoch 1271\n",
      "-------------------------------\n",
      "loss: 0.390081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524058 \n",
      "\n",
      "Epoch 1272\n",
      "-------------------------------\n",
      "loss: 0.401956  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522824 \n",
      "\n",
      "Epoch 1273\n",
      "-------------------------------\n",
      "loss: 0.389922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521575 \n",
      "\n",
      "Epoch 1274\n",
      "-------------------------------\n",
      "loss: 0.385783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521052 \n",
      "\n",
      "Epoch 1275\n",
      "-------------------------------\n",
      "loss: 0.377395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520822 \n",
      "\n",
      "Epoch 1276\n",
      "-------------------------------\n",
      "loss: 0.379674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521314 \n",
      "\n",
      "Epoch 1277\n",
      "-------------------------------\n",
      "loss: 0.370743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523259 \n",
      "\n",
      "Epoch 1278\n",
      "-------------------------------\n",
      "loss: 0.386897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525445 \n",
      "\n",
      "Epoch 1279\n",
      "-------------------------------\n",
      "loss: 0.364798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526589 \n",
      "\n",
      "Epoch 1280\n",
      "-------------------------------\n",
      "loss: 0.388950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527077 \n",
      "\n",
      "Epoch 1281\n",
      "-------------------------------\n",
      "loss: 0.379683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529942 \n",
      "\n",
      "Epoch 1282\n",
      "-------------------------------\n",
      "loss: 0.403833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536246 \n",
      "\n",
      "Epoch 1283\n",
      "-------------------------------\n",
      "loss: 0.375329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.540909 \n",
      "\n",
      "Epoch 1284\n",
      "-------------------------------\n",
      "loss: 0.383425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.538395 \n",
      "\n",
      "Epoch 1285\n",
      "-------------------------------\n",
      "loss: 0.394444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532214 \n",
      "\n",
      "Epoch 1286\n",
      "-------------------------------\n",
      "loss: 0.388415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527860 \n",
      "\n",
      "Epoch 1287\n",
      "-------------------------------\n",
      "loss: 0.379811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526269 \n",
      "\n",
      "Epoch 1288\n",
      "-------------------------------\n",
      "loss: 0.391118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528026 \n",
      "\n",
      "Epoch 1289\n",
      "-------------------------------\n",
      "loss: 0.396945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529268 \n",
      "\n",
      "Epoch 1290\n",
      "-------------------------------\n",
      "loss: 0.403874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529973 \n",
      "\n",
      "Epoch 1291\n",
      "-------------------------------\n",
      "loss: 0.384727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531943 \n",
      "\n",
      "Epoch 1292\n",
      "-------------------------------\n",
      "loss: 0.369286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535205 \n",
      "\n",
      "Epoch 1293\n",
      "-------------------------------\n",
      "loss: 0.397743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.534421 \n",
      "\n",
      "Epoch 1294\n",
      "-------------------------------\n",
      "loss: 0.382601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532264 \n",
      "\n",
      "Epoch 1295\n",
      "-------------------------------\n",
      "loss: 0.390102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531085 \n",
      "\n",
      "Epoch 1296\n",
      "-------------------------------\n",
      "loss: 0.357009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529003 \n",
      "\n",
      "Epoch 1297\n",
      "-------------------------------\n",
      "loss: 0.393135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527387 \n",
      "\n",
      "Epoch 1298\n",
      "-------------------------------\n",
      "loss: 0.391687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525230 \n",
      "\n",
      "Epoch 1299\n",
      "-------------------------------\n",
      "loss: 0.378680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524497 \n",
      "\n",
      "Epoch 1300\n",
      "-------------------------------\n",
      "loss: 0.391188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525246 \n",
      "\n",
      "Epoch 1301\n",
      "-------------------------------\n",
      "loss: 0.380805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524893 \n",
      "\n",
      "Epoch 1302\n",
      "-------------------------------\n",
      "loss: 0.354951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524980 \n",
      "\n",
      "Epoch 1303\n",
      "-------------------------------\n",
      "loss: 0.377147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524637 \n",
      "\n",
      "Epoch 1304\n",
      "-------------------------------\n",
      "loss: 0.401101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523942 \n",
      "\n",
      "Epoch 1305\n",
      "-------------------------------\n",
      "loss: 0.379530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525317 \n",
      "\n",
      "Epoch 1306\n",
      "-------------------------------\n",
      "loss: 0.372566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525849 \n",
      "\n",
      "Epoch 1307\n",
      "-------------------------------\n",
      "loss: 0.370825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525155 \n",
      "\n",
      "Epoch 1308\n",
      "-------------------------------\n",
      "loss: 0.352117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524524 \n",
      "\n",
      "Epoch 1309\n",
      "-------------------------------\n",
      "loss: 0.367048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524707 \n",
      "\n",
      "Epoch 1310\n",
      "-------------------------------\n",
      "loss: 0.378275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526632 \n",
      "\n",
      "Epoch 1311\n",
      "-------------------------------\n",
      "loss: 0.361960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529899 \n",
      "\n",
      "Epoch 1312\n",
      "-------------------------------\n",
      "loss: 0.386323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530779 \n",
      "\n",
      "Epoch 1313\n",
      "-------------------------------\n",
      "loss: 0.372188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528610 \n",
      "\n",
      "Epoch 1314\n",
      "-------------------------------\n",
      "loss: 0.360851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526816 \n",
      "\n",
      "Epoch 1315\n",
      "-------------------------------\n",
      "loss: 0.383650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526792 \n",
      "\n",
      "Epoch 1316\n",
      "-------------------------------\n",
      "loss: 0.375081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527625 \n",
      "\n",
      "Epoch 1317\n",
      "-------------------------------\n",
      "loss: 0.375724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527836 \n",
      "\n",
      "Epoch 1318\n",
      "-------------------------------\n",
      "loss: 0.368199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527243 \n",
      "\n",
      "Epoch 1319\n",
      "-------------------------------\n",
      "loss: 0.378630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526720 \n",
      "\n",
      "Epoch 1320\n",
      "-------------------------------\n",
      "loss: 0.373129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525995 \n",
      "\n",
      "Epoch 1321\n",
      "-------------------------------\n",
      "loss: 0.369279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525086 \n",
      "\n",
      "Epoch 1322\n",
      "-------------------------------\n",
      "loss: 0.376369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523911 \n",
      "\n",
      "Epoch 1323\n",
      "-------------------------------\n",
      "loss: 0.377481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523903 \n",
      "\n",
      "Epoch 1324\n",
      "-------------------------------\n",
      "loss: 0.361218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523984 \n",
      "\n",
      "Epoch 1325\n",
      "-------------------------------\n",
      "loss: 0.378768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524051 \n",
      "\n",
      "Epoch 1326\n",
      "-------------------------------\n",
      "loss: 0.375109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524404 \n",
      "\n",
      "Epoch 1327\n",
      "-------------------------------\n",
      "loss: 0.371552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524492 \n",
      "\n",
      "Epoch 1328\n",
      "-------------------------------\n",
      "loss: 0.371225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526370 \n",
      "\n",
      "Epoch 1329\n",
      "-------------------------------\n",
      "loss: 0.372365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528932 \n",
      "\n",
      "Epoch 1330\n",
      "-------------------------------\n",
      "loss: 0.370149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531873 \n",
      "\n",
      "Epoch 1331\n",
      "-------------------------------\n",
      "loss: 0.376001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533219 \n",
      "\n",
      "Epoch 1332\n",
      "-------------------------------\n",
      "loss: 0.390008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533727 \n",
      "\n",
      "Epoch 1333\n",
      "-------------------------------\n",
      "loss: 0.346525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532068 \n",
      "\n",
      "Epoch 1334\n",
      "-------------------------------\n",
      "loss: 0.360614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530522 \n",
      "\n",
      "Epoch 1335\n",
      "-------------------------------\n",
      "loss: 0.359754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527803 \n",
      "\n",
      "Epoch 1336\n",
      "-------------------------------\n",
      "loss: 0.377435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525968 \n",
      "\n",
      "Epoch 1337\n",
      "-------------------------------\n",
      "loss: 0.358680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524699 \n",
      "\n",
      "Epoch 1338\n",
      "-------------------------------\n",
      "loss: 0.350460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524408 \n",
      "\n",
      "Epoch 1339\n",
      "-------------------------------\n",
      "loss: 0.365876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525033 \n",
      "\n",
      "Epoch 1340\n",
      "-------------------------------\n",
      "loss: 0.378467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527419 \n",
      "\n",
      "Epoch 1341\n",
      "-------------------------------\n",
      "loss: 0.379593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531026 \n",
      "\n",
      "Epoch 1342\n",
      "-------------------------------\n",
      "loss: 0.377698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535321 \n",
      "\n",
      "Epoch 1343\n",
      "-------------------------------\n",
      "loss: 0.379258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.537356 \n",
      "\n",
      "Epoch 1344\n",
      "-------------------------------\n",
      "loss: 0.361155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533118 \n",
      "\n",
      "Epoch 1345\n",
      "-------------------------------\n",
      "loss: 0.365240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525046 \n",
      "\n",
      "Epoch 1346\n",
      "-------------------------------\n",
      "loss: 0.385436  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521813 \n",
      "\n",
      "Epoch 1347\n",
      "-------------------------------\n",
      "loss: 0.374657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520532 \n",
      "\n",
      "Epoch 1348\n",
      "-------------------------------\n",
      "loss: 0.376822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519809 \n",
      "\n",
      "Epoch 1349\n",
      "-------------------------------\n",
      "loss: 0.357110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520339 \n",
      "\n",
      "Epoch 1350\n",
      "-------------------------------\n",
      "loss: 0.359293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522792 \n",
      "\n",
      "Epoch 1351\n",
      "-------------------------------\n",
      "loss: 0.373891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526351 \n",
      "\n",
      "Epoch 1352\n",
      "-------------------------------\n",
      "loss: 0.387045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528385 \n",
      "\n",
      "Epoch 1353\n",
      "-------------------------------\n",
      "loss: 0.391224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529008 \n",
      "\n",
      "Epoch 1354\n",
      "-------------------------------\n",
      "loss: 0.348368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528759 \n",
      "\n",
      "Epoch 1355\n",
      "-------------------------------\n",
      "loss: 0.376970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527697 \n",
      "\n",
      "Epoch 1356\n",
      "-------------------------------\n",
      "loss: 0.358039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526850 \n",
      "\n",
      "Epoch 1357\n",
      "-------------------------------\n",
      "loss: 0.378037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526826 \n",
      "\n",
      "Epoch 1358\n",
      "-------------------------------\n",
      "loss: 0.386289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527217 \n",
      "\n",
      "Epoch 1359\n",
      "-------------------------------\n",
      "loss: 0.381501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528214 \n",
      "\n",
      "Epoch 1360\n",
      "-------------------------------\n",
      "loss: 0.370887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530295 \n",
      "\n",
      "Epoch 1361\n",
      "-------------------------------\n",
      "loss: 0.360997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531939 \n",
      "\n",
      "Epoch 1362\n",
      "-------------------------------\n",
      "loss: 0.376529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531605 \n",
      "\n",
      "Epoch 1363\n",
      "-------------------------------\n",
      "loss: 0.386224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529253 \n",
      "\n",
      "Epoch 1364\n",
      "-------------------------------\n",
      "loss: 0.376200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528641 \n",
      "\n",
      "Epoch 1365\n",
      "-------------------------------\n",
      "loss: 0.390145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528724 \n",
      "\n",
      "Epoch 1366\n",
      "-------------------------------\n",
      "loss: 0.359774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528656 \n",
      "\n",
      "Epoch 1367\n",
      "-------------------------------\n",
      "loss: 0.386587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527527 \n",
      "\n",
      "Epoch 1368\n",
      "-------------------------------\n",
      "loss: 0.363374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526453 \n",
      "\n",
      "Epoch 1369\n",
      "-------------------------------\n",
      "loss: 0.382819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526028 \n",
      "\n",
      "Epoch 1370\n",
      "-------------------------------\n",
      "loss: 0.380309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527398 \n",
      "\n",
      "Epoch 1371\n",
      "-------------------------------\n",
      "loss: 0.362887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527462 \n",
      "\n",
      "Epoch 1372\n",
      "-------------------------------\n",
      "loss: 0.383113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525980 \n",
      "\n",
      "Epoch 1373\n",
      "-------------------------------\n",
      "loss: 0.368669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523578 \n",
      "\n",
      "Epoch 1374\n",
      "-------------------------------\n",
      "loss: 0.386549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521861 \n",
      "\n",
      "Epoch 1375\n",
      "-------------------------------\n",
      "loss: 0.379408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520644 \n",
      "\n",
      "Epoch 1376\n",
      "-------------------------------\n",
      "loss: 0.384017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520546 \n",
      "\n",
      "Epoch 1377\n",
      "-------------------------------\n",
      "loss: 0.378305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521517 \n",
      "\n",
      "Epoch 1378\n",
      "-------------------------------\n",
      "loss: 0.371760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522769 \n",
      "\n",
      "Epoch 1379\n",
      "-------------------------------\n",
      "loss: 0.345169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523933 \n",
      "\n",
      "Epoch 1380\n",
      "-------------------------------\n",
      "loss: 0.391746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525678 \n",
      "\n",
      "Epoch 1381\n",
      "-------------------------------\n",
      "loss: 0.380348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526509 \n",
      "\n",
      "Epoch 1382\n",
      "-------------------------------\n",
      "loss: 0.368382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527298 \n",
      "\n",
      "Epoch 1383\n",
      "-------------------------------\n",
      "loss: 0.369536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527306 \n",
      "\n",
      "Epoch 1384\n",
      "-------------------------------\n",
      "loss: 0.375160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526988 \n",
      "\n",
      "Epoch 1385\n",
      "-------------------------------\n",
      "loss: 0.370746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527435 \n",
      "\n",
      "Epoch 1386\n",
      "-------------------------------\n",
      "loss: 0.360780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527652 \n",
      "\n",
      "Epoch 1387\n",
      "-------------------------------\n",
      "loss: 0.373033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527918 \n",
      "\n",
      "Epoch 1388\n",
      "-------------------------------\n",
      "loss: 0.385795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526822 \n",
      "\n",
      "Epoch 1389\n",
      "-------------------------------\n",
      "loss: 0.371509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526295 \n",
      "\n",
      "Epoch 1390\n",
      "-------------------------------\n",
      "loss: 0.363432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524882 \n",
      "\n",
      "Epoch 1391\n",
      "-------------------------------\n",
      "loss: 0.367429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523918 \n",
      "\n",
      "Epoch 1392\n",
      "-------------------------------\n",
      "loss: 0.348428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523798 \n",
      "\n",
      "Epoch 1393\n",
      "-------------------------------\n",
      "loss: 0.364570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525294 \n",
      "\n",
      "Epoch 1394\n",
      "-------------------------------\n",
      "loss: 0.372302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525682 \n",
      "\n",
      "Epoch 1395\n",
      "-------------------------------\n",
      "loss: 0.362966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526677 \n",
      "\n",
      "Epoch 1396\n",
      "-------------------------------\n",
      "loss: 0.379866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527259 \n",
      "\n",
      "Epoch 1397\n",
      "-------------------------------\n",
      "loss: 0.362958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527014 \n",
      "\n",
      "Epoch 1398\n",
      "-------------------------------\n",
      "loss: 0.356496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527259 \n",
      "\n",
      "Epoch 1399\n",
      "-------------------------------\n",
      "loss: 0.371987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528376 \n",
      "\n",
      "Epoch 1400\n",
      "-------------------------------\n",
      "loss: 0.384484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529401 \n",
      "\n",
      "Epoch 1401\n",
      "-------------------------------\n",
      "loss: 0.372796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528950 \n",
      "\n",
      "Epoch 1402\n",
      "-------------------------------\n",
      "loss: 0.370024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528652 \n",
      "\n",
      "Epoch 1403\n",
      "-------------------------------\n",
      "loss: 0.382822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528595 \n",
      "\n",
      "Epoch 1404\n",
      "-------------------------------\n",
      "loss: 0.373410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528949 \n",
      "\n",
      "Epoch 1405\n",
      "-------------------------------\n",
      "loss: 0.361099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528921 \n",
      "\n",
      "Epoch 1406\n",
      "-------------------------------\n",
      "loss: 0.350040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529413 \n",
      "\n",
      "Epoch 1407\n",
      "-------------------------------\n",
      "loss: 0.354796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529117 \n",
      "\n",
      "Epoch 1408\n",
      "-------------------------------\n",
      "loss: 0.370526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529021 \n",
      "\n",
      "Epoch 1409\n",
      "-------------------------------\n",
      "loss: 0.358700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528898 \n",
      "\n",
      "Epoch 1410\n",
      "-------------------------------\n",
      "loss: 0.368021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530747 \n",
      "\n",
      "Epoch 1411\n",
      "-------------------------------\n",
      "loss: 0.380922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533399 \n",
      "\n",
      "Epoch 1412\n",
      "-------------------------------\n",
      "loss: 0.371381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535875 \n",
      "\n",
      "Epoch 1413\n",
      "-------------------------------\n",
      "loss: 0.383892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.537200 \n",
      "\n",
      "Epoch 1414\n",
      "-------------------------------\n",
      "loss: 0.381778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.536250 \n",
      "\n",
      "Epoch 1415\n",
      "-------------------------------\n",
      "loss: 0.357743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.534881 \n",
      "\n",
      "Epoch 1416\n",
      "-------------------------------\n",
      "loss: 0.364354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532399 \n",
      "\n",
      "Epoch 1417\n",
      "-------------------------------\n",
      "loss: 0.371218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528682 \n",
      "\n",
      "Epoch 1418\n",
      "-------------------------------\n",
      "loss: 0.374003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525924 \n",
      "\n",
      "Epoch 1419\n",
      "-------------------------------\n",
      "loss: 0.364921  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524504 \n",
      "\n",
      "Epoch 1420\n",
      "-------------------------------\n",
      "loss: 0.351330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523348 \n",
      "\n",
      "Epoch 1421\n",
      "-------------------------------\n",
      "loss: 0.358789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522926 \n",
      "\n",
      "Epoch 1422\n",
      "-------------------------------\n",
      "loss: 0.353409  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.522613 \n",
      "\n",
      "Epoch 1423\n",
      "-------------------------------\n",
      "loss: 0.363599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522574 \n",
      "\n",
      "Epoch 1424\n",
      "-------------------------------\n",
      "loss: 0.354518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523207 \n",
      "\n",
      "Epoch 1425\n",
      "-------------------------------\n",
      "loss: 0.385169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524089 \n",
      "\n",
      "Epoch 1426\n",
      "-------------------------------\n",
      "loss: 0.379701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524297 \n",
      "\n",
      "Epoch 1427\n",
      "-------------------------------\n",
      "loss: 0.377253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526263 \n",
      "\n",
      "Epoch 1428\n",
      "-------------------------------\n",
      "loss: 0.379449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526169 \n",
      "\n",
      "Epoch 1429\n",
      "-------------------------------\n",
      "loss: 0.370722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525086 \n",
      "\n",
      "Epoch 1430\n",
      "-------------------------------\n",
      "loss: 0.360466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523775 \n",
      "\n",
      "Epoch 1431\n",
      "-------------------------------\n",
      "loss: 0.358077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523804 \n",
      "\n",
      "Epoch 1432\n",
      "-------------------------------\n",
      "loss: 0.362349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523433 \n",
      "\n",
      "Epoch 1433\n",
      "-------------------------------\n",
      "loss: 0.395317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522787 \n",
      "\n",
      "Epoch 1434\n",
      "-------------------------------\n",
      "loss: 0.357305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521662 \n",
      "\n",
      "Epoch 1435\n",
      "-------------------------------\n",
      "loss: 0.370822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521933 \n",
      "\n",
      "Epoch 1436\n",
      "-------------------------------\n",
      "loss: 0.350965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522779 \n",
      "\n",
      "Epoch 1437\n",
      "-------------------------------\n",
      "loss: 0.380527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523157 \n",
      "\n",
      "Epoch 1438\n",
      "-------------------------------\n",
      "loss: 0.354388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522310 \n",
      "\n",
      "Epoch 1439\n",
      "-------------------------------\n",
      "loss: 0.375144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522162 \n",
      "\n",
      "Epoch 1440\n",
      "-------------------------------\n",
      "loss: 0.360630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521930 \n",
      "\n",
      "Epoch 1441\n",
      "-------------------------------\n",
      "loss: 0.365220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522507 \n",
      "\n",
      "Epoch 1442\n",
      "-------------------------------\n",
      "loss: 0.359096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522387 \n",
      "\n",
      "Epoch 1443\n",
      "-------------------------------\n",
      "loss: 0.364439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522885 \n",
      "\n",
      "Epoch 1444\n",
      "-------------------------------\n",
      "loss: 0.372073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522979 \n",
      "\n",
      "Epoch 1445\n",
      "-------------------------------\n",
      "loss: 0.362288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523098 \n",
      "\n",
      "Epoch 1446\n",
      "-------------------------------\n",
      "loss: 0.363045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525090 \n",
      "\n",
      "Epoch 1447\n",
      "-------------------------------\n",
      "loss: 0.353018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528285 \n",
      "\n",
      "Epoch 1448\n",
      "-------------------------------\n",
      "loss: 0.372826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529036 \n",
      "\n",
      "Epoch 1449\n",
      "-------------------------------\n",
      "loss: 0.360055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527095 \n",
      "\n",
      "Epoch 1450\n",
      "-------------------------------\n",
      "loss: 0.371918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523045 \n",
      "\n",
      "Epoch 1451\n",
      "-------------------------------\n",
      "loss: 0.368906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521391 \n",
      "\n",
      "Epoch 1452\n",
      "-------------------------------\n",
      "loss: 0.358809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522265 \n",
      "\n",
      "Epoch 1453\n",
      "-------------------------------\n",
      "loss: 0.371943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523026 \n",
      "\n",
      "Epoch 1454\n",
      "-------------------------------\n",
      "loss: 0.366759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523769 \n",
      "\n",
      "Epoch 1455\n",
      "-------------------------------\n",
      "loss: 0.393240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525355 \n",
      "\n",
      "Epoch 1456\n",
      "-------------------------------\n",
      "loss: 0.376399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529336 \n",
      "\n",
      "Epoch 1457\n",
      "-------------------------------\n",
      "loss: 0.387296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533325 \n",
      "\n",
      "Epoch 1458\n",
      "-------------------------------\n",
      "loss: 0.377074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530361 \n",
      "\n",
      "Epoch 1459\n",
      "-------------------------------\n",
      "loss: 0.414243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523693 \n",
      "\n",
      "Epoch 1460\n",
      "-------------------------------\n",
      "loss: 0.359211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520277 \n",
      "\n",
      "Epoch 1461\n",
      "-------------------------------\n",
      "loss: 0.366305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521643 \n",
      "\n",
      "Epoch 1462\n",
      "-------------------------------\n",
      "loss: 0.377593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521926 \n",
      "\n",
      "Epoch 1463\n",
      "-------------------------------\n",
      "loss: 0.382265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518968 \n",
      "\n",
      "Epoch 1464\n",
      "-------------------------------\n",
      "loss: 0.402011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518380 \n",
      "\n",
      "Epoch 1465\n",
      "-------------------------------\n",
      "loss: 0.371918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523282 \n",
      "\n",
      "Epoch 1466\n",
      "-------------------------------\n",
      "loss: 0.360666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528512 \n",
      "\n",
      "Epoch 1467\n",
      "-------------------------------\n",
      "loss: 0.376562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529652 \n",
      "\n",
      "Epoch 1468\n",
      "-------------------------------\n",
      "loss: 0.377936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527278 \n",
      "\n",
      "Epoch 1469\n",
      "-------------------------------\n",
      "loss: 0.351249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523099 \n",
      "\n",
      "Epoch 1470\n",
      "-------------------------------\n",
      "loss: 0.354252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521526 \n",
      "\n",
      "Epoch 1471\n",
      "-------------------------------\n",
      "loss: 0.347069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521350 \n",
      "\n",
      "Epoch 1472\n",
      "-------------------------------\n",
      "loss: 0.393316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521304 \n",
      "\n",
      "Epoch 1473\n",
      "-------------------------------\n",
      "loss: 0.372203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520453 \n",
      "\n",
      "Epoch 1474\n",
      "-------------------------------\n",
      "loss: 0.362098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520302 \n",
      "\n",
      "Epoch 1475\n",
      "-------------------------------\n",
      "loss: 0.389277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521185 \n",
      "\n",
      "Epoch 1476\n",
      "-------------------------------\n",
      "loss: 0.368214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524373 \n",
      "\n",
      "Epoch 1477\n",
      "-------------------------------\n",
      "loss: 0.363652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527718 \n",
      "\n",
      "Epoch 1478\n",
      "-------------------------------\n",
      "loss: 0.381148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527718 \n",
      "\n",
      "Epoch 1479\n",
      "-------------------------------\n",
      "loss: 0.367088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527294 \n",
      "\n",
      "Epoch 1480\n",
      "-------------------------------\n",
      "loss: 0.363668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525851 \n",
      "\n",
      "Epoch 1481\n",
      "-------------------------------\n",
      "loss: 0.367448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524586 \n",
      "\n",
      "Epoch 1482\n",
      "-------------------------------\n",
      "loss: 0.394818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522839 \n",
      "\n",
      "Epoch 1483\n",
      "-------------------------------\n",
      "loss: 0.371244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520453 \n",
      "\n",
      "Epoch 1484\n",
      "-------------------------------\n",
      "loss: 0.360617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520025 \n",
      "\n",
      "Epoch 1485\n",
      "-------------------------------\n",
      "loss: 0.365492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523021 \n",
      "\n",
      "Epoch 1486\n",
      "-------------------------------\n",
      "loss: 0.371396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524904 \n",
      "\n",
      "Epoch 1487\n",
      "-------------------------------\n",
      "loss: 0.352368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524515 \n",
      "\n",
      "Epoch 1488\n",
      "-------------------------------\n",
      "loss: 0.372828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522937 \n",
      "\n",
      "Epoch 1489\n",
      "-------------------------------\n",
      "loss: 0.344625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522577 \n",
      "\n",
      "Epoch 1490\n",
      "-------------------------------\n",
      "loss: 0.365159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522969 \n",
      "\n",
      "Epoch 1491\n",
      "-------------------------------\n",
      "loss: 0.343829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523777 \n",
      "\n",
      "Epoch 1492\n",
      "-------------------------------\n",
      "loss: 0.350029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524705 \n",
      "\n",
      "Epoch 1493\n",
      "-------------------------------\n",
      "loss: 0.361923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525334 \n",
      "\n",
      "Epoch 1494\n",
      "-------------------------------\n",
      "loss: 0.352167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525520 \n",
      "\n",
      "Epoch 1495\n",
      "-------------------------------\n",
      "loss: 0.354612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527130 \n",
      "\n",
      "Epoch 1496\n",
      "-------------------------------\n",
      "loss: 0.343874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529343 \n",
      "\n",
      "Epoch 1497\n",
      "-------------------------------\n",
      "loss: 0.356975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529572 \n",
      "\n",
      "Epoch 1498\n",
      "-------------------------------\n",
      "loss: 0.365717  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.528172 \n",
      "\n",
      "Epoch 1499\n",
      "-------------------------------\n",
      "loss: 0.381749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526021 \n",
      "\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "loss: 0.361200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522763 \n",
      "\n",
      "Epoch 1501\n",
      "-------------------------------\n",
      "loss: 0.351668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521271 \n",
      "\n",
      "Epoch 1502\n",
      "-------------------------------\n",
      "loss: 0.339847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519748 \n",
      "\n",
      "Epoch 1503\n",
      "-------------------------------\n",
      "loss: 0.364286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518323 \n",
      "\n",
      "Epoch 1504\n",
      "-------------------------------\n",
      "loss: 0.352144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517879 \n",
      "\n",
      "Epoch 1505\n",
      "-------------------------------\n",
      "loss: 0.364160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517950 \n",
      "\n",
      "Epoch 1506\n",
      "-------------------------------\n",
      "loss: 0.352031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518284 \n",
      "\n",
      "Epoch 1507\n",
      "-------------------------------\n",
      "loss: 0.363025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518375 \n",
      "\n",
      "Epoch 1508\n",
      "-------------------------------\n",
      "loss: 0.357723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518570 \n",
      "\n",
      "Epoch 1509\n",
      "-------------------------------\n",
      "loss: 0.361756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519019 \n",
      "\n",
      "Epoch 1510\n",
      "-------------------------------\n",
      "loss: 0.359550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520418 \n",
      "\n",
      "Epoch 1511\n",
      "-------------------------------\n",
      "loss: 0.370727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521045 \n",
      "\n",
      "Epoch 1512\n",
      "-------------------------------\n",
      "loss: 0.364984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520659 \n",
      "\n",
      "Epoch 1513\n",
      "-------------------------------\n",
      "loss: 0.360648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519271 \n",
      "\n",
      "Epoch 1514\n",
      "-------------------------------\n",
      "loss: 0.360623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519154 \n",
      "\n",
      "Epoch 1515\n",
      "-------------------------------\n",
      "loss: 0.374293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519884 \n",
      "\n",
      "Epoch 1516\n",
      "-------------------------------\n",
      "loss: 0.364359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520835 \n",
      "\n",
      "Epoch 1517\n",
      "-------------------------------\n",
      "loss: 0.365943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521744 \n",
      "\n",
      "Epoch 1518\n",
      "-------------------------------\n",
      "loss: 0.341868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524042 \n",
      "\n",
      "Epoch 1519\n",
      "-------------------------------\n",
      "loss: 0.352792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526548 \n",
      "\n",
      "Epoch 1520\n",
      "-------------------------------\n",
      "loss: 0.356443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527282 \n",
      "\n",
      "Epoch 1521\n",
      "-------------------------------\n",
      "loss: 0.350370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526249 \n",
      "\n",
      "Epoch 1522\n",
      "-------------------------------\n",
      "loss: 0.342462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525912 \n",
      "\n",
      "Epoch 1523\n",
      "-------------------------------\n",
      "loss: 0.341698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527118 \n",
      "\n",
      "Epoch 1524\n",
      "-------------------------------\n",
      "loss: 0.363262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528729 \n",
      "\n",
      "Epoch 1525\n",
      "-------------------------------\n",
      "loss: 0.362532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529418 \n",
      "\n",
      "Epoch 1526\n",
      "-------------------------------\n",
      "loss: 0.345394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528755 \n",
      "\n",
      "Epoch 1527\n",
      "-------------------------------\n",
      "loss: 0.342661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527197 \n",
      "\n",
      "Epoch 1528\n",
      "-------------------------------\n",
      "loss: 0.354157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526371 \n",
      "\n",
      "Epoch 1529\n",
      "-------------------------------\n",
      "loss: 0.371042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525420 \n",
      "\n",
      "Epoch 1530\n",
      "-------------------------------\n",
      "loss: 0.345502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524363 \n",
      "\n",
      "Epoch 1531\n",
      "-------------------------------\n",
      "loss: 0.374237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522939 \n",
      "\n",
      "Epoch 1532\n",
      "-------------------------------\n",
      "loss: 0.348569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522012 \n",
      "\n",
      "Epoch 1533\n",
      "-------------------------------\n",
      "loss: 0.355275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520388 \n",
      "\n",
      "Epoch 1534\n",
      "-------------------------------\n",
      "loss: 0.351101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519443 \n",
      "\n",
      "Epoch 1535\n",
      "-------------------------------\n",
      "loss: 0.355970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519388 \n",
      "\n",
      "Epoch 1536\n",
      "-------------------------------\n",
      "loss: 0.345637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520143 \n",
      "\n",
      "Epoch 1537\n",
      "-------------------------------\n",
      "loss: 0.352192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521453 \n",
      "\n",
      "Epoch 1538\n",
      "-------------------------------\n",
      "loss: 0.356045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522054 \n",
      "\n",
      "Epoch 1539\n",
      "-------------------------------\n",
      "loss: 0.357733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523038 \n",
      "\n",
      "Epoch 1540\n",
      "-------------------------------\n",
      "loss: 0.343469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523636 \n",
      "\n",
      "Epoch 1541\n",
      "-------------------------------\n",
      "loss: 0.337722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522657 \n",
      "\n",
      "Epoch 1542\n",
      "-------------------------------\n",
      "loss: 0.346808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520973 \n",
      "\n",
      "Epoch 1543\n",
      "-------------------------------\n",
      "loss: 0.351560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520844 \n",
      "\n",
      "Epoch 1544\n",
      "-------------------------------\n",
      "loss: 0.334536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520742 \n",
      "\n",
      "Epoch 1545\n",
      "-------------------------------\n",
      "loss: 0.346086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521052 \n",
      "\n",
      "Epoch 1546\n",
      "-------------------------------\n",
      "loss: 0.360686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521712 \n",
      "\n",
      "Epoch 1547\n",
      "-------------------------------\n",
      "loss: 0.351934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522733 \n",
      "\n",
      "Epoch 1548\n",
      "-------------------------------\n",
      "loss: 0.340333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525220 \n",
      "\n",
      "Epoch 1549\n",
      "-------------------------------\n",
      "loss: 0.340449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528483 \n",
      "\n",
      "Epoch 1550\n",
      "-------------------------------\n",
      "loss: 0.350511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528464 \n",
      "\n",
      "Epoch 1551\n",
      "-------------------------------\n",
      "loss: 0.366029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527567 \n",
      "\n",
      "Epoch 1552\n",
      "-------------------------------\n",
      "loss: 0.357215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525064 \n",
      "\n",
      "Epoch 1553\n",
      "-------------------------------\n",
      "loss: 0.373767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523244 \n",
      "\n",
      "Epoch 1554\n",
      "-------------------------------\n",
      "loss: 0.367150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522424 \n",
      "\n",
      "Epoch 1555\n",
      "-------------------------------\n",
      "loss: 0.350442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522027 \n",
      "\n",
      "Epoch 1556\n",
      "-------------------------------\n",
      "loss: 0.341159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521998 \n",
      "\n",
      "Epoch 1557\n",
      "-------------------------------\n",
      "loss: 0.357030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523126 \n",
      "\n",
      "Epoch 1558\n",
      "-------------------------------\n",
      "loss: 0.358766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523756 \n",
      "\n",
      "Epoch 1559\n",
      "-------------------------------\n",
      "loss: 0.343994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523380 \n",
      "\n",
      "Epoch 1560\n",
      "-------------------------------\n",
      "loss: 0.359467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523335 \n",
      "\n",
      "Epoch 1561\n",
      "-------------------------------\n",
      "loss: 0.353598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523286 \n",
      "\n",
      "Epoch 1562\n",
      "-------------------------------\n",
      "loss: 0.367163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522124 \n",
      "\n",
      "Epoch 1563\n",
      "-------------------------------\n",
      "loss: 0.367360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520947 \n",
      "\n",
      "Epoch 1564\n",
      "-------------------------------\n",
      "loss: 0.337799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520660 \n",
      "\n",
      "Epoch 1565\n",
      "-------------------------------\n",
      "loss: 0.358827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519855 \n",
      "\n",
      "Epoch 1566\n",
      "-------------------------------\n",
      "loss: 0.357038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518596 \n",
      "\n",
      "Epoch 1567\n",
      "-------------------------------\n",
      "loss: 0.335335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518805 \n",
      "\n",
      "Epoch 1568\n",
      "-------------------------------\n",
      "loss: 0.345774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519086 \n",
      "\n",
      "Epoch 1569\n",
      "-------------------------------\n",
      "loss: 0.335792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519887 \n",
      "\n",
      "Epoch 1570\n",
      "-------------------------------\n",
      "loss: 0.345263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520901 \n",
      "\n",
      "Epoch 1571\n",
      "-------------------------------\n",
      "loss: 0.361586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522563 \n",
      "\n",
      "Epoch 1572\n",
      "-------------------------------\n",
      "loss: 0.349560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525170 \n",
      "\n",
      "Epoch 1573\n",
      "-------------------------------\n",
      "loss: 0.357038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527950 \n",
      "\n",
      "Epoch 1574\n",
      "-------------------------------\n",
      "loss: 0.350654  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.530219 \n",
      "\n",
      "Epoch 1575\n",
      "-------------------------------\n",
      "loss: 0.371000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531480 \n",
      "\n",
      "Epoch 1576\n",
      "-------------------------------\n",
      "loss: 0.358149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531065 \n",
      "\n",
      "Epoch 1577\n",
      "-------------------------------\n",
      "loss: 0.350444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529738 \n",
      "\n",
      "Epoch 1578\n",
      "-------------------------------\n",
      "loss: 0.366727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528801 \n",
      "\n",
      "Epoch 1579\n",
      "-------------------------------\n",
      "loss: 0.348101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527195 \n",
      "\n",
      "Epoch 1580\n",
      "-------------------------------\n",
      "loss: 0.348324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525753 \n",
      "\n",
      "Epoch 1581\n",
      "-------------------------------\n",
      "loss: 0.351921  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523470 \n",
      "\n",
      "Epoch 1582\n",
      "-------------------------------\n",
      "loss: 0.377589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521988 \n",
      "\n",
      "Epoch 1583\n",
      "-------------------------------\n",
      "loss: 0.341405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520840 \n",
      "\n",
      "Epoch 1584\n",
      "-------------------------------\n",
      "loss: 0.376423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520033 \n",
      "\n",
      "Epoch 1585\n",
      "-------------------------------\n",
      "loss: 0.359021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519647 \n",
      "\n",
      "Epoch 1586\n",
      "-------------------------------\n",
      "loss: 0.366418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519602 \n",
      "\n",
      "Epoch 1587\n",
      "-------------------------------\n",
      "loss: 0.333164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519699 \n",
      "\n",
      "Epoch 1588\n",
      "-------------------------------\n",
      "loss: 0.350743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519587 \n",
      "\n",
      "Epoch 1589\n",
      "-------------------------------\n",
      "loss: 0.340303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520643 \n",
      "\n",
      "Epoch 1590\n",
      "-------------------------------\n",
      "loss: 0.363755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523168 \n",
      "\n",
      "Epoch 1591\n",
      "-------------------------------\n",
      "loss: 0.357657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525162 \n",
      "\n",
      "Epoch 1592\n",
      "-------------------------------\n",
      "loss: 0.369454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526473 \n",
      "\n",
      "Epoch 1593\n",
      "-------------------------------\n",
      "loss: 0.347298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527485 \n",
      "\n",
      "Epoch 1594\n",
      "-------------------------------\n",
      "loss: 0.361367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527715 \n",
      "\n",
      "Epoch 1595\n",
      "-------------------------------\n",
      "loss: 0.368336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526774 \n",
      "\n",
      "Epoch 1596\n",
      "-------------------------------\n",
      "loss: 0.368165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524315 \n",
      "\n",
      "Epoch 1597\n",
      "-------------------------------\n",
      "loss: 0.333630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521822 \n",
      "\n",
      "Epoch 1598\n",
      "-------------------------------\n",
      "loss: 0.359817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520854 \n",
      "\n",
      "Epoch 1599\n",
      "-------------------------------\n",
      "loss: 0.375764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520302 \n",
      "\n",
      "Epoch 1600\n",
      "-------------------------------\n",
      "loss: 0.360614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519583 \n",
      "\n",
      "Epoch 1601\n",
      "-------------------------------\n",
      "loss: 0.350820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519752 \n",
      "\n",
      "Epoch 1602\n",
      "-------------------------------\n",
      "loss: 0.349394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522183 \n",
      "\n",
      "Epoch 1603\n",
      "-------------------------------\n",
      "loss: 0.334776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526192 \n",
      "\n",
      "Epoch 1604\n",
      "-------------------------------\n",
      "loss: 0.375713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529366 \n",
      "\n",
      "Epoch 1605\n",
      "-------------------------------\n",
      "loss: 0.330875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530133 \n",
      "\n",
      "Epoch 1606\n",
      "-------------------------------\n",
      "loss: 0.356165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529403 \n",
      "\n",
      "Epoch 1607\n",
      "-------------------------------\n",
      "loss: 0.370624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528832 \n",
      "\n",
      "Epoch 1608\n",
      "-------------------------------\n",
      "loss: 0.341724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528134 \n",
      "\n",
      "Epoch 1609\n",
      "-------------------------------\n",
      "loss: 0.351482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527382 \n",
      "\n",
      "Epoch 1610\n",
      "-------------------------------\n",
      "loss: 0.339955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527328 \n",
      "\n",
      "Epoch 1611\n",
      "-------------------------------\n",
      "loss: 0.344689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527416 \n",
      "\n",
      "Epoch 1612\n",
      "-------------------------------\n",
      "loss: 0.353942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527646 \n",
      "\n",
      "Epoch 1613\n",
      "-------------------------------\n",
      "loss: 0.361079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527499 \n",
      "\n",
      "Epoch 1614\n",
      "-------------------------------\n",
      "loss: 0.358172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526346 \n",
      "\n",
      "Epoch 1615\n",
      "-------------------------------\n",
      "loss: 0.329774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525916 \n",
      "\n",
      "Epoch 1616\n",
      "-------------------------------\n",
      "loss: 0.345808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526636 \n",
      "\n",
      "Epoch 1617\n",
      "-------------------------------\n",
      "loss: 0.341421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525824 \n",
      "\n",
      "Epoch 1618\n",
      "-------------------------------\n",
      "loss: 0.352900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524866 \n",
      "\n",
      "Epoch 1619\n",
      "-------------------------------\n",
      "loss: 0.331263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524121 \n",
      "\n",
      "Epoch 1620\n",
      "-------------------------------\n",
      "loss: 0.351480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523432 \n",
      "\n",
      "Epoch 1621\n",
      "-------------------------------\n",
      "loss: 0.357959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523218 \n",
      "\n",
      "Epoch 1622\n",
      "-------------------------------\n",
      "loss: 0.338390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522851 \n",
      "\n",
      "Epoch 1623\n",
      "-------------------------------\n",
      "loss: 0.356029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522528 \n",
      "\n",
      "Epoch 1624\n",
      "-------------------------------\n",
      "loss: 0.365470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522868 \n",
      "\n",
      "Epoch 1625\n",
      "-------------------------------\n",
      "loss: 0.357153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523249 \n",
      "\n",
      "Epoch 1626\n",
      "-------------------------------\n",
      "loss: 0.360049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523289 \n",
      "\n",
      "Epoch 1627\n",
      "-------------------------------\n",
      "loss: 0.344459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524257 \n",
      "\n",
      "Epoch 1628\n",
      "-------------------------------\n",
      "loss: 0.360633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524179 \n",
      "\n",
      "Epoch 1629\n",
      "-------------------------------\n",
      "loss: 0.350821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524956 \n",
      "\n",
      "Epoch 1630\n",
      "-------------------------------\n",
      "loss: 0.354730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525845 \n",
      "\n",
      "Epoch 1631\n",
      "-------------------------------\n",
      "loss: 0.370432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527017 \n",
      "\n",
      "Epoch 1632\n",
      "-------------------------------\n",
      "loss: 0.375856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527623 \n",
      "\n",
      "Epoch 1633\n",
      "-------------------------------\n",
      "loss: 0.364286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527323 \n",
      "\n",
      "Epoch 1634\n",
      "-------------------------------\n",
      "loss: 0.347107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526165 \n",
      "\n",
      "Epoch 1635\n",
      "-------------------------------\n",
      "loss: 0.370263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524516 \n",
      "\n",
      "Epoch 1636\n",
      "-------------------------------\n",
      "loss: 0.336715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522808 \n",
      "\n",
      "Epoch 1637\n",
      "-------------------------------\n",
      "loss: 0.338686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522005 \n",
      "\n",
      "Epoch 1638\n",
      "-------------------------------\n",
      "loss: 0.357511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521987 \n",
      "\n",
      "Epoch 1639\n",
      "-------------------------------\n",
      "loss: 0.361272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523144 \n",
      "\n",
      "Epoch 1640\n",
      "-------------------------------\n",
      "loss: 0.360880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525266 \n",
      "\n",
      "Epoch 1641\n",
      "-------------------------------\n",
      "loss: 0.339510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527556 \n",
      "\n",
      "Epoch 1642\n",
      "-------------------------------\n",
      "loss: 0.326144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529135 \n",
      "\n",
      "Epoch 1643\n",
      "-------------------------------\n",
      "loss: 0.350726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530042 \n",
      "\n",
      "Epoch 1644\n",
      "-------------------------------\n",
      "loss: 0.369619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527907 \n",
      "\n",
      "Epoch 1645\n",
      "-------------------------------\n",
      "loss: 0.339085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525224 \n",
      "\n",
      "Epoch 1646\n",
      "-------------------------------\n",
      "loss: 0.352251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523686 \n",
      "\n",
      "Epoch 1647\n",
      "-------------------------------\n",
      "loss: 0.350384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524290 \n",
      "\n",
      "Epoch 1648\n",
      "-------------------------------\n",
      "loss: 0.348799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524762 \n",
      "\n",
      "Epoch 1649\n",
      "-------------------------------\n",
      "loss: 0.365478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523826 \n",
      "\n",
      "Epoch 1650\n",
      "-------------------------------\n",
      "loss: 0.332730  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521608 \n",
      "\n",
      "Epoch 1651\n",
      "-------------------------------\n",
      "loss: 0.363454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520451 \n",
      "\n",
      "Epoch 1652\n",
      "-------------------------------\n",
      "loss: 0.335873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520747 \n",
      "\n",
      "Epoch 1653\n",
      "-------------------------------\n",
      "loss: 0.358382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521261 \n",
      "\n",
      "Epoch 1654\n",
      "-------------------------------\n",
      "loss: 0.348859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522495 \n",
      "\n",
      "Epoch 1655\n",
      "-------------------------------\n",
      "loss: 0.344690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524718 \n",
      "\n",
      "Epoch 1656\n",
      "-------------------------------\n",
      "loss: 0.334243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527861 \n",
      "\n",
      "Epoch 1657\n",
      "-------------------------------\n",
      "loss: 0.341589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530888 \n",
      "\n",
      "Epoch 1658\n",
      "-------------------------------\n",
      "loss: 0.350938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532602 \n",
      "\n",
      "Epoch 1659\n",
      "-------------------------------\n",
      "loss: 0.352122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532719 \n",
      "\n",
      "Epoch 1660\n",
      "-------------------------------\n",
      "loss: 0.371016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528496 \n",
      "\n",
      "Epoch 1661\n",
      "-------------------------------\n",
      "loss: 0.348629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525099 \n",
      "\n",
      "Epoch 1662\n",
      "-------------------------------\n",
      "loss: 0.329521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522525 \n",
      "\n",
      "Epoch 1663\n",
      "-------------------------------\n",
      "loss: 0.349102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521623 \n",
      "\n",
      "Epoch 1664\n",
      "-------------------------------\n",
      "loss: 0.333205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521260 \n",
      "\n",
      "Epoch 1665\n",
      "-------------------------------\n",
      "loss: 0.365888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521462 \n",
      "\n",
      "Epoch 1666\n",
      "-------------------------------\n",
      "loss: 0.359244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522828 \n",
      "\n",
      "Epoch 1667\n",
      "-------------------------------\n",
      "loss: 0.348305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524481 \n",
      "\n",
      "Epoch 1668\n",
      "-------------------------------\n",
      "loss: 0.339052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526278 \n",
      "\n",
      "Epoch 1669\n",
      "-------------------------------\n",
      "loss: 0.348392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524765 \n",
      "\n",
      "Epoch 1670\n",
      "-------------------------------\n",
      "loss: 0.335315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522471 \n",
      "\n",
      "Epoch 1671\n",
      "-------------------------------\n",
      "loss: 0.346334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521094 \n",
      "\n",
      "Epoch 1672\n",
      "-------------------------------\n",
      "loss: 0.342091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521829 \n",
      "\n",
      "Epoch 1673\n",
      "-------------------------------\n",
      "loss: 0.347603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522709 \n",
      "\n",
      "Epoch 1674\n",
      "-------------------------------\n",
      "loss: 0.343283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522740 \n",
      "\n",
      "Epoch 1675\n",
      "-------------------------------\n",
      "loss: 0.348708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522993 \n",
      "\n",
      "Epoch 1676\n",
      "-------------------------------\n",
      "loss: 0.339644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524426 \n",
      "\n",
      "Epoch 1677\n",
      "-------------------------------\n",
      "loss: 0.356591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527129 \n",
      "\n",
      "Epoch 1678\n",
      "-------------------------------\n",
      "loss: 0.338837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529388 \n",
      "\n",
      "Epoch 1679\n",
      "-------------------------------\n",
      "loss: 0.337936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527812 \n",
      "\n",
      "Epoch 1680\n",
      "-------------------------------\n",
      "loss: 0.331114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524470 \n",
      "\n",
      "Epoch 1681\n",
      "-------------------------------\n",
      "loss: 0.355845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520582 \n",
      "\n",
      "Epoch 1682\n",
      "-------------------------------\n",
      "loss: 0.341762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519697 \n",
      "\n",
      "Epoch 1683\n",
      "-------------------------------\n",
      "loss: 0.346000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520607 \n",
      "\n",
      "Epoch 1684\n",
      "-------------------------------\n",
      "loss: 0.379926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520198 \n",
      "\n",
      "Epoch 1685\n",
      "-------------------------------\n",
      "loss: 0.370924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519228 \n",
      "\n",
      "Epoch 1686\n",
      "-------------------------------\n",
      "loss: 0.331678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520702 \n",
      "\n",
      "Epoch 1687\n",
      "-------------------------------\n",
      "loss: 0.343664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524236 \n",
      "\n",
      "Epoch 1688\n",
      "-------------------------------\n",
      "loss: 0.356117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525167 \n",
      "\n",
      "Epoch 1689\n",
      "-------------------------------\n",
      "loss: 0.364710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522603 \n",
      "\n",
      "Epoch 1690\n",
      "-------------------------------\n",
      "loss: 0.379346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519397 \n",
      "\n",
      "Epoch 1691\n",
      "-------------------------------\n",
      "loss: 0.360752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518105 \n",
      "\n",
      "Epoch 1692\n",
      "-------------------------------\n",
      "loss: 0.346280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519279 \n",
      "\n",
      "Epoch 1693\n",
      "-------------------------------\n",
      "loss: 0.353803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520890 \n",
      "\n",
      "Epoch 1694\n",
      "-------------------------------\n",
      "loss: 0.342460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522615 \n",
      "\n",
      "Epoch 1695\n",
      "-------------------------------\n",
      "loss: 0.354618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525003 \n",
      "\n",
      "Epoch 1696\n",
      "-------------------------------\n",
      "loss: 0.353010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526701 \n",
      "\n",
      "Epoch 1697\n",
      "-------------------------------\n",
      "loss: 0.343621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527863 \n",
      "\n",
      "Epoch 1698\n",
      "-------------------------------\n",
      "loss: 0.358114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530175 \n",
      "\n",
      "Epoch 1699\n",
      "-------------------------------\n",
      "loss: 0.351727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532300 \n",
      "\n",
      "Epoch 1700\n",
      "-------------------------------\n",
      "loss: 0.354737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531723 \n",
      "\n",
      "Epoch 1701\n",
      "-------------------------------\n",
      "loss: 0.361866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525815 \n",
      "\n",
      "Epoch 1702\n",
      "-------------------------------\n",
      "loss: 0.346941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520841 \n",
      "\n",
      "Epoch 1703\n",
      "-------------------------------\n",
      "loss: 0.347323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519322 \n",
      "\n",
      "Epoch 1704\n",
      "-------------------------------\n",
      "loss: 0.338410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520137 \n",
      "\n",
      "Epoch 1705\n",
      "-------------------------------\n",
      "loss: 0.344971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519775 \n",
      "\n",
      "Epoch 1706\n",
      "-------------------------------\n",
      "loss: 0.335692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518739 \n",
      "\n",
      "Epoch 1707\n",
      "-------------------------------\n",
      "loss: 0.344654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518447 \n",
      "\n",
      "Epoch 1708\n",
      "-------------------------------\n",
      "loss: 0.333207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520128 \n",
      "\n",
      "Epoch 1709\n",
      "-------------------------------\n",
      "loss: 0.350795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522592 \n",
      "\n",
      "Epoch 1710\n",
      "-------------------------------\n",
      "loss: 0.322462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525851 \n",
      "\n",
      "Epoch 1711\n",
      "-------------------------------\n",
      "loss: 0.377736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526435 \n",
      "\n",
      "Epoch 1712\n",
      "-------------------------------\n",
      "loss: 0.337687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524438 \n",
      "\n",
      "Epoch 1713\n",
      "-------------------------------\n",
      "loss: 0.341671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523625 \n",
      "\n",
      "Epoch 1714\n",
      "-------------------------------\n",
      "loss: 0.329725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524962 \n",
      "\n",
      "Epoch 1715\n",
      "-------------------------------\n",
      "loss: 0.370098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527296 \n",
      "\n",
      "Epoch 1716\n",
      "-------------------------------\n",
      "loss: 0.348646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527451 \n",
      "\n",
      "Epoch 1717\n",
      "-------------------------------\n",
      "loss: 0.346287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526031 \n",
      "\n",
      "Epoch 1718\n",
      "-------------------------------\n",
      "loss: 0.339036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525857 \n",
      "\n",
      "Epoch 1719\n",
      "-------------------------------\n",
      "loss: 0.344618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526222 \n",
      "\n",
      "Epoch 1720\n",
      "-------------------------------\n",
      "loss: 0.358856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526101 \n",
      "\n",
      "Epoch 1721\n",
      "-------------------------------\n",
      "loss: 0.343570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524625 \n",
      "\n",
      "Epoch 1722\n",
      "-------------------------------\n",
      "loss: 0.369497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521276 \n",
      "\n",
      "Epoch 1723\n",
      "-------------------------------\n",
      "loss: 0.354787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518581 \n",
      "\n",
      "Epoch 1724\n",
      "-------------------------------\n",
      "loss: 0.343612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518003 \n",
      "\n",
      "Epoch 1725\n",
      "-------------------------------\n",
      "loss: 0.340393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518456 \n",
      "\n",
      "Epoch 1726\n",
      "-------------------------------\n",
      "loss: 0.337238  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.519843 \n",
      "\n",
      "Epoch 1727\n",
      "-------------------------------\n",
      "loss: 0.330904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521512 \n",
      "\n",
      "Epoch 1728\n",
      "-------------------------------\n",
      "loss: 0.336431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523196 \n",
      "\n",
      "Epoch 1729\n",
      "-------------------------------\n",
      "loss: 0.360124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523465 \n",
      "\n",
      "Epoch 1730\n",
      "-------------------------------\n",
      "loss: 0.347341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523918 \n",
      "\n",
      "Epoch 1731\n",
      "-------------------------------\n",
      "loss: 0.337890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523573 \n",
      "\n",
      "Epoch 1732\n",
      "-------------------------------\n",
      "loss: 0.331913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523634 \n",
      "\n",
      "Epoch 1733\n",
      "-------------------------------\n",
      "loss: 0.339670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523432 \n",
      "\n",
      "Epoch 1734\n",
      "-------------------------------\n",
      "loss: 0.333456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523667 \n",
      "\n",
      "Epoch 1735\n",
      "-------------------------------\n",
      "loss: 0.333442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523539 \n",
      "\n",
      "Epoch 1736\n",
      "-------------------------------\n",
      "loss: 0.349558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524503 \n",
      "\n",
      "Epoch 1737\n",
      "-------------------------------\n",
      "loss: 0.335615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526332 \n",
      "\n",
      "Epoch 1738\n",
      "-------------------------------\n",
      "loss: 0.333457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528362 \n",
      "\n",
      "Epoch 1739\n",
      "-------------------------------\n",
      "loss: 0.342713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528823 \n",
      "\n",
      "Epoch 1740\n",
      "-------------------------------\n",
      "loss: 0.341813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527684 \n",
      "\n",
      "Epoch 1741\n",
      "-------------------------------\n",
      "loss: 0.352818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526474 \n",
      "\n",
      "Epoch 1742\n",
      "-------------------------------\n",
      "loss: 0.334796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527294 \n",
      "\n",
      "Epoch 1743\n",
      "-------------------------------\n",
      "loss: 0.341614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529284 \n",
      "\n",
      "Epoch 1744\n",
      "-------------------------------\n",
      "loss: 0.344276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530608 \n",
      "\n",
      "Epoch 1745\n",
      "-------------------------------\n",
      "loss: 0.343974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530763 \n",
      "\n",
      "Epoch 1746\n",
      "-------------------------------\n",
      "loss: 0.366752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529530 \n",
      "\n",
      "Epoch 1747\n",
      "-------------------------------\n",
      "loss: 0.324205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527951 \n",
      "\n",
      "Epoch 1748\n",
      "-------------------------------\n",
      "loss: 0.327043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526038 \n",
      "\n",
      "Epoch 1749\n",
      "-------------------------------\n",
      "loss: 0.364522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523817 \n",
      "\n",
      "Epoch 1750\n",
      "-------------------------------\n",
      "loss: 0.357678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520776 \n",
      "\n",
      "Epoch 1751\n",
      "-------------------------------\n",
      "loss: 0.359025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519637 \n",
      "\n",
      "Epoch 1752\n",
      "-------------------------------\n",
      "loss: 0.346771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519947 \n",
      "\n",
      "Epoch 1753\n",
      "-------------------------------\n",
      "loss: 0.345154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520546 \n",
      "\n",
      "Epoch 1754\n",
      "-------------------------------\n",
      "loss: 0.357326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520467 \n",
      "\n",
      "Epoch 1755\n",
      "-------------------------------\n",
      "loss: 0.353557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521208 \n",
      "\n",
      "Epoch 1756\n",
      "-------------------------------\n",
      "loss: 0.358168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523130 \n",
      "\n",
      "Epoch 1757\n",
      "-------------------------------\n",
      "loss: 0.363847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525480 \n",
      "\n",
      "Epoch 1758\n",
      "-------------------------------\n",
      "loss: 0.349655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526580 \n",
      "\n",
      "Epoch 1759\n",
      "-------------------------------\n",
      "loss: 0.347385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525872 \n",
      "\n",
      "Epoch 1760\n",
      "-------------------------------\n",
      "loss: 0.347488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524016 \n",
      "\n",
      "Epoch 1761\n",
      "-------------------------------\n",
      "loss: 0.345915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522041 \n",
      "\n",
      "Epoch 1762\n",
      "-------------------------------\n",
      "loss: 0.349506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521171 \n",
      "\n",
      "Epoch 1763\n",
      "-------------------------------\n",
      "loss: 0.340141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521157 \n",
      "\n",
      "Epoch 1764\n",
      "-------------------------------\n",
      "loss: 0.313445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520651 \n",
      "\n",
      "Epoch 1765\n",
      "-------------------------------\n",
      "loss: 0.335158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518885 \n",
      "\n",
      "Epoch 1766\n",
      "-------------------------------\n",
      "loss: 0.345062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517949 \n",
      "\n",
      "Epoch 1767\n",
      "-------------------------------\n",
      "loss: 0.350976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518845 \n",
      "\n",
      "Epoch 1768\n",
      "-------------------------------\n",
      "loss: 0.351019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520052 \n",
      "\n",
      "Epoch 1769\n",
      "-------------------------------\n",
      "loss: 0.354192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521558 \n",
      "\n",
      "Epoch 1770\n",
      "-------------------------------\n",
      "loss: 0.347006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521171 \n",
      "\n",
      "Epoch 1771\n",
      "-------------------------------\n",
      "loss: 0.321533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520535 \n",
      "\n",
      "Epoch 1772\n",
      "-------------------------------\n",
      "loss: 0.344220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519330 \n",
      "\n",
      "Epoch 1773\n",
      "-------------------------------\n",
      "loss: 0.348994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519487 \n",
      "\n",
      "Epoch 1774\n",
      "-------------------------------\n",
      "loss: 0.354134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521476 \n",
      "\n",
      "Epoch 1775\n",
      "-------------------------------\n",
      "loss: 0.363748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525648 \n",
      "\n",
      "Epoch 1776\n",
      "-------------------------------\n",
      "loss: 0.346011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528901 \n",
      "\n",
      "Epoch 1777\n",
      "-------------------------------\n",
      "loss: 0.349263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531334 \n",
      "\n",
      "Epoch 1778\n",
      "-------------------------------\n",
      "loss: 0.362066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532313 \n",
      "\n",
      "Epoch 1779\n",
      "-------------------------------\n",
      "loss: 0.343163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531606 \n",
      "\n",
      "Epoch 1780\n",
      "-------------------------------\n",
      "loss: 0.331626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528911 \n",
      "\n",
      "Epoch 1781\n",
      "-------------------------------\n",
      "loss: 0.342924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527596 \n",
      "\n",
      "Epoch 1782\n",
      "-------------------------------\n",
      "loss: 0.369442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526854 \n",
      "\n",
      "Epoch 1783\n",
      "-------------------------------\n",
      "loss: 0.346638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525850 \n",
      "\n",
      "Epoch 1784\n",
      "-------------------------------\n",
      "loss: 0.325999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525156 \n",
      "\n",
      "Epoch 1785\n",
      "-------------------------------\n",
      "loss: 0.357512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524131 \n",
      "\n",
      "Epoch 1786\n",
      "-------------------------------\n",
      "loss: 0.346597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524117 \n",
      "\n",
      "Epoch 1787\n",
      "-------------------------------\n",
      "loss: 0.347310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525186 \n",
      "\n",
      "Epoch 1788\n",
      "-------------------------------\n",
      "loss: 0.348821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526553 \n",
      "\n",
      "Epoch 1789\n",
      "-------------------------------\n",
      "loss: 0.334321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528415 \n",
      "\n",
      "Epoch 1790\n",
      "-------------------------------\n",
      "loss: 0.345152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528730 \n",
      "\n",
      "Epoch 1791\n",
      "-------------------------------\n",
      "loss: 0.340914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528378 \n",
      "\n",
      "Epoch 1792\n",
      "-------------------------------\n",
      "loss: 0.348312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528959 \n",
      "\n",
      "Epoch 1793\n",
      "-------------------------------\n",
      "loss: 0.338944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528768 \n",
      "\n",
      "Epoch 1794\n",
      "-------------------------------\n",
      "loss: 0.334757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529588 \n",
      "\n",
      "Epoch 1795\n",
      "-------------------------------\n",
      "loss: 0.324418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530619 \n",
      "\n",
      "Epoch 1796\n",
      "-------------------------------\n",
      "loss: 0.343072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531140 \n",
      "\n",
      "Epoch 1797\n",
      "-------------------------------\n",
      "loss: 0.337663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529488 \n",
      "\n",
      "Epoch 1798\n",
      "-------------------------------\n",
      "loss: 0.356989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528514 \n",
      "\n",
      "Epoch 1799\n",
      "-------------------------------\n",
      "loss: 0.339874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527341 \n",
      "\n",
      "Epoch 1800\n",
      "-------------------------------\n",
      "loss: 0.341343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525843 \n",
      "\n",
      "Epoch 1801\n",
      "-------------------------------\n",
      "loss: 0.351923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524677 \n",
      "\n",
      "Epoch 1802\n",
      "-------------------------------\n",
      "loss: 0.337078  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.524090 \n",
      "\n",
      "Epoch 1803\n",
      "-------------------------------\n",
      "loss: 0.334843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523825 \n",
      "\n",
      "Epoch 1804\n",
      "-------------------------------\n",
      "loss: 0.339091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523765 \n",
      "\n",
      "Epoch 1805\n",
      "-------------------------------\n",
      "loss: 0.355103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523865 \n",
      "\n",
      "Epoch 1806\n",
      "-------------------------------\n",
      "loss: 0.331295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524535 \n",
      "\n",
      "Epoch 1807\n",
      "-------------------------------\n",
      "loss: 0.337973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524784 \n",
      "\n",
      "Epoch 1808\n",
      "-------------------------------\n",
      "loss: 0.320710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525442 \n",
      "\n",
      "Epoch 1809\n",
      "-------------------------------\n",
      "loss: 0.337510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525423 \n",
      "\n",
      "Epoch 1810\n",
      "-------------------------------\n",
      "loss: 0.358746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524268 \n",
      "\n",
      "Epoch 1811\n",
      "-------------------------------\n",
      "loss: 0.348674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522883 \n",
      "\n",
      "Epoch 1812\n",
      "-------------------------------\n",
      "loss: 0.366236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523054 \n",
      "\n",
      "Epoch 1813\n",
      "-------------------------------\n",
      "loss: 0.337601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523963 \n",
      "\n",
      "Epoch 1814\n",
      "-------------------------------\n",
      "loss: 0.349466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525371 \n",
      "\n",
      "Epoch 1815\n",
      "-------------------------------\n",
      "loss: 0.353542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525969 \n",
      "\n",
      "Epoch 1816\n",
      "-------------------------------\n",
      "loss: 0.355860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526424 \n",
      "\n",
      "Epoch 1817\n",
      "-------------------------------\n",
      "loss: 0.345252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527295 \n",
      "\n",
      "Epoch 1818\n",
      "-------------------------------\n",
      "loss: 0.331334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527636 \n",
      "\n",
      "Epoch 1819\n",
      "-------------------------------\n",
      "loss: 0.348653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527333 \n",
      "\n",
      "Epoch 1820\n",
      "-------------------------------\n",
      "loss: 0.346210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526292 \n",
      "\n",
      "Epoch 1821\n",
      "-------------------------------\n",
      "loss: 0.349276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525585 \n",
      "\n",
      "Epoch 1822\n",
      "-------------------------------\n",
      "loss: 0.334439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524869 \n",
      "\n",
      "Epoch 1823\n",
      "-------------------------------\n",
      "loss: 0.327288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524238 \n",
      "\n",
      "Epoch 1824\n",
      "-------------------------------\n",
      "loss: 0.339509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525082 \n",
      "\n",
      "Epoch 1825\n",
      "-------------------------------\n",
      "loss: 0.356180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525486 \n",
      "\n",
      "Epoch 1826\n",
      "-------------------------------\n",
      "loss: 0.340474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525761 \n",
      "\n",
      "Epoch 1827\n",
      "-------------------------------\n",
      "loss: 0.330889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526287 \n",
      "\n",
      "Epoch 1828\n",
      "-------------------------------\n",
      "loss: 0.338126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525419 \n",
      "\n",
      "Epoch 1829\n",
      "-------------------------------\n",
      "loss: 0.324777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524412 \n",
      "\n",
      "Epoch 1830\n",
      "-------------------------------\n",
      "loss: 0.333849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524280 \n",
      "\n",
      "Epoch 1831\n",
      "-------------------------------\n",
      "loss: 0.337406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523826 \n",
      "\n",
      "Epoch 1832\n",
      "-------------------------------\n",
      "loss: 0.339507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523927 \n",
      "\n",
      "Epoch 1833\n",
      "-------------------------------\n",
      "loss: 0.358324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524092 \n",
      "\n",
      "Epoch 1834\n",
      "-------------------------------\n",
      "loss: 0.325920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523698 \n",
      "\n",
      "Epoch 1835\n",
      "-------------------------------\n",
      "loss: 0.334998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522104 \n",
      "\n",
      "Epoch 1836\n",
      "-------------------------------\n",
      "loss: 0.344430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521149 \n",
      "\n",
      "Epoch 1837\n",
      "-------------------------------\n",
      "loss: 0.366787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520930 \n",
      "\n",
      "Epoch 1838\n",
      "-------------------------------\n",
      "loss: 0.350127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521201 \n",
      "\n",
      "Epoch 1839\n",
      "-------------------------------\n",
      "loss: 0.333181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521321 \n",
      "\n",
      "Epoch 1840\n",
      "-------------------------------\n",
      "loss: 0.358886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521594 \n",
      "\n",
      "Epoch 1841\n",
      "-------------------------------\n",
      "loss: 0.329191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521957 \n",
      "\n",
      "Epoch 1842\n",
      "-------------------------------\n",
      "loss: 0.344141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521563 \n",
      "\n",
      "Epoch 1843\n",
      "-------------------------------\n",
      "loss: 0.346293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521114 \n",
      "\n",
      "Epoch 1844\n",
      "-------------------------------\n",
      "loss: 0.338071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520709 \n",
      "\n",
      "Epoch 1845\n",
      "-------------------------------\n",
      "loss: 0.360758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520625 \n",
      "\n",
      "Epoch 1846\n",
      "-------------------------------\n",
      "loss: 0.340274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519301 \n",
      "\n",
      "Epoch 1847\n",
      "-------------------------------\n",
      "loss: 0.336143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518107 \n",
      "\n",
      "Epoch 1848\n",
      "-------------------------------\n",
      "loss: 0.362206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518618 \n",
      "\n",
      "Epoch 1849\n",
      "-------------------------------\n",
      "loss: 0.363663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520005 \n",
      "\n",
      "Epoch 1850\n",
      "-------------------------------\n",
      "loss: 0.352849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522355 \n",
      "\n",
      "Epoch 1851\n",
      "-------------------------------\n",
      "loss: 0.345868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524745 \n",
      "\n",
      "Epoch 1852\n",
      "-------------------------------\n",
      "loss: 0.321135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526231 \n",
      "\n",
      "Epoch 1853\n",
      "-------------------------------\n",
      "loss: 0.350419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526537 \n",
      "\n",
      "Epoch 1854\n",
      "-------------------------------\n",
      "loss: 0.341109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526140 \n",
      "\n",
      "Epoch 1855\n",
      "-------------------------------\n",
      "loss: 0.321596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525752 \n",
      "\n",
      "Epoch 1856\n",
      "-------------------------------\n",
      "loss: 0.348259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525431 \n",
      "\n",
      "Epoch 1857\n",
      "-------------------------------\n",
      "loss: 0.327418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524673 \n",
      "\n",
      "Epoch 1858\n",
      "-------------------------------\n",
      "loss: 0.340555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524719 \n",
      "\n",
      "Epoch 1859\n",
      "-------------------------------\n",
      "loss: 0.357618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523625 \n",
      "\n",
      "Epoch 1860\n",
      "-------------------------------\n",
      "loss: 0.360919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523243 \n",
      "\n",
      "Epoch 1861\n",
      "-------------------------------\n",
      "loss: 0.345231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523427 \n",
      "\n",
      "Epoch 1862\n",
      "-------------------------------\n",
      "loss: 0.334391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523858 \n",
      "\n",
      "Epoch 1863\n",
      "-------------------------------\n",
      "loss: 0.344223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524185 \n",
      "\n",
      "Epoch 1864\n",
      "-------------------------------\n",
      "loss: 0.348869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524922 \n",
      "\n",
      "Epoch 1865\n",
      "-------------------------------\n",
      "loss: 0.354498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525655 \n",
      "\n",
      "Epoch 1866\n",
      "-------------------------------\n",
      "loss: 0.341315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524778 \n",
      "\n",
      "Epoch 1867\n",
      "-------------------------------\n",
      "loss: 0.326845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523645 \n",
      "\n",
      "Epoch 1868\n",
      "-------------------------------\n",
      "loss: 0.344465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522359 \n",
      "\n",
      "Epoch 1869\n",
      "-------------------------------\n",
      "loss: 0.346154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521566 \n",
      "\n",
      "Epoch 1870\n",
      "-------------------------------\n",
      "loss: 0.327661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522038 \n",
      "\n",
      "Epoch 1871\n",
      "-------------------------------\n",
      "loss: 0.333078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522978 \n",
      "\n",
      "Epoch 1872\n",
      "-------------------------------\n",
      "loss: 0.343845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523736 \n",
      "\n",
      "Epoch 1873\n",
      "-------------------------------\n",
      "loss: 0.333975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525088 \n",
      "\n",
      "Epoch 1874\n",
      "-------------------------------\n",
      "loss: 0.353043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525730 \n",
      "\n",
      "Epoch 1875\n",
      "-------------------------------\n",
      "loss: 0.338627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525979 \n",
      "\n",
      "Epoch 1876\n",
      "-------------------------------\n",
      "loss: 0.324571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525908 \n",
      "\n",
      "Epoch 1877\n",
      "-------------------------------\n",
      "loss: 0.352792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526345 \n",
      "\n",
      "Epoch 1878\n",
      "-------------------------------\n",
      "loss: 0.348979  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.527040 \n",
      "\n",
      "Epoch 1879\n",
      "-------------------------------\n",
      "loss: 0.326071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527524 \n",
      "\n",
      "Epoch 1880\n",
      "-------------------------------\n",
      "loss: 0.337683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527720 \n",
      "\n",
      "Epoch 1881\n",
      "-------------------------------\n",
      "loss: 0.344023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527782 \n",
      "\n",
      "Epoch 1882\n",
      "-------------------------------\n",
      "loss: 0.334308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528759 \n",
      "\n",
      "Epoch 1883\n",
      "-------------------------------\n",
      "loss: 0.347866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529269 \n",
      "\n",
      "Epoch 1884\n",
      "-------------------------------\n",
      "loss: 0.334544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528762 \n",
      "\n",
      "Epoch 1885\n",
      "-------------------------------\n",
      "loss: 0.334568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527911 \n",
      "\n",
      "Epoch 1886\n",
      "-------------------------------\n",
      "loss: 0.336582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526583 \n",
      "\n",
      "Epoch 1887\n",
      "-------------------------------\n",
      "loss: 0.343745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526540 \n",
      "\n",
      "Epoch 1888\n",
      "-------------------------------\n",
      "loss: 0.339126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527927 \n",
      "\n",
      "Epoch 1889\n",
      "-------------------------------\n",
      "loss: 0.350411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529416 \n",
      "\n",
      "Epoch 1890\n",
      "-------------------------------\n",
      "loss: 0.345057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529473 \n",
      "\n",
      "Epoch 1891\n",
      "-------------------------------\n",
      "loss: 0.346623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528329 \n",
      "\n",
      "Epoch 1892\n",
      "-------------------------------\n",
      "loss: 0.340224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526230 \n",
      "\n",
      "Epoch 1893\n",
      "-------------------------------\n",
      "loss: 0.334794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525996 \n",
      "\n",
      "Epoch 1894\n",
      "-------------------------------\n",
      "loss: 0.332865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526207 \n",
      "\n",
      "Epoch 1895\n",
      "-------------------------------\n",
      "loss: 0.355473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526783 \n",
      "\n",
      "Epoch 1896\n",
      "-------------------------------\n",
      "loss: 0.317917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526320 \n",
      "\n",
      "Epoch 1897\n",
      "-------------------------------\n",
      "loss: 0.326688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525904 \n",
      "\n",
      "Epoch 1898\n",
      "-------------------------------\n",
      "loss: 0.325342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522402 \n",
      "\n",
      "Epoch 1899\n",
      "-------------------------------\n",
      "loss: 0.352716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520076 \n",
      "\n",
      "Epoch 1900\n",
      "-------------------------------\n",
      "loss: 0.335050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519706 \n",
      "\n",
      "Epoch 1901\n",
      "-------------------------------\n",
      "loss: 0.358016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520283 \n",
      "\n",
      "Epoch 1902\n",
      "-------------------------------\n",
      "loss: 0.333628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520773 \n",
      "\n",
      "Epoch 1903\n",
      "-------------------------------\n",
      "loss: 0.326544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521475 \n",
      "\n",
      "Epoch 1904\n",
      "-------------------------------\n",
      "loss: 0.340186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522060 \n",
      "\n",
      "Epoch 1905\n",
      "-------------------------------\n",
      "loss: 0.330790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522540 \n",
      "\n",
      "Epoch 1906\n",
      "-------------------------------\n",
      "loss: 0.337643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522283 \n",
      "\n",
      "Epoch 1907\n",
      "-------------------------------\n",
      "loss: 0.318526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521454 \n",
      "\n",
      "Epoch 1908\n",
      "-------------------------------\n",
      "loss: 0.321983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520511 \n",
      "\n",
      "Epoch 1909\n",
      "-------------------------------\n",
      "loss: 0.321062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520577 \n",
      "\n",
      "Epoch 1910\n",
      "-------------------------------\n",
      "loss: 0.330220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520355 \n",
      "\n",
      "Epoch 1911\n",
      "-------------------------------\n",
      "loss: 0.338394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520837 \n",
      "\n",
      "Epoch 1912\n",
      "-------------------------------\n",
      "loss: 0.328191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521910 \n",
      "\n",
      "Epoch 1913\n",
      "-------------------------------\n",
      "loss: 0.319725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523294 \n",
      "\n",
      "Epoch 1914\n",
      "-------------------------------\n",
      "loss: 0.341462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524259 \n",
      "\n",
      "Epoch 1915\n",
      "-------------------------------\n",
      "loss: 0.343309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524883 \n",
      "\n",
      "Epoch 1916\n",
      "-------------------------------\n",
      "loss: 0.326909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526041 \n",
      "\n",
      "Epoch 1917\n",
      "-------------------------------\n",
      "loss: 0.331775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525638 \n",
      "\n",
      "Epoch 1918\n",
      "-------------------------------\n",
      "loss: 0.320093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524286 \n",
      "\n",
      "Epoch 1919\n",
      "-------------------------------\n",
      "loss: 0.329613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523054 \n",
      "\n",
      "Epoch 1920\n",
      "-------------------------------\n",
      "loss: 0.352806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523615 \n",
      "\n",
      "Epoch 1921\n",
      "-------------------------------\n",
      "loss: 0.327434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524813 \n",
      "\n",
      "Epoch 1922\n",
      "-------------------------------\n",
      "loss: 0.342097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526894 \n",
      "\n",
      "Epoch 1923\n",
      "-------------------------------\n",
      "loss: 0.332452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526715 \n",
      "\n",
      "Epoch 1924\n",
      "-------------------------------\n",
      "loss: 0.355451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524742 \n",
      "\n",
      "Epoch 1925\n",
      "-------------------------------\n",
      "loss: 0.321528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522910 \n",
      "\n",
      "Epoch 1926\n",
      "-------------------------------\n",
      "loss: 0.334740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521832 \n",
      "\n",
      "Epoch 1927\n",
      "-------------------------------\n",
      "loss: 0.338814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522371 \n",
      "\n",
      "Epoch 1928\n",
      "-------------------------------\n",
      "loss: 0.352499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524530 \n",
      "\n",
      "Epoch 1929\n",
      "-------------------------------\n",
      "loss: 0.326080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527488 \n",
      "\n",
      "Epoch 1930\n",
      "-------------------------------\n",
      "loss: 0.322488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529507 \n",
      "\n",
      "Epoch 1931\n",
      "-------------------------------\n",
      "loss: 0.316466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530245 \n",
      "\n",
      "Epoch 1932\n",
      "-------------------------------\n",
      "loss: 0.326237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529336 \n",
      "\n",
      "Epoch 1933\n",
      "-------------------------------\n",
      "loss: 0.343040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528504 \n",
      "\n",
      "Epoch 1934\n",
      "-------------------------------\n",
      "loss: 0.326872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526420 \n",
      "\n",
      "Epoch 1935\n",
      "-------------------------------\n",
      "loss: 0.331029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524114 \n",
      "\n",
      "Epoch 1936\n",
      "-------------------------------\n",
      "loss: 0.339937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522748 \n",
      "\n",
      "Epoch 1937\n",
      "-------------------------------\n",
      "loss: 0.334512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521980 \n",
      "\n",
      "Epoch 1938\n",
      "-------------------------------\n",
      "loss: 0.329594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522273 \n",
      "\n",
      "Epoch 1939\n",
      "-------------------------------\n",
      "loss: 0.328888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522545 \n",
      "\n",
      "Epoch 1940\n",
      "-------------------------------\n",
      "loss: 0.328044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522739 \n",
      "\n",
      "Epoch 1941\n",
      "-------------------------------\n",
      "loss: 0.345289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523665 \n",
      "\n",
      "Epoch 1942\n",
      "-------------------------------\n",
      "loss: 0.356744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526204 \n",
      "\n",
      "Epoch 1943\n",
      "-------------------------------\n",
      "loss: 0.339955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530466 \n",
      "\n",
      "Epoch 1944\n",
      "-------------------------------\n",
      "loss: 0.338149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533066 \n",
      "\n",
      "Epoch 1945\n",
      "-------------------------------\n",
      "loss: 0.356816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532866 \n",
      "\n",
      "Epoch 1946\n",
      "-------------------------------\n",
      "loss: 0.334520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530947 \n",
      "\n",
      "Epoch 1947\n",
      "-------------------------------\n",
      "loss: 0.338691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527908 \n",
      "\n",
      "Epoch 1948\n",
      "-------------------------------\n",
      "loss: 0.323957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526017 \n",
      "\n",
      "Epoch 1949\n",
      "-------------------------------\n",
      "loss: 0.332185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525640 \n",
      "\n",
      "Epoch 1950\n",
      "-------------------------------\n",
      "loss: 0.317324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525586 \n",
      "\n",
      "Epoch 1951\n",
      "-------------------------------\n",
      "loss: 0.334806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525173 \n",
      "\n",
      "Epoch 1952\n",
      "-------------------------------\n",
      "loss: 0.359035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524294 \n",
      "\n",
      "Epoch 1953\n",
      "-------------------------------\n",
      "loss: 0.332385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524923 \n",
      "\n",
      "Epoch 1954\n",
      "-------------------------------\n",
      "loss: 0.332519  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.526819 \n",
      "\n",
      "Epoch 1955\n",
      "-------------------------------\n",
      "loss: 0.340619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527543 \n",
      "\n",
      "Epoch 1956\n",
      "-------------------------------\n",
      "loss: 0.322793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525308 \n",
      "\n",
      "Epoch 1957\n",
      "-------------------------------\n",
      "loss: 0.334560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522284 \n",
      "\n",
      "Epoch 1958\n",
      "-------------------------------\n",
      "loss: 0.317195  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521181 \n",
      "\n",
      "Epoch 1959\n",
      "-------------------------------\n",
      "loss: 0.337155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521125 \n",
      "\n",
      "Epoch 1960\n",
      "-------------------------------\n",
      "loss: 0.346272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521602 \n",
      "\n",
      "Epoch 1961\n",
      "-------------------------------\n",
      "loss: 0.342653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521124 \n",
      "\n",
      "Epoch 1962\n",
      "-------------------------------\n",
      "loss: 0.329896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520692 \n",
      "\n",
      "Epoch 1963\n",
      "-------------------------------\n",
      "loss: 0.324226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520435 \n",
      "\n",
      "Epoch 1964\n",
      "-------------------------------\n",
      "loss: 0.310393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520439 \n",
      "\n",
      "Epoch 1965\n",
      "-------------------------------\n",
      "loss: 0.303992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521599 \n",
      "\n",
      "Epoch 1966\n",
      "-------------------------------\n",
      "loss: 0.323945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522216 \n",
      "\n",
      "Epoch 1967\n",
      "-------------------------------\n",
      "loss: 0.310391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521551 \n",
      "\n",
      "Epoch 1968\n",
      "-------------------------------\n",
      "loss: 0.338025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521274 \n",
      "\n",
      "Epoch 1969\n",
      "-------------------------------\n",
      "loss: 0.339004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521185 \n",
      "\n",
      "Epoch 1970\n",
      "-------------------------------\n",
      "loss: 0.311776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521186 \n",
      "\n",
      "Epoch 1971\n",
      "-------------------------------\n",
      "loss: 0.335193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521425 \n",
      "\n",
      "Epoch 1972\n",
      "-------------------------------\n",
      "loss: 0.338043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521417 \n",
      "\n",
      "Epoch 1973\n",
      "-------------------------------\n",
      "loss: 0.328821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521304 \n",
      "\n",
      "Epoch 1974\n",
      "-------------------------------\n",
      "loss: 0.357946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521590 \n",
      "\n",
      "Epoch 1975\n",
      "-------------------------------\n",
      "loss: 0.341256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521796 \n",
      "\n",
      "Epoch 1976\n",
      "-------------------------------\n",
      "loss: 0.329868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521708 \n",
      "\n",
      "Epoch 1977\n",
      "-------------------------------\n",
      "loss: 0.328122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521842 \n",
      "\n",
      "Epoch 1978\n",
      "-------------------------------\n",
      "loss: 0.337149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522633 \n",
      "\n",
      "Epoch 1979\n",
      "-------------------------------\n",
      "loss: 0.339938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523706 \n",
      "\n",
      "Epoch 1980\n",
      "-------------------------------\n",
      "loss: 0.321938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524819 \n",
      "\n",
      "Epoch 1981\n",
      "-------------------------------\n",
      "loss: 0.337231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525050 \n",
      "\n",
      "Epoch 1982\n",
      "-------------------------------\n",
      "loss: 0.332021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523533 \n",
      "\n",
      "Epoch 1983\n",
      "-------------------------------\n",
      "loss: 0.326234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522176 \n",
      "\n",
      "Epoch 1984\n",
      "-------------------------------\n",
      "loss: 0.331655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521756 \n",
      "\n",
      "Epoch 1985\n",
      "-------------------------------\n",
      "loss: 0.318559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522132 \n",
      "\n",
      "Epoch 1986\n",
      "-------------------------------\n",
      "loss: 0.342107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522187 \n",
      "\n",
      "Epoch 1987\n",
      "-------------------------------\n",
      "loss: 0.344942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522227 \n",
      "\n",
      "Epoch 1988\n",
      "-------------------------------\n",
      "loss: 0.339314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522820 \n",
      "\n",
      "Epoch 1989\n",
      "-------------------------------\n",
      "loss: 0.337979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524121 \n",
      "\n",
      "Epoch 1990\n",
      "-------------------------------\n",
      "loss: 0.326086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526009 \n",
      "\n",
      "Epoch 1991\n",
      "-------------------------------\n",
      "loss: 0.335272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527399 \n",
      "\n",
      "Epoch 1992\n",
      "-------------------------------\n",
      "loss: 0.337337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526555 \n",
      "\n",
      "Epoch 1993\n",
      "-------------------------------\n",
      "loss: 0.352134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524952 \n",
      "\n",
      "Epoch 1994\n",
      "-------------------------------\n",
      "loss: 0.340538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524424 \n",
      "\n",
      "Epoch 1995\n",
      "-------------------------------\n",
      "loss: 0.326248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524758 \n",
      "\n",
      "Epoch 1996\n",
      "-------------------------------\n",
      "loss: 0.324519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524819 \n",
      "\n",
      "Epoch 1997\n",
      "-------------------------------\n",
      "loss: 0.340242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523897 \n",
      "\n",
      "Epoch 1998\n",
      "-------------------------------\n",
      "loss: 0.343205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523357 \n",
      "\n",
      "Epoch 1999\n",
      "-------------------------------\n",
      "loss: 0.323388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523445 \n",
      "\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "loss: 0.314253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524095 \n",
      "\n",
      "Epoch 2001\n",
      "-------------------------------\n",
      "loss: 0.335322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524736 \n",
      "\n",
      "Epoch 2002\n",
      "-------------------------------\n",
      "loss: 0.360122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525599 \n",
      "\n",
      "Epoch 2003\n",
      "-------------------------------\n",
      "loss: 0.333489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525442 \n",
      "\n",
      "Epoch 2004\n",
      "-------------------------------\n",
      "loss: 0.339363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523976 \n",
      "\n",
      "Epoch 2005\n",
      "-------------------------------\n",
      "loss: 0.327981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521631 \n",
      "\n",
      "Epoch 2006\n",
      "-------------------------------\n",
      "loss: 0.326723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518833 \n",
      "\n",
      "Epoch 2007\n",
      "-------------------------------\n",
      "loss: 0.316964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518174 \n",
      "\n",
      "Epoch 2008\n",
      "-------------------------------\n",
      "loss: 0.346605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518411 \n",
      "\n",
      "Epoch 2009\n",
      "-------------------------------\n",
      "loss: 0.333209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518691 \n",
      "\n",
      "Epoch 2010\n",
      "-------------------------------\n",
      "loss: 0.344689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518981 \n",
      "\n",
      "Epoch 2011\n",
      "-------------------------------\n",
      "loss: 0.334418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520258 \n",
      "\n",
      "Epoch 2012\n",
      "-------------------------------\n",
      "loss: 0.323400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521761 \n",
      "\n",
      "Epoch 2013\n",
      "-------------------------------\n",
      "loss: 0.311312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522182 \n",
      "\n",
      "Epoch 2014\n",
      "-------------------------------\n",
      "loss: 0.342563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522666 \n",
      "\n",
      "Epoch 2015\n",
      "-------------------------------\n",
      "loss: 0.345553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522405 \n",
      "\n",
      "Epoch 2016\n",
      "-------------------------------\n",
      "loss: 0.329136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522145 \n",
      "\n",
      "Epoch 2017\n",
      "-------------------------------\n",
      "loss: 0.336353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521660 \n",
      "\n",
      "Epoch 2018\n",
      "-------------------------------\n",
      "loss: 0.323727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522782 \n",
      "\n",
      "Epoch 2019\n",
      "-------------------------------\n",
      "loss: 0.329491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523978 \n",
      "\n",
      "Epoch 2020\n",
      "-------------------------------\n",
      "loss: 0.344632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524400 \n",
      "\n",
      "Epoch 2021\n",
      "-------------------------------\n",
      "loss: 0.317613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525012 \n",
      "\n",
      "Epoch 2022\n",
      "-------------------------------\n",
      "loss: 0.325444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526899 \n",
      "\n",
      "Epoch 2023\n",
      "-------------------------------\n",
      "loss: 0.331878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527930 \n",
      "\n",
      "Epoch 2024\n",
      "-------------------------------\n",
      "loss: 0.339866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526941 \n",
      "\n",
      "Epoch 2025\n",
      "-------------------------------\n",
      "loss: 0.333673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525368 \n",
      "\n",
      "Epoch 2026\n",
      "-------------------------------\n",
      "loss: 0.327398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524105 \n",
      "\n",
      "Epoch 2027\n",
      "-------------------------------\n",
      "loss: 0.333918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522898 \n",
      "\n",
      "Epoch 2028\n",
      "-------------------------------\n",
      "loss: 0.327977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521592 \n",
      "\n",
      "Epoch 2029\n",
      "-------------------------------\n",
      "loss: 0.329614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520125 \n",
      "\n",
      "Epoch 2030\n",
      "-------------------------------\n",
      "loss: 0.338252  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.519292 \n",
      "\n",
      "Epoch 2031\n",
      "-------------------------------\n",
      "loss: 0.345458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519529 \n",
      "\n",
      "Epoch 2032\n",
      "-------------------------------\n",
      "loss: 0.325406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520213 \n",
      "\n",
      "Epoch 2033\n",
      "-------------------------------\n",
      "loss: 0.319388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522030 \n",
      "\n",
      "Epoch 2034\n",
      "-------------------------------\n",
      "loss: 0.326804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523232 \n",
      "\n",
      "Epoch 2035\n",
      "-------------------------------\n",
      "loss: 0.335707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522389 \n",
      "\n",
      "Epoch 2036\n",
      "-------------------------------\n",
      "loss: 0.341364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521274 \n",
      "\n",
      "Epoch 2037\n",
      "-------------------------------\n",
      "loss: 0.338120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520354 \n",
      "\n",
      "Epoch 2038\n",
      "-------------------------------\n",
      "loss: 0.351244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519798 \n",
      "\n",
      "Epoch 2039\n",
      "-------------------------------\n",
      "loss: 0.316138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519063 \n",
      "\n",
      "Epoch 2040\n",
      "-------------------------------\n",
      "loss: 0.318853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519166 \n",
      "\n",
      "Epoch 2041\n",
      "-------------------------------\n",
      "loss: 0.311680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518879 \n",
      "\n",
      "Epoch 2042\n",
      "-------------------------------\n",
      "loss: 0.338946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518511 \n",
      "\n",
      "Epoch 2043\n",
      "-------------------------------\n",
      "loss: 0.320683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518864 \n",
      "\n",
      "Epoch 2044\n",
      "-------------------------------\n",
      "loss: 0.328670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518675 \n",
      "\n",
      "Epoch 2045\n",
      "-------------------------------\n",
      "loss: 0.332608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518511 \n",
      "\n",
      "Epoch 2046\n",
      "-------------------------------\n",
      "loss: 0.309319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518654 \n",
      "\n",
      "Epoch 2047\n",
      "-------------------------------\n",
      "loss: 0.319458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518714 \n",
      "\n",
      "Epoch 2048\n",
      "-------------------------------\n",
      "loss: 0.338634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518153 \n",
      "\n",
      "Epoch 2049\n",
      "-------------------------------\n",
      "loss: 0.322268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518056 \n",
      "\n",
      "Epoch 2050\n",
      "-------------------------------\n",
      "loss: 0.315346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518245 \n",
      "\n",
      "Epoch 2051\n",
      "-------------------------------\n",
      "loss: 0.318658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519195 \n",
      "\n",
      "Epoch 2052\n",
      "-------------------------------\n",
      "loss: 0.332321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520387 \n",
      "\n",
      "Epoch 2053\n",
      "-------------------------------\n",
      "loss: 0.329879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521086 \n",
      "\n",
      "Epoch 2054\n",
      "-------------------------------\n",
      "loss: 0.317381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521561 \n",
      "\n",
      "Epoch 2055\n",
      "-------------------------------\n",
      "loss: 0.316593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521534 \n",
      "\n",
      "Epoch 2056\n",
      "-------------------------------\n",
      "loss: 0.343773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521155 \n",
      "\n",
      "Epoch 2057\n",
      "-------------------------------\n",
      "loss: 0.337926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520748 \n",
      "\n",
      "Epoch 2058\n",
      "-------------------------------\n",
      "loss: 0.318800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520349 \n",
      "\n",
      "Epoch 2059\n",
      "-------------------------------\n",
      "loss: 0.331089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520555 \n",
      "\n",
      "Epoch 2060\n",
      "-------------------------------\n",
      "loss: 0.352552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521635 \n",
      "\n",
      "Epoch 2061\n",
      "-------------------------------\n",
      "loss: 0.331685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523508 \n",
      "\n",
      "Epoch 2062\n",
      "-------------------------------\n",
      "loss: 0.313113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525351 \n",
      "\n",
      "Epoch 2063\n",
      "-------------------------------\n",
      "loss: 0.330770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527786 \n",
      "\n",
      "Epoch 2064\n",
      "-------------------------------\n",
      "loss: 0.344693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529615 \n",
      "\n",
      "Epoch 2065\n",
      "-------------------------------\n",
      "loss: 0.323989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530175 \n",
      "\n",
      "Epoch 2066\n",
      "-------------------------------\n",
      "loss: 0.321911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530204 \n",
      "\n",
      "Epoch 2067\n",
      "-------------------------------\n",
      "loss: 0.346678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529622 \n",
      "\n",
      "Epoch 2068\n",
      "-------------------------------\n",
      "loss: 0.331633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527797 \n",
      "\n",
      "Epoch 2069\n",
      "-------------------------------\n",
      "loss: 0.326743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525333 \n",
      "\n",
      "Epoch 2070\n",
      "-------------------------------\n",
      "loss: 0.336738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523323 \n",
      "\n",
      "Epoch 2071\n",
      "-------------------------------\n",
      "loss: 0.326069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522326 \n",
      "\n",
      "Epoch 2072\n",
      "-------------------------------\n",
      "loss: 0.347584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521597 \n",
      "\n",
      "Epoch 2073\n",
      "-------------------------------\n",
      "loss: 0.319722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521439 \n",
      "\n",
      "Epoch 2074\n",
      "-------------------------------\n",
      "loss: 0.336013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521423 \n",
      "\n",
      "Epoch 2075\n",
      "-------------------------------\n",
      "loss: 0.319918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521000 \n",
      "\n",
      "Epoch 2076\n",
      "-------------------------------\n",
      "loss: 0.338463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520185 \n",
      "\n",
      "Epoch 2077\n",
      "-------------------------------\n",
      "loss: 0.317538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520216 \n",
      "\n",
      "Epoch 2078\n",
      "-------------------------------\n",
      "loss: 0.332771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521629 \n",
      "\n",
      "Epoch 2079\n",
      "-------------------------------\n",
      "loss: 0.326277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521511 \n",
      "\n",
      "Epoch 2080\n",
      "-------------------------------\n",
      "loss: 0.323573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521035 \n",
      "\n",
      "Epoch 2081\n",
      "-------------------------------\n",
      "loss: 0.340349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519370 \n",
      "\n",
      "Epoch 2082\n",
      "-------------------------------\n",
      "loss: 0.326086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517422 \n",
      "\n",
      "Epoch 2083\n",
      "-------------------------------\n",
      "loss: 0.311065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516749 \n",
      "\n",
      "Epoch 2084\n",
      "-------------------------------\n",
      "loss: 0.332667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515929 \n",
      "\n",
      "Epoch 2085\n",
      "-------------------------------\n",
      "loss: 0.330863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515685 \n",
      "\n",
      "Epoch 2086\n",
      "-------------------------------\n",
      "loss: 0.351023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515781 \n",
      "\n",
      "Epoch 2087\n",
      "-------------------------------\n",
      "loss: 0.331774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517401 \n",
      "\n",
      "Epoch 2088\n",
      "-------------------------------\n",
      "loss: 0.334390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519882 \n",
      "\n",
      "Epoch 2089\n",
      "-------------------------------\n",
      "loss: 0.346223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522383 \n",
      "\n",
      "Epoch 2090\n",
      "-------------------------------\n",
      "loss: 0.346790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521879 \n",
      "\n",
      "Epoch 2091\n",
      "-------------------------------\n",
      "loss: 0.330917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520094 \n",
      "\n",
      "Epoch 2092\n",
      "-------------------------------\n",
      "loss: 0.327438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519260 \n",
      "\n",
      "Epoch 2093\n",
      "-------------------------------\n",
      "loss: 0.328446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520427 \n",
      "\n",
      "Epoch 2094\n",
      "-------------------------------\n",
      "loss: 0.337521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521724 \n",
      "\n",
      "Epoch 2095\n",
      "-------------------------------\n",
      "loss: 0.329590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521042 \n",
      "\n",
      "Epoch 2096\n",
      "-------------------------------\n",
      "loss: 0.319466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520206 \n",
      "\n",
      "Epoch 2097\n",
      "-------------------------------\n",
      "loss: 0.337738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520597 \n",
      "\n",
      "Epoch 2098\n",
      "-------------------------------\n",
      "loss: 0.326157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521895 \n",
      "\n",
      "Epoch 2099\n",
      "-------------------------------\n",
      "loss: 0.324079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523403 \n",
      "\n",
      "Epoch 2100\n",
      "-------------------------------\n",
      "loss: 0.342312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522469 \n",
      "\n",
      "Epoch 2101\n",
      "-------------------------------\n",
      "loss: 0.334750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520025 \n",
      "\n",
      "Epoch 2102\n",
      "-------------------------------\n",
      "loss: 0.352393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516682 \n",
      "\n",
      "Epoch 2103\n",
      "-------------------------------\n",
      "loss: 0.303998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516117 \n",
      "\n",
      "Epoch 2104\n",
      "-------------------------------\n",
      "loss: 0.326053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517209 \n",
      "\n",
      "Epoch 2105\n",
      "-------------------------------\n",
      "loss: 0.350924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517515 \n",
      "\n",
      "Epoch 2106\n",
      "-------------------------------\n",
      "loss: 0.337352  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.516362 \n",
      "\n",
      "Epoch 2107\n",
      "-------------------------------\n",
      "loss: 0.344774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516425 \n",
      "\n",
      "Epoch 2108\n",
      "-------------------------------\n",
      "loss: 0.337854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518445 \n",
      "\n",
      "Epoch 2109\n",
      "-------------------------------\n",
      "loss: 0.327861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520348 \n",
      "\n",
      "Epoch 2110\n",
      "-------------------------------\n",
      "loss: 0.322063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518802 \n",
      "\n",
      "Epoch 2111\n",
      "-------------------------------\n",
      "loss: 0.329672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516738 \n",
      "\n",
      "Epoch 2112\n",
      "-------------------------------\n",
      "loss: 0.324884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516040 \n",
      "\n",
      "Epoch 2113\n",
      "-------------------------------\n",
      "loss: 0.321835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516493 \n",
      "\n",
      "Epoch 2114\n",
      "-------------------------------\n",
      "loss: 0.316159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517347 \n",
      "\n",
      "Epoch 2115\n",
      "-------------------------------\n",
      "loss: 0.351968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518584 \n",
      "\n",
      "Epoch 2116\n",
      "-------------------------------\n",
      "loss: 0.325643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520347 \n",
      "\n",
      "Epoch 2117\n",
      "-------------------------------\n",
      "loss: 0.319716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522009 \n",
      "\n",
      "Epoch 2118\n",
      "-------------------------------\n",
      "loss: 0.323563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522448 \n",
      "\n",
      "Epoch 2119\n",
      "-------------------------------\n",
      "loss: 0.350003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522438 \n",
      "\n",
      "Epoch 2120\n",
      "-------------------------------\n",
      "loss: 0.329808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522302 \n",
      "\n",
      "Epoch 2121\n",
      "-------------------------------\n",
      "loss: 0.321824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523012 \n",
      "\n",
      "Epoch 2122\n",
      "-------------------------------\n",
      "loss: 0.320888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524003 \n",
      "\n",
      "Epoch 2123\n",
      "-------------------------------\n",
      "loss: 0.329036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524903 \n",
      "\n",
      "Epoch 2124\n",
      "-------------------------------\n",
      "loss: 0.323826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526594 \n",
      "\n",
      "Epoch 2125\n",
      "-------------------------------\n",
      "loss: 0.329367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527947 \n",
      "\n",
      "Epoch 2126\n",
      "-------------------------------\n",
      "loss: 0.315356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527782 \n",
      "\n",
      "Epoch 2127\n",
      "-------------------------------\n",
      "loss: 0.317652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526615 \n",
      "\n",
      "Epoch 2128\n",
      "-------------------------------\n",
      "loss: 0.320177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524131 \n",
      "\n",
      "Epoch 2129\n",
      "-------------------------------\n",
      "loss: 0.340600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522702 \n",
      "\n",
      "Epoch 2130\n",
      "-------------------------------\n",
      "loss: 0.339156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521950 \n",
      "\n",
      "Epoch 2131\n",
      "-------------------------------\n",
      "loss: 0.325460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522504 \n",
      "\n",
      "Epoch 2132\n",
      "-------------------------------\n",
      "loss: 0.326136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523344 \n",
      "\n",
      "Epoch 2133\n",
      "-------------------------------\n",
      "loss: 0.330035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523824 \n",
      "\n",
      "Epoch 2134\n",
      "-------------------------------\n",
      "loss: 0.332584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524806 \n",
      "\n",
      "Epoch 2135\n",
      "-------------------------------\n",
      "loss: 0.322500  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524999 \n",
      "\n",
      "Epoch 2136\n",
      "-------------------------------\n",
      "loss: 0.326777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525315 \n",
      "\n",
      "Epoch 2137\n",
      "-------------------------------\n",
      "loss: 0.321237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524628 \n",
      "\n",
      "Epoch 2138\n",
      "-------------------------------\n",
      "loss: 0.341985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523869 \n",
      "\n",
      "Epoch 2139\n",
      "-------------------------------\n",
      "loss: 0.330723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523901 \n",
      "\n",
      "Epoch 2140\n",
      "-------------------------------\n",
      "loss: 0.337367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523982 \n",
      "\n",
      "Epoch 2141\n",
      "-------------------------------\n",
      "loss: 0.339578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524674 \n",
      "\n",
      "Epoch 2142\n",
      "-------------------------------\n",
      "loss: 0.330621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523781 \n",
      "\n",
      "Epoch 2143\n",
      "-------------------------------\n",
      "loss: 0.321218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521867 \n",
      "\n",
      "Epoch 2144\n",
      "-------------------------------\n",
      "loss: 0.333536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520892 \n",
      "\n",
      "Epoch 2145\n",
      "-------------------------------\n",
      "loss: 0.323090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521624 \n",
      "\n",
      "Epoch 2146\n",
      "-------------------------------\n",
      "loss: 0.304007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523778 \n",
      "\n",
      "Epoch 2147\n",
      "-------------------------------\n",
      "loss: 0.340913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526106 \n",
      "\n",
      "Epoch 2148\n",
      "-------------------------------\n",
      "loss: 0.330661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529136 \n",
      "\n",
      "Epoch 2149\n",
      "-------------------------------\n",
      "loss: 0.329127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530626 \n",
      "\n",
      "Epoch 2150\n",
      "-------------------------------\n",
      "loss: 0.342676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532307 \n",
      "\n",
      "Epoch 2151\n",
      "-------------------------------\n",
      "loss: 0.335115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530979 \n",
      "\n",
      "Epoch 2152\n",
      "-------------------------------\n",
      "loss: 0.323283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529693 \n",
      "\n",
      "Epoch 2153\n",
      "-------------------------------\n",
      "loss: 0.343224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526826 \n",
      "\n",
      "Epoch 2154\n",
      "-------------------------------\n",
      "loss: 0.317302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524030 \n",
      "\n",
      "Epoch 2155\n",
      "-------------------------------\n",
      "loss: 0.330053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522753 \n",
      "\n",
      "Epoch 2156\n",
      "-------------------------------\n",
      "loss: 0.323930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522874 \n",
      "\n",
      "Epoch 2157\n",
      "-------------------------------\n",
      "loss: 0.329311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522714 \n",
      "\n",
      "Epoch 2158\n",
      "-------------------------------\n",
      "loss: 0.311784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522795 \n",
      "\n",
      "Epoch 2159\n",
      "-------------------------------\n",
      "loss: 0.303715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524035 \n",
      "\n",
      "Epoch 2160\n",
      "-------------------------------\n",
      "loss: 0.321630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525484 \n",
      "\n",
      "Epoch 2161\n",
      "-------------------------------\n",
      "loss: 0.326784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527501 \n",
      "\n",
      "Epoch 2162\n",
      "-------------------------------\n",
      "loss: 0.319904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527079 \n",
      "\n",
      "Epoch 2163\n",
      "-------------------------------\n",
      "loss: 0.314623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526134 \n",
      "\n",
      "Epoch 2164\n",
      "-------------------------------\n",
      "loss: 0.319357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525205 \n",
      "\n",
      "Epoch 2165\n",
      "-------------------------------\n",
      "loss: 0.326481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524850 \n",
      "\n",
      "Epoch 2166\n",
      "-------------------------------\n",
      "loss: 0.307521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524613 \n",
      "\n",
      "Epoch 2167\n",
      "-------------------------------\n",
      "loss: 0.344909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524465 \n",
      "\n",
      "Epoch 2168\n",
      "-------------------------------\n",
      "loss: 0.329151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525825 \n",
      "\n",
      "Epoch 2169\n",
      "-------------------------------\n",
      "loss: 0.328119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526575 \n",
      "\n",
      "Epoch 2170\n",
      "-------------------------------\n",
      "loss: 0.325102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526486 \n",
      "\n",
      "Epoch 2171\n",
      "-------------------------------\n",
      "loss: 0.321256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525607 \n",
      "\n",
      "Epoch 2172\n",
      "-------------------------------\n",
      "loss: 0.330457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525076 \n",
      "\n",
      "Epoch 2173\n",
      "-------------------------------\n",
      "loss: 0.333031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524434 \n",
      "\n",
      "Epoch 2174\n",
      "-------------------------------\n",
      "loss: 0.343511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524924 \n",
      "\n",
      "Epoch 2175\n",
      "-------------------------------\n",
      "loss: 0.325895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525741 \n",
      "\n",
      "Epoch 2176\n",
      "-------------------------------\n",
      "loss: 0.324541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526645 \n",
      "\n",
      "Epoch 2177\n",
      "-------------------------------\n",
      "loss: 0.326876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526807 \n",
      "\n",
      "Epoch 2178\n",
      "-------------------------------\n",
      "loss: 0.333990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527993 \n",
      "\n",
      "Epoch 2179\n",
      "-------------------------------\n",
      "loss: 0.314296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527787 \n",
      "\n",
      "Epoch 2180\n",
      "-------------------------------\n",
      "loss: 0.316935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526794 \n",
      "\n",
      "Epoch 2181\n",
      "-------------------------------\n",
      "loss: 0.308693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526105 \n",
      "\n",
      "Epoch 2182\n",
      "-------------------------------\n",
      "loss: 0.316993  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.525869 \n",
      "\n",
      "Epoch 2183\n",
      "-------------------------------\n",
      "loss: 0.327844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526606 \n",
      "\n",
      "Epoch 2184\n",
      "-------------------------------\n",
      "loss: 0.312451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526558 \n",
      "\n",
      "Epoch 2185\n",
      "-------------------------------\n",
      "loss: 0.330581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526577 \n",
      "\n",
      "Epoch 2186\n",
      "-------------------------------\n",
      "loss: 0.329150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526185 \n",
      "\n",
      "Epoch 2187\n",
      "-------------------------------\n",
      "loss: 0.316969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526147 \n",
      "\n",
      "Epoch 2188\n",
      "-------------------------------\n",
      "loss: 0.331945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525632 \n",
      "\n",
      "Epoch 2189\n",
      "-------------------------------\n",
      "loss: 0.317353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524720 \n",
      "\n",
      "Epoch 2190\n",
      "-------------------------------\n",
      "loss: 0.321727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524133 \n",
      "\n",
      "Epoch 2191\n",
      "-------------------------------\n",
      "loss: 0.326819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523279 \n",
      "\n",
      "Epoch 2192\n",
      "-------------------------------\n",
      "loss: 0.325936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522333 \n",
      "\n",
      "Epoch 2193\n",
      "-------------------------------\n",
      "loss: 0.333097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522048 \n",
      "\n",
      "Epoch 2194\n",
      "-------------------------------\n",
      "loss: 0.316484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522174 \n",
      "\n",
      "Epoch 2195\n",
      "-------------------------------\n",
      "loss: 0.310372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522770 \n",
      "\n",
      "Epoch 2196\n",
      "-------------------------------\n",
      "loss: 0.341174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523578 \n",
      "\n",
      "Epoch 2197\n",
      "-------------------------------\n",
      "loss: 0.327146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523335 \n",
      "\n",
      "Epoch 2198\n",
      "-------------------------------\n",
      "loss: 0.321473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522358 \n",
      "\n",
      "Epoch 2199\n",
      "-------------------------------\n",
      "loss: 0.323410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521843 \n",
      "\n",
      "Epoch 2200\n",
      "-------------------------------\n",
      "loss: 0.304127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521648 \n",
      "\n",
      "Epoch 2201\n",
      "-------------------------------\n",
      "loss: 0.325957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521352 \n",
      "\n",
      "Epoch 2202\n",
      "-------------------------------\n",
      "loss: 0.306526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521012 \n",
      "\n",
      "Epoch 2203\n",
      "-------------------------------\n",
      "loss: 0.319592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520735 \n",
      "\n",
      "Epoch 2204\n",
      "-------------------------------\n",
      "loss: 0.334847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521875 \n",
      "\n",
      "Epoch 2205\n",
      "-------------------------------\n",
      "loss: 0.313833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522806 \n",
      "\n",
      "Epoch 2206\n",
      "-------------------------------\n",
      "loss: 0.336551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523488 \n",
      "\n",
      "Epoch 2207\n",
      "-------------------------------\n",
      "loss: 0.331535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523985 \n",
      "\n",
      "Epoch 2208\n",
      "-------------------------------\n",
      "loss: 0.323178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525731 \n",
      "\n",
      "Epoch 2209\n",
      "-------------------------------\n",
      "loss: 0.318118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526590 \n",
      "\n",
      "Epoch 2210\n",
      "-------------------------------\n",
      "loss: 0.323942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526094 \n",
      "\n",
      "Epoch 2211\n",
      "-------------------------------\n",
      "loss: 0.324690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524992 \n",
      "\n",
      "Epoch 2212\n",
      "-------------------------------\n",
      "loss: 0.317587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524365 \n",
      "\n",
      "Epoch 2213\n",
      "-------------------------------\n",
      "loss: 0.310386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524326 \n",
      "\n",
      "Epoch 2214\n",
      "-------------------------------\n",
      "loss: 0.321355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524345 \n",
      "\n",
      "Epoch 2215\n",
      "-------------------------------\n",
      "loss: 0.311582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524919 \n",
      "\n",
      "Epoch 2216\n",
      "-------------------------------\n",
      "loss: 0.330781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524546 \n",
      "\n",
      "Epoch 2217\n",
      "-------------------------------\n",
      "loss: 0.333963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524611 \n",
      "\n",
      "Epoch 2218\n",
      "-------------------------------\n",
      "loss: 0.309906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524120 \n",
      "\n",
      "Epoch 2219\n",
      "-------------------------------\n",
      "loss: 0.308487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522606 \n",
      "\n",
      "Epoch 2220\n",
      "-------------------------------\n",
      "loss: 0.327636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522057 \n",
      "\n",
      "Epoch 2221\n",
      "-------------------------------\n",
      "loss: 0.334067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522393 \n",
      "\n",
      "Epoch 2222\n",
      "-------------------------------\n",
      "loss: 0.317998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523073 \n",
      "\n",
      "Epoch 2223\n",
      "-------------------------------\n",
      "loss: 0.322055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524441 \n",
      "\n",
      "Epoch 2224\n",
      "-------------------------------\n",
      "loss: 0.316438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525293 \n",
      "\n",
      "Epoch 2225\n",
      "-------------------------------\n",
      "loss: 0.330257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525606 \n",
      "\n",
      "Epoch 2226\n",
      "-------------------------------\n",
      "loss: 0.335757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524415 \n",
      "\n",
      "Epoch 2227\n",
      "-------------------------------\n",
      "loss: 0.323769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523215 \n",
      "\n",
      "Epoch 2228\n",
      "-------------------------------\n",
      "loss: 0.312020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522155 \n",
      "\n",
      "Epoch 2229\n",
      "-------------------------------\n",
      "loss: 0.309153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521268 \n",
      "\n",
      "Epoch 2230\n",
      "-------------------------------\n",
      "loss: 0.310817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520844 \n",
      "\n",
      "Epoch 2231\n",
      "-------------------------------\n",
      "loss: 0.326677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520022 \n",
      "\n",
      "Epoch 2232\n",
      "-------------------------------\n",
      "loss: 0.305911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518454 \n",
      "\n",
      "Epoch 2233\n",
      "-------------------------------\n",
      "loss: 0.333810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517060 \n",
      "\n",
      "Epoch 2234\n",
      "-------------------------------\n",
      "loss: 0.323873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516194 \n",
      "\n",
      "Epoch 2235\n",
      "-------------------------------\n",
      "loss: 0.331894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516100 \n",
      "\n",
      "Epoch 2236\n",
      "-------------------------------\n",
      "loss: 0.354371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516187 \n",
      "\n",
      "Epoch 2237\n",
      "-------------------------------\n",
      "loss: 0.323783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517897 \n",
      "\n",
      "Epoch 2238\n",
      "-------------------------------\n",
      "loss: 0.326693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519810 \n",
      "\n",
      "Epoch 2239\n",
      "-------------------------------\n",
      "loss: 0.321312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520319 \n",
      "\n",
      "Epoch 2240\n",
      "-------------------------------\n",
      "loss: 0.328960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520048 \n",
      "\n",
      "Epoch 2241\n",
      "-------------------------------\n",
      "loss: 0.316891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519924 \n",
      "\n",
      "Epoch 2242\n",
      "-------------------------------\n",
      "loss: 0.316595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520150 \n",
      "\n",
      "Epoch 2243\n",
      "-------------------------------\n",
      "loss: 0.333861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520138 \n",
      "\n",
      "Epoch 2244\n",
      "-------------------------------\n",
      "loss: 0.313028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519938 \n",
      "\n",
      "Epoch 2245\n",
      "-------------------------------\n",
      "loss: 0.322628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520852 \n",
      "\n",
      "Epoch 2246\n",
      "-------------------------------\n",
      "loss: 0.317198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521945 \n",
      "\n",
      "Epoch 2247\n",
      "-------------------------------\n",
      "loss: 0.307452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523692 \n",
      "\n",
      "Epoch 2248\n",
      "-------------------------------\n",
      "loss: 0.324439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525008 \n",
      "\n",
      "Epoch 2249\n",
      "-------------------------------\n",
      "loss: 0.311932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525495 \n",
      "\n",
      "Epoch 2250\n",
      "-------------------------------\n",
      "loss: 0.324481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525503 \n",
      "\n",
      "Epoch 2251\n",
      "-------------------------------\n",
      "loss: 0.336242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525941 \n",
      "\n",
      "Epoch 2252\n",
      "-------------------------------\n",
      "loss: 0.337509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526328 \n",
      "\n",
      "Epoch 2253\n",
      "-------------------------------\n",
      "loss: 0.305871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526643 \n",
      "\n",
      "Epoch 2254\n",
      "-------------------------------\n",
      "loss: 0.347619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527491 \n",
      "\n",
      "Epoch 2255\n",
      "-------------------------------\n",
      "loss: 0.311047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529071 \n",
      "\n",
      "Epoch 2256\n",
      "-------------------------------\n",
      "loss: 0.329627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530281 \n",
      "\n",
      "Epoch 2257\n",
      "-------------------------------\n",
      "loss: 0.352144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529541 \n",
      "\n",
      "Epoch 2258\n",
      "-------------------------------\n",
      "loss: 0.308050  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.527044 \n",
      "\n",
      "Epoch 2259\n",
      "-------------------------------\n",
      "loss: 0.328922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524059 \n",
      "\n",
      "Epoch 2260\n",
      "-------------------------------\n",
      "loss: 0.321855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522267 \n",
      "\n",
      "Epoch 2261\n",
      "-------------------------------\n",
      "loss: 0.337131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522525 \n",
      "\n",
      "Epoch 2262\n",
      "-------------------------------\n",
      "loss: 0.323315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523873 \n",
      "\n",
      "Epoch 2263\n",
      "-------------------------------\n",
      "loss: 0.325606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525339 \n",
      "\n",
      "Epoch 2264\n",
      "-------------------------------\n",
      "loss: 0.353854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525726 \n",
      "\n",
      "Epoch 2265\n",
      "-------------------------------\n",
      "loss: 0.300957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526110 \n",
      "\n",
      "Epoch 2266\n",
      "-------------------------------\n",
      "loss: 0.329968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526569 \n",
      "\n",
      "Epoch 2267\n",
      "-------------------------------\n",
      "loss: 0.312656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525757 \n",
      "\n",
      "Epoch 2268\n",
      "-------------------------------\n",
      "loss: 0.321046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524112 \n",
      "\n",
      "Epoch 2269\n",
      "-------------------------------\n",
      "loss: 0.317591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522927 \n",
      "\n",
      "Epoch 2270\n",
      "-------------------------------\n",
      "loss: 0.306463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522197 \n",
      "\n",
      "Epoch 2271\n",
      "-------------------------------\n",
      "loss: 0.313340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522307 \n",
      "\n",
      "Epoch 2272\n",
      "-------------------------------\n",
      "loss: 0.316199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522308 \n",
      "\n",
      "Epoch 2273\n",
      "-------------------------------\n",
      "loss: 0.330448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521685 \n",
      "\n",
      "Epoch 2274\n",
      "-------------------------------\n",
      "loss: 0.347414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522833 \n",
      "\n",
      "Epoch 2275\n",
      "-------------------------------\n",
      "loss: 0.317717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525175 \n",
      "\n",
      "Epoch 2276\n",
      "-------------------------------\n",
      "loss: 0.322871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526674 \n",
      "\n",
      "Epoch 2277\n",
      "-------------------------------\n",
      "loss: 0.331286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527393 \n",
      "\n",
      "Epoch 2278\n",
      "-------------------------------\n",
      "loss: 0.319638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526005 \n",
      "\n",
      "Epoch 2279\n",
      "-------------------------------\n",
      "loss: 0.332111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523460 \n",
      "\n",
      "Epoch 2280\n",
      "-------------------------------\n",
      "loss: 0.308653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522069 \n",
      "\n",
      "Epoch 2281\n",
      "-------------------------------\n",
      "loss: 0.315642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521436 \n",
      "\n",
      "Epoch 2282\n",
      "-------------------------------\n",
      "loss: 0.341877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521604 \n",
      "\n",
      "Epoch 2283\n",
      "-------------------------------\n",
      "loss: 0.327056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521332 \n",
      "\n",
      "Epoch 2284\n",
      "-------------------------------\n",
      "loss: 0.317128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521831 \n",
      "\n",
      "Epoch 2285\n",
      "-------------------------------\n",
      "loss: 0.314178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522004 \n",
      "\n",
      "Epoch 2286\n",
      "-------------------------------\n",
      "loss: 0.327680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522461 \n",
      "\n",
      "Epoch 2287\n",
      "-------------------------------\n",
      "loss: 0.325401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523454 \n",
      "\n",
      "Epoch 2288\n",
      "-------------------------------\n",
      "loss: 0.313849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525125 \n",
      "\n",
      "Epoch 2289\n",
      "-------------------------------\n",
      "loss: 0.328420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526007 \n",
      "\n",
      "Epoch 2290\n",
      "-------------------------------\n",
      "loss: 0.314390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526702 \n",
      "\n",
      "Epoch 2291\n",
      "-------------------------------\n",
      "loss: 0.318673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526660 \n",
      "\n",
      "Epoch 2292\n",
      "-------------------------------\n",
      "loss: 0.321891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525457 \n",
      "\n",
      "Epoch 2293\n",
      "-------------------------------\n",
      "loss: 0.309133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524128 \n",
      "\n",
      "Epoch 2294\n",
      "-------------------------------\n",
      "loss: 0.317218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523174 \n",
      "\n",
      "Epoch 2295\n",
      "-------------------------------\n",
      "loss: 0.327988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522767 \n",
      "\n",
      "Epoch 2296\n",
      "-------------------------------\n",
      "loss: 0.333280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521632 \n",
      "\n",
      "Epoch 2297\n",
      "-------------------------------\n",
      "loss: 0.323415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520773 \n",
      "\n",
      "Epoch 2298\n",
      "-------------------------------\n",
      "loss: 0.327312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519950 \n",
      "\n",
      "Epoch 2299\n",
      "-------------------------------\n",
      "loss: 0.316894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520288 \n",
      "\n",
      "Epoch 2300\n",
      "-------------------------------\n",
      "loss: 0.346192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520894 \n",
      "\n",
      "Epoch 2301\n",
      "-------------------------------\n",
      "loss: 0.317708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521750 \n",
      "\n",
      "Epoch 2302\n",
      "-------------------------------\n",
      "loss: 0.314513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523023 \n",
      "\n",
      "Epoch 2303\n",
      "-------------------------------\n",
      "loss: 0.306006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525421 \n",
      "\n",
      "Epoch 2304\n",
      "-------------------------------\n",
      "loss: 0.320648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527434 \n",
      "\n",
      "Epoch 2305\n",
      "-------------------------------\n",
      "loss: 0.332178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528522 \n",
      "\n",
      "Epoch 2306\n",
      "-------------------------------\n",
      "loss: 0.328471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527749 \n",
      "\n",
      "Epoch 2307\n",
      "-------------------------------\n",
      "loss: 0.318680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526057 \n",
      "\n",
      "Epoch 2308\n",
      "-------------------------------\n",
      "loss: 0.318681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524451 \n",
      "\n",
      "Epoch 2309\n",
      "-------------------------------\n",
      "loss: 0.314020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522152 \n",
      "\n",
      "Epoch 2310\n",
      "-------------------------------\n",
      "loss: 0.315371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521189 \n",
      "\n",
      "Epoch 2311\n",
      "-------------------------------\n",
      "loss: 0.324550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520929 \n",
      "\n",
      "Epoch 2312\n",
      "-------------------------------\n",
      "loss: 0.317901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521189 \n",
      "\n",
      "Epoch 2313\n",
      "-------------------------------\n",
      "loss: 0.325323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522626 \n",
      "\n",
      "Epoch 2314\n",
      "-------------------------------\n",
      "loss: 0.314938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523722 \n",
      "\n",
      "Epoch 2315\n",
      "-------------------------------\n",
      "loss: 0.341326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524616 \n",
      "\n",
      "Epoch 2316\n",
      "-------------------------------\n",
      "loss: 0.325423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525901 \n",
      "\n",
      "Epoch 2317\n",
      "-------------------------------\n",
      "loss: 0.321310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526564 \n",
      "\n",
      "Epoch 2318\n",
      "-------------------------------\n",
      "loss: 0.327246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527381 \n",
      "\n",
      "Epoch 2319\n",
      "-------------------------------\n",
      "loss: 0.321607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527097 \n",
      "\n",
      "Epoch 2320\n",
      "-------------------------------\n",
      "loss: 0.318885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525646 \n",
      "\n",
      "Epoch 2321\n",
      "-------------------------------\n",
      "loss: 0.333317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524529 \n",
      "\n",
      "Epoch 2322\n",
      "-------------------------------\n",
      "loss: 0.320015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523026 \n",
      "\n",
      "Epoch 2323\n",
      "-------------------------------\n",
      "loss: 0.328272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521132 \n",
      "\n",
      "Epoch 2324\n",
      "-------------------------------\n",
      "loss: 0.313559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519923 \n",
      "\n",
      "Epoch 2325\n",
      "-------------------------------\n",
      "loss: 0.317038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520052 \n",
      "\n",
      "Epoch 2326\n",
      "-------------------------------\n",
      "loss: 0.310589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519776 \n",
      "\n",
      "Epoch 2327\n",
      "-------------------------------\n",
      "loss: 0.324903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519439 \n",
      "\n",
      "Epoch 2328\n",
      "-------------------------------\n",
      "loss: 0.332852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518632 \n",
      "\n",
      "Epoch 2329\n",
      "-------------------------------\n",
      "loss: 0.304835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518390 \n",
      "\n",
      "Epoch 2330\n",
      "-------------------------------\n",
      "loss: 0.315785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519614 \n",
      "\n",
      "Epoch 2331\n",
      "-------------------------------\n",
      "loss: 0.314471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519933 \n",
      "\n",
      "Epoch 2332\n",
      "-------------------------------\n",
      "loss: 0.326464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519607 \n",
      "\n",
      "Epoch 2333\n",
      "-------------------------------\n",
      "loss: 0.317226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518528 \n",
      "\n",
      "Epoch 2334\n",
      "-------------------------------\n",
      "loss: 0.332625  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.517633 \n",
      "\n",
      "Epoch 2335\n",
      "-------------------------------\n",
      "loss: 0.332226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517461 \n",
      "\n",
      "Epoch 2336\n",
      "-------------------------------\n",
      "loss: 0.328513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517649 \n",
      "\n",
      "Epoch 2337\n",
      "-------------------------------\n",
      "loss: 0.312097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518260 \n",
      "\n",
      "Epoch 2338\n",
      "-------------------------------\n",
      "loss: 0.332343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518930 \n",
      "\n",
      "Epoch 2339\n",
      "-------------------------------\n",
      "loss: 0.302724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519492 \n",
      "\n",
      "Epoch 2340\n",
      "-------------------------------\n",
      "loss: 0.308175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519540 \n",
      "\n",
      "Epoch 2341\n",
      "-------------------------------\n",
      "loss: 0.323284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519111 \n",
      "\n",
      "Epoch 2342\n",
      "-------------------------------\n",
      "loss: 0.315344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519003 \n",
      "\n",
      "Epoch 2343\n",
      "-------------------------------\n",
      "loss: 0.332906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519572 \n",
      "\n",
      "Epoch 2344\n",
      "-------------------------------\n",
      "loss: 0.320605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521086 \n",
      "\n",
      "Epoch 2345\n",
      "-------------------------------\n",
      "loss: 0.297774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522518 \n",
      "\n",
      "Epoch 2346\n",
      "-------------------------------\n",
      "loss: 0.317247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523345 \n",
      "\n",
      "Epoch 2347\n",
      "-------------------------------\n",
      "loss: 0.322806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523847 \n",
      "\n",
      "Epoch 2348\n",
      "-------------------------------\n",
      "loss: 0.302370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524495 \n",
      "\n",
      "Epoch 2349\n",
      "-------------------------------\n",
      "loss: 0.323147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525632 \n",
      "\n",
      "Epoch 2350\n",
      "-------------------------------\n",
      "loss: 0.313107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526915 \n",
      "\n",
      "Epoch 2351\n",
      "-------------------------------\n",
      "loss: 0.322158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527186 \n",
      "\n",
      "Epoch 2352\n",
      "-------------------------------\n",
      "loss: 0.321104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526909 \n",
      "\n",
      "Epoch 2353\n",
      "-------------------------------\n",
      "loss: 0.318277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527318 \n",
      "\n",
      "Epoch 2354\n",
      "-------------------------------\n",
      "loss: 0.312004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526337 \n",
      "\n",
      "Epoch 2355\n",
      "-------------------------------\n",
      "loss: 0.333246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524833 \n",
      "\n",
      "Epoch 2356\n",
      "-------------------------------\n",
      "loss: 0.327902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524354 \n",
      "\n",
      "Epoch 2357\n",
      "-------------------------------\n",
      "loss: 0.317045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523626 \n",
      "\n",
      "Epoch 2358\n",
      "-------------------------------\n",
      "loss: 0.298772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523452 \n",
      "\n",
      "Epoch 2359\n",
      "-------------------------------\n",
      "loss: 0.312576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524457 \n",
      "\n",
      "Epoch 2360\n",
      "-------------------------------\n",
      "loss: 0.318007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525544 \n",
      "\n",
      "Epoch 2361\n",
      "-------------------------------\n",
      "loss: 0.309617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527358 \n",
      "\n",
      "Epoch 2362\n",
      "-------------------------------\n",
      "loss: 0.292130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528268 \n",
      "\n",
      "Epoch 2363\n",
      "-------------------------------\n",
      "loss: 0.312351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527202 \n",
      "\n",
      "Epoch 2364\n",
      "-------------------------------\n",
      "loss: 0.304374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525716 \n",
      "\n",
      "Epoch 2365\n",
      "-------------------------------\n",
      "loss: 0.323033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524116 \n",
      "\n",
      "Epoch 2366\n",
      "-------------------------------\n",
      "loss: 0.318499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523516 \n",
      "\n",
      "Epoch 2367\n",
      "-------------------------------\n",
      "loss: 0.320527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523296 \n",
      "\n",
      "Epoch 2368\n",
      "-------------------------------\n",
      "loss: 0.310165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523692 \n",
      "\n",
      "Epoch 2369\n",
      "-------------------------------\n",
      "loss: 0.339614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524098 \n",
      "\n",
      "Epoch 2370\n",
      "-------------------------------\n",
      "loss: 0.326264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524043 \n",
      "\n",
      "Epoch 2371\n",
      "-------------------------------\n",
      "loss: 0.329416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522593 \n",
      "\n",
      "Epoch 2372\n",
      "-------------------------------\n",
      "loss: 0.319736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521534 \n",
      "\n",
      "Epoch 2373\n",
      "-------------------------------\n",
      "loss: 0.315371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521586 \n",
      "\n",
      "Epoch 2374\n",
      "-------------------------------\n",
      "loss: 0.323017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522111 \n",
      "\n",
      "Epoch 2375\n",
      "-------------------------------\n",
      "loss: 0.308792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522577 \n",
      "\n",
      "Epoch 2376\n",
      "-------------------------------\n",
      "loss: 0.309571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522451 \n",
      "\n",
      "Epoch 2377\n",
      "-------------------------------\n",
      "loss: 0.311604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521689 \n",
      "\n",
      "Epoch 2378\n",
      "-------------------------------\n",
      "loss: 0.313112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520801 \n",
      "\n",
      "Epoch 2379\n",
      "-------------------------------\n",
      "loss: 0.318489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521063 \n",
      "\n",
      "Epoch 2380\n",
      "-------------------------------\n",
      "loss: 0.307098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521037 \n",
      "\n",
      "Epoch 2381\n",
      "-------------------------------\n",
      "loss: 0.324094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520948 \n",
      "\n",
      "Epoch 2382\n",
      "-------------------------------\n",
      "loss: 0.305916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521219 \n",
      "\n",
      "Epoch 2383\n",
      "-------------------------------\n",
      "loss: 0.321478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521253 \n",
      "\n",
      "Epoch 2384\n",
      "-------------------------------\n",
      "loss: 0.314765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521957 \n",
      "\n",
      "Epoch 2385\n",
      "-------------------------------\n",
      "loss: 0.314640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522468 \n",
      "\n",
      "Epoch 2386\n",
      "-------------------------------\n",
      "loss: 0.328526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523012 \n",
      "\n",
      "Epoch 2387\n",
      "-------------------------------\n",
      "loss: 0.308300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523424 \n",
      "\n",
      "Epoch 2388\n",
      "-------------------------------\n",
      "loss: 0.311040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523723 \n",
      "\n",
      "Epoch 2389\n",
      "-------------------------------\n",
      "loss: 0.311773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522645 \n",
      "\n",
      "Epoch 2390\n",
      "-------------------------------\n",
      "loss: 0.308412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522525 \n",
      "\n",
      "Epoch 2391\n",
      "-------------------------------\n",
      "loss: 0.316322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522318 \n",
      "\n",
      "Epoch 2392\n",
      "-------------------------------\n",
      "loss: 0.313172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521801 \n",
      "\n",
      "Epoch 2393\n",
      "-------------------------------\n",
      "loss: 0.338027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521328 \n",
      "\n",
      "Epoch 2394\n",
      "-------------------------------\n",
      "loss: 0.318525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521495 \n",
      "\n",
      "Epoch 2395\n",
      "-------------------------------\n",
      "loss: 0.322839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522755 \n",
      "\n",
      "Epoch 2396\n",
      "-------------------------------\n",
      "loss: 0.316779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523774 \n",
      "\n",
      "Epoch 2397\n",
      "-------------------------------\n",
      "loss: 0.328390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523481 \n",
      "\n",
      "Epoch 2398\n",
      "-------------------------------\n",
      "loss: 0.308551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522966 \n",
      "\n",
      "Epoch 2399\n",
      "-------------------------------\n",
      "loss: 0.305414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522587 \n",
      "\n",
      "Epoch 2400\n",
      "-------------------------------\n",
      "loss: 0.327901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523051 \n",
      "\n",
      "Epoch 2401\n",
      "-------------------------------\n",
      "loss: 0.333462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523341 \n",
      "\n",
      "Epoch 2402\n",
      "-------------------------------\n",
      "loss: 0.286384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523199 \n",
      "\n",
      "Epoch 2403\n",
      "-------------------------------\n",
      "loss: 0.313850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522575 \n",
      "\n",
      "Epoch 2404\n",
      "-------------------------------\n",
      "loss: 0.319088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521799 \n",
      "\n",
      "Epoch 2405\n",
      "-------------------------------\n",
      "loss: 0.328757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521667 \n",
      "\n",
      "Epoch 2406\n",
      "-------------------------------\n",
      "loss: 0.308744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521392 \n",
      "\n",
      "Epoch 2407\n",
      "-------------------------------\n",
      "loss: 0.329235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520376 \n",
      "\n",
      "Epoch 2408\n",
      "-------------------------------\n",
      "loss: 0.320287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518140 \n",
      "\n",
      "Epoch 2409\n",
      "-------------------------------\n",
      "loss: 0.296749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516268 \n",
      "\n",
      "Epoch 2410\n",
      "-------------------------------\n",
      "loss: 0.317057  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.515594 \n",
      "\n",
      "Epoch 2411\n",
      "-------------------------------\n",
      "loss: 0.305652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515784 \n",
      "\n",
      "Epoch 2412\n",
      "-------------------------------\n",
      "loss: 0.309597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516067 \n",
      "\n",
      "Epoch 2413\n",
      "-------------------------------\n",
      "loss: 0.320522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516370 \n",
      "\n",
      "Epoch 2414\n",
      "-------------------------------\n",
      "loss: 0.287050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516570 \n",
      "\n",
      "Epoch 2415\n",
      "-------------------------------\n",
      "loss: 0.322666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516810 \n",
      "\n",
      "Epoch 2416\n",
      "-------------------------------\n",
      "loss: 0.309066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517641 \n",
      "\n",
      "Epoch 2417\n",
      "-------------------------------\n",
      "loss: 0.319479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518425 \n",
      "\n",
      "Epoch 2418\n",
      "-------------------------------\n",
      "loss: 0.328755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518989 \n",
      "\n",
      "Epoch 2419\n",
      "-------------------------------\n",
      "loss: 0.304196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519542 \n",
      "\n",
      "Epoch 2420\n",
      "-------------------------------\n",
      "loss: 0.310065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519864 \n",
      "\n",
      "Epoch 2421\n",
      "-------------------------------\n",
      "loss: 0.302772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519875 \n",
      "\n",
      "Epoch 2422\n",
      "-------------------------------\n",
      "loss: 0.323119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520312 \n",
      "\n",
      "Epoch 2423\n",
      "-------------------------------\n",
      "loss: 0.320770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520187 \n",
      "\n",
      "Epoch 2424\n",
      "-------------------------------\n",
      "loss: 0.325975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520791 \n",
      "\n",
      "Epoch 2425\n",
      "-------------------------------\n",
      "loss: 0.314529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521947 \n",
      "\n",
      "Epoch 2426\n",
      "-------------------------------\n",
      "loss: 0.316907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523953 \n",
      "\n",
      "Epoch 2427\n",
      "-------------------------------\n",
      "loss: 0.310671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526375 \n",
      "\n",
      "Epoch 2428\n",
      "-------------------------------\n",
      "loss: 0.326475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528485 \n",
      "\n",
      "Epoch 2429\n",
      "-------------------------------\n",
      "loss: 0.338239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529364 \n",
      "\n",
      "Epoch 2430\n",
      "-------------------------------\n",
      "loss: 0.317158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529051 \n",
      "\n",
      "Epoch 2431\n",
      "-------------------------------\n",
      "loss: 0.303460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526802 \n",
      "\n",
      "Epoch 2432\n",
      "-------------------------------\n",
      "loss: 0.329768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524554 \n",
      "\n",
      "Epoch 2433\n",
      "-------------------------------\n",
      "loss: 0.312576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523200 \n",
      "\n",
      "Epoch 2434\n",
      "-------------------------------\n",
      "loss: 0.313273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522604 \n",
      "\n",
      "Epoch 2435\n",
      "-------------------------------\n",
      "loss: 0.329384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521814 \n",
      "\n",
      "Epoch 2436\n",
      "-------------------------------\n",
      "loss: 0.325554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521734 \n",
      "\n",
      "Epoch 2437\n",
      "-------------------------------\n",
      "loss: 0.314314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523032 \n",
      "\n",
      "Epoch 2438\n",
      "-------------------------------\n",
      "loss: 0.319421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524766 \n",
      "\n",
      "Epoch 2439\n",
      "-------------------------------\n",
      "loss: 0.317280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526300 \n",
      "\n",
      "Epoch 2440\n",
      "-------------------------------\n",
      "loss: 0.325132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524643 \n",
      "\n",
      "Epoch 2441\n",
      "-------------------------------\n",
      "loss: 0.311883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521239 \n",
      "\n",
      "Epoch 2442\n",
      "-------------------------------\n",
      "loss: 0.321006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517220 \n",
      "\n",
      "Epoch 2443\n",
      "-------------------------------\n",
      "loss: 0.315177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515931 \n",
      "\n",
      "Epoch 2444\n",
      "-------------------------------\n",
      "loss: 0.330635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515357 \n",
      "\n",
      "Epoch 2445\n",
      "-------------------------------\n",
      "loss: 0.322977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514438 \n",
      "\n",
      "Epoch 2446\n",
      "-------------------------------\n",
      "loss: 0.317976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513900 \n",
      "\n",
      "Epoch 2447\n",
      "-------------------------------\n",
      "loss: 0.328652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513896 \n",
      "\n",
      "Epoch 2448\n",
      "-------------------------------\n",
      "loss: 0.303789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514870 \n",
      "\n",
      "Epoch 2449\n",
      "-------------------------------\n",
      "loss: 0.308515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516799 \n",
      "\n",
      "Epoch 2450\n",
      "-------------------------------\n",
      "loss: 0.326356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519121 \n",
      "\n",
      "Epoch 2451\n",
      "-------------------------------\n",
      "loss: 0.310757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519158 \n",
      "\n",
      "Epoch 2452\n",
      "-------------------------------\n",
      "loss: 0.313292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517514 \n",
      "\n",
      "Epoch 2453\n",
      "-------------------------------\n",
      "loss: 0.328367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516665 \n",
      "\n",
      "Epoch 2454\n",
      "-------------------------------\n",
      "loss: 0.297108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518068 \n",
      "\n",
      "Epoch 2455\n",
      "-------------------------------\n",
      "loss: 0.301005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520126 \n",
      "\n",
      "Epoch 2456\n",
      "-------------------------------\n",
      "loss: 0.337526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521458 \n",
      "\n",
      "Epoch 2457\n",
      "-------------------------------\n",
      "loss: 0.326542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520891 \n",
      "\n",
      "Epoch 2458\n",
      "-------------------------------\n",
      "loss: 0.315102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520482 \n",
      "\n",
      "Epoch 2459\n",
      "-------------------------------\n",
      "loss: 0.301412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520154 \n",
      "\n",
      "Epoch 2460\n",
      "-------------------------------\n",
      "loss: 0.310726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519921 \n",
      "\n",
      "Epoch 2461\n",
      "-------------------------------\n",
      "loss: 0.315355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520115 \n",
      "\n",
      "Epoch 2462\n",
      "-------------------------------\n",
      "loss: 0.322752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520373 \n",
      "\n",
      "Epoch 2463\n",
      "-------------------------------\n",
      "loss: 0.312296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520220 \n",
      "\n",
      "Epoch 2464\n",
      "-------------------------------\n",
      "loss: 0.306943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520037 \n",
      "\n",
      "Epoch 2465\n",
      "-------------------------------\n",
      "loss: 0.320098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519612 \n",
      "\n",
      "Epoch 2466\n",
      "-------------------------------\n",
      "loss: 0.314484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519398 \n",
      "\n",
      "Epoch 2467\n",
      "-------------------------------\n",
      "loss: 0.306044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519272 \n",
      "\n",
      "Epoch 2468\n",
      "-------------------------------\n",
      "loss: 0.301009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519021 \n",
      "\n",
      "Epoch 2469\n",
      "-------------------------------\n",
      "loss: 0.300775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519111 \n",
      "\n",
      "Epoch 2470\n",
      "-------------------------------\n",
      "loss: 0.328281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519900 \n",
      "\n",
      "Epoch 2471\n",
      "-------------------------------\n",
      "loss: 0.309363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521363 \n",
      "\n",
      "Epoch 2472\n",
      "-------------------------------\n",
      "loss: 0.306275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522725 \n",
      "\n",
      "Epoch 2473\n",
      "-------------------------------\n",
      "loss: 0.320480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523901 \n",
      "\n",
      "Epoch 2474\n",
      "-------------------------------\n",
      "loss: 0.302158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523887 \n",
      "\n",
      "Epoch 2475\n",
      "-------------------------------\n",
      "loss: 0.307593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522784 \n",
      "\n",
      "Epoch 2476\n",
      "-------------------------------\n",
      "loss: 0.308538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520996 \n",
      "\n",
      "Epoch 2477\n",
      "-------------------------------\n",
      "loss: 0.324303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520305 \n",
      "\n",
      "Epoch 2478\n",
      "-------------------------------\n",
      "loss: 0.310290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520453 \n",
      "\n",
      "Epoch 2479\n",
      "-------------------------------\n",
      "loss: 0.318092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520860 \n",
      "\n",
      "Epoch 2480\n",
      "-------------------------------\n",
      "loss: 0.309288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522250 \n",
      "\n",
      "Epoch 2481\n",
      "-------------------------------\n",
      "loss: 0.311321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524494 \n",
      "\n",
      "Epoch 2482\n",
      "-------------------------------\n",
      "loss: 0.313535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525735 \n",
      "\n",
      "Epoch 2483\n",
      "-------------------------------\n",
      "loss: 0.324119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525786 \n",
      "\n",
      "Epoch 2484\n",
      "-------------------------------\n",
      "loss: 0.318483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524655 \n",
      "\n",
      "Epoch 2485\n",
      "-------------------------------\n",
      "loss: 0.307574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522980 \n",
      "\n",
      "Epoch 2486\n",
      "-------------------------------\n",
      "loss: 0.310989  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.522017 \n",
      "\n",
      "Epoch 2487\n",
      "-------------------------------\n",
      "loss: 0.326615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522407 \n",
      "\n",
      "Epoch 2488\n",
      "-------------------------------\n",
      "loss: 0.303948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523282 \n",
      "\n",
      "Epoch 2489\n",
      "-------------------------------\n",
      "loss: 0.335403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523791 \n",
      "\n",
      "Epoch 2490\n",
      "-------------------------------\n",
      "loss: 0.307100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524306 \n",
      "\n",
      "Epoch 2491\n",
      "-------------------------------\n",
      "loss: 0.308866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524694 \n",
      "\n",
      "Epoch 2492\n",
      "-------------------------------\n",
      "loss: 0.303937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524073 \n",
      "\n",
      "Epoch 2493\n",
      "-------------------------------\n",
      "loss: 0.314366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523177 \n",
      "\n",
      "Epoch 2494\n",
      "-------------------------------\n",
      "loss: 0.324545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522968 \n",
      "\n",
      "Epoch 2495\n",
      "-------------------------------\n",
      "loss: 0.316511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522420 \n",
      "\n",
      "Epoch 2496\n",
      "-------------------------------\n",
      "loss: 0.320923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522652 \n",
      "\n",
      "Epoch 2497\n",
      "-------------------------------\n",
      "loss: 0.292158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523395 \n",
      "\n",
      "Epoch 2498\n",
      "-------------------------------\n",
      "loss: 0.315883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523162 \n",
      "\n",
      "Epoch 2499\n",
      "-------------------------------\n",
      "loss: 0.324392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522978 \n",
      "\n",
      "Epoch 2500\n",
      "-------------------------------\n",
      "loss: 0.304249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523211 \n",
      "\n",
      "Epoch 2501\n",
      "-------------------------------\n",
      "loss: 0.316686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523060 \n",
      "\n",
      "Epoch 2502\n",
      "-------------------------------\n",
      "loss: 0.298419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523133 \n",
      "\n",
      "Epoch 2503\n",
      "-------------------------------\n",
      "loss: 0.331458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523369 \n",
      "\n",
      "Epoch 2504\n",
      "-------------------------------\n",
      "loss: 0.303575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523342 \n",
      "\n",
      "Epoch 2505\n",
      "-------------------------------\n",
      "loss: 0.303688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522934 \n",
      "\n",
      "Epoch 2506\n",
      "-------------------------------\n",
      "loss: 0.310863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523231 \n",
      "\n",
      "Epoch 2507\n",
      "-------------------------------\n",
      "loss: 0.311961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522912 \n",
      "\n",
      "Epoch 2508\n",
      "-------------------------------\n",
      "loss: 0.328080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522500 \n",
      "\n",
      "Epoch 2509\n",
      "-------------------------------\n",
      "loss: 0.320914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522186 \n",
      "\n",
      "Epoch 2510\n",
      "-------------------------------\n",
      "loss: 0.311112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522042 \n",
      "\n",
      "Epoch 2511\n",
      "-------------------------------\n",
      "loss: 0.289476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522428 \n",
      "\n",
      "Epoch 2512\n",
      "-------------------------------\n",
      "loss: 0.305689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522944 \n",
      "\n",
      "Epoch 2513\n",
      "-------------------------------\n",
      "loss: 0.311736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523441 \n",
      "\n",
      "Epoch 2514\n",
      "-------------------------------\n",
      "loss: 0.317899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524484 \n",
      "\n",
      "Epoch 2515\n",
      "-------------------------------\n",
      "loss: 0.317522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524572 \n",
      "\n",
      "Epoch 2516\n",
      "-------------------------------\n",
      "loss: 0.306659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524048 \n",
      "\n",
      "Epoch 2517\n",
      "-------------------------------\n",
      "loss: 0.296621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523400 \n",
      "\n",
      "Epoch 2518\n",
      "-------------------------------\n",
      "loss: 0.308386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521763 \n",
      "\n",
      "Epoch 2519\n",
      "-------------------------------\n",
      "loss: 0.312048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520865 \n",
      "\n",
      "Epoch 2520\n",
      "-------------------------------\n",
      "loss: 0.306198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520221 \n",
      "\n",
      "Epoch 2521\n",
      "-------------------------------\n",
      "loss: 0.319510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520224 \n",
      "\n",
      "Epoch 2522\n",
      "-------------------------------\n",
      "loss: 0.309415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520309 \n",
      "\n",
      "Epoch 2523\n",
      "-------------------------------\n",
      "loss: 0.302837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519919 \n",
      "\n",
      "Epoch 2524\n",
      "-------------------------------\n",
      "loss: 0.312353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519273 \n",
      "\n",
      "Epoch 2525\n",
      "-------------------------------\n",
      "loss: 0.307942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518885 \n",
      "\n",
      "Epoch 2526\n",
      "-------------------------------\n",
      "loss: 0.318062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518797 \n",
      "\n",
      "Epoch 2527\n",
      "-------------------------------\n",
      "loss: 0.312355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518740 \n",
      "\n",
      "Epoch 2528\n",
      "-------------------------------\n",
      "loss: 0.311049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518035 \n",
      "\n",
      "Epoch 2529\n",
      "-------------------------------\n",
      "loss: 0.309304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517018 \n",
      "\n",
      "Epoch 2530\n",
      "-------------------------------\n",
      "loss: 0.294944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516614 \n",
      "\n",
      "Epoch 2531\n",
      "-------------------------------\n",
      "loss: 0.309725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517039 \n",
      "\n",
      "Epoch 2532\n",
      "-------------------------------\n",
      "loss: 0.288827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517948 \n",
      "\n",
      "Epoch 2533\n",
      "-------------------------------\n",
      "loss: 0.323340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519251 \n",
      "\n",
      "Epoch 2534\n",
      "-------------------------------\n",
      "loss: 0.313372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520345 \n",
      "\n",
      "Epoch 2535\n",
      "-------------------------------\n",
      "loss: 0.311208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521780 \n",
      "\n",
      "Epoch 2536\n",
      "-------------------------------\n",
      "loss: 0.313476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521833 \n",
      "\n",
      "Epoch 2537\n",
      "-------------------------------\n",
      "loss: 0.327765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521082 \n",
      "\n",
      "Epoch 2538\n",
      "-------------------------------\n",
      "loss: 0.320180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520444 \n",
      "\n",
      "Epoch 2539\n",
      "-------------------------------\n",
      "loss: 0.308859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520029 \n",
      "\n",
      "Epoch 2540\n",
      "-------------------------------\n",
      "loss: 0.319470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519939 \n",
      "\n",
      "Epoch 2541\n",
      "-------------------------------\n",
      "loss: 0.307321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520355 \n",
      "\n",
      "Epoch 2542\n",
      "-------------------------------\n",
      "loss: 0.308378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521137 \n",
      "\n",
      "Epoch 2543\n",
      "-------------------------------\n",
      "loss: 0.304504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522740 \n",
      "\n",
      "Epoch 2544\n",
      "-------------------------------\n",
      "loss: 0.302918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523934 \n",
      "\n",
      "Epoch 2545\n",
      "-------------------------------\n",
      "loss: 0.307019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523054 \n",
      "\n",
      "Epoch 2546\n",
      "-------------------------------\n",
      "loss: 0.321528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520930 \n",
      "\n",
      "Epoch 2547\n",
      "-------------------------------\n",
      "loss: 0.310381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519817 \n",
      "\n",
      "Epoch 2548\n",
      "-------------------------------\n",
      "loss: 0.318671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519837 \n",
      "\n",
      "Epoch 2549\n",
      "-------------------------------\n",
      "loss: 0.317752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519758 \n",
      "\n",
      "Epoch 2550\n",
      "-------------------------------\n",
      "loss: 0.327460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519992 \n",
      "\n",
      "Epoch 2551\n",
      "-------------------------------\n",
      "loss: 0.298033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520797 \n",
      "\n",
      "Epoch 2552\n",
      "-------------------------------\n",
      "loss: 0.320539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523222 \n",
      "\n",
      "Epoch 2553\n",
      "-------------------------------\n",
      "loss: 0.324285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524477 \n",
      "\n",
      "Epoch 2554\n",
      "-------------------------------\n",
      "loss: 0.320059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523173 \n",
      "\n",
      "Epoch 2555\n",
      "-------------------------------\n",
      "loss: 0.314704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520256 \n",
      "\n",
      "Epoch 2556\n",
      "-------------------------------\n",
      "loss: 0.300469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517580 \n",
      "\n",
      "Epoch 2557\n",
      "-------------------------------\n",
      "loss: 0.314999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515750 \n",
      "\n",
      "Epoch 2558\n",
      "-------------------------------\n",
      "loss: 0.323065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515593 \n",
      "\n",
      "Epoch 2559\n",
      "-------------------------------\n",
      "loss: 0.293053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515637 \n",
      "\n",
      "Epoch 2560\n",
      "-------------------------------\n",
      "loss: 0.303682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516319 \n",
      "\n",
      "Epoch 2561\n",
      "-------------------------------\n",
      "loss: 0.294689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516786 \n",
      "\n",
      "Epoch 2562\n",
      "-------------------------------\n",
      "loss: 0.303120  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.518063 \n",
      "\n",
      "Epoch 2563\n",
      "-------------------------------\n",
      "loss: 0.312697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519519 \n",
      "\n",
      "Epoch 2564\n",
      "-------------------------------\n",
      "loss: 0.299715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521127 \n",
      "\n",
      "Epoch 2565\n",
      "-------------------------------\n",
      "loss: 0.312206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522723 \n",
      "\n",
      "Epoch 2566\n",
      "-------------------------------\n",
      "loss: 0.308843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522090 \n",
      "\n",
      "Epoch 2567\n",
      "-------------------------------\n",
      "loss: 0.316999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520563 \n",
      "\n",
      "Epoch 2568\n",
      "-------------------------------\n",
      "loss: 0.324817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518543 \n",
      "\n",
      "Epoch 2569\n",
      "-------------------------------\n",
      "loss: 0.305517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516678 \n",
      "\n",
      "Epoch 2570\n",
      "-------------------------------\n",
      "loss: 0.301100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515802 \n",
      "\n",
      "Epoch 2571\n",
      "-------------------------------\n",
      "loss: 0.302416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515277 \n",
      "\n",
      "Epoch 2572\n",
      "-------------------------------\n",
      "loss: 0.288589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515093 \n",
      "\n",
      "Epoch 2573\n",
      "-------------------------------\n",
      "loss: 0.321815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515320 \n",
      "\n",
      "Epoch 2574\n",
      "-------------------------------\n",
      "loss: 0.296639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515670 \n",
      "\n",
      "Epoch 2575\n",
      "-------------------------------\n",
      "loss: 0.300717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515914 \n",
      "\n",
      "Epoch 2576\n",
      "-------------------------------\n",
      "loss: 0.288784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516769 \n",
      "\n",
      "Epoch 2577\n",
      "-------------------------------\n",
      "loss: 0.298252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516845 \n",
      "\n",
      "Epoch 2578\n",
      "-------------------------------\n",
      "loss: 0.318747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517029 \n",
      "\n",
      "Epoch 2579\n",
      "-------------------------------\n",
      "loss: 0.311700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517486 \n",
      "\n",
      "Epoch 2580\n",
      "-------------------------------\n",
      "loss: 0.315132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518877 \n",
      "\n",
      "Epoch 2581\n",
      "-------------------------------\n",
      "loss: 0.289218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518761 \n",
      "\n",
      "Epoch 2582\n",
      "-------------------------------\n",
      "loss: 0.313148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518076 \n",
      "\n",
      "Epoch 2583\n",
      "-------------------------------\n",
      "loss: 0.304523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518131 \n",
      "\n",
      "Epoch 2584\n",
      "-------------------------------\n",
      "loss: 0.300571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518493 \n",
      "\n",
      "Epoch 2585\n",
      "-------------------------------\n",
      "loss: 0.326078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519944 \n",
      "\n",
      "Epoch 2586\n",
      "-------------------------------\n",
      "loss: 0.292484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521236 \n",
      "\n",
      "Epoch 2587\n",
      "-------------------------------\n",
      "loss: 0.312488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522246 \n",
      "\n",
      "Epoch 2588\n",
      "-------------------------------\n",
      "loss: 0.316575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522673 \n",
      "\n",
      "Epoch 2589\n",
      "-------------------------------\n",
      "loss: 0.296497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521614 \n",
      "\n",
      "Epoch 2590\n",
      "-------------------------------\n",
      "loss: 0.307044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521230 \n",
      "\n",
      "Epoch 2591\n",
      "-------------------------------\n",
      "loss: 0.303666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520998 \n",
      "\n",
      "Epoch 2592\n",
      "-------------------------------\n",
      "loss: 0.288748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520632 \n",
      "\n",
      "Epoch 2593\n",
      "-------------------------------\n",
      "loss: 0.314556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519913 \n",
      "\n",
      "Epoch 2594\n",
      "-------------------------------\n",
      "loss: 0.311325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519066 \n",
      "\n",
      "Epoch 2595\n",
      "-------------------------------\n",
      "loss: 0.311071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519224 \n",
      "\n",
      "Epoch 2596\n",
      "-------------------------------\n",
      "loss: 0.309595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519373 \n",
      "\n",
      "Epoch 2597\n",
      "-------------------------------\n",
      "loss: 0.320411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519865 \n",
      "\n",
      "Epoch 2598\n",
      "-------------------------------\n",
      "loss: 0.305636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519744 \n",
      "\n",
      "Epoch 2599\n",
      "-------------------------------\n",
      "loss: 0.302315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519080 \n",
      "\n",
      "Epoch 2600\n",
      "-------------------------------\n",
      "loss: 0.307975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518826 \n",
      "\n",
      "Epoch 2601\n",
      "-------------------------------\n",
      "loss: 0.301668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518741 \n",
      "\n",
      "Epoch 2602\n",
      "-------------------------------\n",
      "loss: 0.305822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517978 \n",
      "\n",
      "Epoch 2603\n",
      "-------------------------------\n",
      "loss: 0.296636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517071 \n",
      "\n",
      "Epoch 2604\n",
      "-------------------------------\n",
      "loss: 0.304220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516316 \n",
      "\n",
      "Epoch 2605\n",
      "-------------------------------\n",
      "loss: 0.319368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516319 \n",
      "\n",
      "Epoch 2606\n",
      "-------------------------------\n",
      "loss: 0.306072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516682 \n",
      "\n",
      "Epoch 2607\n",
      "-------------------------------\n",
      "loss: 0.304287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517378 \n",
      "\n",
      "Epoch 2608\n",
      "-------------------------------\n",
      "loss: 0.317174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519295 \n",
      "\n",
      "Epoch 2609\n",
      "-------------------------------\n",
      "loss: 0.317357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521198 \n",
      "\n",
      "Epoch 2610\n",
      "-------------------------------\n",
      "loss: 0.306143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522192 \n",
      "\n",
      "Epoch 2611\n",
      "-------------------------------\n",
      "loss: 0.307918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522607 \n",
      "\n",
      "Epoch 2612\n",
      "-------------------------------\n",
      "loss: 0.314268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521904 \n",
      "\n",
      "Epoch 2613\n",
      "-------------------------------\n",
      "loss: 0.302092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520809 \n",
      "\n",
      "Epoch 2614\n",
      "-------------------------------\n",
      "loss: 0.311198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520588 \n",
      "\n",
      "Epoch 2615\n",
      "-------------------------------\n",
      "loss: 0.318134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521257 \n",
      "\n",
      "Epoch 2616\n",
      "-------------------------------\n",
      "loss: 0.298041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522400 \n",
      "\n",
      "Epoch 2617\n",
      "-------------------------------\n",
      "loss: 0.308767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523924 \n",
      "\n",
      "Epoch 2618\n",
      "-------------------------------\n",
      "loss: 0.311431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524425 \n",
      "\n",
      "Epoch 2619\n",
      "-------------------------------\n",
      "loss: 0.301356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525049 \n",
      "\n",
      "Epoch 2620\n",
      "-------------------------------\n",
      "loss: 0.315907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525424 \n",
      "\n",
      "Epoch 2621\n",
      "-------------------------------\n",
      "loss: 0.319589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525892 \n",
      "\n",
      "Epoch 2622\n",
      "-------------------------------\n",
      "loss: 0.294010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526528 \n",
      "\n",
      "Epoch 2623\n",
      "-------------------------------\n",
      "loss: 0.295352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526007 \n",
      "\n",
      "Epoch 2624\n",
      "-------------------------------\n",
      "loss: 0.312399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525034 \n",
      "\n",
      "Epoch 2625\n",
      "-------------------------------\n",
      "loss: 0.311948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524326 \n",
      "\n",
      "Epoch 2626\n",
      "-------------------------------\n",
      "loss: 0.300747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523492 \n",
      "\n",
      "Epoch 2627\n",
      "-------------------------------\n",
      "loss: 0.301112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522685 \n",
      "\n",
      "Epoch 2628\n",
      "-------------------------------\n",
      "loss: 0.305804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521958 \n",
      "\n",
      "Epoch 2629\n",
      "-------------------------------\n",
      "loss: 0.305957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521431 \n",
      "\n",
      "Epoch 2630\n",
      "-------------------------------\n",
      "loss: 0.304951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520826 \n",
      "\n",
      "Epoch 2631\n",
      "-------------------------------\n",
      "loss: 0.307914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520579 \n",
      "\n",
      "Epoch 2632\n",
      "-------------------------------\n",
      "loss: 0.285966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520159 \n",
      "\n",
      "Epoch 2633\n",
      "-------------------------------\n",
      "loss: 0.292630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520188 \n",
      "\n",
      "Epoch 2634\n",
      "-------------------------------\n",
      "loss: 0.300766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520343 \n",
      "\n",
      "Epoch 2635\n",
      "-------------------------------\n",
      "loss: 0.305993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520531 \n",
      "\n",
      "Epoch 2636\n",
      "-------------------------------\n",
      "loss: 0.298707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520304 \n",
      "\n",
      "Epoch 2637\n",
      "-------------------------------\n",
      "loss: 0.294563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520162 \n",
      "\n",
      "Epoch 2638\n",
      "-------------------------------\n",
      "loss: 0.314661  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.520810 \n",
      "\n",
      "Epoch 2639\n",
      "-------------------------------\n",
      "loss: 0.298388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522201 \n",
      "\n",
      "Epoch 2640\n",
      "-------------------------------\n",
      "loss: 0.302263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522266 \n",
      "\n",
      "Epoch 2641\n",
      "-------------------------------\n",
      "loss: 0.305059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522797 \n",
      "\n",
      "Epoch 2642\n",
      "-------------------------------\n",
      "loss: 0.294985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522919 \n",
      "\n",
      "Epoch 2643\n",
      "-------------------------------\n",
      "loss: 0.316615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523176 \n",
      "\n",
      "Epoch 2644\n",
      "-------------------------------\n",
      "loss: 0.295447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523677 \n",
      "\n",
      "Epoch 2645\n",
      "-------------------------------\n",
      "loss: 0.302625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524968 \n",
      "\n",
      "Epoch 2646\n",
      "-------------------------------\n",
      "loss: 0.315822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526141 \n",
      "\n",
      "Epoch 2647\n",
      "-------------------------------\n",
      "loss: 0.300589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525678 \n",
      "\n",
      "Epoch 2648\n",
      "-------------------------------\n",
      "loss: 0.320969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525392 \n",
      "\n",
      "Epoch 2649\n",
      "-------------------------------\n",
      "loss: 0.323306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524690 \n",
      "\n",
      "Epoch 2650\n",
      "-------------------------------\n",
      "loss: 0.318028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523826 \n",
      "\n",
      "Epoch 2651\n",
      "-------------------------------\n",
      "loss: 0.308486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523048 \n",
      "\n",
      "Epoch 2652\n",
      "-------------------------------\n",
      "loss: 0.310872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521795 \n",
      "\n",
      "Epoch 2653\n",
      "-------------------------------\n",
      "loss: 0.295226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521377 \n",
      "\n",
      "Epoch 2654\n",
      "-------------------------------\n",
      "loss: 0.318968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521252 \n",
      "\n",
      "Epoch 2655\n",
      "-------------------------------\n",
      "loss: 0.293209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520826 \n",
      "\n",
      "Epoch 2656\n",
      "-------------------------------\n",
      "loss: 0.328629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520806 \n",
      "\n",
      "Epoch 2657\n",
      "-------------------------------\n",
      "loss: 0.293109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520993 \n",
      "\n",
      "Epoch 2658\n",
      "-------------------------------\n",
      "loss: 0.314126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522178 \n",
      "\n",
      "Epoch 2659\n",
      "-------------------------------\n",
      "loss: 0.289409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523091 \n",
      "\n",
      "Epoch 2660\n",
      "-------------------------------\n",
      "loss: 0.308013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523775 \n",
      "\n",
      "Epoch 2661\n",
      "-------------------------------\n",
      "loss: 0.308559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523254 \n",
      "\n",
      "Epoch 2662\n",
      "-------------------------------\n",
      "loss: 0.301632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522337 \n",
      "\n",
      "Epoch 2663\n",
      "-------------------------------\n",
      "loss: 0.319048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521442 \n",
      "\n",
      "Epoch 2664\n",
      "-------------------------------\n",
      "loss: 0.304305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520701 \n",
      "\n",
      "Epoch 2665\n",
      "-------------------------------\n",
      "loss: 0.316350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520254 \n",
      "\n",
      "Epoch 2666\n",
      "-------------------------------\n",
      "loss: 0.302404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519726 \n",
      "\n",
      "Epoch 2667\n",
      "-------------------------------\n",
      "loss: 0.312884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519727 \n",
      "\n",
      "Epoch 2668\n",
      "-------------------------------\n",
      "loss: 0.297339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520076 \n",
      "\n",
      "Epoch 2669\n",
      "-------------------------------\n",
      "loss: 0.288560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521045 \n",
      "\n",
      "Epoch 2670\n",
      "-------------------------------\n",
      "loss: 0.290641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521417 \n",
      "\n",
      "Epoch 2671\n",
      "-------------------------------\n",
      "loss: 0.307192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522075 \n",
      "\n",
      "Epoch 2672\n",
      "-------------------------------\n",
      "loss: 0.296251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522663 \n",
      "\n",
      "Epoch 2673\n",
      "-------------------------------\n",
      "loss: 0.303689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523100 \n",
      "\n",
      "Epoch 2674\n",
      "-------------------------------\n",
      "loss: 0.294287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523223 \n",
      "\n",
      "Epoch 2675\n",
      "-------------------------------\n",
      "loss: 0.314166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523500 \n",
      "\n",
      "Epoch 2676\n",
      "-------------------------------\n",
      "loss: 0.300314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523718 \n",
      "\n",
      "Epoch 2677\n",
      "-------------------------------\n",
      "loss: 0.316240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523370 \n",
      "\n",
      "Epoch 2678\n",
      "-------------------------------\n",
      "loss: 0.298947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522968 \n",
      "\n",
      "Epoch 2679\n",
      "-------------------------------\n",
      "loss: 0.312508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522833 \n",
      "\n",
      "Epoch 2680\n",
      "-------------------------------\n",
      "loss: 0.310508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521920 \n",
      "\n",
      "Epoch 2681\n",
      "-------------------------------\n",
      "loss: 0.312253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521344 \n",
      "\n",
      "Epoch 2682\n",
      "-------------------------------\n",
      "loss: 0.278648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521409 \n",
      "\n",
      "Epoch 2683\n",
      "-------------------------------\n",
      "loss: 0.309441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521640 \n",
      "\n",
      "Epoch 2684\n",
      "-------------------------------\n",
      "loss: 0.317877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522696 \n",
      "\n",
      "Epoch 2685\n",
      "-------------------------------\n",
      "loss: 0.314582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523594 \n",
      "\n",
      "Epoch 2686\n",
      "-------------------------------\n",
      "loss: 0.311125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524423 \n",
      "\n",
      "Epoch 2687\n",
      "-------------------------------\n",
      "loss: 0.306966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524959 \n",
      "\n",
      "Epoch 2688\n",
      "-------------------------------\n",
      "loss: 0.310620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524353 \n",
      "\n",
      "Epoch 2689\n",
      "-------------------------------\n",
      "loss: 0.308979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523620 \n",
      "\n",
      "Epoch 2690\n",
      "-------------------------------\n",
      "loss: 0.311558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523449 \n",
      "\n",
      "Epoch 2691\n",
      "-------------------------------\n",
      "loss: 0.305781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522656 \n",
      "\n",
      "Epoch 2692\n",
      "-------------------------------\n",
      "loss: 0.280239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521774 \n",
      "\n",
      "Epoch 2693\n",
      "-------------------------------\n",
      "loss: 0.293560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521086 \n",
      "\n",
      "Epoch 2694\n",
      "-------------------------------\n",
      "loss: 0.300895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521196 \n",
      "\n",
      "Epoch 2695\n",
      "-------------------------------\n",
      "loss: 0.319832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521252 \n",
      "\n",
      "Epoch 2696\n",
      "-------------------------------\n",
      "loss: 0.324999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521899 \n",
      "\n",
      "Epoch 2697\n",
      "-------------------------------\n",
      "loss: 0.287111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523317 \n",
      "\n",
      "Epoch 2698\n",
      "-------------------------------\n",
      "loss: 0.301839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524785 \n",
      "\n",
      "Epoch 2699\n",
      "-------------------------------\n",
      "loss: 0.313292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525253 \n",
      "\n",
      "Epoch 2700\n",
      "-------------------------------\n",
      "loss: 0.317297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524970 \n",
      "\n",
      "Epoch 2701\n",
      "-------------------------------\n",
      "loss: 0.309811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523060 \n",
      "\n",
      "Epoch 2702\n",
      "-------------------------------\n",
      "loss: 0.307349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522257 \n",
      "\n",
      "Epoch 2703\n",
      "-------------------------------\n",
      "loss: 0.300089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521624 \n",
      "\n",
      "Epoch 2704\n",
      "-------------------------------\n",
      "loss: 0.306763  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521158 \n",
      "\n",
      "Epoch 2705\n",
      "-------------------------------\n",
      "loss: 0.316108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520402 \n",
      "\n",
      "Epoch 2706\n",
      "-------------------------------\n",
      "loss: 0.299988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520502 \n",
      "\n",
      "Epoch 2707\n",
      "-------------------------------\n",
      "loss: 0.311352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521449 \n",
      "\n",
      "Epoch 2708\n",
      "-------------------------------\n",
      "loss: 0.331452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521939 \n",
      "\n",
      "Epoch 2709\n",
      "-------------------------------\n",
      "loss: 0.297170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521495 \n",
      "\n",
      "Epoch 2710\n",
      "-------------------------------\n",
      "loss: 0.288192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520708 \n",
      "\n",
      "Epoch 2711\n",
      "-------------------------------\n",
      "loss: 0.299254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519799 \n",
      "\n",
      "Epoch 2712\n",
      "-------------------------------\n",
      "loss: 0.312403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520291 \n",
      "\n",
      "Epoch 2713\n",
      "-------------------------------\n",
      "loss: 0.308125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520965 \n",
      "\n",
      "Epoch 2714\n",
      "-------------------------------\n",
      "loss: 0.329603  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521358 \n",
      "\n",
      "Epoch 2715\n",
      "-------------------------------\n",
      "loss: 0.299155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521321 \n",
      "\n",
      "Epoch 2716\n",
      "-------------------------------\n",
      "loss: 0.298947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522310 \n",
      "\n",
      "Epoch 2717\n",
      "-------------------------------\n",
      "loss: 0.311841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523671 \n",
      "\n",
      "Epoch 2718\n",
      "-------------------------------\n",
      "loss: 0.331107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525428 \n",
      "\n",
      "Epoch 2719\n",
      "-------------------------------\n",
      "loss: 0.315801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525501 \n",
      "\n",
      "Epoch 2720\n",
      "-------------------------------\n",
      "loss: 0.297308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524707 \n",
      "\n",
      "Epoch 2721\n",
      "-------------------------------\n",
      "loss: 0.325824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522595 \n",
      "\n",
      "Epoch 2722\n",
      "-------------------------------\n",
      "loss: 0.317918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520537 \n",
      "\n",
      "Epoch 2723\n",
      "-------------------------------\n",
      "loss: 0.313114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519069 \n",
      "\n",
      "Epoch 2724\n",
      "-------------------------------\n",
      "loss: 0.308784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518692 \n",
      "\n",
      "Epoch 2725\n",
      "-------------------------------\n",
      "loss: 0.310594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518327 \n",
      "\n",
      "Epoch 2726\n",
      "-------------------------------\n",
      "loss: 0.318471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517963 \n",
      "\n",
      "Epoch 2727\n",
      "-------------------------------\n",
      "loss: 0.310502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518954 \n",
      "\n",
      "Epoch 2728\n",
      "-------------------------------\n",
      "loss: 0.300025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520907 \n",
      "\n",
      "Epoch 2729\n",
      "-------------------------------\n",
      "loss: 0.307097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523191 \n",
      "\n",
      "Epoch 2730\n",
      "-------------------------------\n",
      "loss: 0.304925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524370 \n",
      "\n",
      "Epoch 2731\n",
      "-------------------------------\n",
      "loss: 0.300219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524183 \n",
      "\n",
      "Epoch 2732\n",
      "-------------------------------\n",
      "loss: 0.297509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521970 \n",
      "\n",
      "Epoch 2733\n",
      "-------------------------------\n",
      "loss: 0.307299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519420 \n",
      "\n",
      "Epoch 2734\n",
      "-------------------------------\n",
      "loss: 0.309914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517836 \n",
      "\n",
      "Epoch 2735\n",
      "-------------------------------\n",
      "loss: 0.301139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516423 \n",
      "\n",
      "Epoch 2736\n",
      "-------------------------------\n",
      "loss: 0.300546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516372 \n",
      "\n",
      "Epoch 2737\n",
      "-------------------------------\n",
      "loss: 0.312170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516385 \n",
      "\n",
      "Epoch 2738\n",
      "-------------------------------\n",
      "loss: 0.296712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516230 \n",
      "\n",
      "Epoch 2739\n",
      "-------------------------------\n",
      "loss: 0.292393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516624 \n",
      "\n",
      "Epoch 2740\n",
      "-------------------------------\n",
      "loss: 0.315916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516917 \n",
      "\n",
      "Epoch 2741\n",
      "-------------------------------\n",
      "loss: 0.301852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518690 \n",
      "\n",
      "Epoch 2742\n",
      "-------------------------------\n",
      "loss: 0.320893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520528 \n",
      "\n",
      "Epoch 2743\n",
      "-------------------------------\n",
      "loss: 0.302226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520106 \n",
      "\n",
      "Epoch 2744\n",
      "-------------------------------\n",
      "loss: 0.324145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519419 \n",
      "\n",
      "Epoch 2745\n",
      "-------------------------------\n",
      "loss: 0.311531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519028 \n",
      "\n",
      "Epoch 2746\n",
      "-------------------------------\n",
      "loss: 0.317200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518482 \n",
      "\n",
      "Epoch 2747\n",
      "-------------------------------\n",
      "loss: 0.308820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518189 \n",
      "\n",
      "Epoch 2748\n",
      "-------------------------------\n",
      "loss: 0.309645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517618 \n",
      "\n",
      "Epoch 2749\n",
      "-------------------------------\n",
      "loss: 0.303001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517874 \n",
      "\n",
      "Epoch 2750\n",
      "-------------------------------\n",
      "loss: 0.302509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518268 \n",
      "\n",
      "Epoch 2751\n",
      "-------------------------------\n",
      "loss: 0.301553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518789 \n",
      "\n",
      "Epoch 2752\n",
      "-------------------------------\n",
      "loss: 0.308669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518725 \n",
      "\n",
      "Epoch 2753\n",
      "-------------------------------\n",
      "loss: 0.316156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518759 \n",
      "\n",
      "Epoch 2754\n",
      "-------------------------------\n",
      "loss: 0.295886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519369 \n",
      "\n",
      "Epoch 2755\n",
      "-------------------------------\n",
      "loss: 0.299562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520234 \n",
      "\n",
      "Epoch 2756\n",
      "-------------------------------\n",
      "loss: 0.304712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521087 \n",
      "\n",
      "Epoch 2757\n",
      "-------------------------------\n",
      "loss: 0.298296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521013 \n",
      "\n",
      "Epoch 2758\n",
      "-------------------------------\n",
      "loss: 0.301138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520549 \n",
      "\n",
      "Epoch 2759\n",
      "-------------------------------\n",
      "loss: 0.312246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519713 \n",
      "\n",
      "Epoch 2760\n",
      "-------------------------------\n",
      "loss: 0.306599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519526 \n",
      "\n",
      "Epoch 2761\n",
      "-------------------------------\n",
      "loss: 0.316768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520273 \n",
      "\n",
      "Epoch 2762\n",
      "-------------------------------\n",
      "loss: 0.304188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519993 \n",
      "\n",
      "Epoch 2763\n",
      "-------------------------------\n",
      "loss: 0.300008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519197 \n",
      "\n",
      "Epoch 2764\n",
      "-------------------------------\n",
      "loss: 0.291733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517531 \n",
      "\n",
      "Epoch 2765\n",
      "-------------------------------\n",
      "loss: 0.296001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517062 \n",
      "\n",
      "Epoch 2766\n",
      "-------------------------------\n",
      "loss: 0.305777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518303 \n",
      "\n",
      "Epoch 2767\n",
      "-------------------------------\n",
      "loss: 0.294392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519369 \n",
      "\n",
      "Epoch 2768\n",
      "-------------------------------\n",
      "loss: 0.316036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518832 \n",
      "\n",
      "Epoch 2769\n",
      "-------------------------------\n",
      "loss: 0.313912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518997 \n",
      "\n",
      "Epoch 2770\n",
      "-------------------------------\n",
      "loss: 0.312766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520138 \n",
      "\n",
      "Epoch 2771\n",
      "-------------------------------\n",
      "loss: 0.293447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521871 \n",
      "\n",
      "Epoch 2772\n",
      "-------------------------------\n",
      "loss: 0.292562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522609 \n",
      "\n",
      "Epoch 2773\n",
      "-------------------------------\n",
      "loss: 0.308347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521255 \n",
      "\n",
      "Epoch 2774\n",
      "-------------------------------\n",
      "loss: 0.299029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520437 \n",
      "\n",
      "Epoch 2775\n",
      "-------------------------------\n",
      "loss: 0.307244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521045 \n",
      "\n",
      "Epoch 2776\n",
      "-------------------------------\n",
      "loss: 0.304483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521464 \n",
      "\n",
      "Epoch 2777\n",
      "-------------------------------\n",
      "loss: 0.308428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520947 \n",
      "\n",
      "Epoch 2778\n",
      "-------------------------------\n",
      "loss: 0.301788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520756 \n",
      "\n",
      "Epoch 2779\n",
      "-------------------------------\n",
      "loss: 0.307304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521192 \n",
      "\n",
      "Epoch 2780\n",
      "-------------------------------\n",
      "loss: 0.303256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522345 \n",
      "\n",
      "Epoch 2781\n",
      "-------------------------------\n",
      "loss: 0.304004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523571 \n",
      "\n",
      "Epoch 2782\n",
      "-------------------------------\n",
      "loss: 0.311146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521779 \n",
      "\n",
      "Epoch 2783\n",
      "-------------------------------\n",
      "loss: 0.300685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519860 \n",
      "\n",
      "Epoch 2784\n",
      "-------------------------------\n",
      "loss: 0.285096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518321 \n",
      "\n",
      "Epoch 2785\n",
      "-------------------------------\n",
      "loss: 0.300534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518134 \n",
      "\n",
      "Epoch 2786\n",
      "-------------------------------\n",
      "loss: 0.315217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519745 \n",
      "\n",
      "Epoch 2787\n",
      "-------------------------------\n",
      "loss: 0.309848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521622 \n",
      "\n",
      "Epoch 2788\n",
      "-------------------------------\n",
      "loss: 0.325535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522075 \n",
      "\n",
      "Epoch 2789\n",
      "-------------------------------\n",
      "loss: 0.322192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524225 \n",
      "\n",
      "Epoch 2790\n",
      "-------------------------------\n",
      "loss: 0.295165  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.526700 \n",
      "\n",
      "Epoch 2791\n",
      "-------------------------------\n",
      "loss: 0.299536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528568 \n",
      "\n",
      "Epoch 2792\n",
      "-------------------------------\n",
      "loss: 0.308530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527029 \n",
      "\n",
      "Epoch 2793\n",
      "-------------------------------\n",
      "loss: 0.321509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522864 \n",
      "\n",
      "Epoch 2794\n",
      "-------------------------------\n",
      "loss: 0.320289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521756 \n",
      "\n",
      "Epoch 2795\n",
      "-------------------------------\n",
      "loss: 0.300028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522407 \n",
      "\n",
      "Epoch 2796\n",
      "-------------------------------\n",
      "loss: 0.331610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522979 \n",
      "\n",
      "Epoch 2797\n",
      "-------------------------------\n",
      "loss: 0.305431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522285 \n",
      "\n",
      "Epoch 2798\n",
      "-------------------------------\n",
      "loss: 0.284786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521788 \n",
      "\n",
      "Epoch 2799\n",
      "-------------------------------\n",
      "loss: 0.297172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522146 \n",
      "\n",
      "Epoch 2800\n",
      "-------------------------------\n",
      "loss: 0.308550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523091 \n",
      "\n",
      "Epoch 2801\n",
      "-------------------------------\n",
      "loss: 0.299501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524063 \n",
      "\n",
      "Epoch 2802\n",
      "-------------------------------\n",
      "loss: 0.309111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523135 \n",
      "\n",
      "Epoch 2803\n",
      "-------------------------------\n",
      "loss: 0.320161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519990 \n",
      "\n",
      "Epoch 2804\n",
      "-------------------------------\n",
      "loss: 0.313109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516508 \n",
      "\n",
      "Epoch 2805\n",
      "-------------------------------\n",
      "loss: 0.300401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515576 \n",
      "\n",
      "Epoch 2806\n",
      "-------------------------------\n",
      "loss: 0.296619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515944 \n",
      "\n",
      "Epoch 2807\n",
      "-------------------------------\n",
      "loss: 0.307956  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516518 \n",
      "\n",
      "Epoch 2808\n",
      "-------------------------------\n",
      "loss: 0.291494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516123 \n",
      "\n",
      "Epoch 2809\n",
      "-------------------------------\n",
      "loss: 0.299929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515769 \n",
      "\n",
      "Epoch 2810\n",
      "-------------------------------\n",
      "loss: 0.316812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516583 \n",
      "\n",
      "Epoch 2811\n",
      "-------------------------------\n",
      "loss: 0.292553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518797 \n",
      "\n",
      "Epoch 2812\n",
      "-------------------------------\n",
      "loss: 0.303147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521447 \n",
      "\n",
      "Epoch 2813\n",
      "-------------------------------\n",
      "loss: 0.283308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522392 \n",
      "\n",
      "Epoch 2814\n",
      "-------------------------------\n",
      "loss: 0.296044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522692 \n",
      "\n",
      "Epoch 2815\n",
      "-------------------------------\n",
      "loss: 0.300800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522307 \n",
      "\n",
      "Epoch 2816\n",
      "-------------------------------\n",
      "loss: 0.285129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522108 \n",
      "\n",
      "Epoch 2817\n",
      "-------------------------------\n",
      "loss: 0.316015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522132 \n",
      "\n",
      "Epoch 2818\n",
      "-------------------------------\n",
      "loss: 0.298612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521419 \n",
      "\n",
      "Epoch 2819\n",
      "-------------------------------\n",
      "loss: 0.305727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520788 \n",
      "\n",
      "Epoch 2820\n",
      "-------------------------------\n",
      "loss: 0.303203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520292 \n",
      "\n",
      "Epoch 2821\n",
      "-------------------------------\n",
      "loss: 0.289646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520059 \n",
      "\n",
      "Epoch 2822\n",
      "-------------------------------\n",
      "loss: 0.306102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519972 \n",
      "\n",
      "Epoch 2823\n",
      "-------------------------------\n",
      "loss: 0.292956  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520339 \n",
      "\n",
      "Epoch 2824\n",
      "-------------------------------\n",
      "loss: 0.296654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520399 \n",
      "\n",
      "Epoch 2825\n",
      "-------------------------------\n",
      "loss: 0.325745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520659 \n",
      "\n",
      "Epoch 2826\n",
      "-------------------------------\n",
      "loss: 0.334324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521938 \n",
      "\n",
      "Epoch 2827\n",
      "-------------------------------\n",
      "loss: 0.328706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523987 \n",
      "\n",
      "Epoch 2828\n",
      "-------------------------------\n",
      "loss: 0.302392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525867 \n",
      "\n",
      "Epoch 2829\n",
      "-------------------------------\n",
      "loss: 0.310706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526611 \n",
      "\n",
      "Epoch 2830\n",
      "-------------------------------\n",
      "loss: 0.312703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526640 \n",
      "\n",
      "Epoch 2831\n",
      "-------------------------------\n",
      "loss: 0.299709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525157 \n",
      "\n",
      "Epoch 2832\n",
      "-------------------------------\n",
      "loss: 0.303552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522110 \n",
      "\n",
      "Epoch 2833\n",
      "-------------------------------\n",
      "loss: 0.303893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520540 \n",
      "\n",
      "Epoch 2834\n",
      "-------------------------------\n",
      "loss: 0.300911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519533 \n",
      "\n",
      "Epoch 2835\n",
      "-------------------------------\n",
      "loss: 0.291827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519933 \n",
      "\n",
      "Epoch 2836\n",
      "-------------------------------\n",
      "loss: 0.298495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520924 \n",
      "\n",
      "Epoch 2837\n",
      "-------------------------------\n",
      "loss: 0.289920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521477 \n",
      "\n",
      "Epoch 2838\n",
      "-------------------------------\n",
      "loss: 0.314396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521449 \n",
      "\n",
      "Epoch 2839\n",
      "-------------------------------\n",
      "loss: 0.312567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520776 \n",
      "\n",
      "Epoch 2840\n",
      "-------------------------------\n",
      "loss: 0.299110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520877 \n",
      "\n",
      "Epoch 2841\n",
      "-------------------------------\n",
      "loss: 0.299741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521056 \n",
      "\n",
      "Epoch 2842\n",
      "-------------------------------\n",
      "loss: 0.298305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520469 \n",
      "\n",
      "Epoch 2843\n",
      "-------------------------------\n",
      "loss: 0.284403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519117 \n",
      "\n",
      "Epoch 2844\n",
      "-------------------------------\n",
      "loss: 0.300609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518457 \n",
      "\n",
      "Epoch 2845\n",
      "-------------------------------\n",
      "loss: 0.291494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518443 \n",
      "\n",
      "Epoch 2846\n",
      "-------------------------------\n",
      "loss: 0.284333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519342 \n",
      "\n",
      "Epoch 2847\n",
      "-------------------------------\n",
      "loss: 0.307187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519653 \n",
      "\n",
      "Epoch 2848\n",
      "-------------------------------\n",
      "loss: 0.308636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520049 \n",
      "\n",
      "Epoch 2849\n",
      "-------------------------------\n",
      "loss: 0.283154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521255 \n",
      "\n",
      "Epoch 2850\n",
      "-------------------------------\n",
      "loss: 0.304756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522281 \n",
      "\n",
      "Epoch 2851\n",
      "-------------------------------\n",
      "loss: 0.302062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523078 \n",
      "\n",
      "Epoch 2852\n",
      "-------------------------------\n",
      "loss: 0.313818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523023 \n",
      "\n",
      "Epoch 2853\n",
      "-------------------------------\n",
      "loss: 0.319249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522983 \n",
      "\n",
      "Epoch 2854\n",
      "-------------------------------\n",
      "loss: 0.319202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522174 \n",
      "\n",
      "Epoch 2855\n",
      "-------------------------------\n",
      "loss: 0.316773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520496 \n",
      "\n",
      "Epoch 2856\n",
      "-------------------------------\n",
      "loss: 0.305123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518162 \n",
      "\n",
      "Epoch 2857\n",
      "-------------------------------\n",
      "loss: 0.283099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516505 \n",
      "\n",
      "Epoch 2858\n",
      "-------------------------------\n",
      "loss: 0.280679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515872 \n",
      "\n",
      "Epoch 2859\n",
      "-------------------------------\n",
      "loss: 0.298414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515513 \n",
      "\n",
      "Epoch 2860\n",
      "-------------------------------\n",
      "loss: 0.298232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515737 \n",
      "\n",
      "Epoch 2861\n",
      "-------------------------------\n",
      "loss: 0.305625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516266 \n",
      "\n",
      "Epoch 2862\n",
      "-------------------------------\n",
      "loss: 0.293606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517125 \n",
      "\n",
      "Epoch 2863\n",
      "-------------------------------\n",
      "loss: 0.314919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518263 \n",
      "\n",
      "Epoch 2864\n",
      "-------------------------------\n",
      "loss: 0.300377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517541 \n",
      "\n",
      "Epoch 2865\n",
      "-------------------------------\n",
      "loss: 0.291879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517748 \n",
      "\n",
      "Epoch 2866\n",
      "-------------------------------\n",
      "loss: 0.303834  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.517813 \n",
      "\n",
      "Epoch 2867\n",
      "-------------------------------\n",
      "loss: 0.293111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517805 \n",
      "\n",
      "Epoch 2868\n",
      "-------------------------------\n",
      "loss: 0.311536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518068 \n",
      "\n",
      "Epoch 2869\n",
      "-------------------------------\n",
      "loss: 0.298865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519261 \n",
      "\n",
      "Epoch 2870\n",
      "-------------------------------\n",
      "loss: 0.300155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519950 \n",
      "\n",
      "Epoch 2871\n",
      "-------------------------------\n",
      "loss: 0.295035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519869 \n",
      "\n",
      "Epoch 2872\n",
      "-------------------------------\n",
      "loss: 0.293331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519989 \n",
      "\n",
      "Epoch 2873\n",
      "-------------------------------\n",
      "loss: 0.301183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518919 \n",
      "\n",
      "Epoch 2874\n",
      "-------------------------------\n",
      "loss: 0.282991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518236 \n",
      "\n",
      "Epoch 2875\n",
      "-------------------------------\n",
      "loss: 0.302932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517407 \n",
      "\n",
      "Epoch 2876\n",
      "-------------------------------\n",
      "loss: 0.293384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517000 \n",
      "\n",
      "Epoch 2877\n",
      "-------------------------------\n",
      "loss: 0.315275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517831 \n",
      "\n",
      "Epoch 2878\n",
      "-------------------------------\n",
      "loss: 0.298556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518895 \n",
      "\n",
      "Epoch 2879\n",
      "-------------------------------\n",
      "loss: 0.305766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519903 \n",
      "\n",
      "Epoch 2880\n",
      "-------------------------------\n",
      "loss: 0.298388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520412 \n",
      "\n",
      "Epoch 2881\n",
      "-------------------------------\n",
      "loss: 0.318683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521468 \n",
      "\n",
      "Epoch 2882\n",
      "-------------------------------\n",
      "loss: 0.298423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522420 \n",
      "\n",
      "Epoch 2883\n",
      "-------------------------------\n",
      "loss: 0.285507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522630 \n",
      "\n",
      "Epoch 2884\n",
      "-------------------------------\n",
      "loss: 0.290713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522419 \n",
      "\n",
      "Epoch 2885\n",
      "-------------------------------\n",
      "loss: 0.299563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520959 \n",
      "\n",
      "Epoch 2886\n",
      "-------------------------------\n",
      "loss: 0.315287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519541 \n",
      "\n",
      "Epoch 2887\n",
      "-------------------------------\n",
      "loss: 0.305204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518918 \n",
      "\n",
      "Epoch 2888\n",
      "-------------------------------\n",
      "loss: 0.303919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519155 \n",
      "\n",
      "Epoch 2889\n",
      "-------------------------------\n",
      "loss: 0.298545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520021 \n",
      "\n",
      "Epoch 2890\n",
      "-------------------------------\n",
      "loss: 0.307553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522087 \n",
      "\n",
      "Epoch 2891\n",
      "-------------------------------\n",
      "loss: 0.283840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525285 \n",
      "\n",
      "Epoch 2892\n",
      "-------------------------------\n",
      "loss: 0.310721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528168 \n",
      "\n",
      "Epoch 2893\n",
      "-------------------------------\n",
      "loss: 0.304643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529348 \n",
      "\n",
      "Epoch 2894\n",
      "-------------------------------\n",
      "loss: 0.299967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529523 \n",
      "\n",
      "Epoch 2895\n",
      "-------------------------------\n",
      "loss: 0.289848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528199 \n",
      "\n",
      "Epoch 2896\n",
      "-------------------------------\n",
      "loss: 0.303213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526197 \n",
      "\n",
      "Epoch 2897\n",
      "-------------------------------\n",
      "loss: 0.301031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524307 \n",
      "\n",
      "Epoch 2898\n",
      "-------------------------------\n",
      "loss: 0.303243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522572 \n",
      "\n",
      "Epoch 2899\n",
      "-------------------------------\n",
      "loss: 0.299128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520975 \n",
      "\n",
      "Epoch 2900\n",
      "-------------------------------\n",
      "loss: 0.280412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520619 \n",
      "\n",
      "Epoch 2901\n",
      "-------------------------------\n",
      "loss: 0.295758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520260 \n",
      "\n",
      "Epoch 2902\n",
      "-------------------------------\n",
      "loss: 0.309768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519759 \n",
      "\n",
      "Epoch 2903\n",
      "-------------------------------\n",
      "loss: 0.301253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519501 \n",
      "\n",
      "Epoch 2904\n",
      "-------------------------------\n",
      "loss: 0.318840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519680 \n",
      "\n",
      "Epoch 2905\n",
      "-------------------------------\n",
      "loss: 0.306837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520621 \n",
      "\n",
      "Epoch 2906\n",
      "-------------------------------\n",
      "loss: 0.312109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522238 \n",
      "\n",
      "Epoch 2907\n",
      "-------------------------------\n",
      "loss: 0.302050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523874 \n",
      "\n",
      "Epoch 2908\n",
      "-------------------------------\n",
      "loss: 0.288762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525741 \n",
      "\n",
      "Epoch 2909\n",
      "-------------------------------\n",
      "loss: 0.315950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526283 \n",
      "\n",
      "Epoch 2910\n",
      "-------------------------------\n",
      "loss: 0.297600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524602 \n",
      "\n",
      "Epoch 2911\n",
      "-------------------------------\n",
      "loss: 0.295417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521717 \n",
      "\n",
      "Epoch 2912\n",
      "-------------------------------\n",
      "loss: 0.306722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520724 \n",
      "\n",
      "Epoch 2913\n",
      "-------------------------------\n",
      "loss: 0.290716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521272 \n",
      "\n",
      "Epoch 2914\n",
      "-------------------------------\n",
      "loss: 0.310967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521417 \n",
      "\n",
      "Epoch 2915\n",
      "-------------------------------\n",
      "loss: 0.295586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522237 \n",
      "\n",
      "Epoch 2916\n",
      "-------------------------------\n",
      "loss: 0.308846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523084 \n",
      "\n",
      "Epoch 2917\n",
      "-------------------------------\n",
      "loss: 0.293532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523315 \n",
      "\n",
      "Epoch 2918\n",
      "-------------------------------\n",
      "loss: 0.310306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523543 \n",
      "\n",
      "Epoch 2919\n",
      "-------------------------------\n",
      "loss: 0.299310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523241 \n",
      "\n",
      "Epoch 2920\n",
      "-------------------------------\n",
      "loss: 0.291869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522828 \n",
      "\n",
      "Epoch 2921\n",
      "-------------------------------\n",
      "loss: 0.300180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521844 \n",
      "\n",
      "Epoch 2922\n",
      "-------------------------------\n",
      "loss: 0.294202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521539 \n",
      "\n",
      "Epoch 2923\n",
      "-------------------------------\n",
      "loss: 0.300246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521604 \n",
      "\n",
      "Epoch 2924\n",
      "-------------------------------\n",
      "loss: 0.280250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521971 \n",
      "\n",
      "Epoch 2925\n",
      "-------------------------------\n",
      "loss: 0.286245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522088 \n",
      "\n",
      "Epoch 2926\n",
      "-------------------------------\n",
      "loss: 0.294416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522435 \n",
      "\n",
      "Epoch 2927\n",
      "-------------------------------\n",
      "loss: 0.316791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523343 \n",
      "\n",
      "Epoch 2928\n",
      "-------------------------------\n",
      "loss: 0.310450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524301 \n",
      "\n",
      "Epoch 2929\n",
      "-------------------------------\n",
      "loss: 0.293109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524168 \n",
      "\n",
      "Epoch 2930\n",
      "-------------------------------\n",
      "loss: 0.296480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524127 \n",
      "\n",
      "Epoch 2931\n",
      "-------------------------------\n",
      "loss: 0.307621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523686 \n",
      "\n",
      "Epoch 2932\n",
      "-------------------------------\n",
      "loss: 0.297904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523836 \n",
      "\n",
      "Epoch 2933\n",
      "-------------------------------\n",
      "loss: 0.304322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523963 \n",
      "\n",
      "Epoch 2934\n",
      "-------------------------------\n",
      "loss: 0.304196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523290 \n",
      "\n",
      "Epoch 2935\n",
      "-------------------------------\n",
      "loss: 0.291564  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522128 \n",
      "\n",
      "Epoch 2936\n",
      "-------------------------------\n",
      "loss: 0.308979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520637 \n",
      "\n",
      "Epoch 2937\n",
      "-------------------------------\n",
      "loss: 0.289554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519661 \n",
      "\n",
      "Epoch 2938\n",
      "-------------------------------\n",
      "loss: 0.294480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519383 \n",
      "\n",
      "Epoch 2939\n",
      "-------------------------------\n",
      "loss: 0.304562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519272 \n",
      "\n",
      "Epoch 2940\n",
      "-------------------------------\n",
      "loss: 0.306719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518303 \n",
      "\n",
      "Epoch 2941\n",
      "-------------------------------\n",
      "loss: 0.297373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517558 \n",
      "\n",
      "Epoch 2942\n",
      "-------------------------------\n",
      "loss: 0.305301  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.518282 \n",
      "\n",
      "Epoch 2943\n",
      "-------------------------------\n",
      "loss: 0.310366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519921 \n",
      "\n",
      "Epoch 2944\n",
      "-------------------------------\n",
      "loss: 0.307980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522139 \n",
      "\n",
      "Epoch 2945\n",
      "-------------------------------\n",
      "loss: 0.295595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523563 \n",
      "\n",
      "Epoch 2946\n",
      "-------------------------------\n",
      "loss: 0.325808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522793 \n",
      "\n",
      "Epoch 2947\n",
      "-------------------------------\n",
      "loss: 0.303487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521534 \n",
      "\n",
      "Epoch 2948\n",
      "-------------------------------\n",
      "loss: 0.297582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520746 \n",
      "\n",
      "Epoch 2949\n",
      "-------------------------------\n",
      "loss: 0.305262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519801 \n",
      "\n",
      "Epoch 2950\n",
      "-------------------------------\n",
      "loss: 0.313785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517472 \n",
      "\n",
      "Epoch 2951\n",
      "-------------------------------\n",
      "loss: 0.295638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515793 \n",
      "\n",
      "Epoch 2952\n",
      "-------------------------------\n",
      "loss: 0.300098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515652 \n",
      "\n",
      "Epoch 2953\n",
      "-------------------------------\n",
      "loss: 0.282832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516201 \n",
      "\n",
      "Epoch 2954\n",
      "-------------------------------\n",
      "loss: 0.302024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516292 \n",
      "\n",
      "Epoch 2955\n",
      "-------------------------------\n",
      "loss: 0.307893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515666 \n",
      "\n",
      "Epoch 2956\n",
      "-------------------------------\n",
      "loss: 0.327836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515925 \n",
      "\n",
      "Epoch 2957\n",
      "-------------------------------\n",
      "loss: 0.303452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517311 \n",
      "\n",
      "Epoch 2958\n",
      "-------------------------------\n",
      "loss: 0.298110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519782 \n",
      "\n",
      "Epoch 2959\n",
      "-------------------------------\n",
      "loss: 0.300964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521869 \n",
      "\n",
      "Epoch 2960\n",
      "-------------------------------\n",
      "loss: 0.307946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523617 \n",
      "\n",
      "Epoch 2961\n",
      "-------------------------------\n",
      "loss: 0.296609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524122 \n",
      "\n",
      "Epoch 2962\n",
      "-------------------------------\n",
      "loss: 0.314517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522971 \n",
      "\n",
      "Epoch 2963\n",
      "-------------------------------\n",
      "loss: 0.298379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520418 \n",
      "\n",
      "Epoch 2964\n",
      "-------------------------------\n",
      "loss: 0.298429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518098 \n",
      "\n",
      "Epoch 2965\n",
      "-------------------------------\n",
      "loss: 0.285468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516334 \n",
      "\n",
      "Epoch 2966\n",
      "-------------------------------\n",
      "loss: 0.286835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514566 \n",
      "\n",
      "Epoch 2967\n",
      "-------------------------------\n",
      "loss: 0.290612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512963 \n",
      "\n",
      "Epoch 2968\n",
      "-------------------------------\n",
      "loss: 0.307386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512622 \n",
      "\n",
      "Epoch 2969\n",
      "-------------------------------\n",
      "loss: 0.286685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513099 \n",
      "\n",
      "Epoch 2970\n",
      "-------------------------------\n",
      "loss: 0.298372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513718 \n",
      "\n",
      "Epoch 2971\n",
      "-------------------------------\n",
      "loss: 0.289708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514159 \n",
      "\n",
      "Epoch 2972\n",
      "-------------------------------\n",
      "loss: 0.299623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515174 \n",
      "\n",
      "Epoch 2973\n",
      "-------------------------------\n",
      "loss: 0.293634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515689 \n",
      "\n",
      "Epoch 2974\n",
      "-------------------------------\n",
      "loss: 0.283781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516008 \n",
      "\n",
      "Epoch 2975\n",
      "-------------------------------\n",
      "loss: 0.314307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516181 \n",
      "\n",
      "Epoch 2976\n",
      "-------------------------------\n",
      "loss: 0.292662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515986 \n",
      "\n",
      "Epoch 2977\n",
      "-------------------------------\n",
      "loss: 0.305591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516201 \n",
      "\n",
      "Epoch 2978\n",
      "-------------------------------\n",
      "loss: 0.296799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516812 \n",
      "\n",
      "Epoch 2979\n",
      "-------------------------------\n",
      "loss: 0.315324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517103 \n",
      "\n",
      "Epoch 2980\n",
      "-------------------------------\n",
      "loss: 0.300544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516976 \n",
      "\n",
      "Epoch 2981\n",
      "-------------------------------\n",
      "loss: 0.298440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516940 \n",
      "\n",
      "Epoch 2982\n",
      "-------------------------------\n",
      "loss: 0.300733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516404 \n",
      "\n",
      "Epoch 2983\n",
      "-------------------------------\n",
      "loss: 0.302893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516040 \n",
      "\n",
      "Epoch 2984\n",
      "-------------------------------\n",
      "loss: 0.294654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516049 \n",
      "\n",
      "Epoch 2985\n",
      "-------------------------------\n",
      "loss: 0.295858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516167 \n",
      "\n",
      "Epoch 2986\n",
      "-------------------------------\n",
      "loss: 0.306981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516553 \n",
      "\n",
      "Epoch 2987\n",
      "-------------------------------\n",
      "loss: 0.317997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517176 \n",
      "\n",
      "Epoch 2988\n",
      "-------------------------------\n",
      "loss: 0.291390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516708 \n",
      "\n",
      "Epoch 2989\n",
      "-------------------------------\n",
      "loss: 0.296537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516369 \n",
      "\n",
      "Epoch 2990\n",
      "-------------------------------\n",
      "loss: 0.303621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517094 \n",
      "\n",
      "Epoch 2991\n",
      "-------------------------------\n",
      "loss: 0.300295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517482 \n",
      "\n",
      "Epoch 2992\n",
      "-------------------------------\n",
      "loss: 0.300371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517796 \n",
      "\n",
      "Epoch 2993\n",
      "-------------------------------\n",
      "loss: 0.291608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517926 \n",
      "\n",
      "Epoch 2994\n",
      "-------------------------------\n",
      "loss: 0.291269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518246 \n",
      "\n",
      "Epoch 2995\n",
      "-------------------------------\n",
      "loss: 0.325166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518454 \n",
      "\n",
      "Epoch 2996\n",
      "-------------------------------\n",
      "loss: 0.287419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518802 \n",
      "\n",
      "Epoch 2997\n",
      "-------------------------------\n",
      "loss: 0.289659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519166 \n",
      "\n",
      "Epoch 2998\n",
      "-------------------------------\n",
      "loss: 0.297780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519107 \n",
      "\n",
      "Epoch 2999\n",
      "-------------------------------\n",
      "loss: 0.294658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519990 \n",
      "\n",
      "Epoch 3000\n",
      "-------------------------------\n",
      "loss: 0.306406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520551 \n",
      "\n",
      "Epoch 3001\n",
      "-------------------------------\n",
      "loss: 0.287638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521079 \n",
      "\n",
      "Epoch 3002\n",
      "-------------------------------\n",
      "loss: 0.282272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521235 \n",
      "\n",
      "Epoch 3003\n",
      "-------------------------------\n",
      "loss: 0.302083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521513 \n",
      "\n",
      "Epoch 3004\n",
      "-------------------------------\n",
      "loss: 0.310183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521031 \n",
      "\n",
      "Epoch 3005\n",
      "-------------------------------\n",
      "loss: 0.302170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519141 \n",
      "\n",
      "Epoch 3006\n",
      "-------------------------------\n",
      "loss: 0.308234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519706 \n",
      "\n",
      "Epoch 3007\n",
      "-------------------------------\n",
      "loss: 0.297248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521413 \n",
      "\n",
      "Epoch 3008\n",
      "-------------------------------\n",
      "loss: 0.291132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522286 \n",
      "\n",
      "Epoch 3009\n",
      "-------------------------------\n",
      "loss: 0.302155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520611 \n",
      "\n",
      "Epoch 3010\n",
      "-------------------------------\n",
      "loss: 0.303655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517911 \n",
      "\n",
      "Epoch 3011\n",
      "-------------------------------\n",
      "loss: 0.300436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517266 \n",
      "\n",
      "Epoch 3012\n",
      "-------------------------------\n",
      "loss: 0.307560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517630 \n",
      "\n",
      "Epoch 3013\n",
      "-------------------------------\n",
      "loss: 0.298748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518461 \n",
      "\n",
      "Epoch 3014\n",
      "-------------------------------\n",
      "loss: 0.296413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519508 \n",
      "\n",
      "Epoch 3015\n",
      "-------------------------------\n",
      "loss: 0.301560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520484 \n",
      "\n",
      "Epoch 3016\n",
      "-------------------------------\n",
      "loss: 0.304176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521995 \n",
      "\n",
      "Epoch 3017\n",
      "-------------------------------\n",
      "loss: 0.298661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522489 \n",
      "\n",
      "Epoch 3018\n",
      "-------------------------------\n",
      "loss: 0.313836  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.522789 \n",
      "\n",
      "Epoch 3019\n",
      "-------------------------------\n",
      "loss: 0.295443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521347 \n",
      "\n",
      "Epoch 3020\n",
      "-------------------------------\n",
      "loss: 0.319578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517696 \n",
      "\n",
      "Epoch 3021\n",
      "-------------------------------\n",
      "loss: 0.309033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515454 \n",
      "\n",
      "Epoch 3022\n",
      "-------------------------------\n",
      "loss: 0.294515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515827 \n",
      "\n",
      "Epoch 3023\n",
      "-------------------------------\n",
      "loss: 0.314672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516334 \n",
      "\n",
      "Epoch 3024\n",
      "-------------------------------\n",
      "loss: 0.302294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516687 \n",
      "\n",
      "Epoch 3025\n",
      "-------------------------------\n",
      "loss: 0.324700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518324 \n",
      "\n",
      "Epoch 3026\n",
      "-------------------------------\n",
      "loss: 0.297770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521586 \n",
      "\n",
      "Epoch 3027\n",
      "-------------------------------\n",
      "loss: 0.296911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525376 \n",
      "\n",
      "Epoch 3028\n",
      "-------------------------------\n",
      "loss: 0.307281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528712 \n",
      "\n",
      "Epoch 3029\n",
      "-------------------------------\n",
      "loss: 0.315444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528697 \n",
      "\n",
      "Epoch 3030\n",
      "-------------------------------\n",
      "loss: 0.306108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526011 \n",
      "\n",
      "Epoch 3031\n",
      "-------------------------------\n",
      "loss: 0.308877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522678 \n",
      "\n",
      "Epoch 3032\n",
      "-------------------------------\n",
      "loss: 0.292662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520521 \n",
      "\n",
      "Epoch 3033\n",
      "-------------------------------\n",
      "loss: 0.281898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521379 \n",
      "\n",
      "Epoch 3034\n",
      "-------------------------------\n",
      "loss: 0.300104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522641 \n",
      "\n",
      "Epoch 3035\n",
      "-------------------------------\n",
      "loss: 0.292376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522639 \n",
      "\n",
      "Epoch 3036\n",
      "-------------------------------\n",
      "loss: 0.302600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522533 \n",
      "\n",
      "Epoch 3037\n",
      "-------------------------------\n",
      "loss: 0.298490  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524373 \n",
      "\n",
      "Epoch 3038\n",
      "-------------------------------\n",
      "loss: 0.296026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528571 \n",
      "\n",
      "Epoch 3039\n",
      "-------------------------------\n",
      "loss: 0.290933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.532032 \n",
      "\n",
      "Epoch 3040\n",
      "-------------------------------\n",
      "loss: 0.314832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.533737 \n",
      "\n",
      "Epoch 3041\n",
      "-------------------------------\n",
      "loss: 0.316847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.530562 \n",
      "\n",
      "Epoch 3042\n",
      "-------------------------------\n",
      "loss: 0.300356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524141 \n",
      "\n",
      "Epoch 3043\n",
      "-------------------------------\n",
      "loss: 0.285667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520725 \n",
      "\n",
      "Epoch 3044\n",
      "-------------------------------\n",
      "loss: 0.316550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521004 \n",
      "\n",
      "Epoch 3045\n",
      "-------------------------------\n",
      "loss: 0.325436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521352 \n",
      "\n",
      "Epoch 3046\n",
      "-------------------------------\n",
      "loss: 0.302948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520612 \n",
      "\n",
      "Epoch 3047\n",
      "-------------------------------\n",
      "loss: 0.306382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520616 \n",
      "\n",
      "Epoch 3048\n",
      "-------------------------------\n",
      "loss: 0.294461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521250 \n",
      "\n",
      "Epoch 3049\n",
      "-------------------------------\n",
      "loss: 0.295291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523085 \n",
      "\n",
      "Epoch 3050\n",
      "-------------------------------\n",
      "loss: 0.302145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524932 \n",
      "\n",
      "Epoch 3051\n",
      "-------------------------------\n",
      "loss: 0.317293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524728 \n",
      "\n",
      "Epoch 3052\n",
      "-------------------------------\n",
      "loss: 0.294198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523955 \n",
      "\n",
      "Epoch 3053\n",
      "-------------------------------\n",
      "loss: 0.317985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521922 \n",
      "\n",
      "Epoch 3054\n",
      "-------------------------------\n",
      "loss: 0.296317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519927 \n",
      "\n",
      "Epoch 3055\n",
      "-------------------------------\n",
      "loss: 0.289711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519571 \n",
      "\n",
      "Epoch 3056\n",
      "-------------------------------\n",
      "loss: 0.315405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518759 \n",
      "\n",
      "Epoch 3057\n",
      "-------------------------------\n",
      "loss: 0.299342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518397 \n",
      "\n",
      "Epoch 3058\n",
      "-------------------------------\n",
      "loss: 0.290223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519130 \n",
      "\n",
      "Epoch 3059\n",
      "-------------------------------\n",
      "loss: 0.292781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520826 \n",
      "\n",
      "Epoch 3060\n",
      "-------------------------------\n",
      "loss: 0.309553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521867 \n",
      "\n",
      "Epoch 3061\n",
      "-------------------------------\n",
      "loss: 0.314348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520359 \n",
      "\n",
      "Epoch 3062\n",
      "-------------------------------\n",
      "loss: 0.297617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518746 \n",
      "\n",
      "Epoch 3063\n",
      "-------------------------------\n",
      "loss: 0.309808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518737 \n",
      "\n",
      "Epoch 3064\n",
      "-------------------------------\n",
      "loss: 0.297556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519124 \n",
      "\n",
      "Epoch 3065\n",
      "-------------------------------\n",
      "loss: 0.289165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518712 \n",
      "\n",
      "Epoch 3066\n",
      "-------------------------------\n",
      "loss: 0.283549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519199 \n",
      "\n",
      "Epoch 3067\n",
      "-------------------------------\n",
      "loss: 0.306298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519430 \n",
      "\n",
      "Epoch 3068\n",
      "-------------------------------\n",
      "loss: 0.310298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520179 \n",
      "\n",
      "Epoch 3069\n",
      "-------------------------------\n",
      "loss: 0.298964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521686 \n",
      "\n",
      "Epoch 3070\n",
      "-------------------------------\n",
      "loss: 0.303980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522705 \n",
      "\n",
      "Epoch 3071\n",
      "-------------------------------\n",
      "loss: 0.311296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522769 \n",
      "\n",
      "Epoch 3072\n",
      "-------------------------------\n",
      "loss: 0.307787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522007 \n",
      "\n",
      "Epoch 3073\n",
      "-------------------------------\n",
      "loss: 0.297161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520871 \n",
      "\n",
      "Epoch 3074\n",
      "-------------------------------\n",
      "loss: 0.306599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520767 \n",
      "\n",
      "Epoch 3075\n",
      "-------------------------------\n",
      "loss: 0.296521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521819 \n",
      "\n",
      "Epoch 3076\n",
      "-------------------------------\n",
      "loss: 0.301816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523165 \n",
      "\n",
      "Epoch 3077\n",
      "-------------------------------\n",
      "loss: 0.298849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523649 \n",
      "\n",
      "Epoch 3078\n",
      "-------------------------------\n",
      "loss: 0.302354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523973 \n",
      "\n",
      "Epoch 3079\n",
      "-------------------------------\n",
      "loss: 0.290676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525034 \n",
      "\n",
      "Epoch 3080\n",
      "-------------------------------\n",
      "loss: 0.285177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525796 \n",
      "\n",
      "Epoch 3081\n",
      "-------------------------------\n",
      "loss: 0.293353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525215 \n",
      "\n",
      "Epoch 3082\n",
      "-------------------------------\n",
      "loss: 0.290778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523700 \n",
      "\n",
      "Epoch 3083\n",
      "-------------------------------\n",
      "loss: 0.301105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523452 \n",
      "\n",
      "Epoch 3084\n",
      "-------------------------------\n",
      "loss: 0.295745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523819 \n",
      "\n",
      "Epoch 3085\n",
      "-------------------------------\n",
      "loss: 0.294068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523579 \n",
      "\n",
      "Epoch 3086\n",
      "-------------------------------\n",
      "loss: 0.296024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523339 \n",
      "\n",
      "Epoch 3087\n",
      "-------------------------------\n",
      "loss: 0.310213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522452 \n",
      "\n",
      "Epoch 3088\n",
      "-------------------------------\n",
      "loss: 0.304331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521885 \n",
      "\n",
      "Epoch 3089\n",
      "-------------------------------\n",
      "loss: 0.281760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522026 \n",
      "\n",
      "Epoch 3090\n",
      "-------------------------------\n",
      "loss: 0.295072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522369 \n",
      "\n",
      "Epoch 3091\n",
      "-------------------------------\n",
      "loss: 0.277611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523403 \n",
      "\n",
      "Epoch 3092\n",
      "-------------------------------\n",
      "loss: 0.304518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524943 \n",
      "\n",
      "Epoch 3093\n",
      "-------------------------------\n",
      "loss: 0.318236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525769 \n",
      "\n",
      "Epoch 3094\n",
      "-------------------------------\n",
      "loss: 0.310338  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.525456 \n",
      "\n",
      "Epoch 3095\n",
      "-------------------------------\n",
      "loss: 0.298744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523345 \n",
      "\n",
      "Epoch 3096\n",
      "-------------------------------\n",
      "loss: 0.312004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521666 \n",
      "\n",
      "Epoch 3097\n",
      "-------------------------------\n",
      "loss: 0.296205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519557 \n",
      "\n",
      "Epoch 3098\n",
      "-------------------------------\n",
      "loss: 0.316866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517473 \n",
      "\n",
      "Epoch 3099\n",
      "-------------------------------\n",
      "loss: 0.289695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516426 \n",
      "\n",
      "Epoch 3100\n",
      "-------------------------------\n",
      "loss: 0.312632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515651 \n",
      "\n",
      "Epoch 3101\n",
      "-------------------------------\n",
      "loss: 0.296426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515225 \n",
      "\n",
      "Epoch 3102\n",
      "-------------------------------\n",
      "loss: 0.306236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514812 \n",
      "\n",
      "Epoch 3103\n",
      "-------------------------------\n",
      "loss: 0.307362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513932 \n",
      "\n",
      "Epoch 3104\n",
      "-------------------------------\n",
      "loss: 0.304434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514099 \n",
      "\n",
      "Epoch 3105\n",
      "-------------------------------\n",
      "loss: 0.293139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515224 \n",
      "\n",
      "Epoch 3106\n",
      "-------------------------------\n",
      "loss: 0.305649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517310 \n",
      "\n",
      "Epoch 3107\n",
      "-------------------------------\n",
      "loss: 0.288358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519243 \n",
      "\n",
      "Epoch 3108\n",
      "-------------------------------\n",
      "loss: 0.291341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520282 \n",
      "\n",
      "Epoch 3109\n",
      "-------------------------------\n",
      "loss: 0.310363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521369 \n",
      "\n",
      "Epoch 3110\n",
      "-------------------------------\n",
      "loss: 0.304049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521634 \n",
      "\n",
      "Epoch 3111\n",
      "-------------------------------\n",
      "loss: 0.314620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520849 \n",
      "\n",
      "Epoch 3112\n",
      "-------------------------------\n",
      "loss: 0.288126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519529 \n",
      "\n",
      "Epoch 3113\n",
      "-------------------------------\n",
      "loss: 0.291111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519480 \n",
      "\n",
      "Epoch 3114\n",
      "-------------------------------\n",
      "loss: 0.308170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520699 \n",
      "\n",
      "Epoch 3115\n",
      "-------------------------------\n",
      "loss: 0.286414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522008 \n",
      "\n",
      "Epoch 3116\n",
      "-------------------------------\n",
      "loss: 0.300132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523192 \n",
      "\n",
      "Epoch 3117\n",
      "-------------------------------\n",
      "loss: 0.302506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523633 \n",
      "\n",
      "Epoch 3118\n",
      "-------------------------------\n",
      "loss: 0.295259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522148 \n",
      "\n",
      "Epoch 3119\n",
      "-------------------------------\n",
      "loss: 0.300405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521351 \n",
      "\n",
      "Epoch 3120\n",
      "-------------------------------\n",
      "loss: 0.297138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521724 \n",
      "\n",
      "Epoch 3121\n",
      "-------------------------------\n",
      "loss: 0.300885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522820 \n",
      "\n",
      "Epoch 3122\n",
      "-------------------------------\n",
      "loss: 0.293561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523978 \n",
      "\n",
      "Epoch 3123\n",
      "-------------------------------\n",
      "loss: 0.302733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524572 \n",
      "\n",
      "Epoch 3124\n",
      "-------------------------------\n",
      "loss: 0.304452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525218 \n",
      "\n",
      "Epoch 3125\n",
      "-------------------------------\n",
      "loss: 0.304374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525175 \n",
      "\n",
      "Epoch 3126\n",
      "-------------------------------\n",
      "loss: 0.305983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524104 \n",
      "\n",
      "Epoch 3127\n",
      "-------------------------------\n",
      "loss: 0.301322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522787 \n",
      "\n",
      "Epoch 3128\n",
      "-------------------------------\n",
      "loss: 0.295760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521711 \n",
      "\n",
      "Epoch 3129\n",
      "-------------------------------\n",
      "loss: 0.272924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521572 \n",
      "\n",
      "Epoch 3130\n",
      "-------------------------------\n",
      "loss: 0.295821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521639 \n",
      "\n",
      "Epoch 3131\n",
      "-------------------------------\n",
      "loss: 0.281811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521994 \n",
      "\n",
      "Epoch 3132\n",
      "-------------------------------\n",
      "loss: 0.295426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522394 \n",
      "\n",
      "Epoch 3133\n",
      "-------------------------------\n",
      "loss: 0.308767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522897 \n",
      "\n",
      "Epoch 3134\n",
      "-------------------------------\n",
      "loss: 0.313930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523955 \n",
      "\n",
      "Epoch 3135\n",
      "-------------------------------\n",
      "loss: 0.285925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525352 \n",
      "\n",
      "Epoch 3136\n",
      "-------------------------------\n",
      "loss: 0.290569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526153 \n",
      "\n",
      "Epoch 3137\n",
      "-------------------------------\n",
      "loss: 0.292448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525985 \n",
      "\n",
      "Epoch 3138\n",
      "-------------------------------\n",
      "loss: 0.288095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524968 \n",
      "\n",
      "Epoch 3139\n",
      "-------------------------------\n",
      "loss: 0.297039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523992 \n",
      "\n",
      "Epoch 3140\n",
      "-------------------------------\n",
      "loss: 0.294404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523360 \n",
      "\n",
      "Epoch 3141\n",
      "-------------------------------\n",
      "loss: 0.295469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523148 \n",
      "\n",
      "Epoch 3142\n",
      "-------------------------------\n",
      "loss: 0.304366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522293 \n",
      "\n",
      "Epoch 3143\n",
      "-------------------------------\n",
      "loss: 0.303363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521044 \n",
      "\n",
      "Epoch 3144\n",
      "-------------------------------\n",
      "loss: 0.295607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520996 \n",
      "\n",
      "Epoch 3145\n",
      "-------------------------------\n",
      "loss: 0.282570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521203 \n",
      "\n",
      "Epoch 3146\n",
      "-------------------------------\n",
      "loss: 0.288854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521615 \n",
      "\n",
      "Epoch 3147\n",
      "-------------------------------\n",
      "loss: 0.301259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520269 \n",
      "\n",
      "Epoch 3148\n",
      "-------------------------------\n",
      "loss: 0.292592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519748 \n",
      "\n",
      "Epoch 3149\n",
      "-------------------------------\n",
      "loss: 0.293433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519688 \n",
      "\n",
      "Epoch 3150\n",
      "-------------------------------\n",
      "loss: 0.290228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520324 \n",
      "\n",
      "Epoch 3151\n",
      "-------------------------------\n",
      "loss: 0.305868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522467 \n",
      "\n",
      "Epoch 3152\n",
      "-------------------------------\n",
      "loss: 0.299005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524407 \n",
      "\n",
      "Epoch 3153\n",
      "-------------------------------\n",
      "loss: 0.293893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524918 \n",
      "\n",
      "Epoch 3154\n",
      "-------------------------------\n",
      "loss: 0.290782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524711 \n",
      "\n",
      "Epoch 3155\n",
      "-------------------------------\n",
      "loss: 0.295245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524984 \n",
      "\n",
      "Epoch 3156\n",
      "-------------------------------\n",
      "loss: 0.290737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526009 \n",
      "\n",
      "Epoch 3157\n",
      "-------------------------------\n",
      "loss: 0.290930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527106 \n",
      "\n",
      "Epoch 3158\n",
      "-------------------------------\n",
      "loss: 0.294792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526385 \n",
      "\n",
      "Epoch 3159\n",
      "-------------------------------\n",
      "loss: 0.315928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523189 \n",
      "\n",
      "Epoch 3160\n",
      "-------------------------------\n",
      "loss: 0.287559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519651 \n",
      "\n",
      "Epoch 3161\n",
      "-------------------------------\n",
      "loss: 0.288094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517573 \n",
      "\n",
      "Epoch 3162\n",
      "-------------------------------\n",
      "loss: 0.298513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516852 \n",
      "\n",
      "Epoch 3163\n",
      "-------------------------------\n",
      "loss: 0.306183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516640 \n",
      "\n",
      "Epoch 3164\n",
      "-------------------------------\n",
      "loss: 0.295010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516096 \n",
      "\n",
      "Epoch 3165\n",
      "-------------------------------\n",
      "loss: 0.327855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516235 \n",
      "\n",
      "Epoch 3166\n",
      "-------------------------------\n",
      "loss: 0.276989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518196 \n",
      "\n",
      "Epoch 3167\n",
      "-------------------------------\n",
      "loss: 0.297301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520356 \n",
      "\n",
      "Epoch 3168\n",
      "-------------------------------\n",
      "loss: 0.277502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521770 \n",
      "\n",
      "Epoch 3169\n",
      "-------------------------------\n",
      "loss: 0.295615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521644 \n",
      "\n",
      "Epoch 3170\n",
      "-------------------------------\n",
      "loss: 0.309395  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.519870 \n",
      "\n",
      "Epoch 3171\n",
      "-------------------------------\n",
      "loss: 0.288148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518102 \n",
      "\n",
      "Epoch 3172\n",
      "-------------------------------\n",
      "loss: 0.289974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517431 \n",
      "\n",
      "Epoch 3173\n",
      "-------------------------------\n",
      "loss: 0.284920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517069 \n",
      "\n",
      "Epoch 3174\n",
      "-------------------------------\n",
      "loss: 0.299481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517030 \n",
      "\n",
      "Epoch 3175\n",
      "-------------------------------\n",
      "loss: 0.311486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517700 \n",
      "\n",
      "Epoch 3176\n",
      "-------------------------------\n",
      "loss: 0.291636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519474 \n",
      "\n",
      "Epoch 3177\n",
      "-------------------------------\n",
      "loss: 0.296735  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520149 \n",
      "\n",
      "Epoch 3178\n",
      "-------------------------------\n",
      "loss: 0.291707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519551 \n",
      "\n",
      "Epoch 3179\n",
      "-------------------------------\n",
      "loss: 0.313775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519511 \n",
      "\n",
      "Epoch 3180\n",
      "-------------------------------\n",
      "loss: 0.295589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518941 \n",
      "\n",
      "Epoch 3181\n",
      "-------------------------------\n",
      "loss: 0.292476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516889 \n",
      "\n",
      "Epoch 3182\n",
      "-------------------------------\n",
      "loss: 0.287730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515078 \n",
      "\n",
      "Epoch 3183\n",
      "-------------------------------\n",
      "loss: 0.297053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515630 \n",
      "\n",
      "Epoch 3184\n",
      "-------------------------------\n",
      "loss: 0.287296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517234 \n",
      "\n",
      "Epoch 3185\n",
      "-------------------------------\n",
      "loss: 0.292091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518496 \n",
      "\n",
      "Epoch 3186\n",
      "-------------------------------\n",
      "loss: 0.297155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518272 \n",
      "\n",
      "Epoch 3187\n",
      "-------------------------------\n",
      "loss: 0.299186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517968 \n",
      "\n",
      "Epoch 3188\n",
      "-------------------------------\n",
      "loss: 0.311583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516958 \n",
      "\n",
      "Epoch 3189\n",
      "-------------------------------\n",
      "loss: 0.311311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517428 \n",
      "\n",
      "Epoch 3190\n",
      "-------------------------------\n",
      "loss: 0.301473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517965 \n",
      "\n",
      "Epoch 3191\n",
      "-------------------------------\n",
      "loss: 0.290758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517033 \n",
      "\n",
      "Epoch 3192\n",
      "-------------------------------\n",
      "loss: 0.305365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516208 \n",
      "\n",
      "Epoch 3193\n",
      "-------------------------------\n",
      "loss: 0.297091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516491 \n",
      "\n",
      "Epoch 3194\n",
      "-------------------------------\n",
      "loss: 0.290067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517020 \n",
      "\n",
      "Epoch 3195\n",
      "-------------------------------\n",
      "loss: 0.286839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518055 \n",
      "\n",
      "Epoch 3196\n",
      "-------------------------------\n",
      "loss: 0.310350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519243 \n",
      "\n",
      "Epoch 3197\n",
      "-------------------------------\n",
      "loss: 0.288198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521052 \n",
      "\n",
      "Epoch 3198\n",
      "-------------------------------\n",
      "loss: 0.282915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522243 \n",
      "\n",
      "Epoch 3199\n",
      "-------------------------------\n",
      "loss: 0.290354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522271 \n",
      "\n",
      "Epoch 3200\n",
      "-------------------------------\n",
      "loss: 0.297889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522514 \n",
      "\n",
      "Epoch 3201\n",
      "-------------------------------\n",
      "loss: 0.290032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522578 \n",
      "\n",
      "Epoch 3202\n",
      "-------------------------------\n",
      "loss: 0.278591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522870 \n",
      "\n",
      "Epoch 3203\n",
      "-------------------------------\n",
      "loss: 0.297052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523534 \n",
      "\n",
      "Epoch 3204\n",
      "-------------------------------\n",
      "loss: 0.294309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522500 \n",
      "\n",
      "Epoch 3205\n",
      "-------------------------------\n",
      "loss: 0.300993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520117 \n",
      "\n",
      "Epoch 3206\n",
      "-------------------------------\n",
      "loss: 0.289884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518381 \n",
      "\n",
      "Epoch 3207\n",
      "-------------------------------\n",
      "loss: 0.291217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518068 \n",
      "\n",
      "Epoch 3208\n",
      "-------------------------------\n",
      "loss: 0.297002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518337 \n",
      "\n",
      "Epoch 3209\n",
      "-------------------------------\n",
      "loss: 0.302803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518465 \n",
      "\n",
      "Epoch 3210\n",
      "-------------------------------\n",
      "loss: 0.292603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519054 \n",
      "\n",
      "Epoch 3211\n",
      "-------------------------------\n",
      "loss: 0.281736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520924 \n",
      "\n",
      "Epoch 3212\n",
      "-------------------------------\n",
      "loss: 0.298449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522063 \n",
      "\n",
      "Epoch 3213\n",
      "-------------------------------\n",
      "loss: 0.279193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521698 \n",
      "\n",
      "Epoch 3214\n",
      "-------------------------------\n",
      "loss: 0.292634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520865 \n",
      "\n",
      "Epoch 3215\n",
      "-------------------------------\n",
      "loss: 0.287055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520895 \n",
      "\n",
      "Epoch 3216\n",
      "-------------------------------\n",
      "loss: 0.296854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521674 \n",
      "\n",
      "Epoch 3217\n",
      "-------------------------------\n",
      "loss: 0.292410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521387 \n",
      "\n",
      "Epoch 3218\n",
      "-------------------------------\n",
      "loss: 0.301391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521749 \n",
      "\n",
      "Epoch 3219\n",
      "-------------------------------\n",
      "loss: 0.295352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523197 \n",
      "\n",
      "Epoch 3220\n",
      "-------------------------------\n",
      "loss: 0.306557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524017 \n",
      "\n",
      "Epoch 3221\n",
      "-------------------------------\n",
      "loss: 0.295114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523872 \n",
      "\n",
      "Epoch 3222\n",
      "-------------------------------\n",
      "loss: 0.297542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523954 \n",
      "\n",
      "Epoch 3223\n",
      "-------------------------------\n",
      "loss: 0.292076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523121 \n",
      "\n",
      "Epoch 3224\n",
      "-------------------------------\n",
      "loss: 0.292833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522715 \n",
      "\n",
      "Epoch 3225\n",
      "-------------------------------\n",
      "loss: 0.295700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522794 \n",
      "\n",
      "Epoch 3226\n",
      "-------------------------------\n",
      "loss: 0.286280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523155 \n",
      "\n",
      "Epoch 3227\n",
      "-------------------------------\n",
      "loss: 0.283507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524539 \n",
      "\n",
      "Epoch 3228\n",
      "-------------------------------\n",
      "loss: 0.293488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526032 \n",
      "\n",
      "Epoch 3229\n",
      "-------------------------------\n",
      "loss: 0.303372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527397 \n",
      "\n",
      "Epoch 3230\n",
      "-------------------------------\n",
      "loss: 0.303391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526211 \n",
      "\n",
      "Epoch 3231\n",
      "-------------------------------\n",
      "loss: 0.308831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523419 \n",
      "\n",
      "Epoch 3232\n",
      "-------------------------------\n",
      "loss: 0.295095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521333 \n",
      "\n",
      "Epoch 3233\n",
      "-------------------------------\n",
      "loss: 0.299491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521108 \n",
      "\n",
      "Epoch 3234\n",
      "-------------------------------\n",
      "loss: 0.305162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521506 \n",
      "\n",
      "Epoch 3235\n",
      "-------------------------------\n",
      "loss: 0.297775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523464 \n",
      "\n",
      "Epoch 3236\n",
      "-------------------------------\n",
      "loss: 0.279066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525402 \n",
      "\n",
      "Epoch 3237\n",
      "-------------------------------\n",
      "loss: 0.293504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525272 \n",
      "\n",
      "Epoch 3238\n",
      "-------------------------------\n",
      "loss: 0.288411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524212 \n",
      "\n",
      "Epoch 3239\n",
      "-------------------------------\n",
      "loss: 0.296835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523421 \n",
      "\n",
      "Epoch 3240\n",
      "-------------------------------\n",
      "loss: 0.317335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523919 \n",
      "\n",
      "Epoch 3241\n",
      "-------------------------------\n",
      "loss: 0.295611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524648 \n",
      "\n",
      "Epoch 3242\n",
      "-------------------------------\n",
      "loss: 0.302866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524566 \n",
      "\n",
      "Epoch 3243\n",
      "-------------------------------\n",
      "loss: 0.314400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524480 \n",
      "\n",
      "Epoch 3244\n",
      "-------------------------------\n",
      "loss: 0.309787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524334 \n",
      "\n",
      "Epoch 3245\n",
      "-------------------------------\n",
      "loss: 0.299618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525955 \n",
      "\n",
      "Epoch 3246\n",
      "-------------------------------\n",
      "loss: 0.295794  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.526075 \n",
      "\n",
      "Epoch 3247\n",
      "-------------------------------\n",
      "loss: 0.286828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524360 \n",
      "\n",
      "Epoch 3248\n",
      "-------------------------------\n",
      "loss: 0.289719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522372 \n",
      "\n",
      "Epoch 3249\n",
      "-------------------------------\n",
      "loss: 0.281375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520847 \n",
      "\n",
      "Epoch 3250\n",
      "-------------------------------\n",
      "loss: 0.336620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520157 \n",
      "\n",
      "Epoch 3251\n",
      "-------------------------------\n",
      "loss: 0.298405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519534 \n",
      "\n",
      "Epoch 3252\n",
      "-------------------------------\n",
      "loss: 0.281381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519812 \n",
      "\n",
      "Epoch 3253\n",
      "-------------------------------\n",
      "loss: 0.294016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521991 \n",
      "\n",
      "Epoch 3254\n",
      "-------------------------------\n",
      "loss: 0.288335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525880 \n",
      "\n",
      "Epoch 3255\n",
      "-------------------------------\n",
      "loss: 0.295034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527375 \n",
      "\n",
      "Epoch 3256\n",
      "-------------------------------\n",
      "loss: 0.296677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525504 \n",
      "\n",
      "Epoch 3257\n",
      "-------------------------------\n",
      "loss: 0.299599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522144 \n",
      "\n",
      "Epoch 3258\n",
      "-------------------------------\n",
      "loss: 0.283362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518969 \n",
      "\n",
      "Epoch 3259\n",
      "-------------------------------\n",
      "loss: 0.295137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517850 \n",
      "\n",
      "Epoch 3260\n",
      "-------------------------------\n",
      "loss: 0.299753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518316 \n",
      "\n",
      "Epoch 3261\n",
      "-------------------------------\n",
      "loss: 0.290230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519647 \n",
      "\n",
      "Epoch 3262\n",
      "-------------------------------\n",
      "loss: 0.305377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520469 \n",
      "\n",
      "Epoch 3263\n",
      "-------------------------------\n",
      "loss: 0.293396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520559 \n",
      "\n",
      "Epoch 3264\n",
      "-------------------------------\n",
      "loss: 0.293875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520569 \n",
      "\n",
      "Epoch 3265\n",
      "-------------------------------\n",
      "loss: 0.292780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519755 \n",
      "\n",
      "Epoch 3266\n",
      "-------------------------------\n",
      "loss: 0.295023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519514 \n",
      "\n",
      "Epoch 3267\n",
      "-------------------------------\n",
      "loss: 0.301571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519351 \n",
      "\n",
      "Epoch 3268\n",
      "-------------------------------\n",
      "loss: 0.302348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519890 \n",
      "\n",
      "Epoch 3269\n",
      "-------------------------------\n",
      "loss: 0.306466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521330 \n",
      "\n",
      "Epoch 3270\n",
      "-------------------------------\n",
      "loss: 0.268590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522655 \n",
      "\n",
      "Epoch 3271\n",
      "-------------------------------\n",
      "loss: 0.284302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523963 \n",
      "\n",
      "Epoch 3272\n",
      "-------------------------------\n",
      "loss: 0.273832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524575 \n",
      "\n",
      "Epoch 3273\n",
      "-------------------------------\n",
      "loss: 0.277043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524524 \n",
      "\n",
      "Epoch 3274\n",
      "-------------------------------\n",
      "loss: 0.282367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524446 \n",
      "\n",
      "Epoch 3275\n",
      "-------------------------------\n",
      "loss: 0.287383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524404 \n",
      "\n",
      "Epoch 3276\n",
      "-------------------------------\n",
      "loss: 0.292839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524158 \n",
      "\n",
      "Epoch 3277\n",
      "-------------------------------\n",
      "loss: 0.298635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523947 \n",
      "\n",
      "Epoch 3278\n",
      "-------------------------------\n",
      "loss: 0.286385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523710 \n",
      "\n",
      "Epoch 3279\n",
      "-------------------------------\n",
      "loss: 0.278759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523364 \n",
      "\n",
      "Epoch 3280\n",
      "-------------------------------\n",
      "loss: 0.302206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522860 \n",
      "\n",
      "Epoch 3281\n",
      "-------------------------------\n",
      "loss: 0.295986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522770 \n",
      "\n",
      "Epoch 3282\n",
      "-------------------------------\n",
      "loss: 0.303285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522465 \n",
      "\n",
      "Epoch 3283\n",
      "-------------------------------\n",
      "loss: 0.289346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522383 \n",
      "\n",
      "Epoch 3284\n",
      "-------------------------------\n",
      "loss: 0.296271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522724 \n",
      "\n",
      "Epoch 3285\n",
      "-------------------------------\n",
      "loss: 0.292221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522749 \n",
      "\n",
      "Epoch 3286\n",
      "-------------------------------\n",
      "loss: 0.306270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523023 \n",
      "\n",
      "Epoch 3287\n",
      "-------------------------------\n",
      "loss: 0.270708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522998 \n",
      "\n",
      "Epoch 3288\n",
      "-------------------------------\n",
      "loss: 0.301020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522966 \n",
      "\n",
      "Epoch 3289\n",
      "-------------------------------\n",
      "loss: 0.300242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521155 \n",
      "\n",
      "Epoch 3290\n",
      "-------------------------------\n",
      "loss: 0.298643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520343 \n",
      "\n",
      "Epoch 3291\n",
      "-------------------------------\n",
      "loss: 0.286417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519538 \n",
      "\n",
      "Epoch 3292\n",
      "-------------------------------\n",
      "loss: 0.304392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519304 \n",
      "\n",
      "Epoch 3293\n",
      "-------------------------------\n",
      "loss: 0.294506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518742 \n",
      "\n",
      "Epoch 3294\n",
      "-------------------------------\n",
      "loss: 0.289240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518865 \n",
      "\n",
      "Epoch 3295\n",
      "-------------------------------\n",
      "loss: 0.279919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519599 \n",
      "\n",
      "Epoch 3296\n",
      "-------------------------------\n",
      "loss: 0.288993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520436 \n",
      "\n",
      "Epoch 3297\n",
      "-------------------------------\n",
      "loss: 0.295280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522084 \n",
      "\n",
      "Epoch 3298\n",
      "-------------------------------\n",
      "loss: 0.300942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523394 \n",
      "\n",
      "Epoch 3299\n",
      "-------------------------------\n",
      "loss: 0.282962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524950 \n",
      "\n",
      "Epoch 3300\n",
      "-------------------------------\n",
      "loss: 0.288380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526817 \n",
      "\n",
      "Epoch 3301\n",
      "-------------------------------\n",
      "loss: 0.279222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527738 \n",
      "\n",
      "Epoch 3302\n",
      "-------------------------------\n",
      "loss: 0.282469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528389 \n",
      "\n",
      "Epoch 3303\n",
      "-------------------------------\n",
      "loss: 0.301534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527534 \n",
      "\n",
      "Epoch 3304\n",
      "-------------------------------\n",
      "loss: 0.298174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524761 \n",
      "\n",
      "Epoch 3305\n",
      "-------------------------------\n",
      "loss: 0.289622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521891 \n",
      "\n",
      "Epoch 3306\n",
      "-------------------------------\n",
      "loss: 0.280377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519674 \n",
      "\n",
      "Epoch 3307\n",
      "-------------------------------\n",
      "loss: 0.299598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519342 \n",
      "\n",
      "Epoch 3308\n",
      "-------------------------------\n",
      "loss: 0.300262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519200 \n",
      "\n",
      "Epoch 3309\n",
      "-------------------------------\n",
      "loss: 0.290939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518906 \n",
      "\n",
      "Epoch 3310\n",
      "-------------------------------\n",
      "loss: 0.283659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519317 \n",
      "\n",
      "Epoch 3311\n",
      "-------------------------------\n",
      "loss: 0.288185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520735 \n",
      "\n",
      "Epoch 3312\n",
      "-------------------------------\n",
      "loss: 0.281651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522432 \n",
      "\n",
      "Epoch 3313\n",
      "-------------------------------\n",
      "loss: 0.284313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523560 \n",
      "\n",
      "Epoch 3314\n",
      "-------------------------------\n",
      "loss: 0.294838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523896 \n",
      "\n",
      "Epoch 3315\n",
      "-------------------------------\n",
      "loss: 0.303487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524649 \n",
      "\n",
      "Epoch 3316\n",
      "-------------------------------\n",
      "loss: 0.284960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525868 \n",
      "\n",
      "Epoch 3317\n",
      "-------------------------------\n",
      "loss: 0.293739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525937 \n",
      "\n",
      "Epoch 3318\n",
      "-------------------------------\n",
      "loss: 0.298328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525438 \n",
      "\n",
      "Epoch 3319\n",
      "-------------------------------\n",
      "loss: 0.302977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525586 \n",
      "\n",
      "Epoch 3320\n",
      "-------------------------------\n",
      "loss: 0.295774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525337 \n",
      "\n",
      "Epoch 3321\n",
      "-------------------------------\n",
      "loss: 0.303124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524648 \n",
      "\n",
      "Epoch 3322\n",
      "-------------------------------\n",
      "loss: 0.275460  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.523944 \n",
      "\n",
      "Epoch 3323\n",
      "-------------------------------\n",
      "loss: 0.293026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522812 \n",
      "\n",
      "Epoch 3324\n",
      "-------------------------------\n",
      "loss: 0.285358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522290 \n",
      "\n",
      "Epoch 3325\n",
      "-------------------------------\n",
      "loss: 0.302179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522531 \n",
      "\n",
      "Epoch 3326\n",
      "-------------------------------\n",
      "loss: 0.275852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522598 \n",
      "\n",
      "Epoch 3327\n",
      "-------------------------------\n",
      "loss: 0.294656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522417 \n",
      "\n",
      "Epoch 3328\n",
      "-------------------------------\n",
      "loss: 0.295857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521711 \n",
      "\n",
      "Epoch 3329\n",
      "-------------------------------\n",
      "loss: 0.301351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520423 \n",
      "\n",
      "Epoch 3330\n",
      "-------------------------------\n",
      "loss: 0.305895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519622 \n",
      "\n",
      "Epoch 3331\n",
      "-------------------------------\n",
      "loss: 0.306159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519411 \n",
      "\n",
      "Epoch 3332\n",
      "-------------------------------\n",
      "loss: 0.320104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519639 \n",
      "\n",
      "Epoch 3333\n",
      "-------------------------------\n",
      "loss: 0.297750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519888 \n",
      "\n",
      "Epoch 3334\n",
      "-------------------------------\n",
      "loss: 0.295048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520372 \n",
      "\n",
      "Epoch 3335\n",
      "-------------------------------\n",
      "loss: 0.283822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520017 \n",
      "\n",
      "Epoch 3336\n",
      "-------------------------------\n",
      "loss: 0.284450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520349 \n",
      "\n",
      "Epoch 3337\n",
      "-------------------------------\n",
      "loss: 0.273713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520786 \n",
      "\n",
      "Epoch 3338\n",
      "-------------------------------\n",
      "loss: 0.300779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522062 \n",
      "\n",
      "Epoch 3339\n",
      "-------------------------------\n",
      "loss: 0.296748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523040 \n",
      "\n",
      "Epoch 3340\n",
      "-------------------------------\n",
      "loss: 0.302000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523469 \n",
      "\n",
      "Epoch 3341\n",
      "-------------------------------\n",
      "loss: 0.273358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524066 \n",
      "\n",
      "Epoch 3342\n",
      "-------------------------------\n",
      "loss: 0.287949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524086 \n",
      "\n",
      "Epoch 3343\n",
      "-------------------------------\n",
      "loss: 0.289160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523781 \n",
      "\n",
      "Epoch 3344\n",
      "-------------------------------\n",
      "loss: 0.303839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523473 \n",
      "\n",
      "Epoch 3345\n",
      "-------------------------------\n",
      "loss: 0.303022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522940 \n",
      "\n",
      "Epoch 3346\n",
      "-------------------------------\n",
      "loss: 0.288379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522325 \n",
      "\n",
      "Epoch 3347\n",
      "-------------------------------\n",
      "loss: 0.294726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521484 \n",
      "\n",
      "Epoch 3348\n",
      "-------------------------------\n",
      "loss: 0.290630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520793 \n",
      "\n",
      "Epoch 3349\n",
      "-------------------------------\n",
      "loss: 0.293457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520157 \n",
      "\n",
      "Epoch 3350\n",
      "-------------------------------\n",
      "loss: 0.295231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519935 \n",
      "\n",
      "Epoch 3351\n",
      "-------------------------------\n",
      "loss: 0.293570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519842 \n",
      "\n",
      "Epoch 3352\n",
      "-------------------------------\n",
      "loss: 0.302583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519144 \n",
      "\n",
      "Epoch 3353\n",
      "-------------------------------\n",
      "loss: 0.294937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518776 \n",
      "\n",
      "Epoch 3354\n",
      "-------------------------------\n",
      "loss: 0.299427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518598 \n",
      "\n",
      "Epoch 3355\n",
      "-------------------------------\n",
      "loss: 0.298021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518555 \n",
      "\n",
      "Epoch 3356\n",
      "-------------------------------\n",
      "loss: 0.300889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517849 \n",
      "\n",
      "Epoch 3357\n",
      "-------------------------------\n",
      "loss: 0.287705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517299 \n",
      "\n",
      "Epoch 3358\n",
      "-------------------------------\n",
      "loss: 0.276578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516385 \n",
      "\n",
      "Epoch 3359\n",
      "-------------------------------\n",
      "loss: 0.290426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516305 \n",
      "\n",
      "Epoch 3360\n",
      "-------------------------------\n",
      "loss: 0.278148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517047 \n",
      "\n",
      "Epoch 3361\n",
      "-------------------------------\n",
      "loss: 0.296469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517901 \n",
      "\n",
      "Epoch 3362\n",
      "-------------------------------\n",
      "loss: 0.287891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518635 \n",
      "\n",
      "Epoch 3363\n",
      "-------------------------------\n",
      "loss: 0.290812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519380 \n",
      "\n",
      "Epoch 3364\n",
      "-------------------------------\n",
      "loss: 0.281679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520553 \n",
      "\n",
      "Epoch 3365\n",
      "-------------------------------\n",
      "loss: 0.283024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521078 \n",
      "\n",
      "Epoch 3366\n",
      "-------------------------------\n",
      "loss: 0.287139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520723 \n",
      "\n",
      "Epoch 3367\n",
      "-------------------------------\n",
      "loss: 0.295191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520557 \n",
      "\n",
      "Epoch 3368\n",
      "-------------------------------\n",
      "loss: 0.298545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520894 \n",
      "\n",
      "Epoch 3369\n",
      "-------------------------------\n",
      "loss: 0.295154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521091 \n",
      "\n",
      "Epoch 3370\n",
      "-------------------------------\n",
      "loss: 0.275631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521804 \n",
      "\n",
      "Epoch 3371\n",
      "-------------------------------\n",
      "loss: 0.282881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523419 \n",
      "\n",
      "Epoch 3372\n",
      "-------------------------------\n",
      "loss: 0.297165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524369 \n",
      "\n",
      "Epoch 3373\n",
      "-------------------------------\n",
      "loss: 0.288420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523814 \n",
      "\n",
      "Epoch 3374\n",
      "-------------------------------\n",
      "loss: 0.291872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523631 \n",
      "\n",
      "Epoch 3375\n",
      "-------------------------------\n",
      "loss: 0.280674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523068 \n",
      "\n",
      "Epoch 3376\n",
      "-------------------------------\n",
      "loss: 0.279075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522998 \n",
      "\n",
      "Epoch 3377\n",
      "-------------------------------\n",
      "loss: 0.284944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523619 \n",
      "\n",
      "Epoch 3378\n",
      "-------------------------------\n",
      "loss: 0.283696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524489 \n",
      "\n",
      "Epoch 3379\n",
      "-------------------------------\n",
      "loss: 0.277742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524347 \n",
      "\n",
      "Epoch 3380\n",
      "-------------------------------\n",
      "loss: 0.288609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522562 \n",
      "\n",
      "Epoch 3381\n",
      "-------------------------------\n",
      "loss: 0.298863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520626 \n",
      "\n",
      "Epoch 3382\n",
      "-------------------------------\n",
      "loss: 0.278466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519394 \n",
      "\n",
      "Epoch 3383\n",
      "-------------------------------\n",
      "loss: 0.315283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518499 \n",
      "\n",
      "Epoch 3384\n",
      "-------------------------------\n",
      "loss: 0.285772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518296 \n",
      "\n",
      "Epoch 3385\n",
      "-------------------------------\n",
      "loss: 0.291362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518323 \n",
      "\n",
      "Epoch 3386\n",
      "-------------------------------\n",
      "loss: 0.267380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518341 \n",
      "\n",
      "Epoch 3387\n",
      "-------------------------------\n",
      "loss: 0.298694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518052 \n",
      "\n",
      "Epoch 3388\n",
      "-------------------------------\n",
      "loss: 0.297566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518956 \n",
      "\n",
      "Epoch 3389\n",
      "-------------------------------\n",
      "loss: 0.295480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520625 \n",
      "\n",
      "Epoch 3390\n",
      "-------------------------------\n",
      "loss: 0.296927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521561 \n",
      "\n",
      "Epoch 3391\n",
      "-------------------------------\n",
      "loss: 0.293144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521872 \n",
      "\n",
      "Epoch 3392\n",
      "-------------------------------\n",
      "loss: 0.293092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522081 \n",
      "\n",
      "Epoch 3393\n",
      "-------------------------------\n",
      "loss: 0.291711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521978 \n",
      "\n",
      "Epoch 3394\n",
      "-------------------------------\n",
      "loss: 0.283272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522435 \n",
      "\n",
      "Epoch 3395\n",
      "-------------------------------\n",
      "loss: 0.288292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522191 \n",
      "\n",
      "Epoch 3396\n",
      "-------------------------------\n",
      "loss: 0.300007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522284 \n",
      "\n",
      "Epoch 3397\n",
      "-------------------------------\n",
      "loss: 0.300820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521404 \n",
      "\n",
      "Epoch 3398\n",
      "-------------------------------\n",
      "loss: 0.280327  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521065 \n",
      "\n",
      "Epoch 3399\n",
      "-------------------------------\n",
      "loss: 0.287799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520065 \n",
      "\n",
      "Epoch 3400\n",
      "-------------------------------\n",
      "loss: 0.305188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518824 \n",
      "\n",
      "Epoch 3401\n",
      "-------------------------------\n",
      "loss: 0.281134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517764 \n",
      "\n",
      "Epoch 3402\n",
      "-------------------------------\n",
      "loss: 0.298698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516595 \n",
      "\n",
      "Epoch 3403\n",
      "-------------------------------\n",
      "loss: 0.284355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516017 \n",
      "\n",
      "Epoch 3404\n",
      "-------------------------------\n",
      "loss: 0.280245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516407 \n",
      "\n",
      "Epoch 3405\n",
      "-------------------------------\n",
      "loss: 0.305168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517443 \n",
      "\n",
      "Epoch 3406\n",
      "-------------------------------\n",
      "loss: 0.277738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518091 \n",
      "\n",
      "Epoch 3407\n",
      "-------------------------------\n",
      "loss: 0.287179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519654 \n",
      "\n",
      "Epoch 3408\n",
      "-------------------------------\n",
      "loss: 0.291593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520860 \n",
      "\n",
      "Epoch 3409\n",
      "-------------------------------\n",
      "loss: 0.293765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521550 \n",
      "\n",
      "Epoch 3410\n",
      "-------------------------------\n",
      "loss: 0.296849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521273 \n",
      "\n",
      "Epoch 3411\n",
      "-------------------------------\n",
      "loss: 0.283533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521519 \n",
      "\n",
      "Epoch 3412\n",
      "-------------------------------\n",
      "loss: 0.284500  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522051 \n",
      "\n",
      "Epoch 3413\n",
      "-------------------------------\n",
      "loss: 0.289409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521853 \n",
      "\n",
      "Epoch 3414\n",
      "-------------------------------\n",
      "loss: 0.277868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521639 \n",
      "\n",
      "Epoch 3415\n",
      "-------------------------------\n",
      "loss: 0.284178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521814 \n",
      "\n",
      "Epoch 3416\n",
      "-------------------------------\n",
      "loss: 0.284320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521584 \n",
      "\n",
      "Epoch 3417\n",
      "-------------------------------\n",
      "loss: 0.288070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521507 \n",
      "\n",
      "Epoch 3418\n",
      "-------------------------------\n",
      "loss: 0.296914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521338 \n",
      "\n",
      "Epoch 3419\n",
      "-------------------------------\n",
      "loss: 0.269907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521425 \n",
      "\n",
      "Epoch 3420\n",
      "-------------------------------\n",
      "loss: 0.295676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521722 \n",
      "\n",
      "Epoch 3421\n",
      "-------------------------------\n",
      "loss: 0.292774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521749 \n",
      "\n",
      "Epoch 3422\n",
      "-------------------------------\n",
      "loss: 0.288900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522380 \n",
      "\n",
      "Epoch 3423\n",
      "-------------------------------\n",
      "loss: 0.286532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522791 \n",
      "\n",
      "Epoch 3424\n",
      "-------------------------------\n",
      "loss: 0.297293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522319 \n",
      "\n",
      "Epoch 3425\n",
      "-------------------------------\n",
      "loss: 0.300916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521888 \n",
      "\n",
      "Epoch 3426\n",
      "-------------------------------\n",
      "loss: 0.274314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522133 \n",
      "\n",
      "Epoch 3427\n",
      "-------------------------------\n",
      "loss: 0.309691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522252 \n",
      "\n",
      "Epoch 3428\n",
      "-------------------------------\n",
      "loss: 0.303891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522054 \n",
      "\n",
      "Epoch 3429\n",
      "-------------------------------\n",
      "loss: 0.290968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521389 \n",
      "\n",
      "Epoch 3430\n",
      "-------------------------------\n",
      "loss: 0.283161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521082 \n",
      "\n",
      "Epoch 3431\n",
      "-------------------------------\n",
      "loss: 0.304964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520728 \n",
      "\n",
      "Epoch 3432\n",
      "-------------------------------\n",
      "loss: 0.287095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519913 \n",
      "\n",
      "Epoch 3433\n",
      "-------------------------------\n",
      "loss: 0.311285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518755 \n",
      "\n",
      "Epoch 3434\n",
      "-------------------------------\n",
      "loss: 0.293697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518048 \n",
      "\n",
      "Epoch 3435\n",
      "-------------------------------\n",
      "loss: 0.298684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517583 \n",
      "\n",
      "Epoch 3436\n",
      "-------------------------------\n",
      "loss: 0.286493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518202 \n",
      "\n",
      "Epoch 3437\n",
      "-------------------------------\n",
      "loss: 0.290328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519286 \n",
      "\n",
      "Epoch 3438\n",
      "-------------------------------\n",
      "loss: 0.304353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520716 \n",
      "\n",
      "Epoch 3439\n",
      "-------------------------------\n",
      "loss: 0.285117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521472 \n",
      "\n",
      "Epoch 3440\n",
      "-------------------------------\n",
      "loss: 0.277523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520765 \n",
      "\n",
      "Epoch 3441\n",
      "-------------------------------\n",
      "loss: 0.285507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520681 \n",
      "\n",
      "Epoch 3442\n",
      "-------------------------------\n",
      "loss: 0.283688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520542 \n",
      "\n",
      "Epoch 3443\n",
      "-------------------------------\n",
      "loss: 0.289799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520036 \n",
      "\n",
      "Epoch 3444\n",
      "-------------------------------\n",
      "loss: 0.289749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520097 \n",
      "\n",
      "Epoch 3445\n",
      "-------------------------------\n",
      "loss: 0.300765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520104 \n",
      "\n",
      "Epoch 3446\n",
      "-------------------------------\n",
      "loss: 0.286292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519969 \n",
      "\n",
      "Epoch 3447\n",
      "-------------------------------\n",
      "loss: 0.284884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520468 \n",
      "\n",
      "Epoch 3448\n",
      "-------------------------------\n",
      "loss: 0.290622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521203 \n",
      "\n",
      "Epoch 3449\n",
      "-------------------------------\n",
      "loss: 0.292146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522065 \n",
      "\n",
      "Epoch 3450\n",
      "-------------------------------\n",
      "loss: 0.281256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523500 \n",
      "\n",
      "Epoch 3451\n",
      "-------------------------------\n",
      "loss: 0.285723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524662 \n",
      "\n",
      "Epoch 3452\n",
      "-------------------------------\n",
      "loss: 0.281361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525152 \n",
      "\n",
      "Epoch 3453\n",
      "-------------------------------\n",
      "loss: 0.292486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525167 \n",
      "\n",
      "Epoch 3454\n",
      "-------------------------------\n",
      "loss: 0.297440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524341 \n",
      "\n",
      "Epoch 3455\n",
      "-------------------------------\n",
      "loss: 0.291730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523062 \n",
      "\n",
      "Epoch 3456\n",
      "-------------------------------\n",
      "loss: 0.286217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521588 \n",
      "\n",
      "Epoch 3457\n",
      "-------------------------------\n",
      "loss: 0.315666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519267 \n",
      "\n",
      "Epoch 3458\n",
      "-------------------------------\n",
      "loss: 0.301387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518045 \n",
      "\n",
      "Epoch 3459\n",
      "-------------------------------\n",
      "loss: 0.312457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518119 \n",
      "\n",
      "Epoch 3460\n",
      "-------------------------------\n",
      "loss: 0.275188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519004 \n",
      "\n",
      "Epoch 3461\n",
      "-------------------------------\n",
      "loss: 0.301891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518573 \n",
      "\n",
      "Epoch 3462\n",
      "-------------------------------\n",
      "loss: 0.289613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516773 \n",
      "\n",
      "Epoch 3463\n",
      "-------------------------------\n",
      "loss: 0.289348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516198 \n",
      "\n",
      "Epoch 3464\n",
      "-------------------------------\n",
      "loss: 0.307738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517256 \n",
      "\n",
      "Epoch 3465\n",
      "-------------------------------\n",
      "loss: 0.308224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518090 \n",
      "\n",
      "Epoch 3466\n",
      "-------------------------------\n",
      "loss: 0.294386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517730 \n",
      "\n",
      "Epoch 3467\n",
      "-------------------------------\n",
      "loss: 0.307370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517486 \n",
      "\n",
      "Epoch 3468\n",
      "-------------------------------\n",
      "loss: 0.288730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517423 \n",
      "\n",
      "Epoch 3469\n",
      "-------------------------------\n",
      "loss: 0.288045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517668 \n",
      "\n",
      "Epoch 3470\n",
      "-------------------------------\n",
      "loss: 0.290362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517661 \n",
      "\n",
      "Epoch 3471\n",
      "-------------------------------\n",
      "loss: 0.299546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517212 \n",
      "\n",
      "Epoch 3472\n",
      "-------------------------------\n",
      "loss: 0.299827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517382 \n",
      "\n",
      "Epoch 3473\n",
      "-------------------------------\n",
      "loss: 0.294883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518180 \n",
      "\n",
      "Epoch 3474\n",
      "-------------------------------\n",
      "loss: 0.282918  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.519008 \n",
      "\n",
      "Epoch 3475\n",
      "-------------------------------\n",
      "loss: 0.276204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519069 \n",
      "\n",
      "Epoch 3476\n",
      "-------------------------------\n",
      "loss: 0.303002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519990 \n",
      "\n",
      "Epoch 3477\n",
      "-------------------------------\n",
      "loss: 0.275431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521059 \n",
      "\n",
      "Epoch 3478\n",
      "-------------------------------\n",
      "loss: 0.286440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521392 \n",
      "\n",
      "Epoch 3479\n",
      "-------------------------------\n",
      "loss: 0.293836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521123 \n",
      "\n",
      "Epoch 3480\n",
      "-------------------------------\n",
      "loss: 0.287973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520716 \n",
      "\n",
      "Epoch 3481\n",
      "-------------------------------\n",
      "loss: 0.287036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520249 \n",
      "\n",
      "Epoch 3482\n",
      "-------------------------------\n",
      "loss: 0.302233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520687 \n",
      "\n",
      "Epoch 3483\n",
      "-------------------------------\n",
      "loss: 0.310752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521665 \n",
      "\n",
      "Epoch 3484\n",
      "-------------------------------\n",
      "loss: 0.288060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522765 \n",
      "\n",
      "Epoch 3485\n",
      "-------------------------------\n",
      "loss: 0.292969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522311 \n",
      "\n",
      "Epoch 3486\n",
      "-------------------------------\n",
      "loss: 0.289455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521842 \n",
      "\n",
      "Epoch 3487\n",
      "-------------------------------\n",
      "loss: 0.291102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521620 \n",
      "\n",
      "Epoch 3488\n",
      "-------------------------------\n",
      "loss: 0.298720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522267 \n",
      "\n",
      "Epoch 3489\n",
      "-------------------------------\n",
      "loss: 0.285802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523496 \n",
      "\n",
      "Epoch 3490\n",
      "-------------------------------\n",
      "loss: 0.295943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524458 \n",
      "\n",
      "Epoch 3491\n",
      "-------------------------------\n",
      "loss: 0.280572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523722 \n",
      "\n",
      "Epoch 3492\n",
      "-------------------------------\n",
      "loss: 0.293488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521986 \n",
      "\n",
      "Epoch 3493\n",
      "-------------------------------\n",
      "loss: 0.283146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520157 \n",
      "\n",
      "Epoch 3494\n",
      "-------------------------------\n",
      "loss: 0.312779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518615 \n",
      "\n",
      "Epoch 3495\n",
      "-------------------------------\n",
      "loss: 0.290626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517914 \n",
      "\n",
      "Epoch 3496\n",
      "-------------------------------\n",
      "loss: 0.283294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518254 \n",
      "\n",
      "Epoch 3497\n",
      "-------------------------------\n",
      "loss: 0.296148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518837 \n",
      "\n",
      "Epoch 3498\n",
      "-------------------------------\n",
      "loss: 0.302605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518693 \n",
      "\n",
      "Epoch 3499\n",
      "-------------------------------\n",
      "loss: 0.286371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518054 \n",
      "\n",
      "Epoch 3500\n",
      "-------------------------------\n",
      "loss: 0.298000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517469 \n",
      "\n",
      "Epoch 3501\n",
      "-------------------------------\n",
      "loss: 0.300242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518480 \n",
      "\n",
      "Epoch 3502\n",
      "-------------------------------\n",
      "loss: 0.311281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519956 \n",
      "\n",
      "Epoch 3503\n",
      "-------------------------------\n",
      "loss: 0.293621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521756 \n",
      "\n",
      "Epoch 3504\n",
      "-------------------------------\n",
      "loss: 0.307492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523677 \n",
      "\n",
      "Epoch 3505\n",
      "-------------------------------\n",
      "loss: 0.283417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524924 \n",
      "\n",
      "Epoch 3506\n",
      "-------------------------------\n",
      "loss: 0.270609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524562 \n",
      "\n",
      "Epoch 3507\n",
      "-------------------------------\n",
      "loss: 0.284454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522735 \n",
      "\n",
      "Epoch 3508\n",
      "-------------------------------\n",
      "loss: 0.283725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520394 \n",
      "\n",
      "Epoch 3509\n",
      "-------------------------------\n",
      "loss: 0.284713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518536 \n",
      "\n",
      "Epoch 3510\n",
      "-------------------------------\n",
      "loss: 0.307679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517510 \n",
      "\n",
      "Epoch 3511\n",
      "-------------------------------\n",
      "loss: 0.297529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517322 \n",
      "\n",
      "Epoch 3512\n",
      "-------------------------------\n",
      "loss: 0.272990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517607 \n",
      "\n",
      "Epoch 3513\n",
      "-------------------------------\n",
      "loss: 0.287979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517300 \n",
      "\n",
      "Epoch 3514\n",
      "-------------------------------\n",
      "loss: 0.278690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517236 \n",
      "\n",
      "Epoch 3515\n",
      "-------------------------------\n",
      "loss: 0.292345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516466 \n",
      "\n",
      "Epoch 3516\n",
      "-------------------------------\n",
      "loss: 0.291668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515105 \n",
      "\n",
      "Epoch 3517\n",
      "-------------------------------\n",
      "loss: 0.285580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514476 \n",
      "\n",
      "Epoch 3518\n",
      "-------------------------------\n",
      "loss: 0.308052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515844 \n",
      "\n",
      "Epoch 3519\n",
      "-------------------------------\n",
      "loss: 0.274305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517252 \n",
      "\n",
      "Epoch 3520\n",
      "-------------------------------\n",
      "loss: 0.279000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518652 \n",
      "\n",
      "Epoch 3521\n",
      "-------------------------------\n",
      "loss: 0.289070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520012 \n",
      "\n",
      "Epoch 3522\n",
      "-------------------------------\n",
      "loss: 0.286349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521020 \n",
      "\n",
      "Epoch 3523\n",
      "-------------------------------\n",
      "loss: 0.273209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522187 \n",
      "\n",
      "Epoch 3524\n",
      "-------------------------------\n",
      "loss: 0.296427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521923 \n",
      "\n",
      "Epoch 3525\n",
      "-------------------------------\n",
      "loss: 0.283328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520755 \n",
      "\n",
      "Epoch 3526\n",
      "-------------------------------\n",
      "loss: 0.286812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519716 \n",
      "\n",
      "Epoch 3527\n",
      "-------------------------------\n",
      "loss: 0.298998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518281 \n",
      "\n",
      "Epoch 3528\n",
      "-------------------------------\n",
      "loss: 0.279240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517594 \n",
      "\n",
      "Epoch 3529\n",
      "-------------------------------\n",
      "loss: 0.291235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516655 \n",
      "\n",
      "Epoch 3530\n",
      "-------------------------------\n",
      "loss: 0.299643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516547 \n",
      "\n",
      "Epoch 3531\n",
      "-------------------------------\n",
      "loss: 0.312731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517166 \n",
      "\n",
      "Epoch 3532\n",
      "-------------------------------\n",
      "loss: 0.299809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517362 \n",
      "\n",
      "Epoch 3533\n",
      "-------------------------------\n",
      "loss: 0.284869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517915 \n",
      "\n",
      "Epoch 3534\n",
      "-------------------------------\n",
      "loss: 0.299888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519377 \n",
      "\n",
      "Epoch 3535\n",
      "-------------------------------\n",
      "loss: 0.278381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520916 \n",
      "\n",
      "Epoch 3536\n",
      "-------------------------------\n",
      "loss: 0.281517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520391 \n",
      "\n",
      "Epoch 3537\n",
      "-------------------------------\n",
      "loss: 0.281748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519891 \n",
      "\n",
      "Epoch 3538\n",
      "-------------------------------\n",
      "loss: 0.280116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519060 \n",
      "\n",
      "Epoch 3539\n",
      "-------------------------------\n",
      "loss: 0.281740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518736 \n",
      "\n",
      "Epoch 3540\n",
      "-------------------------------\n",
      "loss: 0.274643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518438 \n",
      "\n",
      "Epoch 3541\n",
      "-------------------------------\n",
      "loss: 0.292775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518313 \n",
      "\n",
      "Epoch 3542\n",
      "-------------------------------\n",
      "loss: 0.292446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518683 \n",
      "\n",
      "Epoch 3543\n",
      "-------------------------------\n",
      "loss: 0.280001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519997 \n",
      "\n",
      "Epoch 3544\n",
      "-------------------------------\n",
      "loss: 0.298222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520169 \n",
      "\n",
      "Epoch 3545\n",
      "-------------------------------\n",
      "loss: 0.298803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518846 \n",
      "\n",
      "Epoch 3546\n",
      "-------------------------------\n",
      "loss: 0.294959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517528 \n",
      "\n",
      "Epoch 3547\n",
      "-------------------------------\n",
      "loss: 0.282573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517562 \n",
      "\n",
      "Epoch 3548\n",
      "-------------------------------\n",
      "loss: 0.292693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518254 \n",
      "\n",
      "Epoch 3549\n",
      "-------------------------------\n",
      "loss: 0.267716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519096 \n",
      "\n",
      "Epoch 3550\n",
      "-------------------------------\n",
      "loss: 0.283289  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.519524 \n",
      "\n",
      "Epoch 3551\n",
      "-------------------------------\n",
      "loss: 0.304143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519711 \n",
      "\n",
      "Epoch 3552\n",
      "-------------------------------\n",
      "loss: 0.285979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519399 \n",
      "\n",
      "Epoch 3553\n",
      "-------------------------------\n",
      "loss: 0.281914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518478 \n",
      "\n",
      "Epoch 3554\n",
      "-------------------------------\n",
      "loss: 0.306697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517139 \n",
      "\n",
      "Epoch 3555\n",
      "-------------------------------\n",
      "loss: 0.301652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515162 \n",
      "\n",
      "Epoch 3556\n",
      "-------------------------------\n",
      "loss: 0.297741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513952 \n",
      "\n",
      "Epoch 3557\n",
      "-------------------------------\n",
      "loss: 0.278584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513451 \n",
      "\n",
      "Epoch 3558\n",
      "-------------------------------\n",
      "loss: 0.291643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513398 \n",
      "\n",
      "Epoch 3559\n",
      "-------------------------------\n",
      "loss: 0.289018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513094 \n",
      "\n",
      "Epoch 3560\n",
      "-------------------------------\n",
      "loss: 0.284071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512942 \n",
      "\n",
      "Epoch 3561\n",
      "-------------------------------\n",
      "loss: 0.270548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513855 \n",
      "\n",
      "Epoch 3562\n",
      "-------------------------------\n",
      "loss: 0.279400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515813 \n",
      "\n",
      "Epoch 3563\n",
      "-------------------------------\n",
      "loss: 0.288851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517434 \n",
      "\n",
      "Epoch 3564\n",
      "-------------------------------\n",
      "loss: 0.282946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518729 \n",
      "\n",
      "Epoch 3565\n",
      "-------------------------------\n",
      "loss: 0.300517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519988 \n",
      "\n",
      "Epoch 3566\n",
      "-------------------------------\n",
      "loss: 0.283068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520302 \n",
      "\n",
      "Epoch 3567\n",
      "-------------------------------\n",
      "loss: 0.285943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519357 \n",
      "\n",
      "Epoch 3568\n",
      "-------------------------------\n",
      "loss: 0.287526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518793 \n",
      "\n",
      "Epoch 3569\n",
      "-------------------------------\n",
      "loss: 0.267042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518246 \n",
      "\n",
      "Epoch 3570\n",
      "-------------------------------\n",
      "loss: 0.277969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518132 \n",
      "\n",
      "Epoch 3571\n",
      "-------------------------------\n",
      "loss: 0.282025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518129 \n",
      "\n",
      "Epoch 3572\n",
      "-------------------------------\n",
      "loss: 0.293199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518973 \n",
      "\n",
      "Epoch 3573\n",
      "-------------------------------\n",
      "loss: 0.291420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518950 \n",
      "\n",
      "Epoch 3574\n",
      "-------------------------------\n",
      "loss: 0.277517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517697 \n",
      "\n",
      "Epoch 3575\n",
      "-------------------------------\n",
      "loss: 0.295602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516432 \n",
      "\n",
      "Epoch 3576\n",
      "-------------------------------\n",
      "loss: 0.286415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516196 \n",
      "\n",
      "Epoch 3577\n",
      "-------------------------------\n",
      "loss: 0.293745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516465 \n",
      "\n",
      "Epoch 3578\n",
      "-------------------------------\n",
      "loss: 0.300538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516751 \n",
      "\n",
      "Epoch 3579\n",
      "-------------------------------\n",
      "loss: 0.284631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518185 \n",
      "\n",
      "Epoch 3580\n",
      "-------------------------------\n",
      "loss: 0.284769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520170 \n",
      "\n",
      "Epoch 3581\n",
      "-------------------------------\n",
      "loss: 0.280421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521728 \n",
      "\n",
      "Epoch 3582\n",
      "-------------------------------\n",
      "loss: 0.284427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520992 \n",
      "\n",
      "Epoch 3583\n",
      "-------------------------------\n",
      "loss: 0.296865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518495 \n",
      "\n",
      "Epoch 3584\n",
      "-------------------------------\n",
      "loss: 0.286900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516079 \n",
      "\n",
      "Epoch 3585\n",
      "-------------------------------\n",
      "loss: 0.272029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515220 \n",
      "\n",
      "Epoch 3586\n",
      "-------------------------------\n",
      "loss: 0.300335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515846 \n",
      "\n",
      "Epoch 3587\n",
      "-------------------------------\n",
      "loss: 0.289904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515516 \n",
      "\n",
      "Epoch 3588\n",
      "-------------------------------\n",
      "loss: 0.303549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514315 \n",
      "\n",
      "Epoch 3589\n",
      "-------------------------------\n",
      "loss: 0.277270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513915 \n",
      "\n",
      "Epoch 3590\n",
      "-------------------------------\n",
      "loss: 0.282026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515603 \n",
      "\n",
      "Epoch 3591\n",
      "-------------------------------\n",
      "loss: 0.277438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519083 \n",
      "\n",
      "Epoch 3592\n",
      "-------------------------------\n",
      "loss: 0.281629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521288 \n",
      "\n",
      "Epoch 3593\n",
      "-------------------------------\n",
      "loss: 0.298140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520815 \n",
      "\n",
      "Epoch 3594\n",
      "-------------------------------\n",
      "loss: 0.281970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518635 \n",
      "\n",
      "Epoch 3595\n",
      "-------------------------------\n",
      "loss: 0.272692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517069 \n",
      "\n",
      "Epoch 3596\n",
      "-------------------------------\n",
      "loss: 0.290064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517068 \n",
      "\n",
      "Epoch 3597\n",
      "-------------------------------\n",
      "loss: 0.283713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519035 \n",
      "\n",
      "Epoch 3598\n",
      "-------------------------------\n",
      "loss: 0.308871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520262 \n",
      "\n",
      "Epoch 3599\n",
      "-------------------------------\n",
      "loss: 0.278742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519899 \n",
      "\n",
      "Epoch 3600\n",
      "-------------------------------\n",
      "loss: 0.283376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521346 \n",
      "\n",
      "Epoch 3601\n",
      "-------------------------------\n",
      "loss: 0.278330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524044 \n",
      "\n",
      "Epoch 3602\n",
      "-------------------------------\n",
      "loss: 0.291601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524889 \n",
      "\n",
      "Epoch 3603\n",
      "-------------------------------\n",
      "loss: 0.292179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522652 \n",
      "\n",
      "Epoch 3604\n",
      "-------------------------------\n",
      "loss: 0.299948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518626 \n",
      "\n",
      "Epoch 3605\n",
      "-------------------------------\n",
      "loss: 0.276268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515083 \n",
      "\n",
      "Epoch 3606\n",
      "-------------------------------\n",
      "loss: 0.288805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512842 \n",
      "\n",
      "Epoch 3607\n",
      "-------------------------------\n",
      "loss: 0.280821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511573 \n",
      "\n",
      "Epoch 3608\n",
      "-------------------------------\n",
      "loss: 0.286905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512144 \n",
      "\n",
      "Epoch 3609\n",
      "-------------------------------\n",
      "loss: 0.281432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513579 \n",
      "\n",
      "Epoch 3610\n",
      "-------------------------------\n",
      "loss: 0.282571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513963 \n",
      "\n",
      "Epoch 3611\n",
      "-------------------------------\n",
      "loss: 0.305109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514175 \n",
      "\n",
      "Epoch 3612\n",
      "-------------------------------\n",
      "loss: 0.284710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514512 \n",
      "\n",
      "Epoch 3613\n",
      "-------------------------------\n",
      "loss: 0.278833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514232 \n",
      "\n",
      "Epoch 3614\n",
      "-------------------------------\n",
      "loss: 0.267542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514426 \n",
      "\n",
      "Epoch 3615\n",
      "-------------------------------\n",
      "loss: 0.292225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515030 \n",
      "\n",
      "Epoch 3616\n",
      "-------------------------------\n",
      "loss: 0.290324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515621 \n",
      "\n",
      "Epoch 3617\n",
      "-------------------------------\n",
      "loss: 0.285390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515122 \n",
      "\n",
      "Epoch 3618\n",
      "-------------------------------\n",
      "loss: 0.294563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514764 \n",
      "\n",
      "Epoch 3619\n",
      "-------------------------------\n",
      "loss: 0.275269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514184 \n",
      "\n",
      "Epoch 3620\n",
      "-------------------------------\n",
      "loss: 0.287181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514115 \n",
      "\n",
      "Epoch 3621\n",
      "-------------------------------\n",
      "loss: 0.276779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514805 \n",
      "\n",
      "Epoch 3622\n",
      "-------------------------------\n",
      "loss: 0.284238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515689 \n",
      "\n",
      "Epoch 3623\n",
      "-------------------------------\n",
      "loss: 0.266385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516680 \n",
      "\n",
      "Epoch 3624\n",
      "-------------------------------\n",
      "loss: 0.293977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517579 \n",
      "\n",
      "Epoch 3625\n",
      "-------------------------------\n",
      "loss: 0.294164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517105 \n",
      "\n",
      "Epoch 3626\n",
      "-------------------------------\n",
      "loss: 0.283566  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.516441 \n",
      "\n",
      "Epoch 3627\n",
      "-------------------------------\n",
      "loss: 0.283079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516513 \n",
      "\n",
      "Epoch 3628\n",
      "-------------------------------\n",
      "loss: 0.275727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516733 \n",
      "\n",
      "Epoch 3629\n",
      "-------------------------------\n",
      "loss: 0.279551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517558 \n",
      "\n",
      "Epoch 3630\n",
      "-------------------------------\n",
      "loss: 0.304070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518983 \n",
      "\n",
      "Epoch 3631\n",
      "-------------------------------\n",
      "loss: 0.302280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521538 \n",
      "\n",
      "Epoch 3632\n",
      "-------------------------------\n",
      "loss: 0.286424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522104 \n",
      "\n",
      "Epoch 3633\n",
      "-------------------------------\n",
      "loss: 0.305988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521562 \n",
      "\n",
      "Epoch 3634\n",
      "-------------------------------\n",
      "loss: 0.284685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520701 \n",
      "\n",
      "Epoch 3635\n",
      "-------------------------------\n",
      "loss: 0.266650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519591 \n",
      "\n",
      "Epoch 3636\n",
      "-------------------------------\n",
      "loss: 0.284291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518516 \n",
      "\n",
      "Epoch 3637\n",
      "-------------------------------\n",
      "loss: 0.287260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517916 \n",
      "\n",
      "Epoch 3638\n",
      "-------------------------------\n",
      "loss: 0.301258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517520 \n",
      "\n",
      "Epoch 3639\n",
      "-------------------------------\n",
      "loss: 0.282155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518016 \n",
      "\n",
      "Epoch 3640\n",
      "-------------------------------\n",
      "loss: 0.304323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519198 \n",
      "\n",
      "Epoch 3641\n",
      "-------------------------------\n",
      "loss: 0.289039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521097 \n",
      "\n",
      "Epoch 3642\n",
      "-------------------------------\n",
      "loss: 0.289251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520591 \n",
      "\n",
      "Epoch 3643\n",
      "-------------------------------\n",
      "loss: 0.312952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519279 \n",
      "\n",
      "Epoch 3644\n",
      "-------------------------------\n",
      "loss: 0.275634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519315 \n",
      "\n",
      "Epoch 3645\n",
      "-------------------------------\n",
      "loss: 0.306127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519197 \n",
      "\n",
      "Epoch 3646\n",
      "-------------------------------\n",
      "loss: 0.263709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519901 \n",
      "\n",
      "Epoch 3647\n",
      "-------------------------------\n",
      "loss: 0.272242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521177 \n",
      "\n",
      "Epoch 3648\n",
      "-------------------------------\n",
      "loss: 0.292794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521249 \n",
      "\n",
      "Epoch 3649\n",
      "-------------------------------\n",
      "loss: 0.293168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520600 \n",
      "\n",
      "Epoch 3650\n",
      "-------------------------------\n",
      "loss: 0.288257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519727 \n",
      "\n",
      "Epoch 3651\n",
      "-------------------------------\n",
      "loss: 0.293423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519717 \n",
      "\n",
      "Epoch 3652\n",
      "-------------------------------\n",
      "loss: 0.293428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519976 \n",
      "\n",
      "Epoch 3653\n",
      "-------------------------------\n",
      "loss: 0.298929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520380 \n",
      "\n",
      "Epoch 3654\n",
      "-------------------------------\n",
      "loss: 0.279275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519399 \n",
      "\n",
      "Epoch 3655\n",
      "-------------------------------\n",
      "loss: 0.290718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519044 \n",
      "\n",
      "Epoch 3656\n",
      "-------------------------------\n",
      "loss: 0.310681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519113 \n",
      "\n",
      "Epoch 3657\n",
      "-------------------------------\n",
      "loss: 0.289296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519161 \n",
      "\n",
      "Epoch 3658\n",
      "-------------------------------\n",
      "loss: 0.285982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519130 \n",
      "\n",
      "Epoch 3659\n",
      "-------------------------------\n",
      "loss: 0.291246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519746 \n",
      "\n",
      "Epoch 3660\n",
      "-------------------------------\n",
      "loss: 0.281327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520603 \n",
      "\n",
      "Epoch 3661\n",
      "-------------------------------\n",
      "loss: 0.276788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521594 \n",
      "\n",
      "Epoch 3662\n",
      "-------------------------------\n",
      "loss: 0.295552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521588 \n",
      "\n",
      "Epoch 3663\n",
      "-------------------------------\n",
      "loss: 0.290328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521207 \n",
      "\n",
      "Epoch 3664\n",
      "-------------------------------\n",
      "loss: 0.296887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521073 \n",
      "\n",
      "Epoch 3665\n",
      "-------------------------------\n",
      "loss: 0.289735  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521217 \n",
      "\n",
      "Epoch 3666\n",
      "-------------------------------\n",
      "loss: 0.280077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521087 \n",
      "\n",
      "Epoch 3667\n",
      "-------------------------------\n",
      "loss: 0.290818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519916 \n",
      "\n",
      "Epoch 3668\n",
      "-------------------------------\n",
      "loss: 0.289784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518828 \n",
      "\n",
      "Epoch 3669\n",
      "-------------------------------\n",
      "loss: 0.258592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517547 \n",
      "\n",
      "Epoch 3670\n",
      "-------------------------------\n",
      "loss: 0.294124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516705 \n",
      "\n",
      "Epoch 3671\n",
      "-------------------------------\n",
      "loss: 0.296145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516452 \n",
      "\n",
      "Epoch 3672\n",
      "-------------------------------\n",
      "loss: 0.294300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517130 \n",
      "\n",
      "Epoch 3673\n",
      "-------------------------------\n",
      "loss: 0.296270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517765 \n",
      "\n",
      "Epoch 3674\n",
      "-------------------------------\n",
      "loss: 0.267935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518393 \n",
      "\n",
      "Epoch 3675\n",
      "-------------------------------\n",
      "loss: 0.284749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519509 \n",
      "\n",
      "Epoch 3676\n",
      "-------------------------------\n",
      "loss: 0.286401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520375 \n",
      "\n",
      "Epoch 3677\n",
      "-------------------------------\n",
      "loss: 0.282347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520920 \n",
      "\n",
      "Epoch 3678\n",
      "-------------------------------\n",
      "loss: 0.291342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520800 \n",
      "\n",
      "Epoch 3679\n",
      "-------------------------------\n",
      "loss: 0.286404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519877 \n",
      "\n",
      "Epoch 3680\n",
      "-------------------------------\n",
      "loss: 0.278139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518066 \n",
      "\n",
      "Epoch 3681\n",
      "-------------------------------\n",
      "loss: 0.279026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515592 \n",
      "\n",
      "Epoch 3682\n",
      "-------------------------------\n",
      "loss: 0.273818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514697 \n",
      "\n",
      "Epoch 3683\n",
      "-------------------------------\n",
      "loss: 0.273721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514668 \n",
      "\n",
      "Epoch 3684\n",
      "-------------------------------\n",
      "loss: 0.306266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514243 \n",
      "\n",
      "Epoch 3685\n",
      "-------------------------------\n",
      "loss: 0.309768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514370 \n",
      "\n",
      "Epoch 3686\n",
      "-------------------------------\n",
      "loss: 0.285113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514060 \n",
      "\n",
      "Epoch 3687\n",
      "-------------------------------\n",
      "loss: 0.288111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514660 \n",
      "\n",
      "Epoch 3688\n",
      "-------------------------------\n",
      "loss: 0.281385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515393 \n",
      "\n",
      "Epoch 3689\n",
      "-------------------------------\n",
      "loss: 0.255612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516041 \n",
      "\n",
      "Epoch 3690\n",
      "-------------------------------\n",
      "loss: 0.293825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517204 \n",
      "\n",
      "Epoch 3691\n",
      "-------------------------------\n",
      "loss: 0.267183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518177 \n",
      "\n",
      "Epoch 3692\n",
      "-------------------------------\n",
      "loss: 0.297133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518357 \n",
      "\n",
      "Epoch 3693\n",
      "-------------------------------\n",
      "loss: 0.297762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517965 \n",
      "\n",
      "Epoch 3694\n",
      "-------------------------------\n",
      "loss: 0.283435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517313 \n",
      "\n",
      "Epoch 3695\n",
      "-------------------------------\n",
      "loss: 0.290998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516371 \n",
      "\n",
      "Epoch 3696\n",
      "-------------------------------\n",
      "loss: 0.296204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516063 \n",
      "\n",
      "Epoch 3697\n",
      "-------------------------------\n",
      "loss: 0.282414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515608 \n",
      "\n",
      "Epoch 3698\n",
      "-------------------------------\n",
      "loss: 0.288850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514798 \n",
      "\n",
      "Epoch 3699\n",
      "-------------------------------\n",
      "loss: 0.276238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514031 \n",
      "\n",
      "Epoch 3700\n",
      "-------------------------------\n",
      "loss: 0.301852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513378 \n",
      "\n",
      "Epoch 3701\n",
      "-------------------------------\n",
      "loss: 0.283757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512785 \n",
      "\n",
      "Epoch 3702\n",
      "-------------------------------\n",
      "loss: 0.296275  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.512535 \n",
      "\n",
      "Epoch 3703\n",
      "-------------------------------\n",
      "loss: 0.263439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513077 \n",
      "\n",
      "Epoch 3704\n",
      "-------------------------------\n",
      "loss: 0.303928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513339 \n",
      "\n",
      "Epoch 3705\n",
      "-------------------------------\n",
      "loss: 0.267946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513656 \n",
      "\n",
      "Epoch 3706\n",
      "-------------------------------\n",
      "loss: 0.278529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513905 \n",
      "\n",
      "Epoch 3707\n",
      "-------------------------------\n",
      "loss: 0.281862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513447 \n",
      "\n",
      "Epoch 3708\n",
      "-------------------------------\n",
      "loss: 0.272395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513175 \n",
      "\n",
      "Epoch 3709\n",
      "-------------------------------\n",
      "loss: 0.278244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513083 \n",
      "\n",
      "Epoch 3710\n",
      "-------------------------------\n",
      "loss: 0.292011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513711 \n",
      "\n",
      "Epoch 3711\n",
      "-------------------------------\n",
      "loss: 0.294080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514522 \n",
      "\n",
      "Epoch 3712\n",
      "-------------------------------\n",
      "loss: 0.280113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514738 \n",
      "\n",
      "Epoch 3713\n",
      "-------------------------------\n",
      "loss: 0.307791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515510 \n",
      "\n",
      "Epoch 3714\n",
      "-------------------------------\n",
      "loss: 0.272669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516984 \n",
      "\n",
      "Epoch 3715\n",
      "-------------------------------\n",
      "loss: 0.286249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517494 \n",
      "\n",
      "Epoch 3716\n",
      "-------------------------------\n",
      "loss: 0.281569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517206 \n",
      "\n",
      "Epoch 3717\n",
      "-------------------------------\n",
      "loss: 0.294669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517342 \n",
      "\n",
      "Epoch 3718\n",
      "-------------------------------\n",
      "loss: 0.292053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517675 \n",
      "\n",
      "Epoch 3719\n",
      "-------------------------------\n",
      "loss: 0.266704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517848 \n",
      "\n",
      "Epoch 3720\n",
      "-------------------------------\n",
      "loss: 0.279380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518178 \n",
      "\n",
      "Epoch 3721\n",
      "-------------------------------\n",
      "loss: 0.292110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518518 \n",
      "\n",
      "Epoch 3722\n",
      "-------------------------------\n",
      "loss: 0.276863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519697 \n",
      "\n",
      "Epoch 3723\n",
      "-------------------------------\n",
      "loss: 0.277627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520788 \n",
      "\n",
      "Epoch 3724\n",
      "-------------------------------\n",
      "loss: 0.295020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521170 \n",
      "\n",
      "Epoch 3725\n",
      "-------------------------------\n",
      "loss: 0.288317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522005 \n",
      "\n",
      "Epoch 3726\n",
      "-------------------------------\n",
      "loss: 0.286512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522798 \n",
      "\n",
      "Epoch 3727\n",
      "-------------------------------\n",
      "loss: 0.278671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523063 \n",
      "\n",
      "Epoch 3728\n",
      "-------------------------------\n",
      "loss: 0.275378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523026 \n",
      "\n",
      "Epoch 3729\n",
      "-------------------------------\n",
      "loss: 0.289043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523169 \n",
      "\n",
      "Epoch 3730\n",
      "-------------------------------\n",
      "loss: 0.271699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522926 \n",
      "\n",
      "Epoch 3731\n",
      "-------------------------------\n",
      "loss: 0.291511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522476 \n",
      "\n",
      "Epoch 3732\n",
      "-------------------------------\n",
      "loss: 0.276403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522716 \n",
      "\n",
      "Epoch 3733\n",
      "-------------------------------\n",
      "loss: 0.286228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523940 \n",
      "\n",
      "Epoch 3734\n",
      "-------------------------------\n",
      "loss: 0.279852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523943 \n",
      "\n",
      "Epoch 3735\n",
      "-------------------------------\n",
      "loss: 0.303003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524064 \n",
      "\n",
      "Epoch 3736\n",
      "-------------------------------\n",
      "loss: 0.283210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521729 \n",
      "\n",
      "Epoch 3737\n",
      "-------------------------------\n",
      "loss: 0.289953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519306 \n",
      "\n",
      "Epoch 3738\n",
      "-------------------------------\n",
      "loss: 0.304632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519255 \n",
      "\n",
      "Epoch 3739\n",
      "-------------------------------\n",
      "loss: 0.283428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520383 \n",
      "\n",
      "Epoch 3740\n",
      "-------------------------------\n",
      "loss: 0.310190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521302 \n",
      "\n",
      "Epoch 3741\n",
      "-------------------------------\n",
      "loss: 0.296970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522076 \n",
      "\n",
      "Epoch 3742\n",
      "-------------------------------\n",
      "loss: 0.289080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522485 \n",
      "\n",
      "Epoch 3743\n",
      "-------------------------------\n",
      "loss: 0.283170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523254 \n",
      "\n",
      "Epoch 3744\n",
      "-------------------------------\n",
      "loss: 0.275214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523875 \n",
      "\n",
      "Epoch 3745\n",
      "-------------------------------\n",
      "loss: 0.290834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523872 \n",
      "\n",
      "Epoch 3746\n",
      "-------------------------------\n",
      "loss: 0.284404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522976 \n",
      "\n",
      "Epoch 3747\n",
      "-------------------------------\n",
      "loss: 0.301359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521422 \n",
      "\n",
      "Epoch 3748\n",
      "-------------------------------\n",
      "loss: 0.276725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519295 \n",
      "\n",
      "Epoch 3749\n",
      "-------------------------------\n",
      "loss: 0.299273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517846 \n",
      "\n",
      "Epoch 3750\n",
      "-------------------------------\n",
      "loss: 0.279606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517158 \n",
      "\n",
      "Epoch 3751\n",
      "-------------------------------\n",
      "loss: 0.303845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516300 \n",
      "\n",
      "Epoch 3752\n",
      "-------------------------------\n",
      "loss: 0.258999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515743 \n",
      "\n",
      "Epoch 3753\n",
      "-------------------------------\n",
      "loss: 0.278526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515830 \n",
      "\n",
      "Epoch 3754\n",
      "-------------------------------\n",
      "loss: 0.273172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516026 \n",
      "\n",
      "Epoch 3755\n",
      "-------------------------------\n",
      "loss: 0.279645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516349 \n",
      "\n",
      "Epoch 3756\n",
      "-------------------------------\n",
      "loss: 0.281173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516959 \n",
      "\n",
      "Epoch 3757\n",
      "-------------------------------\n",
      "loss: 0.281282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518141 \n",
      "\n",
      "Epoch 3758\n",
      "-------------------------------\n",
      "loss: 0.290869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519963 \n",
      "\n",
      "Epoch 3759\n",
      "-------------------------------\n",
      "loss: 0.287724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521303 \n",
      "\n",
      "Epoch 3760\n",
      "-------------------------------\n",
      "loss: 0.281727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521571 \n",
      "\n",
      "Epoch 3761\n",
      "-------------------------------\n",
      "loss: 0.296276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522549 \n",
      "\n",
      "Epoch 3762\n",
      "-------------------------------\n",
      "loss: 0.273224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522332 \n",
      "\n",
      "Epoch 3763\n",
      "-------------------------------\n",
      "loss: 0.277017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522518 \n",
      "\n",
      "Epoch 3764\n",
      "-------------------------------\n",
      "loss: 0.274556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521485 \n",
      "\n",
      "Epoch 3765\n",
      "-------------------------------\n",
      "loss: 0.283277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519990 \n",
      "\n",
      "Epoch 3766\n",
      "-------------------------------\n",
      "loss: 0.300004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518456 \n",
      "\n",
      "Epoch 3767\n",
      "-------------------------------\n",
      "loss: 0.262764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518294 \n",
      "\n",
      "Epoch 3768\n",
      "-------------------------------\n",
      "loss: 0.265920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518490 \n",
      "\n",
      "Epoch 3769\n",
      "-------------------------------\n",
      "loss: 0.289792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518073 \n",
      "\n",
      "Epoch 3770\n",
      "-------------------------------\n",
      "loss: 0.296180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517723 \n",
      "\n",
      "Epoch 3771\n",
      "-------------------------------\n",
      "loss: 0.296293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517799 \n",
      "\n",
      "Epoch 3772\n",
      "-------------------------------\n",
      "loss: 0.285144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518397 \n",
      "\n",
      "Epoch 3773\n",
      "-------------------------------\n",
      "loss: 0.288428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519347 \n",
      "\n",
      "Epoch 3774\n",
      "-------------------------------\n",
      "loss: 0.301040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520528 \n",
      "\n",
      "Epoch 3775\n",
      "-------------------------------\n",
      "loss: 0.291126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520329 \n",
      "\n",
      "Epoch 3776\n",
      "-------------------------------\n",
      "loss: 0.305422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519273 \n",
      "\n",
      "Epoch 3777\n",
      "-------------------------------\n",
      "loss: 0.275747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519145 \n",
      "\n",
      "Epoch 3778\n",
      "-------------------------------\n",
      "loss: 0.288978  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.519181 \n",
      "\n",
      "Epoch 3779\n",
      "-------------------------------\n",
      "loss: 0.279744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519254 \n",
      "\n",
      "Epoch 3780\n",
      "-------------------------------\n",
      "loss: 0.294144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518917 \n",
      "\n",
      "Epoch 3781\n",
      "-------------------------------\n",
      "loss: 0.278699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518893 \n",
      "\n",
      "Epoch 3782\n",
      "-------------------------------\n",
      "loss: 0.294580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518387 \n",
      "\n",
      "Epoch 3783\n",
      "-------------------------------\n",
      "loss: 0.290163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518350 \n",
      "\n",
      "Epoch 3784\n",
      "-------------------------------\n",
      "loss: 0.280031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518239 \n",
      "\n",
      "Epoch 3785\n",
      "-------------------------------\n",
      "loss: 0.281750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518228 \n",
      "\n",
      "Epoch 3786\n",
      "-------------------------------\n",
      "loss: 0.278647  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518363 \n",
      "\n",
      "Epoch 3787\n",
      "-------------------------------\n",
      "loss: 0.287792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519056 \n",
      "\n",
      "Epoch 3788\n",
      "-------------------------------\n",
      "loss: 0.280699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519857 \n",
      "\n",
      "Epoch 3789\n",
      "-------------------------------\n",
      "loss: 0.287921  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521091 \n",
      "\n",
      "Epoch 3790\n",
      "-------------------------------\n",
      "loss: 0.275466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521977 \n",
      "\n",
      "Epoch 3791\n",
      "-------------------------------\n",
      "loss: 0.279918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521662 \n",
      "\n",
      "Epoch 3792\n",
      "-------------------------------\n",
      "loss: 0.281130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520465 \n",
      "\n",
      "Epoch 3793\n",
      "-------------------------------\n",
      "loss: 0.282781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519310 \n",
      "\n",
      "Epoch 3794\n",
      "-------------------------------\n",
      "loss: 0.289172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518390 \n",
      "\n",
      "Epoch 3795\n",
      "-------------------------------\n",
      "loss: 0.282554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517520 \n",
      "\n",
      "Epoch 3796\n",
      "-------------------------------\n",
      "loss: 0.279772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516942 \n",
      "\n",
      "Epoch 3797\n",
      "-------------------------------\n",
      "loss: 0.259235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516752 \n",
      "\n",
      "Epoch 3798\n",
      "-------------------------------\n",
      "loss: 0.282295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516759 \n",
      "\n",
      "Epoch 3799\n",
      "-------------------------------\n",
      "loss: 0.270920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516890 \n",
      "\n",
      "Epoch 3800\n",
      "-------------------------------\n",
      "loss: 0.270884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517726 \n",
      "\n",
      "Epoch 3801\n",
      "-------------------------------\n",
      "loss: 0.286083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519760 \n",
      "\n",
      "Epoch 3802\n",
      "-------------------------------\n",
      "loss: 0.283183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522095 \n",
      "\n",
      "Epoch 3803\n",
      "-------------------------------\n",
      "loss: 0.274745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523085 \n",
      "\n",
      "Epoch 3804\n",
      "-------------------------------\n",
      "loss: 0.275140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522458 \n",
      "\n",
      "Epoch 3805\n",
      "-------------------------------\n",
      "loss: 0.289464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521244 \n",
      "\n",
      "Epoch 3806\n",
      "-------------------------------\n",
      "loss: 0.288203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520569 \n",
      "\n",
      "Epoch 3807\n",
      "-------------------------------\n",
      "loss: 0.266653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520484 \n",
      "\n",
      "Epoch 3808\n",
      "-------------------------------\n",
      "loss: 0.279079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520215 \n",
      "\n",
      "Epoch 3809\n",
      "-------------------------------\n",
      "loss: 0.278039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520306 \n",
      "\n",
      "Epoch 3810\n",
      "-------------------------------\n",
      "loss: 0.293372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520153 \n",
      "\n",
      "Epoch 3811\n",
      "-------------------------------\n",
      "loss: 0.272738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519504 \n",
      "\n",
      "Epoch 3812\n",
      "-------------------------------\n",
      "loss: 0.263967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519286 \n",
      "\n",
      "Epoch 3813\n",
      "-------------------------------\n",
      "loss: 0.276307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519538 \n",
      "\n",
      "Epoch 3814\n",
      "-------------------------------\n",
      "loss: 0.285357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519424 \n",
      "\n",
      "Epoch 3815\n",
      "-------------------------------\n",
      "loss: 0.295011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519656 \n",
      "\n",
      "Epoch 3816\n",
      "-------------------------------\n",
      "loss: 0.280769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519540 \n",
      "\n",
      "Epoch 3817\n",
      "-------------------------------\n",
      "loss: 0.289532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519021 \n",
      "\n",
      "Epoch 3818\n",
      "-------------------------------\n",
      "loss: 0.282679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519226 \n",
      "\n",
      "Epoch 3819\n",
      "-------------------------------\n",
      "loss: 0.285628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519585 \n",
      "\n",
      "Epoch 3820\n",
      "-------------------------------\n",
      "loss: 0.275906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520462 \n",
      "\n",
      "Epoch 3821\n",
      "-------------------------------\n",
      "loss: 0.290318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521748 \n",
      "\n",
      "Epoch 3822\n",
      "-------------------------------\n",
      "loss: 0.290847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522559 \n",
      "\n",
      "Epoch 3823\n",
      "-------------------------------\n",
      "loss: 0.287612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521479 \n",
      "\n",
      "Epoch 3824\n",
      "-------------------------------\n",
      "loss: 0.293511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520622 \n",
      "\n",
      "Epoch 3825\n",
      "-------------------------------\n",
      "loss: 0.274223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520077 \n",
      "\n",
      "Epoch 3826\n",
      "-------------------------------\n",
      "loss: 0.291472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519755 \n",
      "\n",
      "Epoch 3827\n",
      "-------------------------------\n",
      "loss: 0.296158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519596 \n",
      "\n",
      "Epoch 3828\n",
      "-------------------------------\n",
      "loss: 0.295119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519200 \n",
      "\n",
      "Epoch 3829\n",
      "-------------------------------\n",
      "loss: 0.285270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519203 \n",
      "\n",
      "Epoch 3830\n",
      "-------------------------------\n",
      "loss: 0.283749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518078 \n",
      "\n",
      "Epoch 3831\n",
      "-------------------------------\n",
      "loss: 0.295879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517207 \n",
      "\n",
      "Epoch 3832\n",
      "-------------------------------\n",
      "loss: 0.301188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517545 \n",
      "\n",
      "Epoch 3833\n",
      "-------------------------------\n",
      "loss: 0.278122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517031 \n",
      "\n",
      "Epoch 3834\n",
      "-------------------------------\n",
      "loss: 0.293010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516828 \n",
      "\n",
      "Epoch 3835\n",
      "-------------------------------\n",
      "loss: 0.267945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517360 \n",
      "\n",
      "Epoch 3836\n",
      "-------------------------------\n",
      "loss: 0.267060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518436 \n",
      "\n",
      "Epoch 3837\n",
      "-------------------------------\n",
      "loss: 0.276975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519617 \n",
      "\n",
      "Epoch 3838\n",
      "-------------------------------\n",
      "loss: 0.297835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520928 \n",
      "\n",
      "Epoch 3839\n",
      "-------------------------------\n",
      "loss: 0.290224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521624 \n",
      "\n",
      "Epoch 3840\n",
      "-------------------------------\n",
      "loss: 0.297187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521830 \n",
      "\n",
      "Epoch 3841\n",
      "-------------------------------\n",
      "loss: 0.286627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521603 \n",
      "\n",
      "Epoch 3842\n",
      "-------------------------------\n",
      "loss: 0.300347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521839 \n",
      "\n",
      "Epoch 3843\n",
      "-------------------------------\n",
      "loss: 0.289325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521218 \n",
      "\n",
      "Epoch 3844\n",
      "-------------------------------\n",
      "loss: 0.281960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520715 \n",
      "\n",
      "Epoch 3845\n",
      "-------------------------------\n",
      "loss: 0.281364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520416 \n",
      "\n",
      "Epoch 3846\n",
      "-------------------------------\n",
      "loss: 0.264139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520666 \n",
      "\n",
      "Epoch 3847\n",
      "-------------------------------\n",
      "loss: 0.276478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520714 \n",
      "\n",
      "Epoch 3848\n",
      "-------------------------------\n",
      "loss: 0.280881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520509 \n",
      "\n",
      "Epoch 3849\n",
      "-------------------------------\n",
      "loss: 0.274704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520715 \n",
      "\n",
      "Epoch 3850\n",
      "-------------------------------\n",
      "loss: 0.271803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520234 \n",
      "\n",
      "Epoch 3851\n",
      "-------------------------------\n",
      "loss: 0.271403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520009 \n",
      "\n",
      "Epoch 3852\n",
      "-------------------------------\n",
      "loss: 0.279208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519858 \n",
      "\n",
      "Epoch 3853\n",
      "-------------------------------\n",
      "loss: 0.277502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520033 \n",
      "\n",
      "Epoch 3854\n",
      "-------------------------------\n",
      "loss: 0.279486  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.520100 \n",
      "\n",
      "Epoch 3855\n",
      "-------------------------------\n",
      "loss: 0.277671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519981 \n",
      "\n",
      "Epoch 3856\n",
      "-------------------------------\n",
      "loss: 0.263092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519676 \n",
      "\n",
      "Epoch 3857\n",
      "-------------------------------\n",
      "loss: 0.266441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519466 \n",
      "\n",
      "Epoch 3858\n",
      "-------------------------------\n",
      "loss: 0.273082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519952 \n",
      "\n",
      "Epoch 3859\n",
      "-------------------------------\n",
      "loss: 0.274643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520549 \n",
      "\n",
      "Epoch 3860\n",
      "-------------------------------\n",
      "loss: 0.275533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521049 \n",
      "\n",
      "Epoch 3861\n",
      "-------------------------------\n",
      "loss: 0.279297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521896 \n",
      "\n",
      "Epoch 3862\n",
      "-------------------------------\n",
      "loss: 0.268705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522712 \n",
      "\n",
      "Epoch 3863\n",
      "-------------------------------\n",
      "loss: 0.280856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523176 \n",
      "\n",
      "Epoch 3864\n",
      "-------------------------------\n",
      "loss: 0.290041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524438 \n",
      "\n",
      "Epoch 3865\n",
      "-------------------------------\n",
      "loss: 0.283981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525487 \n",
      "\n",
      "Epoch 3866\n",
      "-------------------------------\n",
      "loss: 0.270032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526206 \n",
      "\n",
      "Epoch 3867\n",
      "-------------------------------\n",
      "loss: 0.273204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525885 \n",
      "\n",
      "Epoch 3868\n",
      "-------------------------------\n",
      "loss: 0.280501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525470 \n",
      "\n",
      "Epoch 3869\n",
      "-------------------------------\n",
      "loss: 0.300167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523098 \n",
      "\n",
      "Epoch 3870\n",
      "-------------------------------\n",
      "loss: 0.270698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521061 \n",
      "\n",
      "Epoch 3871\n",
      "-------------------------------\n",
      "loss: 0.268789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519554 \n",
      "\n",
      "Epoch 3872\n",
      "-------------------------------\n",
      "loss: 0.277663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518239 \n",
      "\n",
      "Epoch 3873\n",
      "-------------------------------\n",
      "loss: 0.273132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518166 \n",
      "\n",
      "Epoch 3874\n",
      "-------------------------------\n",
      "loss: 0.299969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519749 \n",
      "\n",
      "Epoch 3875\n",
      "-------------------------------\n",
      "loss: 0.261962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522137 \n",
      "\n",
      "Epoch 3876\n",
      "-------------------------------\n",
      "loss: 0.279579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522891 \n",
      "\n",
      "Epoch 3877\n",
      "-------------------------------\n",
      "loss: 0.261141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522059 \n",
      "\n",
      "Epoch 3878\n",
      "-------------------------------\n",
      "loss: 0.284512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520881 \n",
      "\n",
      "Epoch 3879\n",
      "-------------------------------\n",
      "loss: 0.274225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519696 \n",
      "\n",
      "Epoch 3880\n",
      "-------------------------------\n",
      "loss: 0.285437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518865 \n",
      "\n",
      "Epoch 3881\n",
      "-------------------------------\n",
      "loss: 0.281593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518430 \n",
      "\n",
      "Epoch 3882\n",
      "-------------------------------\n",
      "loss: 0.274790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518325 \n",
      "\n",
      "Epoch 3883\n",
      "-------------------------------\n",
      "loss: 0.288114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518567 \n",
      "\n",
      "Epoch 3884\n",
      "-------------------------------\n",
      "loss: 0.287301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519325 \n",
      "\n",
      "Epoch 3885\n",
      "-------------------------------\n",
      "loss: 0.284712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520299 \n",
      "\n",
      "Epoch 3886\n",
      "-------------------------------\n",
      "loss: 0.293557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521638 \n",
      "\n",
      "Epoch 3887\n",
      "-------------------------------\n",
      "loss: 0.292467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521482 \n",
      "\n",
      "Epoch 3888\n",
      "-------------------------------\n",
      "loss: 0.284558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520303 \n",
      "\n",
      "Epoch 3889\n",
      "-------------------------------\n",
      "loss: 0.288098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519341 \n",
      "\n",
      "Epoch 3890\n",
      "-------------------------------\n",
      "loss: 0.279408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519265 \n",
      "\n",
      "Epoch 3891\n",
      "-------------------------------\n",
      "loss: 0.282381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519802 \n",
      "\n",
      "Epoch 3892\n",
      "-------------------------------\n",
      "loss: 0.303647  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520142 \n",
      "\n",
      "Epoch 3893\n",
      "-------------------------------\n",
      "loss: 0.285594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520254 \n",
      "\n",
      "Epoch 3894\n",
      "-------------------------------\n",
      "loss: 0.284902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520882 \n",
      "\n",
      "Epoch 3895\n",
      "-------------------------------\n",
      "loss: 0.273237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522540 \n",
      "\n",
      "Epoch 3896\n",
      "-------------------------------\n",
      "loss: 0.284400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523932 \n",
      "\n",
      "Epoch 3897\n",
      "-------------------------------\n",
      "loss: 0.297446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523238 \n",
      "\n",
      "Epoch 3898\n",
      "-------------------------------\n",
      "loss: 0.278184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521852 \n",
      "\n",
      "Epoch 3899\n",
      "-------------------------------\n",
      "loss: 0.271318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521040 \n",
      "\n",
      "Epoch 3900\n",
      "-------------------------------\n",
      "loss: 0.274803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521284 \n",
      "\n",
      "Epoch 3901\n",
      "-------------------------------\n",
      "loss: 0.282171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521531 \n",
      "\n",
      "Epoch 3902\n",
      "-------------------------------\n",
      "loss: 0.308086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521404 \n",
      "\n",
      "Epoch 3903\n",
      "-------------------------------\n",
      "loss: 0.281744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520786 \n",
      "\n",
      "Epoch 3904\n",
      "-------------------------------\n",
      "loss: 0.294051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520776 \n",
      "\n",
      "Epoch 3905\n",
      "-------------------------------\n",
      "loss: 0.288353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521214 \n",
      "\n",
      "Epoch 3906\n",
      "-------------------------------\n",
      "loss: 0.277855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522423 \n",
      "\n",
      "Epoch 3907\n",
      "-------------------------------\n",
      "loss: 0.276627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523629 \n",
      "\n",
      "Epoch 3908\n",
      "-------------------------------\n",
      "loss: 0.296691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521966 \n",
      "\n",
      "Epoch 3909\n",
      "-------------------------------\n",
      "loss: 0.289832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519912 \n",
      "\n",
      "Epoch 3910\n",
      "-------------------------------\n",
      "loss: 0.295916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518380 \n",
      "\n",
      "Epoch 3911\n",
      "-------------------------------\n",
      "loss: 0.269451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518114 \n",
      "\n",
      "Epoch 3912\n",
      "-------------------------------\n",
      "loss: 0.303774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518430 \n",
      "\n",
      "Epoch 3913\n",
      "-------------------------------\n",
      "loss: 0.286056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519213 \n",
      "\n",
      "Epoch 3914\n",
      "-------------------------------\n",
      "loss: 0.289762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521180 \n",
      "\n",
      "Epoch 3915\n",
      "-------------------------------\n",
      "loss: 0.293786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523473 \n",
      "\n",
      "Epoch 3916\n",
      "-------------------------------\n",
      "loss: 0.285561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524958 \n",
      "\n",
      "Epoch 3917\n",
      "-------------------------------\n",
      "loss: 0.285033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525099 \n",
      "\n",
      "Epoch 3918\n",
      "-------------------------------\n",
      "loss: 0.277929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525941 \n",
      "\n",
      "Epoch 3919\n",
      "-------------------------------\n",
      "loss: 0.282203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526130 \n",
      "\n",
      "Epoch 3920\n",
      "-------------------------------\n",
      "loss: 0.266142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526201 \n",
      "\n",
      "Epoch 3921\n",
      "-------------------------------\n",
      "loss: 0.283075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526403 \n",
      "\n",
      "Epoch 3922\n",
      "-------------------------------\n",
      "loss: 0.277289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525908 \n",
      "\n",
      "Epoch 3923\n",
      "-------------------------------\n",
      "loss: 0.287256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525874 \n",
      "\n",
      "Epoch 3924\n",
      "-------------------------------\n",
      "loss: 0.272970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525787 \n",
      "\n",
      "Epoch 3925\n",
      "-------------------------------\n",
      "loss: 0.277012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525215 \n",
      "\n",
      "Epoch 3926\n",
      "-------------------------------\n",
      "loss: 0.296584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524676 \n",
      "\n",
      "Epoch 3927\n",
      "-------------------------------\n",
      "loss: 0.287583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524084 \n",
      "\n",
      "Epoch 3928\n",
      "-------------------------------\n",
      "loss: 0.280478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523797 \n",
      "\n",
      "Epoch 3929\n",
      "-------------------------------\n",
      "loss: 0.271785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522848 \n",
      "\n",
      "Epoch 3930\n",
      "-------------------------------\n",
      "loss: 0.262340  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521693 \n",
      "\n",
      "Epoch 3931\n",
      "-------------------------------\n",
      "loss: 0.292939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521068 \n",
      "\n",
      "Epoch 3932\n",
      "-------------------------------\n",
      "loss: 0.283129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520398 \n",
      "\n",
      "Epoch 3933\n",
      "-------------------------------\n",
      "loss: 0.272943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519892 \n",
      "\n",
      "Epoch 3934\n",
      "-------------------------------\n",
      "loss: 0.280400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519588 \n",
      "\n",
      "Epoch 3935\n",
      "-------------------------------\n",
      "loss: 0.287904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519327 \n",
      "\n",
      "Epoch 3936\n",
      "-------------------------------\n",
      "loss: 0.282595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518765 \n",
      "\n",
      "Epoch 3937\n",
      "-------------------------------\n",
      "loss: 0.290065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518130 \n",
      "\n",
      "Epoch 3938\n",
      "-------------------------------\n",
      "loss: 0.284379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517533 \n",
      "\n",
      "Epoch 3939\n",
      "-------------------------------\n",
      "loss: 0.282960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516719 \n",
      "\n",
      "Epoch 3940\n",
      "-------------------------------\n",
      "loss: 0.273653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516553 \n",
      "\n",
      "Epoch 3941\n",
      "-------------------------------\n",
      "loss: 0.293401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516499 \n",
      "\n",
      "Epoch 3942\n",
      "-------------------------------\n",
      "loss: 0.279276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517236 \n",
      "\n",
      "Epoch 3943\n",
      "-------------------------------\n",
      "loss: 0.277702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518001 \n",
      "\n",
      "Epoch 3944\n",
      "-------------------------------\n",
      "loss: 0.274686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518887 \n",
      "\n",
      "Epoch 3945\n",
      "-------------------------------\n",
      "loss: 0.286250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519382 \n",
      "\n",
      "Epoch 3946\n",
      "-------------------------------\n",
      "loss: 0.268462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519987 \n",
      "\n",
      "Epoch 3947\n",
      "-------------------------------\n",
      "loss: 0.284064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519943 \n",
      "\n",
      "Epoch 3948\n",
      "-------------------------------\n",
      "loss: 0.268659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520028 \n",
      "\n",
      "Epoch 3949\n",
      "-------------------------------\n",
      "loss: 0.284940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520002 \n",
      "\n",
      "Epoch 3950\n",
      "-------------------------------\n",
      "loss: 0.270082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519803 \n",
      "\n",
      "Epoch 3951\n",
      "-------------------------------\n",
      "loss: 0.287707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520030 \n",
      "\n",
      "Epoch 3952\n",
      "-------------------------------\n",
      "loss: 0.283653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520445 \n",
      "\n",
      "Epoch 3953\n",
      "-------------------------------\n",
      "loss: 0.281881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520320 \n",
      "\n",
      "Epoch 3954\n",
      "-------------------------------\n",
      "loss: 0.267759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520259 \n",
      "\n",
      "Epoch 3955\n",
      "-------------------------------\n",
      "loss: 0.277157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519773 \n",
      "\n",
      "Epoch 3956\n",
      "-------------------------------\n",
      "loss: 0.266618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520463 \n",
      "\n",
      "Epoch 3957\n",
      "-------------------------------\n",
      "loss: 0.291442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520870 \n",
      "\n",
      "Epoch 3958\n",
      "-------------------------------\n",
      "loss: 0.282449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521087 \n",
      "\n",
      "Epoch 3959\n",
      "-------------------------------\n",
      "loss: 0.291683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521470 \n",
      "\n",
      "Epoch 3960\n",
      "-------------------------------\n",
      "loss: 0.287026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522737 \n",
      "\n",
      "Epoch 3961\n",
      "-------------------------------\n",
      "loss: 0.271395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524872 \n",
      "\n",
      "Epoch 3962\n",
      "-------------------------------\n",
      "loss: 0.280938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525498 \n",
      "\n",
      "Epoch 3963\n",
      "-------------------------------\n",
      "loss: 0.280701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523276 \n",
      "\n",
      "Epoch 3964\n",
      "-------------------------------\n",
      "loss: 0.288827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520968 \n",
      "\n",
      "Epoch 3965\n",
      "-------------------------------\n",
      "loss: 0.269646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519902 \n",
      "\n",
      "Epoch 3966\n",
      "-------------------------------\n",
      "loss: 0.293458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519915 \n",
      "\n",
      "Epoch 3967\n",
      "-------------------------------\n",
      "loss: 0.299577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519629 \n",
      "\n",
      "Epoch 3968\n",
      "-------------------------------\n",
      "loss: 0.305547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519527 \n",
      "\n",
      "Epoch 3969\n",
      "-------------------------------\n",
      "loss: 0.287900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519558 \n",
      "\n",
      "Epoch 3970\n",
      "-------------------------------\n",
      "loss: 0.270780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520308 \n",
      "\n",
      "Epoch 3971\n",
      "-------------------------------\n",
      "loss: 0.290945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520570 \n",
      "\n",
      "Epoch 3972\n",
      "-------------------------------\n",
      "loss: 0.283379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520272 \n",
      "\n",
      "Epoch 3973\n",
      "-------------------------------\n",
      "loss: 0.293680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519569 \n",
      "\n",
      "Epoch 3974\n",
      "-------------------------------\n",
      "loss: 0.259526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518540 \n",
      "\n",
      "Epoch 3975\n",
      "-------------------------------\n",
      "loss: 0.289965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517610 \n",
      "\n",
      "Epoch 3976\n",
      "-------------------------------\n",
      "loss: 0.289670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517510 \n",
      "\n",
      "Epoch 3977\n",
      "-------------------------------\n",
      "loss: 0.297551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517078 \n",
      "\n",
      "Epoch 3978\n",
      "-------------------------------\n",
      "loss: 0.276147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516608 \n",
      "\n",
      "Epoch 3979\n",
      "-------------------------------\n",
      "loss: 0.270310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516705 \n",
      "\n",
      "Epoch 3980\n",
      "-------------------------------\n",
      "loss: 0.269581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516844 \n",
      "\n",
      "Epoch 3981\n",
      "-------------------------------\n",
      "loss: 0.274486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517627 \n",
      "\n",
      "Epoch 3982\n",
      "-------------------------------\n",
      "loss: 0.289111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518593 \n",
      "\n",
      "Epoch 3983\n",
      "-------------------------------\n",
      "loss: 0.273551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519679 \n",
      "\n",
      "Epoch 3984\n",
      "-------------------------------\n",
      "loss: 0.281110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520507 \n",
      "\n",
      "Epoch 3985\n",
      "-------------------------------\n",
      "loss: 0.269510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521565 \n",
      "\n",
      "Epoch 3986\n",
      "-------------------------------\n",
      "loss: 0.280263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522407 \n",
      "\n",
      "Epoch 3987\n",
      "-------------------------------\n",
      "loss: 0.270118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523464 \n",
      "\n",
      "Epoch 3988\n",
      "-------------------------------\n",
      "loss: 0.284409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524790 \n",
      "\n",
      "Epoch 3989\n",
      "-------------------------------\n",
      "loss: 0.279628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525765 \n",
      "\n",
      "Epoch 3990\n",
      "-------------------------------\n",
      "loss: 0.271502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525741 \n",
      "\n",
      "Epoch 3991\n",
      "-------------------------------\n",
      "loss: 0.298250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525279 \n",
      "\n",
      "Epoch 3992\n",
      "-------------------------------\n",
      "loss: 0.290559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523851 \n",
      "\n",
      "Epoch 3993\n",
      "-------------------------------\n",
      "loss: 0.262336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523113 \n",
      "\n",
      "Epoch 3994\n",
      "-------------------------------\n",
      "loss: 0.289408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521666 \n",
      "\n",
      "Epoch 3995\n",
      "-------------------------------\n",
      "loss: 0.277006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520028 \n",
      "\n",
      "Epoch 3996\n",
      "-------------------------------\n",
      "loss: 0.271708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518861 \n",
      "\n",
      "Epoch 3997\n",
      "-------------------------------\n",
      "loss: 0.277371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518360 \n",
      "\n",
      "Epoch 3998\n",
      "-------------------------------\n",
      "loss: 0.275425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517903 \n",
      "\n",
      "Epoch 3999\n",
      "-------------------------------\n",
      "loss: 0.266420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517764 \n",
      "\n",
      "Epoch 4000\n",
      "-------------------------------\n",
      "loss: 0.264586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517751 \n",
      "\n",
      "Epoch 4001\n",
      "-------------------------------\n",
      "loss: 0.271800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518319 \n",
      "\n",
      "Epoch 4002\n",
      "-------------------------------\n",
      "loss: 0.290466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518423 \n",
      "\n",
      "Epoch 4003\n",
      "-------------------------------\n",
      "loss: 0.282430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518296 \n",
      "\n",
      "Epoch 4004\n",
      "-------------------------------\n",
      "loss: 0.277721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518081 \n",
      "\n",
      "Epoch 4005\n",
      "-------------------------------\n",
      "loss: 0.287028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517119 \n",
      "\n",
      "Epoch 4006\n",
      "-------------------------------\n",
      "loss: 0.278718  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.516708 \n",
      "\n",
      "Epoch 4007\n",
      "-------------------------------\n",
      "loss: 0.272630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516046 \n",
      "\n",
      "Epoch 4008\n",
      "-------------------------------\n",
      "loss: 0.287802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515591 \n",
      "\n",
      "Epoch 4009\n",
      "-------------------------------\n",
      "loss: 0.274133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515722 \n",
      "\n",
      "Epoch 4010\n",
      "-------------------------------\n",
      "loss: 0.288594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515971 \n",
      "\n",
      "Epoch 4011\n",
      "-------------------------------\n",
      "loss: 0.266615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516248 \n",
      "\n",
      "Epoch 4012\n",
      "-------------------------------\n",
      "loss: 0.276209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516982 \n",
      "\n",
      "Epoch 4013\n",
      "-------------------------------\n",
      "loss: 0.276353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517299 \n",
      "\n",
      "Epoch 4014\n",
      "-------------------------------\n",
      "loss: 0.271789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517600 \n",
      "\n",
      "Epoch 4015\n",
      "-------------------------------\n",
      "loss: 0.285028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518237 \n",
      "\n",
      "Epoch 4016\n",
      "-------------------------------\n",
      "loss: 0.266530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518740 \n",
      "\n",
      "Epoch 4017\n",
      "-------------------------------\n",
      "loss: 0.274317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519683 \n",
      "\n",
      "Epoch 4018\n",
      "-------------------------------\n",
      "loss: 0.266680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520531 \n",
      "\n",
      "Epoch 4019\n",
      "-------------------------------\n",
      "loss: 0.284185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521277 \n",
      "\n",
      "Epoch 4020\n",
      "-------------------------------\n",
      "loss: 0.284222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521339 \n",
      "\n",
      "Epoch 4021\n",
      "-------------------------------\n",
      "loss: 0.278190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521018 \n",
      "\n",
      "Epoch 4022\n",
      "-------------------------------\n",
      "loss: 0.291775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520607 \n",
      "\n",
      "Epoch 4023\n",
      "-------------------------------\n",
      "loss: 0.295166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520172 \n",
      "\n",
      "Epoch 4024\n",
      "-------------------------------\n",
      "loss: 0.273518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520194 \n",
      "\n",
      "Epoch 4025\n",
      "-------------------------------\n",
      "loss: 0.272618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520420 \n",
      "\n",
      "Epoch 4026\n",
      "-------------------------------\n",
      "loss: 0.276571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520765 \n",
      "\n",
      "Epoch 4027\n",
      "-------------------------------\n",
      "loss: 0.273411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520921 \n",
      "\n",
      "Epoch 4028\n",
      "-------------------------------\n",
      "loss: 0.275657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521131 \n",
      "\n",
      "Epoch 4029\n",
      "-------------------------------\n",
      "loss: 0.292962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521748 \n",
      "\n",
      "Epoch 4030\n",
      "-------------------------------\n",
      "loss: 0.286159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521626 \n",
      "\n",
      "Epoch 4031\n",
      "-------------------------------\n",
      "loss: 0.275844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521781 \n",
      "\n",
      "Epoch 4032\n",
      "-------------------------------\n",
      "loss: 0.288387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521012 \n",
      "\n",
      "Epoch 4033\n",
      "-------------------------------\n",
      "loss: 0.282593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520873 \n",
      "\n",
      "Epoch 4034\n",
      "-------------------------------\n",
      "loss: 0.294680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520073 \n",
      "\n",
      "Epoch 4035\n",
      "-------------------------------\n",
      "loss: 0.280984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520035 \n",
      "\n",
      "Epoch 4036\n",
      "-------------------------------\n",
      "loss: 0.273870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520820 \n",
      "\n",
      "Epoch 4037\n",
      "-------------------------------\n",
      "loss: 0.277016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521227 \n",
      "\n",
      "Epoch 4038\n",
      "-------------------------------\n",
      "loss: 0.284803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521735 \n",
      "\n",
      "Epoch 4039\n",
      "-------------------------------\n",
      "loss: 0.279550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521851 \n",
      "\n",
      "Epoch 4040\n",
      "-------------------------------\n",
      "loss: 0.284854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520853 \n",
      "\n",
      "Epoch 4041\n",
      "-------------------------------\n",
      "loss: 0.271619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520489 \n",
      "\n",
      "Epoch 4042\n",
      "-------------------------------\n",
      "loss: 0.264977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520117 \n",
      "\n",
      "Epoch 4043\n",
      "-------------------------------\n",
      "loss: 0.269358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519213 \n",
      "\n",
      "Epoch 4044\n",
      "-------------------------------\n",
      "loss: 0.269159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518967 \n",
      "\n",
      "Epoch 4045\n",
      "-------------------------------\n",
      "loss: 0.294643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518595 \n",
      "\n",
      "Epoch 4046\n",
      "-------------------------------\n",
      "loss: 0.259257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518610 \n",
      "\n",
      "Epoch 4047\n",
      "-------------------------------\n",
      "loss: 0.272684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519174 \n",
      "\n",
      "Epoch 4048\n",
      "-------------------------------\n",
      "loss: 0.280299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520547 \n",
      "\n",
      "Epoch 4049\n",
      "-------------------------------\n",
      "loss: 0.281800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522221 \n",
      "\n",
      "Epoch 4050\n",
      "-------------------------------\n",
      "loss: 0.274043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523575 \n",
      "\n",
      "Epoch 4051\n",
      "-------------------------------\n",
      "loss: 0.268943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524031 \n",
      "\n",
      "Epoch 4052\n",
      "-------------------------------\n",
      "loss: 0.274655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524407 \n",
      "\n",
      "Epoch 4053\n",
      "-------------------------------\n",
      "loss: 0.279893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524410 \n",
      "\n",
      "Epoch 4054\n",
      "-------------------------------\n",
      "loss: 0.280001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524623 \n",
      "\n",
      "Epoch 4055\n",
      "-------------------------------\n",
      "loss: 0.282218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524929 \n",
      "\n",
      "Epoch 4056\n",
      "-------------------------------\n",
      "loss: 0.274477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526201 \n",
      "\n",
      "Epoch 4057\n",
      "-------------------------------\n",
      "loss: 0.266986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526633 \n",
      "\n",
      "Epoch 4058\n",
      "-------------------------------\n",
      "loss: 0.268960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526538 \n",
      "\n",
      "Epoch 4059\n",
      "-------------------------------\n",
      "loss: 0.292851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524894 \n",
      "\n",
      "Epoch 4060\n",
      "-------------------------------\n",
      "loss: 0.267719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523410 \n",
      "\n",
      "Epoch 4061\n",
      "-------------------------------\n",
      "loss: 0.278824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522173 \n",
      "\n",
      "Epoch 4062\n",
      "-------------------------------\n",
      "loss: 0.290363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521281 \n",
      "\n",
      "Epoch 4063\n",
      "-------------------------------\n",
      "loss: 0.295871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520569 \n",
      "\n",
      "Epoch 4064\n",
      "-------------------------------\n",
      "loss: 0.285209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520389 \n",
      "\n",
      "Epoch 4065\n",
      "-------------------------------\n",
      "loss: 0.272151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519323 \n",
      "\n",
      "Epoch 4066\n",
      "-------------------------------\n",
      "loss: 0.281900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518022 \n",
      "\n",
      "Epoch 4067\n",
      "-------------------------------\n",
      "loss: 0.288114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516806 \n",
      "\n",
      "Epoch 4068\n",
      "-------------------------------\n",
      "loss: 0.275682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515852 \n",
      "\n",
      "Epoch 4069\n",
      "-------------------------------\n",
      "loss: 0.272384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515092 \n",
      "\n",
      "Epoch 4070\n",
      "-------------------------------\n",
      "loss: 0.291375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514736 \n",
      "\n",
      "Epoch 4071\n",
      "-------------------------------\n",
      "loss: 0.284501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513954 \n",
      "\n",
      "Epoch 4072\n",
      "-------------------------------\n",
      "loss: 0.271593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513717 \n",
      "\n",
      "Epoch 4073\n",
      "-------------------------------\n",
      "loss: 0.279253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513378 \n",
      "\n",
      "Epoch 4074\n",
      "-------------------------------\n",
      "loss: 0.288459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513766 \n",
      "\n",
      "Epoch 4075\n",
      "-------------------------------\n",
      "loss: 0.283105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514292 \n",
      "\n",
      "Epoch 4076\n",
      "-------------------------------\n",
      "loss: 0.275816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514342 \n",
      "\n",
      "Epoch 4077\n",
      "-------------------------------\n",
      "loss: 0.292263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515202 \n",
      "\n",
      "Epoch 4078\n",
      "-------------------------------\n",
      "loss: 0.276987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516153 \n",
      "\n",
      "Epoch 4079\n",
      "-------------------------------\n",
      "loss: 0.292946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517443 \n",
      "\n",
      "Epoch 4080\n",
      "-------------------------------\n",
      "loss: 0.283235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519188 \n",
      "\n",
      "Epoch 4081\n",
      "-------------------------------\n",
      "loss: 0.278241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520511 \n",
      "\n",
      "Epoch 4082\n",
      "-------------------------------\n",
      "loss: 0.275791  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521480 \n",
      "\n",
      "Epoch 4083\n",
      "-------------------------------\n",
      "loss: 0.276395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522245 \n",
      "\n",
      "Epoch 4084\n",
      "-------------------------------\n",
      "loss: 0.293289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522683 \n",
      "\n",
      "Epoch 4085\n",
      "-------------------------------\n",
      "loss: 0.284431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522996 \n",
      "\n",
      "Epoch 4086\n",
      "-------------------------------\n",
      "loss: 0.280992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522662 \n",
      "\n",
      "Epoch 4087\n",
      "-------------------------------\n",
      "loss: 0.274511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522975 \n",
      "\n",
      "Epoch 4088\n",
      "-------------------------------\n",
      "loss: 0.274807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523368 \n",
      "\n",
      "Epoch 4089\n",
      "-------------------------------\n",
      "loss: 0.296762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524140 \n",
      "\n",
      "Epoch 4090\n",
      "-------------------------------\n",
      "loss: 0.287530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524837 \n",
      "\n",
      "Epoch 4091\n",
      "-------------------------------\n",
      "loss: 0.285111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525926 \n",
      "\n",
      "Epoch 4092\n",
      "-------------------------------\n",
      "loss: 0.275567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526460 \n",
      "\n",
      "Epoch 4093\n",
      "-------------------------------\n",
      "loss: 0.278488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525927 \n",
      "\n",
      "Epoch 4094\n",
      "-------------------------------\n",
      "loss: 0.278479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525299 \n",
      "\n",
      "Epoch 4095\n",
      "-------------------------------\n",
      "loss: 0.272008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524897 \n",
      "\n",
      "Epoch 4096\n",
      "-------------------------------\n",
      "loss: 0.287739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523451 \n",
      "\n",
      "Epoch 4097\n",
      "-------------------------------\n",
      "loss: 0.298597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522425 \n",
      "\n",
      "Epoch 4098\n",
      "-------------------------------\n",
      "loss: 0.289257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521775 \n",
      "\n",
      "Epoch 4099\n",
      "-------------------------------\n",
      "loss: 0.267693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521686 \n",
      "\n",
      "Epoch 4100\n",
      "-------------------------------\n",
      "loss: 0.277085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521156 \n",
      "\n",
      "Epoch 4101\n",
      "-------------------------------\n",
      "loss: 0.276549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520296 \n",
      "\n",
      "Epoch 4102\n",
      "-------------------------------\n",
      "loss: 0.289212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519109 \n",
      "\n",
      "Epoch 4103\n",
      "-------------------------------\n",
      "loss: 0.283573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517416 \n",
      "\n",
      "Epoch 4104\n",
      "-------------------------------\n",
      "loss: 0.278700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516365 \n",
      "\n",
      "Epoch 4105\n",
      "-------------------------------\n",
      "loss: 0.276758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516131 \n",
      "\n",
      "Epoch 4106\n",
      "-------------------------------\n",
      "loss: 0.269929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516098 \n",
      "\n",
      "Epoch 4107\n",
      "-------------------------------\n",
      "loss: 0.281134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516499 \n",
      "\n",
      "Epoch 4108\n",
      "-------------------------------\n",
      "loss: 0.275809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517652 \n",
      "\n",
      "Epoch 4109\n",
      "-------------------------------\n",
      "loss: 0.281154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519375 \n",
      "\n",
      "Epoch 4110\n",
      "-------------------------------\n",
      "loss: 0.275216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521334 \n",
      "\n",
      "Epoch 4111\n",
      "-------------------------------\n",
      "loss: 0.284898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522739 \n",
      "\n",
      "Epoch 4112\n",
      "-------------------------------\n",
      "loss: 0.276101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523401 \n",
      "\n",
      "Epoch 4113\n",
      "-------------------------------\n",
      "loss: 0.269899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522643 \n",
      "\n",
      "Epoch 4114\n",
      "-------------------------------\n",
      "loss: 0.281364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521558 \n",
      "\n",
      "Epoch 4115\n",
      "-------------------------------\n",
      "loss: 0.274699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520625 \n",
      "\n",
      "Epoch 4116\n",
      "-------------------------------\n",
      "loss: 0.262547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520358 \n",
      "\n",
      "Epoch 4117\n",
      "-------------------------------\n",
      "loss: 0.285004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520183 \n",
      "\n",
      "Epoch 4118\n",
      "-------------------------------\n",
      "loss: 0.290239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520343 \n",
      "\n",
      "Epoch 4119\n",
      "-------------------------------\n",
      "loss: 0.295638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520550 \n",
      "\n",
      "Epoch 4120\n",
      "-------------------------------\n",
      "loss: 0.260332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520351 \n",
      "\n",
      "Epoch 4121\n",
      "-------------------------------\n",
      "loss: 0.278201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519352 \n",
      "\n",
      "Epoch 4122\n",
      "-------------------------------\n",
      "loss: 0.280722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517771 \n",
      "\n",
      "Epoch 4123\n",
      "-------------------------------\n",
      "loss: 0.282029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516994 \n",
      "\n",
      "Epoch 4124\n",
      "-------------------------------\n",
      "loss: 0.280432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516811 \n",
      "\n",
      "Epoch 4125\n",
      "-------------------------------\n",
      "loss: 0.287939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517256 \n",
      "\n",
      "Epoch 4126\n",
      "-------------------------------\n",
      "loss: 0.273603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516845 \n",
      "\n",
      "Epoch 4127\n",
      "-------------------------------\n",
      "loss: 0.277516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516795 \n",
      "\n",
      "Epoch 4128\n",
      "-------------------------------\n",
      "loss: 0.269240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516653 \n",
      "\n",
      "Epoch 4129\n",
      "-------------------------------\n",
      "loss: 0.271659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517026 \n",
      "\n",
      "Epoch 4130\n",
      "-------------------------------\n",
      "loss: 0.278621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517094 \n",
      "\n",
      "Epoch 4131\n",
      "-------------------------------\n",
      "loss: 0.278153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515893 \n",
      "\n",
      "Epoch 4132\n",
      "-------------------------------\n",
      "loss: 0.284625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515294 \n",
      "\n",
      "Epoch 4133\n",
      "-------------------------------\n",
      "loss: 0.284658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515484 \n",
      "\n",
      "Epoch 4134\n",
      "-------------------------------\n",
      "loss: 0.267561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516091 \n",
      "\n",
      "Epoch 4135\n",
      "-------------------------------\n",
      "loss: 0.278837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517061 \n",
      "\n",
      "Epoch 4136\n",
      "-------------------------------\n",
      "loss: 0.295003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517736 \n",
      "\n",
      "Epoch 4137\n",
      "-------------------------------\n",
      "loss: 0.280298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516615 \n",
      "\n",
      "Epoch 4138\n",
      "-------------------------------\n",
      "loss: 0.272347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515130 \n",
      "\n",
      "Epoch 4139\n",
      "-------------------------------\n",
      "loss: 0.292242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514573 \n",
      "\n",
      "Epoch 4140\n",
      "-------------------------------\n",
      "loss: 0.267026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514986 \n",
      "\n",
      "Epoch 4141\n",
      "-------------------------------\n",
      "loss: 0.288249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515244 \n",
      "\n",
      "Epoch 4142\n",
      "-------------------------------\n",
      "loss: 0.279212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515692 \n",
      "\n",
      "Epoch 4143\n",
      "-------------------------------\n",
      "loss: 0.282419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516517 \n",
      "\n",
      "Epoch 4144\n",
      "-------------------------------\n",
      "loss: 0.270408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517155 \n",
      "\n",
      "Epoch 4145\n",
      "-------------------------------\n",
      "loss: 0.276251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518090 \n",
      "\n",
      "Epoch 4146\n",
      "-------------------------------\n",
      "loss: 0.271201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519054 \n",
      "\n",
      "Epoch 4147\n",
      "-------------------------------\n",
      "loss: 0.273936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518966 \n",
      "\n",
      "Epoch 4148\n",
      "-------------------------------\n",
      "loss: 0.280620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518423 \n",
      "\n",
      "Epoch 4149\n",
      "-------------------------------\n",
      "loss: 0.266279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518635 \n",
      "\n",
      "Epoch 4150\n",
      "-------------------------------\n",
      "loss: 0.272351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518988 \n",
      "\n",
      "Epoch 4151\n",
      "-------------------------------\n",
      "loss: 0.283648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519903 \n",
      "\n",
      "Epoch 4152\n",
      "-------------------------------\n",
      "loss: 0.288826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520889 \n",
      "\n",
      "Epoch 4153\n",
      "-------------------------------\n",
      "loss: 0.276902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521557 \n",
      "\n",
      "Epoch 4154\n",
      "-------------------------------\n",
      "loss: 0.280260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521549 \n",
      "\n",
      "Epoch 4155\n",
      "-------------------------------\n",
      "loss: 0.267207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521076 \n",
      "\n",
      "Epoch 4156\n",
      "-------------------------------\n",
      "loss: 0.270558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520692 \n",
      "\n",
      "Epoch 4157\n",
      "-------------------------------\n",
      "loss: 0.279836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520154 \n",
      "\n",
      "Epoch 4158\n",
      "-------------------------------\n",
      "loss: 0.283000  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.520031 \n",
      "\n",
      "Epoch 4159\n",
      "-------------------------------\n",
      "loss: 0.298126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519805 \n",
      "\n",
      "Epoch 4160\n",
      "-------------------------------\n",
      "loss: 0.262448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519504 \n",
      "\n",
      "Epoch 4161\n",
      "-------------------------------\n",
      "loss: 0.264079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518775 \n",
      "\n",
      "Epoch 4162\n",
      "-------------------------------\n",
      "loss: 0.287468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517629 \n",
      "\n",
      "Epoch 4163\n",
      "-------------------------------\n",
      "loss: 0.272147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517103 \n",
      "\n",
      "Epoch 4164\n",
      "-------------------------------\n",
      "loss: 0.298381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516696 \n",
      "\n",
      "Epoch 4165\n",
      "-------------------------------\n",
      "loss: 0.260477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516971 \n",
      "\n",
      "Epoch 4166\n",
      "-------------------------------\n",
      "loss: 0.279243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517386 \n",
      "\n",
      "Epoch 4167\n",
      "-------------------------------\n",
      "loss: 0.276901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518371 \n",
      "\n",
      "Epoch 4168\n",
      "-------------------------------\n",
      "loss: 0.275568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519537 \n",
      "\n",
      "Epoch 4169\n",
      "-------------------------------\n",
      "loss: 0.291916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519756 \n",
      "\n",
      "Epoch 4170\n",
      "-------------------------------\n",
      "loss: 0.268176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519303 \n",
      "\n",
      "Epoch 4171\n",
      "-------------------------------\n",
      "loss: 0.259432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518894 \n",
      "\n",
      "Epoch 4172\n",
      "-------------------------------\n",
      "loss: 0.274967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518360 \n",
      "\n",
      "Epoch 4173\n",
      "-------------------------------\n",
      "loss: 0.263234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518076 \n",
      "\n",
      "Epoch 4174\n",
      "-------------------------------\n",
      "loss: 0.275673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517671 \n",
      "\n",
      "Epoch 4175\n",
      "-------------------------------\n",
      "loss: 0.272258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517767 \n",
      "\n",
      "Epoch 4176\n",
      "-------------------------------\n",
      "loss: 0.284365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518495 \n",
      "\n",
      "Epoch 4177\n",
      "-------------------------------\n",
      "loss: 0.266676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519738 \n",
      "\n",
      "Epoch 4178\n",
      "-------------------------------\n",
      "loss: 0.296382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520363 \n",
      "\n",
      "Epoch 4179\n",
      "-------------------------------\n",
      "loss: 0.284858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519424 \n",
      "\n",
      "Epoch 4180\n",
      "-------------------------------\n",
      "loss: 0.277986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518097 \n",
      "\n",
      "Epoch 4181\n",
      "-------------------------------\n",
      "loss: 0.265574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516898 \n",
      "\n",
      "Epoch 4182\n",
      "-------------------------------\n",
      "loss: 0.288514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516281 \n",
      "\n",
      "Epoch 4183\n",
      "-------------------------------\n",
      "loss: 0.278862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515723 \n",
      "\n",
      "Epoch 4184\n",
      "-------------------------------\n",
      "loss: 0.291511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515531 \n",
      "\n",
      "Epoch 4185\n",
      "-------------------------------\n",
      "loss: 0.278393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514959 \n",
      "\n",
      "Epoch 4186\n",
      "-------------------------------\n",
      "loss: 0.276961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514412 \n",
      "\n",
      "Epoch 4187\n",
      "-------------------------------\n",
      "loss: 0.294061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513932 \n",
      "\n",
      "Epoch 4188\n",
      "-------------------------------\n",
      "loss: 0.273153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514214 \n",
      "\n",
      "Epoch 4189\n",
      "-------------------------------\n",
      "loss: 0.291317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514421 \n",
      "\n",
      "Epoch 4190\n",
      "-------------------------------\n",
      "loss: 0.272265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514176 \n",
      "\n",
      "Epoch 4191\n",
      "-------------------------------\n",
      "loss: 0.284160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513786 \n",
      "\n",
      "Epoch 4192\n",
      "-------------------------------\n",
      "loss: 0.295882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513373 \n",
      "\n",
      "Epoch 4193\n",
      "-------------------------------\n",
      "loss: 0.285047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513534 \n",
      "\n",
      "Epoch 4194\n",
      "-------------------------------\n",
      "loss: 0.281078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513730 \n",
      "\n",
      "Epoch 4195\n",
      "-------------------------------\n",
      "loss: 0.244844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513689 \n",
      "\n",
      "Epoch 4196\n",
      "-------------------------------\n",
      "loss: 0.279660  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513758 \n",
      "\n",
      "Epoch 4197\n",
      "-------------------------------\n",
      "loss: 0.283282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513936 \n",
      "\n",
      "Epoch 4198\n",
      "-------------------------------\n",
      "loss: 0.282493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513791 \n",
      "\n",
      "Epoch 4199\n",
      "-------------------------------\n",
      "loss: 0.286873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512931 \n",
      "\n",
      "Epoch 4200\n",
      "-------------------------------\n",
      "loss: 0.278716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512559 \n",
      "\n",
      "Epoch 4201\n",
      "-------------------------------\n",
      "loss: 0.276568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512639 \n",
      "\n",
      "Epoch 4202\n",
      "-------------------------------\n",
      "loss: 0.267289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512766 \n",
      "\n",
      "Epoch 4203\n",
      "-------------------------------\n",
      "loss: 0.269104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512557 \n",
      "\n",
      "Epoch 4204\n",
      "-------------------------------\n",
      "loss: 0.277678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512540 \n",
      "\n",
      "Epoch 4205\n",
      "-------------------------------\n",
      "loss: 0.266060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512135 \n",
      "\n",
      "Epoch 4206\n",
      "-------------------------------\n",
      "loss: 0.284412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511738 \n",
      "\n",
      "Epoch 4207\n",
      "-------------------------------\n",
      "loss: 0.300968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511988 \n",
      "\n",
      "Epoch 4208\n",
      "-------------------------------\n",
      "loss: 0.274629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512220 \n",
      "\n",
      "Epoch 4209\n",
      "-------------------------------\n",
      "loss: 0.264162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512579 \n",
      "\n",
      "Epoch 4210\n",
      "-------------------------------\n",
      "loss: 0.268711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513246 \n",
      "\n",
      "Epoch 4211\n",
      "-------------------------------\n",
      "loss: 0.262403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513623 \n",
      "\n",
      "Epoch 4212\n",
      "-------------------------------\n",
      "loss: 0.288479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514002 \n",
      "\n",
      "Epoch 4213\n",
      "-------------------------------\n",
      "loss: 0.265776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514410 \n",
      "\n",
      "Epoch 4214\n",
      "-------------------------------\n",
      "loss: 0.278709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514584 \n",
      "\n",
      "Epoch 4215\n",
      "-------------------------------\n",
      "loss: 0.276639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514713 \n",
      "\n",
      "Epoch 4216\n",
      "-------------------------------\n",
      "loss: 0.270173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514227 \n",
      "\n",
      "Epoch 4217\n",
      "-------------------------------\n",
      "loss: 0.273313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514141 \n",
      "\n",
      "Epoch 4218\n",
      "-------------------------------\n",
      "loss: 0.281187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514229 \n",
      "\n",
      "Epoch 4219\n",
      "-------------------------------\n",
      "loss: 0.284097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514702 \n",
      "\n",
      "Epoch 4220\n",
      "-------------------------------\n",
      "loss: 0.272030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515552 \n",
      "\n",
      "Epoch 4221\n",
      "-------------------------------\n",
      "loss: 0.273193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515725 \n",
      "\n",
      "Epoch 4222\n",
      "-------------------------------\n",
      "loss: 0.274763  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515701 \n",
      "\n",
      "Epoch 4223\n",
      "-------------------------------\n",
      "loss: 0.287470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515142 \n",
      "\n",
      "Epoch 4224\n",
      "-------------------------------\n",
      "loss: 0.265926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514860 \n",
      "\n",
      "Epoch 4225\n",
      "-------------------------------\n",
      "loss: 0.282946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515220 \n",
      "\n",
      "Epoch 4226\n",
      "-------------------------------\n",
      "loss: 0.283010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516705 \n",
      "\n",
      "Epoch 4227\n",
      "-------------------------------\n",
      "loss: 0.286640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518119 \n",
      "\n",
      "Epoch 4228\n",
      "-------------------------------\n",
      "loss: 0.274608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518860 \n",
      "\n",
      "Epoch 4229\n",
      "-------------------------------\n",
      "loss: 0.255471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518858 \n",
      "\n",
      "Epoch 4230\n",
      "-------------------------------\n",
      "loss: 0.276984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518758 \n",
      "\n",
      "Epoch 4231\n",
      "-------------------------------\n",
      "loss: 0.284856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517732 \n",
      "\n",
      "Epoch 4232\n",
      "-------------------------------\n",
      "loss: 0.264484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516797 \n",
      "\n",
      "Epoch 4233\n",
      "-------------------------------\n",
      "loss: 0.266645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515920 \n",
      "\n",
      "Epoch 4234\n",
      "-------------------------------\n",
      "loss: 0.267313  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.515429 \n",
      "\n",
      "Epoch 4235\n",
      "-------------------------------\n",
      "loss: 0.276015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515131 \n",
      "\n",
      "Epoch 4236\n",
      "-------------------------------\n",
      "loss: 0.269137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515477 \n",
      "\n",
      "Epoch 4237\n",
      "-------------------------------\n",
      "loss: 0.297054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515855 \n",
      "\n",
      "Epoch 4238\n",
      "-------------------------------\n",
      "loss: 0.277935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516869 \n",
      "\n",
      "Epoch 4239\n",
      "-------------------------------\n",
      "loss: 0.278928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518331 \n",
      "\n",
      "Epoch 4240\n",
      "-------------------------------\n",
      "loss: 0.265808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520019 \n",
      "\n",
      "Epoch 4241\n",
      "-------------------------------\n",
      "loss: 0.274567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520602 \n",
      "\n",
      "Epoch 4242\n",
      "-------------------------------\n",
      "loss: 0.277294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520884 \n",
      "\n",
      "Epoch 4243\n",
      "-------------------------------\n",
      "loss: 0.282359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520313 \n",
      "\n",
      "Epoch 4244\n",
      "-------------------------------\n",
      "loss: 0.273542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518664 \n",
      "\n",
      "Epoch 4245\n",
      "-------------------------------\n",
      "loss: 0.270267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517696 \n",
      "\n",
      "Epoch 4246\n",
      "-------------------------------\n",
      "loss: 0.268803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518010 \n",
      "\n",
      "Epoch 4247\n",
      "-------------------------------\n",
      "loss: 0.257132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519414 \n",
      "\n",
      "Epoch 4248\n",
      "-------------------------------\n",
      "loss: 0.281819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520031 \n",
      "\n",
      "Epoch 4249\n",
      "-------------------------------\n",
      "loss: 0.279517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520538 \n",
      "\n",
      "Epoch 4250\n",
      "-------------------------------\n",
      "loss: 0.285155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521191 \n",
      "\n",
      "Epoch 4251\n",
      "-------------------------------\n",
      "loss: 0.271829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522269 \n",
      "\n",
      "Epoch 4252\n",
      "-------------------------------\n",
      "loss: 0.266582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522498 \n",
      "\n",
      "Epoch 4253\n",
      "-------------------------------\n",
      "loss: 0.279657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522676 \n",
      "\n",
      "Epoch 4254\n",
      "-------------------------------\n",
      "loss: 0.257934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522905 \n",
      "\n",
      "Epoch 4255\n",
      "-------------------------------\n",
      "loss: 0.276328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523038 \n",
      "\n",
      "Epoch 4256\n",
      "-------------------------------\n",
      "loss: 0.258681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523669 \n",
      "\n",
      "Epoch 4257\n",
      "-------------------------------\n",
      "loss: 0.275934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524893 \n",
      "\n",
      "Epoch 4258\n",
      "-------------------------------\n",
      "loss: 0.269887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527042 \n",
      "\n",
      "Epoch 4259\n",
      "-------------------------------\n",
      "loss: 0.272222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528812 \n",
      "\n",
      "Epoch 4260\n",
      "-------------------------------\n",
      "loss: 0.285881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.529259 \n",
      "\n",
      "Epoch 4261\n",
      "-------------------------------\n",
      "loss: 0.265799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.528276 \n",
      "\n",
      "Epoch 4262\n",
      "-------------------------------\n",
      "loss: 0.257235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.527271 \n",
      "\n",
      "Epoch 4263\n",
      "-------------------------------\n",
      "loss: 0.263640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525798 \n",
      "\n",
      "Epoch 4264\n",
      "-------------------------------\n",
      "loss: 0.278208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524504 \n",
      "\n",
      "Epoch 4265\n",
      "-------------------------------\n",
      "loss: 0.267349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523770 \n",
      "\n",
      "Epoch 4266\n",
      "-------------------------------\n",
      "loss: 0.281804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523001 \n",
      "\n",
      "Epoch 4267\n",
      "-------------------------------\n",
      "loss: 0.271647  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522831 \n",
      "\n",
      "Epoch 4268\n",
      "-------------------------------\n",
      "loss: 0.290922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522815 \n",
      "\n",
      "Epoch 4269\n",
      "-------------------------------\n",
      "loss: 0.292907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522777 \n",
      "\n",
      "Epoch 4270\n",
      "-------------------------------\n",
      "loss: 0.256703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522226 \n",
      "\n",
      "Epoch 4271\n",
      "-------------------------------\n",
      "loss: 0.260710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521952 \n",
      "\n",
      "Epoch 4272\n",
      "-------------------------------\n",
      "loss: 0.268608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521755 \n",
      "\n",
      "Epoch 4273\n",
      "-------------------------------\n",
      "loss: 0.277877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521450 \n",
      "\n",
      "Epoch 4274\n",
      "-------------------------------\n",
      "loss: 0.287267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521229 \n",
      "\n",
      "Epoch 4275\n",
      "-------------------------------\n",
      "loss: 0.282089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520978 \n",
      "\n",
      "Epoch 4276\n",
      "-------------------------------\n",
      "loss: 0.266254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520653 \n",
      "\n",
      "Epoch 4277\n",
      "-------------------------------\n",
      "loss: 0.279386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520007 \n",
      "\n",
      "Epoch 4278\n",
      "-------------------------------\n",
      "loss: 0.281531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520019 \n",
      "\n",
      "Epoch 4279\n",
      "-------------------------------\n",
      "loss: 0.287714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519638 \n",
      "\n",
      "Epoch 4280\n",
      "-------------------------------\n",
      "loss: 0.263309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519289 \n",
      "\n",
      "Epoch 4281\n",
      "-------------------------------\n",
      "loss: 0.277801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519008 \n",
      "\n",
      "Epoch 4282\n",
      "-------------------------------\n",
      "loss: 0.286163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519500 \n",
      "\n",
      "Epoch 4283\n",
      "-------------------------------\n",
      "loss: 0.270374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519911 \n",
      "\n",
      "Epoch 4284\n",
      "-------------------------------\n",
      "loss: 0.275051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518907 \n",
      "\n",
      "Epoch 4285\n",
      "-------------------------------\n",
      "loss: 0.273835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517993 \n",
      "\n",
      "Epoch 4286\n",
      "-------------------------------\n",
      "loss: 0.283109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518736 \n",
      "\n",
      "Epoch 4287\n",
      "-------------------------------\n",
      "loss: 0.271600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519461 \n",
      "\n",
      "Epoch 4288\n",
      "-------------------------------\n",
      "loss: 0.271551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519692 \n",
      "\n",
      "Epoch 4289\n",
      "-------------------------------\n",
      "loss: 0.309986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519175 \n",
      "\n",
      "Epoch 4290\n",
      "-------------------------------\n",
      "loss: 0.286509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518729 \n",
      "\n",
      "Epoch 4291\n",
      "-------------------------------\n",
      "loss: 0.259411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519316 \n",
      "\n",
      "Epoch 4292\n",
      "-------------------------------\n",
      "loss: 0.263121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519844 \n",
      "\n",
      "Epoch 4293\n",
      "-------------------------------\n",
      "loss: 0.260638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521275 \n",
      "\n",
      "Epoch 4294\n",
      "-------------------------------\n",
      "loss: 0.265761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521811 \n",
      "\n",
      "Epoch 4295\n",
      "-------------------------------\n",
      "loss: 0.302078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521527 \n",
      "\n",
      "Epoch 4296\n",
      "-------------------------------\n",
      "loss: 0.275783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520393 \n",
      "\n",
      "Epoch 4297\n",
      "-------------------------------\n",
      "loss: 0.261237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519582 \n",
      "\n",
      "Epoch 4298\n",
      "-------------------------------\n",
      "loss: 0.291200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519426 \n",
      "\n",
      "Epoch 4299\n",
      "-------------------------------\n",
      "loss: 0.267740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519325 \n",
      "\n",
      "Epoch 4300\n",
      "-------------------------------\n",
      "loss: 0.283804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519236 \n",
      "\n",
      "Epoch 4301\n",
      "-------------------------------\n",
      "loss: 0.289724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519261 \n",
      "\n",
      "Epoch 4302\n",
      "-------------------------------\n",
      "loss: 0.274664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519441 \n",
      "\n",
      "Epoch 4303\n",
      "-------------------------------\n",
      "loss: 0.263543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520281 \n",
      "\n",
      "Epoch 4304\n",
      "-------------------------------\n",
      "loss: 0.262114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520817 \n",
      "\n",
      "Epoch 4305\n",
      "-------------------------------\n",
      "loss: 0.276823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520585 \n",
      "\n",
      "Epoch 4306\n",
      "-------------------------------\n",
      "loss: 0.271657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519949 \n",
      "\n",
      "Epoch 4307\n",
      "-------------------------------\n",
      "loss: 0.259505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519126 \n",
      "\n",
      "Epoch 4308\n",
      "-------------------------------\n",
      "loss: 0.278417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518690 \n",
      "\n",
      "Epoch 4309\n",
      "-------------------------------\n",
      "loss: 0.266738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518193 \n",
      "\n",
      "Epoch 4310\n",
      "-------------------------------\n",
      "loss: 0.285410  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.518268 \n",
      "\n",
      "Epoch 4311\n",
      "-------------------------------\n",
      "loss: 0.271576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519291 \n",
      "\n",
      "Epoch 4312\n",
      "-------------------------------\n",
      "loss: 0.278808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519412 \n",
      "\n",
      "Epoch 4313\n",
      "-------------------------------\n",
      "loss: 0.277624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519304 \n",
      "\n",
      "Epoch 4314\n",
      "-------------------------------\n",
      "loss: 0.277053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518223 \n",
      "\n",
      "Epoch 4315\n",
      "-------------------------------\n",
      "loss: 0.275431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516991 \n",
      "\n",
      "Epoch 4316\n",
      "-------------------------------\n",
      "loss: 0.265343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515947 \n",
      "\n",
      "Epoch 4317\n",
      "-------------------------------\n",
      "loss: 0.284993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515765 \n",
      "\n",
      "Epoch 4318\n",
      "-------------------------------\n",
      "loss: 0.286929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515690 \n",
      "\n",
      "Epoch 4319\n",
      "-------------------------------\n",
      "loss: 0.275667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515772 \n",
      "\n",
      "Epoch 4320\n",
      "-------------------------------\n",
      "loss: 0.270838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516025 \n",
      "\n",
      "Epoch 4321\n",
      "-------------------------------\n",
      "loss: 0.276707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516081 \n",
      "\n",
      "Epoch 4322\n",
      "-------------------------------\n",
      "loss: 0.280778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516643 \n",
      "\n",
      "Epoch 4323\n",
      "-------------------------------\n",
      "loss: 0.273775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516984 \n",
      "\n",
      "Epoch 4324\n",
      "-------------------------------\n",
      "loss: 0.274578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516377 \n",
      "\n",
      "Epoch 4325\n",
      "-------------------------------\n",
      "loss: 0.262224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516257 \n",
      "\n",
      "Epoch 4326\n",
      "-------------------------------\n",
      "loss: 0.273821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516058 \n",
      "\n",
      "Epoch 4327\n",
      "-------------------------------\n",
      "loss: 0.277550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516270 \n",
      "\n",
      "Epoch 4328\n",
      "-------------------------------\n",
      "loss: 0.259581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516697 \n",
      "\n",
      "Epoch 4329\n",
      "-------------------------------\n",
      "loss: 0.263375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517302 \n",
      "\n",
      "Epoch 4330\n",
      "-------------------------------\n",
      "loss: 0.270946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517300 \n",
      "\n",
      "Epoch 4331\n",
      "-------------------------------\n",
      "loss: 0.273698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517313 \n",
      "\n",
      "Epoch 4332\n",
      "-------------------------------\n",
      "loss: 0.302805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517595 \n",
      "\n",
      "Epoch 4333\n",
      "-------------------------------\n",
      "loss: 0.268032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517707 \n",
      "\n",
      "Epoch 4334\n",
      "-------------------------------\n",
      "loss: 0.274049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517966 \n",
      "\n",
      "Epoch 4335\n",
      "-------------------------------\n",
      "loss: 0.273517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517793 \n",
      "\n",
      "Epoch 4336\n",
      "-------------------------------\n",
      "loss: 0.271796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517222 \n",
      "\n",
      "Epoch 4337\n",
      "-------------------------------\n",
      "loss: 0.274245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516359 \n",
      "\n",
      "Epoch 4338\n",
      "-------------------------------\n",
      "loss: 0.276356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516014 \n",
      "\n",
      "Epoch 4339\n",
      "-------------------------------\n",
      "loss: 0.274726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515740 \n",
      "\n",
      "Epoch 4340\n",
      "-------------------------------\n",
      "loss: 0.274807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516007 \n",
      "\n",
      "Epoch 4341\n",
      "-------------------------------\n",
      "loss: 0.280241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516017 \n",
      "\n",
      "Epoch 4342\n",
      "-------------------------------\n",
      "loss: 0.267084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515986 \n",
      "\n",
      "Epoch 4343\n",
      "-------------------------------\n",
      "loss: 0.266260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516567 \n",
      "\n",
      "Epoch 4344\n",
      "-------------------------------\n",
      "loss: 0.277848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516862 \n",
      "\n",
      "Epoch 4345\n",
      "-------------------------------\n",
      "loss: 0.283923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517500 \n",
      "\n",
      "Epoch 4346\n",
      "-------------------------------\n",
      "loss: 0.281853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517127 \n",
      "\n",
      "Epoch 4347\n",
      "-------------------------------\n",
      "loss: 0.266720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516603 \n",
      "\n",
      "Epoch 4348\n",
      "-------------------------------\n",
      "loss: 0.286857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516404 \n",
      "\n",
      "Epoch 4349\n",
      "-------------------------------\n",
      "loss: 0.277668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517287 \n",
      "\n",
      "Epoch 4350\n",
      "-------------------------------\n",
      "loss: 0.257636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518660 \n",
      "\n",
      "Epoch 4351\n",
      "-------------------------------\n",
      "loss: 0.279957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519611 \n",
      "\n",
      "Epoch 4352\n",
      "-------------------------------\n",
      "loss: 0.262260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520051 \n",
      "\n",
      "Epoch 4353\n",
      "-------------------------------\n",
      "loss: 0.260822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520652 \n",
      "\n",
      "Epoch 4354\n",
      "-------------------------------\n",
      "loss: 0.278687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521787 \n",
      "\n",
      "Epoch 4355\n",
      "-------------------------------\n",
      "loss: 0.279538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523135 \n",
      "\n",
      "Epoch 4356\n",
      "-------------------------------\n",
      "loss: 0.279630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522609 \n",
      "\n",
      "Epoch 4357\n",
      "-------------------------------\n",
      "loss: 0.277998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520047 \n",
      "\n",
      "Epoch 4358\n",
      "-------------------------------\n",
      "loss: 0.287417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518492 \n",
      "\n",
      "Epoch 4359\n",
      "-------------------------------\n",
      "loss: 0.272447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518542 \n",
      "\n",
      "Epoch 4360\n",
      "-------------------------------\n",
      "loss: 0.271332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519886 \n",
      "\n",
      "Epoch 4361\n",
      "-------------------------------\n",
      "loss: 0.260187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521543 \n",
      "\n",
      "Epoch 4362\n",
      "-------------------------------\n",
      "loss: 0.297947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522522 \n",
      "\n",
      "Epoch 4363\n",
      "-------------------------------\n",
      "loss: 0.264549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523137 \n",
      "\n",
      "Epoch 4364\n",
      "-------------------------------\n",
      "loss: 0.276517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523199 \n",
      "\n",
      "Epoch 4365\n",
      "-------------------------------\n",
      "loss: 0.271422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523730 \n",
      "\n",
      "Epoch 4366\n",
      "-------------------------------\n",
      "loss: 0.276821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522911 \n",
      "\n",
      "Epoch 4367\n",
      "-------------------------------\n",
      "loss: 0.289544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519935 \n",
      "\n",
      "Epoch 4368\n",
      "-------------------------------\n",
      "loss: 0.275599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517859 \n",
      "\n",
      "Epoch 4369\n",
      "-------------------------------\n",
      "loss: 0.264464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517266 \n",
      "\n",
      "Epoch 4370\n",
      "-------------------------------\n",
      "loss: 0.280497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517243 \n",
      "\n",
      "Epoch 4371\n",
      "-------------------------------\n",
      "loss: 0.322137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517251 \n",
      "\n",
      "Epoch 4372\n",
      "-------------------------------\n",
      "loss: 0.272797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517792 \n",
      "\n",
      "Epoch 4373\n",
      "-------------------------------\n",
      "loss: 0.288336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519190 \n",
      "\n",
      "Epoch 4374\n",
      "-------------------------------\n",
      "loss: 0.286183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520085 \n",
      "\n",
      "Epoch 4375\n",
      "-------------------------------\n",
      "loss: 0.258762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519428 \n",
      "\n",
      "Epoch 4376\n",
      "-------------------------------\n",
      "loss: 0.278428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517660 \n",
      "\n",
      "Epoch 4377\n",
      "-------------------------------\n",
      "loss: 0.289210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515122 \n",
      "\n",
      "Epoch 4378\n",
      "-------------------------------\n",
      "loss: 0.269989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514443 \n",
      "\n",
      "Epoch 4379\n",
      "-------------------------------\n",
      "loss: 0.263709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514672 \n",
      "\n",
      "Epoch 4380\n",
      "-------------------------------\n",
      "loss: 0.290248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514968 \n",
      "\n",
      "Epoch 4381\n",
      "-------------------------------\n",
      "loss: 0.293637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515091 \n",
      "\n",
      "Epoch 4382\n",
      "-------------------------------\n",
      "loss: 0.259441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515644 \n",
      "\n",
      "Epoch 4383\n",
      "-------------------------------\n",
      "loss: 0.270095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517221 \n",
      "\n",
      "Epoch 4384\n",
      "-------------------------------\n",
      "loss: 0.271824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518894 \n",
      "\n",
      "Epoch 4385\n",
      "-------------------------------\n",
      "loss: 0.286025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519854 \n",
      "\n",
      "Epoch 4386\n",
      "-------------------------------\n",
      "loss: 0.275474  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.519785 \n",
      "\n",
      "Epoch 4387\n",
      "-------------------------------\n",
      "loss: 0.282517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519361 \n",
      "\n",
      "Epoch 4388\n",
      "-------------------------------\n",
      "loss: 0.268792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518809 \n",
      "\n",
      "Epoch 4389\n",
      "-------------------------------\n",
      "loss: 0.272853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519937 \n",
      "\n",
      "Epoch 4390\n",
      "-------------------------------\n",
      "loss: 0.269359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521340 \n",
      "\n",
      "Epoch 4391\n",
      "-------------------------------\n",
      "loss: 0.296917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521315 \n",
      "\n",
      "Epoch 4392\n",
      "-------------------------------\n",
      "loss: 0.271591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521188 \n",
      "\n",
      "Epoch 4393\n",
      "-------------------------------\n",
      "loss: 0.280569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521936 \n",
      "\n",
      "Epoch 4394\n",
      "-------------------------------\n",
      "loss: 0.260041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522630 \n",
      "\n",
      "Epoch 4395\n",
      "-------------------------------\n",
      "loss: 0.271679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522484 \n",
      "\n",
      "Epoch 4396\n",
      "-------------------------------\n",
      "loss: 0.261323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521982 \n",
      "\n",
      "Epoch 4397\n",
      "-------------------------------\n",
      "loss: 0.262569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521728 \n",
      "\n",
      "Epoch 4398\n",
      "-------------------------------\n",
      "loss: 0.268000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521455 \n",
      "\n",
      "Epoch 4399\n",
      "-------------------------------\n",
      "loss: 0.274200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522014 \n",
      "\n",
      "Epoch 4400\n",
      "-------------------------------\n",
      "loss: 0.254397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522719 \n",
      "\n",
      "Epoch 4401\n",
      "-------------------------------\n",
      "loss: 0.266022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522992 \n",
      "\n",
      "Epoch 4402\n",
      "-------------------------------\n",
      "loss: 0.280675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522527 \n",
      "\n",
      "Epoch 4403\n",
      "-------------------------------\n",
      "loss: 0.258135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522220 \n",
      "\n",
      "Epoch 4404\n",
      "-------------------------------\n",
      "loss: 0.254306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522505 \n",
      "\n",
      "Epoch 4405\n",
      "-------------------------------\n",
      "loss: 0.276340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521983 \n",
      "\n",
      "Epoch 4406\n",
      "-------------------------------\n",
      "loss: 0.267159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521235 \n",
      "\n",
      "Epoch 4407\n",
      "-------------------------------\n",
      "loss: 0.276368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520870 \n",
      "\n",
      "Epoch 4408\n",
      "-------------------------------\n",
      "loss: 0.259770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520329 \n",
      "\n",
      "Epoch 4409\n",
      "-------------------------------\n",
      "loss: 0.263986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519902 \n",
      "\n",
      "Epoch 4410\n",
      "-------------------------------\n",
      "loss: 0.266700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519415 \n",
      "\n",
      "Epoch 4411\n",
      "-------------------------------\n",
      "loss: 0.275528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519768 \n",
      "\n",
      "Epoch 4412\n",
      "-------------------------------\n",
      "loss: 0.273931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520647 \n",
      "\n",
      "Epoch 4413\n",
      "-------------------------------\n",
      "loss: 0.269879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521223 \n",
      "\n",
      "Epoch 4414\n",
      "-------------------------------\n",
      "loss: 0.273634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521366 \n",
      "\n",
      "Epoch 4415\n",
      "-------------------------------\n",
      "loss: 0.263825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522914 \n",
      "\n",
      "Epoch 4416\n",
      "-------------------------------\n",
      "loss: 0.283504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522725 \n",
      "\n",
      "Epoch 4417\n",
      "-------------------------------\n",
      "loss: 0.270449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521943 \n",
      "\n",
      "Epoch 4418\n",
      "-------------------------------\n",
      "loss: 0.269884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521082 \n",
      "\n",
      "Epoch 4419\n",
      "-------------------------------\n",
      "loss: 0.270099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520526 \n",
      "\n",
      "Epoch 4420\n",
      "-------------------------------\n",
      "loss: 0.291765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520005 \n",
      "\n",
      "Epoch 4421\n",
      "-------------------------------\n",
      "loss: 0.267806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519506 \n",
      "\n",
      "Epoch 4422\n",
      "-------------------------------\n",
      "loss: 0.270179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520064 \n",
      "\n",
      "Epoch 4423\n",
      "-------------------------------\n",
      "loss: 0.272603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520386 \n",
      "\n",
      "Epoch 4424\n",
      "-------------------------------\n",
      "loss: 0.266472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521035 \n",
      "\n",
      "Epoch 4425\n",
      "-------------------------------\n",
      "loss: 0.270780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521590 \n",
      "\n",
      "Epoch 4426\n",
      "-------------------------------\n",
      "loss: 0.270051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520744 \n",
      "\n",
      "Epoch 4427\n",
      "-------------------------------\n",
      "loss: 0.288280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520391 \n",
      "\n",
      "Epoch 4428\n",
      "-------------------------------\n",
      "loss: 0.270538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520408 \n",
      "\n",
      "Epoch 4429\n",
      "-------------------------------\n",
      "loss: 0.272677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520761 \n",
      "\n",
      "Epoch 4430\n",
      "-------------------------------\n",
      "loss: 0.262477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521304 \n",
      "\n",
      "Epoch 4431\n",
      "-------------------------------\n",
      "loss: 0.269138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521483 \n",
      "\n",
      "Epoch 4432\n",
      "-------------------------------\n",
      "loss: 0.270605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520663 \n",
      "\n",
      "Epoch 4433\n",
      "-------------------------------\n",
      "loss: 0.267887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519211 \n",
      "\n",
      "Epoch 4434\n",
      "-------------------------------\n",
      "loss: 0.272062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517693 \n",
      "\n",
      "Epoch 4435\n",
      "-------------------------------\n",
      "loss: 0.277708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516803 \n",
      "\n",
      "Epoch 4436\n",
      "-------------------------------\n",
      "loss: 0.268786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516285 \n",
      "\n",
      "Epoch 4437\n",
      "-------------------------------\n",
      "loss: 0.271918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516451 \n",
      "\n",
      "Epoch 4438\n",
      "-------------------------------\n",
      "loss: 0.288142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517287 \n",
      "\n",
      "Epoch 4439\n",
      "-------------------------------\n",
      "loss: 0.266449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518343 \n",
      "\n",
      "Epoch 4440\n",
      "-------------------------------\n",
      "loss: 0.262753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517846 \n",
      "\n",
      "Epoch 4441\n",
      "-------------------------------\n",
      "loss: 0.272490  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516968 \n",
      "\n",
      "Epoch 4442\n",
      "-------------------------------\n",
      "loss: 0.265298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516160 \n",
      "\n",
      "Epoch 4443\n",
      "-------------------------------\n",
      "loss: 0.271081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515467 \n",
      "\n",
      "Epoch 4444\n",
      "-------------------------------\n",
      "loss: 0.269381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515105 \n",
      "\n",
      "Epoch 4445\n",
      "-------------------------------\n",
      "loss: 0.258101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514871 \n",
      "\n",
      "Epoch 4446\n",
      "-------------------------------\n",
      "loss: 0.267628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515062 \n",
      "\n",
      "Epoch 4447\n",
      "-------------------------------\n",
      "loss: 0.272997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515120 \n",
      "\n",
      "Epoch 4448\n",
      "-------------------------------\n",
      "loss: 0.275439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515476 \n",
      "\n",
      "Epoch 4449\n",
      "-------------------------------\n",
      "loss: 0.270387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516209 \n",
      "\n",
      "Epoch 4450\n",
      "-------------------------------\n",
      "loss: 0.267000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516844 \n",
      "\n",
      "Epoch 4451\n",
      "-------------------------------\n",
      "loss: 0.272013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517369 \n",
      "\n",
      "Epoch 4452\n",
      "-------------------------------\n",
      "loss: 0.252185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518059 \n",
      "\n",
      "Epoch 4453\n",
      "-------------------------------\n",
      "loss: 0.279784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518909 \n",
      "\n",
      "Epoch 4454\n",
      "-------------------------------\n",
      "loss: 0.254392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520008 \n",
      "\n",
      "Epoch 4455\n",
      "-------------------------------\n",
      "loss: 0.281870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520966 \n",
      "\n",
      "Epoch 4456\n",
      "-------------------------------\n",
      "loss: 0.267761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521998 \n",
      "\n",
      "Epoch 4457\n",
      "-------------------------------\n",
      "loss: 0.271832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522827 \n",
      "\n",
      "Epoch 4458\n",
      "-------------------------------\n",
      "loss: 0.256779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523026 \n",
      "\n",
      "Epoch 4459\n",
      "-------------------------------\n",
      "loss: 0.271333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522820 \n",
      "\n",
      "Epoch 4460\n",
      "-------------------------------\n",
      "loss: 0.272320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522484 \n",
      "\n",
      "Epoch 4461\n",
      "-------------------------------\n",
      "loss: 0.270671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521912 \n",
      "\n",
      "Epoch 4462\n",
      "-------------------------------\n",
      "loss: 0.257828  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521116 \n",
      "\n",
      "Epoch 4463\n",
      "-------------------------------\n",
      "loss: 0.273430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519852 \n",
      "\n",
      "Epoch 4464\n",
      "-------------------------------\n",
      "loss: 0.293533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518747 \n",
      "\n",
      "Epoch 4465\n",
      "-------------------------------\n",
      "loss: 0.261919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517902 \n",
      "\n",
      "Epoch 4466\n",
      "-------------------------------\n",
      "loss: 0.269950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517707 \n",
      "\n",
      "Epoch 4467\n",
      "-------------------------------\n",
      "loss: 0.274743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517411 \n",
      "\n",
      "Epoch 4468\n",
      "-------------------------------\n",
      "loss: 0.271802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517539 \n",
      "\n",
      "Epoch 4469\n",
      "-------------------------------\n",
      "loss: 0.277562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518050 \n",
      "\n",
      "Epoch 4470\n",
      "-------------------------------\n",
      "loss: 0.272133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519292 \n",
      "\n",
      "Epoch 4471\n",
      "-------------------------------\n",
      "loss: 0.269250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520542 \n",
      "\n",
      "Epoch 4472\n",
      "-------------------------------\n",
      "loss: 0.291864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520494 \n",
      "\n",
      "Epoch 4473\n",
      "-------------------------------\n",
      "loss: 0.291759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520214 \n",
      "\n",
      "Epoch 4474\n",
      "-------------------------------\n",
      "loss: 0.266310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521179 \n",
      "\n",
      "Epoch 4475\n",
      "-------------------------------\n",
      "loss: 0.263150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522393 \n",
      "\n",
      "Epoch 4476\n",
      "-------------------------------\n",
      "loss: 0.269339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523970 \n",
      "\n",
      "Epoch 4477\n",
      "-------------------------------\n",
      "loss: 0.278067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524816 \n",
      "\n",
      "Epoch 4478\n",
      "-------------------------------\n",
      "loss: 0.292096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525688 \n",
      "\n",
      "Epoch 4479\n",
      "-------------------------------\n",
      "loss: 0.267610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.526234 \n",
      "\n",
      "Epoch 4480\n",
      "-------------------------------\n",
      "loss: 0.279223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525698 \n",
      "\n",
      "Epoch 4481\n",
      "-------------------------------\n",
      "loss: 0.279363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524733 \n",
      "\n",
      "Epoch 4482\n",
      "-------------------------------\n",
      "loss: 0.276099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523707 \n",
      "\n",
      "Epoch 4483\n",
      "-------------------------------\n",
      "loss: 0.265874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522881 \n",
      "\n",
      "Epoch 4484\n",
      "-------------------------------\n",
      "loss: 0.273438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522424 \n",
      "\n",
      "Epoch 4485\n",
      "-------------------------------\n",
      "loss: 0.249913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522447 \n",
      "\n",
      "Epoch 4486\n",
      "-------------------------------\n",
      "loss: 0.260105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522026 \n",
      "\n",
      "Epoch 4487\n",
      "-------------------------------\n",
      "loss: 0.278974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521456 \n",
      "\n",
      "Epoch 4488\n",
      "-------------------------------\n",
      "loss: 0.265261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520689 \n",
      "\n",
      "Epoch 4489\n",
      "-------------------------------\n",
      "loss: 0.261634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520089 \n",
      "\n",
      "Epoch 4490\n",
      "-------------------------------\n",
      "loss: 0.263411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519397 \n",
      "\n",
      "Epoch 4491\n",
      "-------------------------------\n",
      "loss: 0.269729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519663 \n",
      "\n",
      "Epoch 4492\n",
      "-------------------------------\n",
      "loss: 0.273893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520498 \n",
      "\n",
      "Epoch 4493\n",
      "-------------------------------\n",
      "loss: 0.284055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521553 \n",
      "\n",
      "Epoch 4494\n",
      "-------------------------------\n",
      "loss: 0.267426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521942 \n",
      "\n",
      "Epoch 4495\n",
      "-------------------------------\n",
      "loss: 0.269218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522138 \n",
      "\n",
      "Epoch 4496\n",
      "-------------------------------\n",
      "loss: 0.298571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521252 \n",
      "\n",
      "Epoch 4497\n",
      "-------------------------------\n",
      "loss: 0.274516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520928 \n",
      "\n",
      "Epoch 4498\n",
      "-------------------------------\n",
      "loss: 0.273833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521516 \n",
      "\n",
      "Epoch 4499\n",
      "-------------------------------\n",
      "loss: 0.266225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521768 \n",
      "\n",
      "Epoch 4500\n",
      "-------------------------------\n",
      "loss: 0.265783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522187 \n",
      "\n",
      "Epoch 4501\n",
      "-------------------------------\n",
      "loss: 0.276258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523744 \n",
      "\n",
      "Epoch 4502\n",
      "-------------------------------\n",
      "loss: 0.270256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524290 \n",
      "\n",
      "Epoch 4503\n",
      "-------------------------------\n",
      "loss: 0.271398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522334 \n",
      "\n",
      "Epoch 4504\n",
      "-------------------------------\n",
      "loss: 0.275379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519125 \n",
      "\n",
      "Epoch 4505\n",
      "-------------------------------\n",
      "loss: 0.266293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517679 \n",
      "\n",
      "Epoch 4506\n",
      "-------------------------------\n",
      "loss: 0.268800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517006 \n",
      "\n",
      "Epoch 4507\n",
      "-------------------------------\n",
      "loss: 0.256337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517079 \n",
      "\n",
      "Epoch 4508\n",
      "-------------------------------\n",
      "loss: 0.276697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517440 \n",
      "\n",
      "Epoch 4509\n",
      "-------------------------------\n",
      "loss: 0.257089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519086 \n",
      "\n",
      "Epoch 4510\n",
      "-------------------------------\n",
      "loss: 0.286185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521477 \n",
      "\n",
      "Epoch 4511\n",
      "-------------------------------\n",
      "loss: 0.275737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523043 \n",
      "\n",
      "Epoch 4512\n",
      "-------------------------------\n",
      "loss: 0.273758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522404 \n",
      "\n",
      "Epoch 4513\n",
      "-------------------------------\n",
      "loss: 0.272947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520961 \n",
      "\n",
      "Epoch 4514\n",
      "-------------------------------\n",
      "loss: 0.279095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519176 \n",
      "\n",
      "Epoch 4515\n",
      "-------------------------------\n",
      "loss: 0.277940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517797 \n",
      "\n",
      "Epoch 4516\n",
      "-------------------------------\n",
      "loss: 0.258802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517817 \n",
      "\n",
      "Epoch 4517\n",
      "-------------------------------\n",
      "loss: 0.284198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517879 \n",
      "\n",
      "Epoch 4518\n",
      "-------------------------------\n",
      "loss: 0.264372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518041 \n",
      "\n",
      "Epoch 4519\n",
      "-------------------------------\n",
      "loss: 0.282333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519057 \n",
      "\n",
      "Epoch 4520\n",
      "-------------------------------\n",
      "loss: 0.273383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519900 \n",
      "\n",
      "Epoch 4521\n",
      "-------------------------------\n",
      "loss: 0.281214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520928 \n",
      "\n",
      "Epoch 4522\n",
      "-------------------------------\n",
      "loss: 0.279100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520624 \n",
      "\n",
      "Epoch 4523\n",
      "-------------------------------\n",
      "loss: 0.283270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519319 \n",
      "\n",
      "Epoch 4524\n",
      "-------------------------------\n",
      "loss: 0.274196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516708 \n",
      "\n",
      "Epoch 4525\n",
      "-------------------------------\n",
      "loss: 0.286664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515172 \n",
      "\n",
      "Epoch 4526\n",
      "-------------------------------\n",
      "loss: 0.262371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515586 \n",
      "\n",
      "Epoch 4527\n",
      "-------------------------------\n",
      "loss: 0.270896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515818 \n",
      "\n",
      "Epoch 4528\n",
      "-------------------------------\n",
      "loss: 0.263362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515689 \n",
      "\n",
      "Epoch 4529\n",
      "-------------------------------\n",
      "loss: 0.277097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515895 \n",
      "\n",
      "Epoch 4530\n",
      "-------------------------------\n",
      "loss: 0.259571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516550 \n",
      "\n",
      "Epoch 4531\n",
      "-------------------------------\n",
      "loss: 0.267704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517646 \n",
      "\n",
      "Epoch 4532\n",
      "-------------------------------\n",
      "loss: 0.264754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518663 \n",
      "\n",
      "Epoch 4533\n",
      "-------------------------------\n",
      "loss: 0.271532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519345 \n",
      "\n",
      "Epoch 4534\n",
      "-------------------------------\n",
      "loss: 0.264420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519555 \n",
      "\n",
      "Epoch 4535\n",
      "-------------------------------\n",
      "loss: 0.254575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519152 \n",
      "\n",
      "Epoch 4536\n",
      "-------------------------------\n",
      "loss: 0.261934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519092 \n",
      "\n",
      "Epoch 4537\n",
      "-------------------------------\n",
      "loss: 0.255684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519571 \n",
      "\n",
      "Epoch 4538\n",
      "-------------------------------\n",
      "loss: 0.270902  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.520331 \n",
      "\n",
      "Epoch 4539\n",
      "-------------------------------\n",
      "loss: 0.293513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519814 \n",
      "\n",
      "Epoch 4540\n",
      "-------------------------------\n",
      "loss: 0.261771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518967 \n",
      "\n",
      "Epoch 4541\n",
      "-------------------------------\n",
      "loss: 0.267230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519061 \n",
      "\n",
      "Epoch 4542\n",
      "-------------------------------\n",
      "loss: 0.281974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520208 \n",
      "\n",
      "Epoch 4543\n",
      "-------------------------------\n",
      "loss: 0.270163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520318 \n",
      "\n",
      "Epoch 4544\n",
      "-------------------------------\n",
      "loss: 0.273553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520938 \n",
      "\n",
      "Epoch 4545\n",
      "-------------------------------\n",
      "loss: 0.269810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519374 \n",
      "\n",
      "Epoch 4546\n",
      "-------------------------------\n",
      "loss: 0.265129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517364 \n",
      "\n",
      "Epoch 4547\n",
      "-------------------------------\n",
      "loss: 0.275267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516326 \n",
      "\n",
      "Epoch 4548\n",
      "-------------------------------\n",
      "loss: 0.262095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516259 \n",
      "\n",
      "Epoch 4549\n",
      "-------------------------------\n",
      "loss: 0.271776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516255 \n",
      "\n",
      "Epoch 4550\n",
      "-------------------------------\n",
      "loss: 0.279145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516167 \n",
      "\n",
      "Epoch 4551\n",
      "-------------------------------\n",
      "loss: 0.262798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516540 \n",
      "\n",
      "Epoch 4552\n",
      "-------------------------------\n",
      "loss: 0.256230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517470 \n",
      "\n",
      "Epoch 4553\n",
      "-------------------------------\n",
      "loss: 0.267762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519185 \n",
      "\n",
      "Epoch 4554\n",
      "-------------------------------\n",
      "loss: 0.261881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519177 \n",
      "\n",
      "Epoch 4555\n",
      "-------------------------------\n",
      "loss: 0.275066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518566 \n",
      "\n",
      "Epoch 4556\n",
      "-------------------------------\n",
      "loss: 0.267284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517522 \n",
      "\n",
      "Epoch 4557\n",
      "-------------------------------\n",
      "loss: 0.261805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517610 \n",
      "\n",
      "Epoch 4558\n",
      "-------------------------------\n",
      "loss: 0.257528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518433 \n",
      "\n",
      "Epoch 4559\n",
      "-------------------------------\n",
      "loss: 0.279879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518527 \n",
      "\n",
      "Epoch 4560\n",
      "-------------------------------\n",
      "loss: 0.305857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518117 \n",
      "\n",
      "Epoch 4561\n",
      "-------------------------------\n",
      "loss: 0.259430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517944 \n",
      "\n",
      "Epoch 4562\n",
      "-------------------------------\n",
      "loss: 0.276163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518338 \n",
      "\n",
      "Epoch 4563\n",
      "-------------------------------\n",
      "loss: 0.270748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518820 \n",
      "\n",
      "Epoch 4564\n",
      "-------------------------------\n",
      "loss: 0.271485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519247 \n",
      "\n",
      "Epoch 4565\n",
      "-------------------------------\n",
      "loss: 0.264093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519060 \n",
      "\n",
      "Epoch 4566\n",
      "-------------------------------\n",
      "loss: 0.282157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519282 \n",
      "\n",
      "Epoch 4567\n",
      "-------------------------------\n",
      "loss: 0.267485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519688 \n",
      "\n",
      "Epoch 4568\n",
      "-------------------------------\n",
      "loss: 0.274629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519658 \n",
      "\n",
      "Epoch 4569\n",
      "-------------------------------\n",
      "loss: 0.279722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520001 \n",
      "\n",
      "Epoch 4570\n",
      "-------------------------------\n",
      "loss: 0.273880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520455 \n",
      "\n",
      "Epoch 4571\n",
      "-------------------------------\n",
      "loss: 0.259557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520202 \n",
      "\n",
      "Epoch 4572\n",
      "-------------------------------\n",
      "loss: 0.267581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519687 \n",
      "\n",
      "Epoch 4573\n",
      "-------------------------------\n",
      "loss: 0.280553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519017 \n",
      "\n",
      "Epoch 4574\n",
      "-------------------------------\n",
      "loss: 0.279138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518502 \n",
      "\n",
      "Epoch 4575\n",
      "-------------------------------\n",
      "loss: 0.260627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518043 \n",
      "\n",
      "Epoch 4576\n",
      "-------------------------------\n",
      "loss: 0.255290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518435 \n",
      "\n",
      "Epoch 4577\n",
      "-------------------------------\n",
      "loss: 0.269362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519685 \n",
      "\n",
      "Epoch 4578\n",
      "-------------------------------\n",
      "loss: 0.277621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520198 \n",
      "\n",
      "Epoch 4579\n",
      "-------------------------------\n",
      "loss: 0.280193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521781 \n",
      "\n",
      "Epoch 4580\n",
      "-------------------------------\n",
      "loss: 0.276944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523323 \n",
      "\n",
      "Epoch 4581\n",
      "-------------------------------\n",
      "loss: 0.281973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524629 \n",
      "\n",
      "Epoch 4582\n",
      "-------------------------------\n",
      "loss: 0.279624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525647 \n",
      "\n",
      "Epoch 4583\n",
      "-------------------------------\n",
      "loss: 0.277691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524652 \n",
      "\n",
      "Epoch 4584\n",
      "-------------------------------\n",
      "loss: 0.287567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522226 \n",
      "\n",
      "Epoch 4585\n",
      "-------------------------------\n",
      "loss: 0.277274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519499 \n",
      "\n",
      "Epoch 4586\n",
      "-------------------------------\n",
      "loss: 0.265173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517058 \n",
      "\n",
      "Epoch 4587\n",
      "-------------------------------\n",
      "loss: 0.271624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516291 \n",
      "\n",
      "Epoch 4588\n",
      "-------------------------------\n",
      "loss: 0.267257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515666 \n",
      "\n",
      "Epoch 4589\n",
      "-------------------------------\n",
      "loss: 0.267846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515289 \n",
      "\n",
      "Epoch 4590\n",
      "-------------------------------\n",
      "loss: 0.266981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515502 \n",
      "\n",
      "Epoch 4591\n",
      "-------------------------------\n",
      "loss: 0.268936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515262 \n",
      "\n",
      "Epoch 4592\n",
      "-------------------------------\n",
      "loss: 0.283309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514960 \n",
      "\n",
      "Epoch 4593\n",
      "-------------------------------\n",
      "loss: 0.273620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515234 \n",
      "\n",
      "Epoch 4594\n",
      "-------------------------------\n",
      "loss: 0.282469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515857 \n",
      "\n",
      "Epoch 4595\n",
      "-------------------------------\n",
      "loss: 0.264586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516671 \n",
      "\n",
      "Epoch 4596\n",
      "-------------------------------\n",
      "loss: 0.273610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516676 \n",
      "\n",
      "Epoch 4597\n",
      "-------------------------------\n",
      "loss: 0.276612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516127 \n",
      "\n",
      "Epoch 4598\n",
      "-------------------------------\n",
      "loss: 0.268573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515154 \n",
      "\n",
      "Epoch 4599\n",
      "-------------------------------\n",
      "loss: 0.279503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515284 \n",
      "\n",
      "Epoch 4600\n",
      "-------------------------------\n",
      "loss: 0.268586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515625 \n",
      "\n",
      "Epoch 4601\n",
      "-------------------------------\n",
      "loss: 0.263503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515949 \n",
      "\n",
      "Epoch 4602\n",
      "-------------------------------\n",
      "loss: 0.264665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515608 \n",
      "\n",
      "Epoch 4603\n",
      "-------------------------------\n",
      "loss: 0.260398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515793 \n",
      "\n",
      "Epoch 4604\n",
      "-------------------------------\n",
      "loss: 0.255433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515634 \n",
      "\n",
      "Epoch 4605\n",
      "-------------------------------\n",
      "loss: 0.277190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515593 \n",
      "\n",
      "Epoch 4606\n",
      "-------------------------------\n",
      "loss: 0.272611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515584 \n",
      "\n",
      "Epoch 4607\n",
      "-------------------------------\n",
      "loss: 0.274368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515541 \n",
      "\n",
      "Epoch 4608\n",
      "-------------------------------\n",
      "loss: 0.279826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515531 \n",
      "\n",
      "Epoch 4609\n",
      "-------------------------------\n",
      "loss: 0.260228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515175 \n",
      "\n",
      "Epoch 4610\n",
      "-------------------------------\n",
      "loss: 0.283402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515394 \n",
      "\n",
      "Epoch 4611\n",
      "-------------------------------\n",
      "loss: 0.263736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515745 \n",
      "\n",
      "Epoch 4612\n",
      "-------------------------------\n",
      "loss: 0.288554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516021 \n",
      "\n",
      "Epoch 4613\n",
      "-------------------------------\n",
      "loss: 0.259665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516569 \n",
      "\n",
      "Epoch 4614\n",
      "-------------------------------\n",
      "loss: 0.289156  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.516678 \n",
      "\n",
      "Epoch 4615\n",
      "-------------------------------\n",
      "loss: 0.272168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516948 \n",
      "\n",
      "Epoch 4616\n",
      "-------------------------------\n",
      "loss: 0.267153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516936 \n",
      "\n",
      "Epoch 4617\n",
      "-------------------------------\n",
      "loss: 0.271886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517138 \n",
      "\n",
      "Epoch 4618\n",
      "-------------------------------\n",
      "loss: 0.272482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516433 \n",
      "\n",
      "Epoch 4619\n",
      "-------------------------------\n",
      "loss: 0.274985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515365 \n",
      "\n",
      "Epoch 4620\n",
      "-------------------------------\n",
      "loss: 0.270514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514287 \n",
      "\n",
      "Epoch 4621\n",
      "-------------------------------\n",
      "loss: 0.271810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513547 \n",
      "\n",
      "Epoch 4622\n",
      "-------------------------------\n",
      "loss: 0.275405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512627 \n",
      "\n",
      "Epoch 4623\n",
      "-------------------------------\n",
      "loss: 0.275239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512535 \n",
      "\n",
      "Epoch 4624\n",
      "-------------------------------\n",
      "loss: 0.266884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513404 \n",
      "\n",
      "Epoch 4625\n",
      "-------------------------------\n",
      "loss: 0.275342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515487 \n",
      "\n",
      "Epoch 4626\n",
      "-------------------------------\n",
      "loss: 0.286048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516112 \n",
      "\n",
      "Epoch 4627\n",
      "-------------------------------\n",
      "loss: 0.265940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516302 \n",
      "\n",
      "Epoch 4628\n",
      "-------------------------------\n",
      "loss: 0.268290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515882 \n",
      "\n",
      "Epoch 4629\n",
      "-------------------------------\n",
      "loss: 0.273524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516046 \n",
      "\n",
      "Epoch 4630\n",
      "-------------------------------\n",
      "loss: 0.284876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516567 \n",
      "\n",
      "Epoch 4631\n",
      "-------------------------------\n",
      "loss: 0.267557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517420 \n",
      "\n",
      "Epoch 4632\n",
      "-------------------------------\n",
      "loss: 0.266311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517982 \n",
      "\n",
      "Epoch 4633\n",
      "-------------------------------\n",
      "loss: 0.253622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519263 \n",
      "\n",
      "Epoch 4634\n",
      "-------------------------------\n",
      "loss: 0.273258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520489 \n",
      "\n",
      "Epoch 4635\n",
      "-------------------------------\n",
      "loss: 0.265119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521392 \n",
      "\n",
      "Epoch 4636\n",
      "-------------------------------\n",
      "loss: 0.264959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521017 \n",
      "\n",
      "Epoch 4637\n",
      "-------------------------------\n",
      "loss: 0.269420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520582 \n",
      "\n",
      "Epoch 4638\n",
      "-------------------------------\n",
      "loss: 0.279828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519908 \n",
      "\n",
      "Epoch 4639\n",
      "-------------------------------\n",
      "loss: 0.263743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519836 \n",
      "\n",
      "Epoch 4640\n",
      "-------------------------------\n",
      "loss: 0.267732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519951 \n",
      "\n",
      "Epoch 4641\n",
      "-------------------------------\n",
      "loss: 0.279386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519976 \n",
      "\n",
      "Epoch 4642\n",
      "-------------------------------\n",
      "loss: 0.296700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519876 \n",
      "\n",
      "Epoch 4643\n",
      "-------------------------------\n",
      "loss: 0.284317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519138 \n",
      "\n",
      "Epoch 4644\n",
      "-------------------------------\n",
      "loss: 0.266975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518297 \n",
      "\n",
      "Epoch 4645\n",
      "-------------------------------\n",
      "loss: 0.277890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518029 \n",
      "\n",
      "Epoch 4646\n",
      "-------------------------------\n",
      "loss: 0.256724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517938 \n",
      "\n",
      "Epoch 4647\n",
      "-------------------------------\n",
      "loss: 0.256371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517429 \n",
      "\n",
      "Epoch 4648\n",
      "-------------------------------\n",
      "loss: 0.272775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516717 \n",
      "\n",
      "Epoch 4649\n",
      "-------------------------------\n",
      "loss: 0.268253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516480 \n",
      "\n",
      "Epoch 4650\n",
      "-------------------------------\n",
      "loss: 0.267446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516927 \n",
      "\n",
      "Epoch 4651\n",
      "-------------------------------\n",
      "loss: 0.277496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517660 \n",
      "\n",
      "Epoch 4652\n",
      "-------------------------------\n",
      "loss: 0.272813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517750 \n",
      "\n",
      "Epoch 4653\n",
      "-------------------------------\n",
      "loss: 0.298254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515885 \n",
      "\n",
      "Epoch 4654\n",
      "-------------------------------\n",
      "loss: 0.253552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513482 \n",
      "\n",
      "Epoch 4655\n",
      "-------------------------------\n",
      "loss: 0.267034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511735 \n",
      "\n",
      "Epoch 4656\n",
      "-------------------------------\n",
      "loss: 0.257685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511068 \n",
      "\n",
      "Epoch 4657\n",
      "-------------------------------\n",
      "loss: 0.265268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.510845 \n",
      "\n",
      "Epoch 4658\n",
      "-------------------------------\n",
      "loss: 0.281121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.510417 \n",
      "\n",
      "Epoch 4659\n",
      "-------------------------------\n",
      "loss: 0.282327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.509901 \n",
      "\n",
      "Epoch 4660\n",
      "-------------------------------\n",
      "loss: 0.274421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.510389 \n",
      "\n",
      "Epoch 4661\n",
      "-------------------------------\n",
      "loss: 0.263471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512027 \n",
      "\n",
      "Epoch 4662\n",
      "-------------------------------\n",
      "loss: 0.276318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513762 \n",
      "\n",
      "Epoch 4663\n",
      "-------------------------------\n",
      "loss: 0.277180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514379 \n",
      "\n",
      "Epoch 4664\n",
      "-------------------------------\n",
      "loss: 0.263182  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514084 \n",
      "\n",
      "Epoch 4665\n",
      "-------------------------------\n",
      "loss: 0.271685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512744 \n",
      "\n",
      "Epoch 4666\n",
      "-------------------------------\n",
      "loss: 0.267678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512784 \n",
      "\n",
      "Epoch 4667\n",
      "-------------------------------\n",
      "loss: 0.269857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513467 \n",
      "\n",
      "Epoch 4668\n",
      "-------------------------------\n",
      "loss: 0.274812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514935 \n",
      "\n",
      "Epoch 4669\n",
      "-------------------------------\n",
      "loss: 0.268495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515880 \n",
      "\n",
      "Epoch 4670\n",
      "-------------------------------\n",
      "loss: 0.277279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516962 \n",
      "\n",
      "Epoch 4671\n",
      "-------------------------------\n",
      "loss: 0.267354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518162 \n",
      "\n",
      "Epoch 4672\n",
      "-------------------------------\n",
      "loss: 0.265569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519009 \n",
      "\n",
      "Epoch 4673\n",
      "-------------------------------\n",
      "loss: 0.280834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519470 \n",
      "\n",
      "Epoch 4674\n",
      "-------------------------------\n",
      "loss: 0.266855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519061 \n",
      "\n",
      "Epoch 4675\n",
      "-------------------------------\n",
      "loss: 0.258977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518852 \n",
      "\n",
      "Epoch 4676\n",
      "-------------------------------\n",
      "loss: 0.254703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518900 \n",
      "\n",
      "Epoch 4677\n",
      "-------------------------------\n",
      "loss: 0.266095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519902 \n",
      "\n",
      "Epoch 4678\n",
      "-------------------------------\n",
      "loss: 0.272564  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520060 \n",
      "\n",
      "Epoch 4679\n",
      "-------------------------------\n",
      "loss: 0.300030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519212 \n",
      "\n",
      "Epoch 4680\n",
      "-------------------------------\n",
      "loss: 0.269106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518831 \n",
      "\n",
      "Epoch 4681\n",
      "-------------------------------\n",
      "loss: 0.280812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520507 \n",
      "\n",
      "Epoch 4682\n",
      "-------------------------------\n",
      "loss: 0.275348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522339 \n",
      "\n",
      "Epoch 4683\n",
      "-------------------------------\n",
      "loss: 0.279539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523282 \n",
      "\n",
      "Epoch 4684\n",
      "-------------------------------\n",
      "loss: 0.278888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522136 \n",
      "\n",
      "Epoch 4685\n",
      "-------------------------------\n",
      "loss: 0.275960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520250 \n",
      "\n",
      "Epoch 4686\n",
      "-------------------------------\n",
      "loss: 0.267141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518178 \n",
      "\n",
      "Epoch 4687\n",
      "-------------------------------\n",
      "loss: 0.262412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517381 \n",
      "\n",
      "Epoch 4688\n",
      "-------------------------------\n",
      "loss: 0.248431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517664 \n",
      "\n",
      "Epoch 4689\n",
      "-------------------------------\n",
      "loss: 0.275427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517375 \n",
      "\n",
      "Epoch 4690\n",
      "-------------------------------\n",
      "loss: 0.274588  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.515385 \n",
      "\n",
      "Epoch 4691\n",
      "-------------------------------\n",
      "loss: 0.275725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514567 \n",
      "\n",
      "Epoch 4692\n",
      "-------------------------------\n",
      "loss: 0.261007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514628 \n",
      "\n",
      "Epoch 4693\n",
      "-------------------------------\n",
      "loss: 0.252468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514904 \n",
      "\n",
      "Epoch 4694\n",
      "-------------------------------\n",
      "loss: 0.278918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514749 \n",
      "\n",
      "Epoch 4695\n",
      "-------------------------------\n",
      "loss: 0.263405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513890 \n",
      "\n",
      "Epoch 4696\n",
      "-------------------------------\n",
      "loss: 0.267669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513347 \n",
      "\n",
      "Epoch 4697\n",
      "-------------------------------\n",
      "loss: 0.274607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512503 \n",
      "\n",
      "Epoch 4698\n",
      "-------------------------------\n",
      "loss: 0.256878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511942 \n",
      "\n",
      "Epoch 4699\n",
      "-------------------------------\n",
      "loss: 0.276933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511830 \n",
      "\n",
      "Epoch 4700\n",
      "-------------------------------\n",
      "loss: 0.267790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511822 \n",
      "\n",
      "Epoch 4701\n",
      "-------------------------------\n",
      "loss: 0.266684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512078 \n",
      "\n",
      "Epoch 4702\n",
      "-------------------------------\n",
      "loss: 0.270049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512508 \n",
      "\n",
      "Epoch 4703\n",
      "-------------------------------\n",
      "loss: 0.254488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512716 \n",
      "\n",
      "Epoch 4704\n",
      "-------------------------------\n",
      "loss: 0.265738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512663 \n",
      "\n",
      "Epoch 4705\n",
      "-------------------------------\n",
      "loss: 0.261081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512535 \n",
      "\n",
      "Epoch 4706\n",
      "-------------------------------\n",
      "loss: 0.255761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512313 \n",
      "\n",
      "Epoch 4707\n",
      "-------------------------------\n",
      "loss: 0.270517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512561 \n",
      "\n",
      "Epoch 4708\n",
      "-------------------------------\n",
      "loss: 0.272854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513697 \n",
      "\n",
      "Epoch 4709\n",
      "-------------------------------\n",
      "loss: 0.276106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513851 \n",
      "\n",
      "Epoch 4710\n",
      "-------------------------------\n",
      "loss: 0.260980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514505 \n",
      "\n",
      "Epoch 4711\n",
      "-------------------------------\n",
      "loss: 0.266112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515085 \n",
      "\n",
      "Epoch 4712\n",
      "-------------------------------\n",
      "loss: 0.273829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516393 \n",
      "\n",
      "Epoch 4713\n",
      "-------------------------------\n",
      "loss: 0.276973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518039 \n",
      "\n",
      "Epoch 4714\n",
      "-------------------------------\n",
      "loss: 0.272884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518455 \n",
      "\n",
      "Epoch 4715\n",
      "-------------------------------\n",
      "loss: 0.267364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517421 \n",
      "\n",
      "Epoch 4716\n",
      "-------------------------------\n",
      "loss: 0.267690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516835 \n",
      "\n",
      "Epoch 4717\n",
      "-------------------------------\n",
      "loss: 0.275361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516223 \n",
      "\n",
      "Epoch 4718\n",
      "-------------------------------\n",
      "loss: 0.271580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516516 \n",
      "\n",
      "Epoch 4719\n",
      "-------------------------------\n",
      "loss: 0.269210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517504 \n",
      "\n",
      "Epoch 4720\n",
      "-------------------------------\n",
      "loss: 0.281646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518078 \n",
      "\n",
      "Epoch 4721\n",
      "-------------------------------\n",
      "loss: 0.291238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518618 \n",
      "\n",
      "Epoch 4722\n",
      "-------------------------------\n",
      "loss: 0.259492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518339 \n",
      "\n",
      "Epoch 4723\n",
      "-------------------------------\n",
      "loss: 0.292679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519536 \n",
      "\n",
      "Epoch 4724\n",
      "-------------------------------\n",
      "loss: 0.275060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521870 \n",
      "\n",
      "Epoch 4725\n",
      "-------------------------------\n",
      "loss: 0.270371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522865 \n",
      "\n",
      "Epoch 4726\n",
      "-------------------------------\n",
      "loss: 0.278727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521528 \n",
      "\n",
      "Epoch 4727\n",
      "-------------------------------\n",
      "loss: 0.290628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520141 \n",
      "\n",
      "Epoch 4728\n",
      "-------------------------------\n",
      "loss: 0.264932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519522 \n",
      "\n",
      "Epoch 4729\n",
      "-------------------------------\n",
      "loss: 0.260975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519826 \n",
      "\n",
      "Epoch 4730\n",
      "-------------------------------\n",
      "loss: 0.275332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520955 \n",
      "\n",
      "Epoch 4731\n",
      "-------------------------------\n",
      "loss: 0.288378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520827 \n",
      "\n",
      "Epoch 4732\n",
      "-------------------------------\n",
      "loss: 0.281368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518902 \n",
      "\n",
      "Epoch 4733\n",
      "-------------------------------\n",
      "loss: 0.291831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518651 \n",
      "\n",
      "Epoch 4734\n",
      "-------------------------------\n",
      "loss: 0.270581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519579 \n",
      "\n",
      "Epoch 4735\n",
      "-------------------------------\n",
      "loss: 0.287150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519056 \n",
      "\n",
      "Epoch 4736\n",
      "-------------------------------\n",
      "loss: 0.269557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517633 \n",
      "\n",
      "Epoch 4737\n",
      "-------------------------------\n",
      "loss: 0.273215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516637 \n",
      "\n",
      "Epoch 4738\n",
      "-------------------------------\n",
      "loss: 0.267605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516275 \n",
      "\n",
      "Epoch 4739\n",
      "-------------------------------\n",
      "loss: 0.276535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515743 \n",
      "\n",
      "Epoch 4740\n",
      "-------------------------------\n",
      "loss: 0.265919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515719 \n",
      "\n",
      "Epoch 4741\n",
      "-------------------------------\n",
      "loss: 0.267990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516570 \n",
      "\n",
      "Epoch 4742\n",
      "-------------------------------\n",
      "loss: 0.261688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516179 \n",
      "\n",
      "Epoch 4743\n",
      "-------------------------------\n",
      "loss: 0.273966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515857 \n",
      "\n",
      "Epoch 4744\n",
      "-------------------------------\n",
      "loss: 0.264017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515741 \n",
      "\n",
      "Epoch 4745\n",
      "-------------------------------\n",
      "loss: 0.252761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516612 \n",
      "\n",
      "Epoch 4746\n",
      "-------------------------------\n",
      "loss: 0.287278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517444 \n",
      "\n",
      "Epoch 4747\n",
      "-------------------------------\n",
      "loss: 0.263908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517306 \n",
      "\n",
      "Epoch 4748\n",
      "-------------------------------\n",
      "loss: 0.276982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516221 \n",
      "\n",
      "Epoch 4749\n",
      "-------------------------------\n",
      "loss: 0.260898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514821 \n",
      "\n",
      "Epoch 4750\n",
      "-------------------------------\n",
      "loss: 0.256582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514198 \n",
      "\n",
      "Epoch 4751\n",
      "-------------------------------\n",
      "loss: 0.273130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514371 \n",
      "\n",
      "Epoch 4752\n",
      "-------------------------------\n",
      "loss: 0.248523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514347 \n",
      "\n",
      "Epoch 4753\n",
      "-------------------------------\n",
      "loss: 0.286423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514105 \n",
      "\n",
      "Epoch 4754\n",
      "-------------------------------\n",
      "loss: 0.266223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514795 \n",
      "\n",
      "Epoch 4755\n",
      "-------------------------------\n",
      "loss: 0.270517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516521 \n",
      "\n",
      "Epoch 4756\n",
      "-------------------------------\n",
      "loss: 0.268109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517983 \n",
      "\n",
      "Epoch 4757\n",
      "-------------------------------\n",
      "loss: 0.261422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517166 \n",
      "\n",
      "Epoch 4758\n",
      "-------------------------------\n",
      "loss: 0.277969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515668 \n",
      "\n",
      "Epoch 4759\n",
      "-------------------------------\n",
      "loss: 0.275580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513734 \n",
      "\n",
      "Epoch 4760\n",
      "-------------------------------\n",
      "loss: 0.272433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513294 \n",
      "\n",
      "Epoch 4761\n",
      "-------------------------------\n",
      "loss: 0.270685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513892 \n",
      "\n",
      "Epoch 4762\n",
      "-------------------------------\n",
      "loss: 0.270841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513643 \n",
      "\n",
      "Epoch 4763\n",
      "-------------------------------\n",
      "loss: 0.294227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512802 \n",
      "\n",
      "Epoch 4764\n",
      "-------------------------------\n",
      "loss: 0.258427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.512898 \n",
      "\n",
      "Epoch 4765\n",
      "-------------------------------\n",
      "loss: 0.275747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514218 \n",
      "\n",
      "Epoch 4766\n",
      "-------------------------------\n",
      "loss: 0.274670  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.517166 \n",
      "\n",
      "Epoch 4767\n",
      "-------------------------------\n",
      "loss: 0.277731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518124 \n",
      "\n",
      "Epoch 4768\n",
      "-------------------------------\n",
      "loss: 0.286806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516882 \n",
      "\n",
      "Epoch 4769\n",
      "-------------------------------\n",
      "loss: 0.290278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514839 \n",
      "\n",
      "Epoch 4770\n",
      "-------------------------------\n",
      "loss: 0.270891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513778 \n",
      "\n",
      "Epoch 4771\n",
      "-------------------------------\n",
      "loss: 0.266607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514198 \n",
      "\n",
      "Epoch 4772\n",
      "-------------------------------\n",
      "loss: 0.265021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514941 \n",
      "\n",
      "Epoch 4773\n",
      "-------------------------------\n",
      "loss: 0.258644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515099 \n",
      "\n",
      "Epoch 4774\n",
      "-------------------------------\n",
      "loss: 0.264891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514900 \n",
      "\n",
      "Epoch 4775\n",
      "-------------------------------\n",
      "loss: 0.268824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514433 \n",
      "\n",
      "Epoch 4776\n",
      "-------------------------------\n",
      "loss: 0.257993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514444 \n",
      "\n",
      "Epoch 4777\n",
      "-------------------------------\n",
      "loss: 0.265529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514896 \n",
      "\n",
      "Epoch 4778\n",
      "-------------------------------\n",
      "loss: 0.259497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515765 \n",
      "\n",
      "Epoch 4779\n",
      "-------------------------------\n",
      "loss: 0.280710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516020 \n",
      "\n",
      "Epoch 4780\n",
      "-------------------------------\n",
      "loss: 0.276457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516437 \n",
      "\n",
      "Epoch 4781\n",
      "-------------------------------\n",
      "loss: 0.275139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516607 \n",
      "\n",
      "Epoch 4782\n",
      "-------------------------------\n",
      "loss: 0.281709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516086 \n",
      "\n",
      "Epoch 4783\n",
      "-------------------------------\n",
      "loss: 0.258578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515220 \n",
      "\n",
      "Epoch 4784\n",
      "-------------------------------\n",
      "loss: 0.261442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514854 \n",
      "\n",
      "Epoch 4785\n",
      "-------------------------------\n",
      "loss: 0.257868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514721 \n",
      "\n",
      "Epoch 4786\n",
      "-------------------------------\n",
      "loss: 0.258554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515023 \n",
      "\n",
      "Epoch 4787\n",
      "-------------------------------\n",
      "loss: 0.274624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515287 \n",
      "\n",
      "Epoch 4788\n",
      "-------------------------------\n",
      "loss: 0.269703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514842 \n",
      "\n",
      "Epoch 4789\n",
      "-------------------------------\n",
      "loss: 0.256233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515611 \n",
      "\n",
      "Epoch 4790\n",
      "-------------------------------\n",
      "loss: 0.281469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517273 \n",
      "\n",
      "Epoch 4791\n",
      "-------------------------------\n",
      "loss: 0.266358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519428 \n",
      "\n",
      "Epoch 4792\n",
      "-------------------------------\n",
      "loss: 0.268922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521528 \n",
      "\n",
      "Epoch 4793\n",
      "-------------------------------\n",
      "loss: 0.276537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521815 \n",
      "\n",
      "Epoch 4794\n",
      "-------------------------------\n",
      "loss: 0.255986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520824 \n",
      "\n",
      "Epoch 4795\n",
      "-------------------------------\n",
      "loss: 0.252145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519998 \n",
      "\n",
      "Epoch 4796\n",
      "-------------------------------\n",
      "loss: 0.261129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519418 \n",
      "\n",
      "Epoch 4797\n",
      "-------------------------------\n",
      "loss: 0.275494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519313 \n",
      "\n",
      "Epoch 4798\n",
      "-------------------------------\n",
      "loss: 0.271360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519296 \n",
      "\n",
      "Epoch 4799\n",
      "-------------------------------\n",
      "loss: 0.253678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519640 \n",
      "\n",
      "Epoch 4800\n",
      "-------------------------------\n",
      "loss: 0.254970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520072 \n",
      "\n",
      "Epoch 4801\n",
      "-------------------------------\n",
      "loss: 0.265947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520541 \n",
      "\n",
      "Epoch 4802\n",
      "-------------------------------\n",
      "loss: 0.279181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520815 \n",
      "\n",
      "Epoch 4803\n",
      "-------------------------------\n",
      "loss: 0.262730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520801 \n",
      "\n",
      "Epoch 4804\n",
      "-------------------------------\n",
      "loss: 0.251397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520575 \n",
      "\n",
      "Epoch 4805\n",
      "-------------------------------\n",
      "loss: 0.274297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519541 \n",
      "\n",
      "Epoch 4806\n",
      "-------------------------------\n",
      "loss: 0.267472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518915 \n",
      "\n",
      "Epoch 4807\n",
      "-------------------------------\n",
      "loss: 0.265506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518788 \n",
      "\n",
      "Epoch 4808\n",
      "-------------------------------\n",
      "loss: 0.268685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518985 \n",
      "\n",
      "Epoch 4809\n",
      "-------------------------------\n",
      "loss: 0.271890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519114 \n",
      "\n",
      "Epoch 4810\n",
      "-------------------------------\n",
      "loss: 0.273643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519617 \n",
      "\n",
      "Epoch 4811\n",
      "-------------------------------\n",
      "loss: 0.276360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519753 \n",
      "\n",
      "Epoch 4812\n",
      "-------------------------------\n",
      "loss: 0.261238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520014 \n",
      "\n",
      "Epoch 4813\n",
      "-------------------------------\n",
      "loss: 0.266447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520097 \n",
      "\n",
      "Epoch 4814\n",
      "-------------------------------\n",
      "loss: 0.266022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520123 \n",
      "\n",
      "Epoch 4815\n",
      "-------------------------------\n",
      "loss: 0.277633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519847 \n",
      "\n",
      "Epoch 4816\n",
      "-------------------------------\n",
      "loss: 0.277657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520011 \n",
      "\n",
      "Epoch 4817\n",
      "-------------------------------\n",
      "loss: 0.280727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520135 \n",
      "\n",
      "Epoch 4818\n",
      "-------------------------------\n",
      "loss: 0.273285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519782 \n",
      "\n",
      "Epoch 4819\n",
      "-------------------------------\n",
      "loss: 0.269910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518762 \n",
      "\n",
      "Epoch 4820\n",
      "-------------------------------\n",
      "loss: 0.274649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518284 \n",
      "\n",
      "Epoch 4821\n",
      "-------------------------------\n",
      "loss: 0.275298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517818 \n",
      "\n",
      "Epoch 4822\n",
      "-------------------------------\n",
      "loss: 0.269181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517148 \n",
      "\n",
      "Epoch 4823\n",
      "-------------------------------\n",
      "loss: 0.258816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517353 \n",
      "\n",
      "Epoch 4824\n",
      "-------------------------------\n",
      "loss: 0.277801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518257 \n",
      "\n",
      "Epoch 4825\n",
      "-------------------------------\n",
      "loss: 0.272574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518730 \n",
      "\n",
      "Epoch 4826\n",
      "-------------------------------\n",
      "loss: 0.274180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518064 \n",
      "\n",
      "Epoch 4827\n",
      "-------------------------------\n",
      "loss: 0.265255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517408 \n",
      "\n",
      "Epoch 4828\n",
      "-------------------------------\n",
      "loss: 0.281952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517290 \n",
      "\n",
      "Epoch 4829\n",
      "-------------------------------\n",
      "loss: 0.271259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517046 \n",
      "\n",
      "Epoch 4830\n",
      "-------------------------------\n",
      "loss: 0.262156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516096 \n",
      "\n",
      "Epoch 4831\n",
      "-------------------------------\n",
      "loss: 0.265499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515328 \n",
      "\n",
      "Epoch 4832\n",
      "-------------------------------\n",
      "loss: 0.250621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514971 \n",
      "\n",
      "Epoch 4833\n",
      "-------------------------------\n",
      "loss: 0.274940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515164 \n",
      "\n",
      "Epoch 4834\n",
      "-------------------------------\n",
      "loss: 0.251198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515725 \n",
      "\n",
      "Epoch 4835\n",
      "-------------------------------\n",
      "loss: 0.271537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515427 \n",
      "\n",
      "Epoch 4836\n",
      "-------------------------------\n",
      "loss: 0.275345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515551 \n",
      "\n",
      "Epoch 4837\n",
      "-------------------------------\n",
      "loss: 0.264636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515811 \n",
      "\n",
      "Epoch 4838\n",
      "-------------------------------\n",
      "loss: 0.267526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515702 \n",
      "\n",
      "Epoch 4839\n",
      "-------------------------------\n",
      "loss: 0.268827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515674 \n",
      "\n",
      "Epoch 4840\n",
      "-------------------------------\n",
      "loss: 0.258724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515616 \n",
      "\n",
      "Epoch 4841\n",
      "-------------------------------\n",
      "loss: 0.262381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516237 \n",
      "\n",
      "Epoch 4842\n",
      "-------------------------------\n",
      "loss: 0.272725  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.516132 \n",
      "\n",
      "Epoch 4843\n",
      "-------------------------------\n",
      "loss: 0.276897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516415 \n",
      "\n",
      "Epoch 4844\n",
      "-------------------------------\n",
      "loss: 0.265300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516620 \n",
      "\n",
      "Epoch 4845\n",
      "-------------------------------\n",
      "loss: 0.283784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516943 \n",
      "\n",
      "Epoch 4846\n",
      "-------------------------------\n",
      "loss: 0.264248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517071 \n",
      "\n",
      "Epoch 4847\n",
      "-------------------------------\n",
      "loss: 0.274680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516137 \n",
      "\n",
      "Epoch 4848\n",
      "-------------------------------\n",
      "loss: 0.260618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515271 \n",
      "\n",
      "Epoch 4849\n",
      "-------------------------------\n",
      "loss: 0.261952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514640 \n",
      "\n",
      "Epoch 4850\n",
      "-------------------------------\n",
      "loss: 0.261044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514098 \n",
      "\n",
      "Epoch 4851\n",
      "-------------------------------\n",
      "loss: 0.253818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513515 \n",
      "\n",
      "Epoch 4852\n",
      "-------------------------------\n",
      "loss: 0.253178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513398 \n",
      "\n",
      "Epoch 4853\n",
      "-------------------------------\n",
      "loss: 0.280606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513207 \n",
      "\n",
      "Epoch 4854\n",
      "-------------------------------\n",
      "loss: 0.256998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513311 \n",
      "\n",
      "Epoch 4855\n",
      "-------------------------------\n",
      "loss: 0.262097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513065 \n",
      "\n",
      "Epoch 4856\n",
      "-------------------------------\n",
      "loss: 0.273331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513271 \n",
      "\n",
      "Epoch 4857\n",
      "-------------------------------\n",
      "loss: 0.248742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.514045 \n",
      "\n",
      "Epoch 4858\n",
      "-------------------------------\n",
      "loss: 0.272022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515190 \n",
      "\n",
      "Epoch 4859\n",
      "-------------------------------\n",
      "loss: 0.278666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516549 \n",
      "\n",
      "Epoch 4860\n",
      "-------------------------------\n",
      "loss: 0.270444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517759 \n",
      "\n",
      "Epoch 4861\n",
      "-------------------------------\n",
      "loss: 0.264783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517412 \n",
      "\n",
      "Epoch 4862\n",
      "-------------------------------\n",
      "loss: 0.261340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516489 \n",
      "\n",
      "Epoch 4863\n",
      "-------------------------------\n",
      "loss: 0.264727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516049 \n",
      "\n",
      "Epoch 4864\n",
      "-------------------------------\n",
      "loss: 0.277137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516568 \n",
      "\n",
      "Epoch 4865\n",
      "-------------------------------\n",
      "loss: 0.276451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517196 \n",
      "\n",
      "Epoch 4866\n",
      "-------------------------------\n",
      "loss: 0.272309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517478 \n",
      "\n",
      "Epoch 4867\n",
      "-------------------------------\n",
      "loss: 0.266339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517751 \n",
      "\n",
      "Epoch 4868\n",
      "-------------------------------\n",
      "loss: 0.258353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518494 \n",
      "\n",
      "Epoch 4869\n",
      "-------------------------------\n",
      "loss: 0.267633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519243 \n",
      "\n",
      "Epoch 4870\n",
      "-------------------------------\n",
      "loss: 0.267165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519220 \n",
      "\n",
      "Epoch 4871\n",
      "-------------------------------\n",
      "loss: 0.272094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519563 \n",
      "\n",
      "Epoch 4872\n",
      "-------------------------------\n",
      "loss: 0.280159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519138 \n",
      "\n",
      "Epoch 4873\n",
      "-------------------------------\n",
      "loss: 0.260809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518490 \n",
      "\n",
      "Epoch 4874\n",
      "-------------------------------\n",
      "loss: 0.271740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518703 \n",
      "\n",
      "Epoch 4875\n",
      "-------------------------------\n",
      "loss: 0.270441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518452 \n",
      "\n",
      "Epoch 4876\n",
      "-------------------------------\n",
      "loss: 0.254119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518556 \n",
      "\n",
      "Epoch 4877\n",
      "-------------------------------\n",
      "loss: 0.286816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518651 \n",
      "\n",
      "Epoch 4878\n",
      "-------------------------------\n",
      "loss: 0.265802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518842 \n",
      "\n",
      "Epoch 4879\n",
      "-------------------------------\n",
      "loss: 0.270413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519431 \n",
      "\n",
      "Epoch 4880\n",
      "-------------------------------\n",
      "loss: 0.277614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520390 \n",
      "\n",
      "Epoch 4881\n",
      "-------------------------------\n",
      "loss: 0.256777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520699 \n",
      "\n",
      "Epoch 4882\n",
      "-------------------------------\n",
      "loss: 0.266577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519746 \n",
      "\n",
      "Epoch 4883\n",
      "-------------------------------\n",
      "loss: 0.267677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519196 \n",
      "\n",
      "Epoch 4884\n",
      "-------------------------------\n",
      "loss: 0.282771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519801 \n",
      "\n",
      "Epoch 4885\n",
      "-------------------------------\n",
      "loss: 0.269549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520916 \n",
      "\n",
      "Epoch 4886\n",
      "-------------------------------\n",
      "loss: 0.298728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521186 \n",
      "\n",
      "Epoch 4887\n",
      "-------------------------------\n",
      "loss: 0.264442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521034 \n",
      "\n",
      "Epoch 4888\n",
      "-------------------------------\n",
      "loss: 0.262820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522314 \n",
      "\n",
      "Epoch 4889\n",
      "-------------------------------\n",
      "loss: 0.259597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524237 \n",
      "\n",
      "Epoch 4890\n",
      "-------------------------------\n",
      "loss: 0.271208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525469 \n",
      "\n",
      "Epoch 4891\n",
      "-------------------------------\n",
      "loss: 0.288593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524481 \n",
      "\n",
      "Epoch 4892\n",
      "-------------------------------\n",
      "loss: 0.282359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522411 \n",
      "\n",
      "Epoch 4893\n",
      "-------------------------------\n",
      "loss: 0.282653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521355 \n",
      "\n",
      "Epoch 4894\n",
      "-------------------------------\n",
      "loss: 0.267016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521947 \n",
      "\n",
      "Epoch 4895\n",
      "-------------------------------\n",
      "loss: 0.254913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522644 \n",
      "\n",
      "Epoch 4896\n",
      "-------------------------------\n",
      "loss: 0.284203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521991 \n",
      "\n",
      "Epoch 4897\n",
      "-------------------------------\n",
      "loss: 0.266184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520393 \n",
      "\n",
      "Epoch 4898\n",
      "-------------------------------\n",
      "loss: 0.265170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520559 \n",
      "\n",
      "Epoch 4899\n",
      "-------------------------------\n",
      "loss: 0.257839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522058 \n",
      "\n",
      "Epoch 4900\n",
      "-------------------------------\n",
      "loss: 0.289243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523563 \n",
      "\n",
      "Epoch 4901\n",
      "-------------------------------\n",
      "loss: 0.279061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523646 \n",
      "\n",
      "Epoch 4902\n",
      "-------------------------------\n",
      "loss: 0.281344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522513 \n",
      "\n",
      "Epoch 4903\n",
      "-------------------------------\n",
      "loss: 0.266073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520807 \n",
      "\n",
      "Epoch 4904\n",
      "-------------------------------\n",
      "loss: 0.263357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519801 \n",
      "\n",
      "Epoch 4905\n",
      "-------------------------------\n",
      "loss: 0.274352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518880 \n",
      "\n",
      "Epoch 4906\n",
      "-------------------------------\n",
      "loss: 0.286339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518145 \n",
      "\n",
      "Epoch 4907\n",
      "-------------------------------\n",
      "loss: 0.267342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518137 \n",
      "\n",
      "Epoch 4908\n",
      "-------------------------------\n",
      "loss: 0.263789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518443 \n",
      "\n",
      "Epoch 4909\n",
      "-------------------------------\n",
      "loss: 0.263385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518293 \n",
      "\n",
      "Epoch 4910\n",
      "-------------------------------\n",
      "loss: 0.261061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518894 \n",
      "\n",
      "Epoch 4911\n",
      "-------------------------------\n",
      "loss: 0.267115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519050 \n",
      "\n",
      "Epoch 4912\n",
      "-------------------------------\n",
      "loss: 0.249450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519679 \n",
      "\n",
      "Epoch 4913\n",
      "-------------------------------\n",
      "loss: 0.267600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520562 \n",
      "\n",
      "Epoch 4914\n",
      "-------------------------------\n",
      "loss: 0.260169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521795 \n",
      "\n",
      "Epoch 4915\n",
      "-------------------------------\n",
      "loss: 0.261861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522842 \n",
      "\n",
      "Epoch 4916\n",
      "-------------------------------\n",
      "loss: 0.263227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523770 \n",
      "\n",
      "Epoch 4917\n",
      "-------------------------------\n",
      "loss: 0.265174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523231 \n",
      "\n",
      "Epoch 4918\n",
      "-------------------------------\n",
      "loss: 0.266052  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.522569 \n",
      "\n",
      "Epoch 4919\n",
      "-------------------------------\n",
      "loss: 0.263808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521821 \n",
      "\n",
      "Epoch 4920\n",
      "-------------------------------\n",
      "loss: 0.253433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521303 \n",
      "\n",
      "Epoch 4921\n",
      "-------------------------------\n",
      "loss: 0.273172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520908 \n",
      "\n",
      "Epoch 4922\n",
      "-------------------------------\n",
      "loss: 0.254000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520551 \n",
      "\n",
      "Epoch 4923\n",
      "-------------------------------\n",
      "loss: 0.263295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520155 \n",
      "\n",
      "Epoch 4924\n",
      "-------------------------------\n",
      "loss: 0.272278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519479 \n",
      "\n",
      "Epoch 4925\n",
      "-------------------------------\n",
      "loss: 0.280391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518718 \n",
      "\n",
      "Epoch 4926\n",
      "-------------------------------\n",
      "loss: 0.257503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518799 \n",
      "\n",
      "Epoch 4927\n",
      "-------------------------------\n",
      "loss: 0.276938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518289 \n",
      "\n",
      "Epoch 4928\n",
      "-------------------------------\n",
      "loss: 0.262779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517527 \n",
      "\n",
      "Epoch 4929\n",
      "-------------------------------\n",
      "loss: 0.270636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517670 \n",
      "\n",
      "Epoch 4930\n",
      "-------------------------------\n",
      "loss: 0.270762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517395 \n",
      "\n",
      "Epoch 4931\n",
      "-------------------------------\n",
      "loss: 0.275391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517570 \n",
      "\n",
      "Epoch 4932\n",
      "-------------------------------\n",
      "loss: 0.251978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517261 \n",
      "\n",
      "Epoch 4933\n",
      "-------------------------------\n",
      "loss: 0.264122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517145 \n",
      "\n",
      "Epoch 4934\n",
      "-------------------------------\n",
      "loss: 0.255991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517197 \n",
      "\n",
      "Epoch 4935\n",
      "-------------------------------\n",
      "loss: 0.256754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517291 \n",
      "\n",
      "Epoch 4936\n",
      "-------------------------------\n",
      "loss: 0.256977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517656 \n",
      "\n",
      "Epoch 4937\n",
      "-------------------------------\n",
      "loss: 0.279455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518013 \n",
      "\n",
      "Epoch 4938\n",
      "-------------------------------\n",
      "loss: 0.247779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518839 \n",
      "\n",
      "Epoch 4939\n",
      "-------------------------------\n",
      "loss: 0.274290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519454 \n",
      "\n",
      "Epoch 4940\n",
      "-------------------------------\n",
      "loss: 0.261523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520441 \n",
      "\n",
      "Epoch 4941\n",
      "-------------------------------\n",
      "loss: 0.293258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521629 \n",
      "\n",
      "Epoch 4942\n",
      "-------------------------------\n",
      "loss: 0.276953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522617 \n",
      "\n",
      "Epoch 4943\n",
      "-------------------------------\n",
      "loss: 0.268529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523236 \n",
      "\n",
      "Epoch 4944\n",
      "-------------------------------\n",
      "loss: 0.265562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522994 \n",
      "\n",
      "Epoch 4945\n",
      "-------------------------------\n",
      "loss: 0.278658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521637 \n",
      "\n",
      "Epoch 4946\n",
      "-------------------------------\n",
      "loss: 0.272567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519718 \n",
      "\n",
      "Epoch 4947\n",
      "-------------------------------\n",
      "loss: 0.253783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518175 \n",
      "\n",
      "Epoch 4948\n",
      "-------------------------------\n",
      "loss: 0.274623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517506 \n",
      "\n",
      "Epoch 4949\n",
      "-------------------------------\n",
      "loss: 0.258562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518000 \n",
      "\n",
      "Epoch 4950\n",
      "-------------------------------\n",
      "loss: 0.268124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518534 \n",
      "\n",
      "Epoch 4951\n",
      "-------------------------------\n",
      "loss: 0.270148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518515 \n",
      "\n",
      "Epoch 4952\n",
      "-------------------------------\n",
      "loss: 0.266446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518049 \n",
      "\n",
      "Epoch 4953\n",
      "-------------------------------\n",
      "loss: 0.265200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518606 \n",
      "\n",
      "Epoch 4954\n",
      "-------------------------------\n",
      "loss: 0.266579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519505 \n",
      "\n",
      "Epoch 4955\n",
      "-------------------------------\n",
      "loss: 0.271118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520496 \n",
      "\n",
      "Epoch 4956\n",
      "-------------------------------\n",
      "loss: 0.256075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520926 \n",
      "\n",
      "Epoch 4957\n",
      "-------------------------------\n",
      "loss: 0.265071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521305 \n",
      "\n",
      "Epoch 4958\n",
      "-------------------------------\n",
      "loss: 0.271123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521106 \n",
      "\n",
      "Epoch 4959\n",
      "-------------------------------\n",
      "loss: 0.260995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520842 \n",
      "\n",
      "Epoch 4960\n",
      "-------------------------------\n",
      "loss: 0.277644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520154 \n",
      "\n",
      "Epoch 4961\n",
      "-------------------------------\n",
      "loss: 0.260475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519635 \n",
      "\n",
      "Epoch 4962\n",
      "-------------------------------\n",
      "loss: 0.283696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518810 \n",
      "\n",
      "Epoch 4963\n",
      "-------------------------------\n",
      "loss: 0.263154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518360 \n",
      "\n",
      "Epoch 4964\n",
      "-------------------------------\n",
      "loss: 0.264711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518607 \n",
      "\n",
      "Epoch 4965\n",
      "-------------------------------\n",
      "loss: 0.258544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518309 \n",
      "\n",
      "Epoch 4966\n",
      "-------------------------------\n",
      "loss: 0.277671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518213 \n",
      "\n",
      "Epoch 4967\n",
      "-------------------------------\n",
      "loss: 0.275169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517908 \n",
      "\n",
      "Epoch 4968\n",
      "-------------------------------\n",
      "loss: 0.252361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517195 \n",
      "\n",
      "Epoch 4969\n",
      "-------------------------------\n",
      "loss: 0.280264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516910 \n",
      "\n",
      "Epoch 4970\n",
      "-------------------------------\n",
      "loss: 0.260398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516614 \n",
      "\n",
      "Epoch 4971\n",
      "-------------------------------\n",
      "loss: 0.262590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516401 \n",
      "\n",
      "Epoch 4972\n",
      "-------------------------------\n",
      "loss: 0.282085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515660 \n",
      "\n",
      "Epoch 4973\n",
      "-------------------------------\n",
      "loss: 0.254869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515291 \n",
      "\n",
      "Epoch 4974\n",
      "-------------------------------\n",
      "loss: 0.268781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515051 \n",
      "\n",
      "Epoch 4975\n",
      "-------------------------------\n",
      "loss: 0.266109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515454 \n",
      "\n",
      "Epoch 4976\n",
      "-------------------------------\n",
      "loss: 0.258436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515495 \n",
      "\n",
      "Epoch 4977\n",
      "-------------------------------\n",
      "loss: 0.259979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.516296 \n",
      "\n",
      "Epoch 4978\n",
      "-------------------------------\n",
      "loss: 0.267920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517065 \n",
      "\n",
      "Epoch 4979\n",
      "-------------------------------\n",
      "loss: 0.276941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517265 \n",
      "\n",
      "Epoch 4980\n",
      "-------------------------------\n",
      "loss: 0.267950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517174 \n",
      "\n",
      "Epoch 4981\n",
      "-------------------------------\n",
      "loss: 0.261985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517779 \n",
      "\n",
      "Epoch 4982\n",
      "-------------------------------\n",
      "loss: 0.281443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.518302 \n",
      "\n",
      "Epoch 4983\n",
      "-------------------------------\n",
      "loss: 0.263589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519043 \n",
      "\n",
      "Epoch 4984\n",
      "-------------------------------\n",
      "loss: 0.261506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519539 \n",
      "\n",
      "Epoch 4985\n",
      "-------------------------------\n",
      "loss: 0.276611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519519 \n",
      "\n",
      "Epoch 4986\n",
      "-------------------------------\n",
      "loss: 0.267221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.519882 \n",
      "\n",
      "Epoch 4987\n",
      "-------------------------------\n",
      "loss: 0.254452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520385 \n",
      "\n",
      "Epoch 4988\n",
      "-------------------------------\n",
      "loss: 0.256690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520716 \n",
      "\n",
      "Epoch 4989\n",
      "-------------------------------\n",
      "loss: 0.275127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520983 \n",
      "\n",
      "Epoch 4990\n",
      "-------------------------------\n",
      "loss: 0.263915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521693 \n",
      "\n",
      "Epoch 4991\n",
      "-------------------------------\n",
      "loss: 0.270375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522531 \n",
      "\n",
      "Epoch 4992\n",
      "-------------------------------\n",
      "loss: 0.256065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522077 \n",
      "\n",
      "Epoch 4993\n",
      "-------------------------------\n",
      "loss: 0.247265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521430 \n",
      "\n",
      "Epoch 4994\n",
      "-------------------------------\n",
      "loss: 0.251818  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.521247 \n",
      "\n",
      "Epoch 4995\n",
      "-------------------------------\n",
      "loss: 0.274875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.521932 \n",
      "\n",
      "Epoch 4996\n",
      "-------------------------------\n",
      "loss: 0.301477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522939 \n",
      "\n",
      "Epoch 4997\n",
      "-------------------------------\n",
      "loss: 0.256904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.523800 \n",
      "\n",
      "Epoch 4998\n",
      "-------------------------------\n",
      "loss: 0.279450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524999 \n",
      "\n",
      "Epoch 4999\n",
      "-------------------------------\n",
      "loss: 0.264463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524262 \n",
      "\n",
      "Epoch 5000\n",
      "-------------------------------\n",
      "loss: 0.266981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.522781 \n",
      "\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 29 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 29 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-67/metadata\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if optChoice == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "elif optChoice == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "else:\n",
    "    optimizer = None\n",
    "    print('no optimizer chosen...')\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=neptuneProject,\n",
    "    api_token=api_token,  \n",
    "    capture_hardware_metrics=True,\n",
    "    capture_stderr=True,\n",
    "    capture_stdout=True,\n",
    ")\n",
    "\n",
    "PARAMS = {\n",
    "    \"modelID\": modelID,\n",
    "    \"targetScalpElectrode\": targetScalpElectrode,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": learningRate,\n",
    "    \"optimizer\": optChoice,\n",
    "    \"patience\": patience,\n",
    "    \"subsampleFreq\": subsampleFreq,\n",
    "    \"secondsInWindow\": secondsInWindow,\n",
    "    \"nperseg\": nperseg,\n",
    "    \"noverlap\": noverlap,\n",
    "    \"window\": stringify_unsupported(window),\n",
    "    \"loss_fn\": stringify_unsupported(loss_fn),\n",
    "    \"architectureString\": str(model),\n",
    "    \"numParameters\": sdm.count_parameters(model)\n",
    "}\n",
    "run[\"parameters\"] = PARAMS\n",
    "\n",
    "noImprovementCount = 0\n",
    "\n",
    "#epochs = 2\n",
    "\n",
    "try:\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = sdm.train(trainDataLoader, model, loss_fn, optimizer, device)\n",
    "        test_loss = sdm.test(validDataLoader, model, loss_fn, device)\n",
    "\n",
    "        if test_loss < bestTestLoss:\n",
    "            noImprovementCount = 0\n",
    "            bestTestLoss = test_loss\n",
    "            \n",
    "            model_scripted = torch.jit.script(model) \n",
    "            model_scripted.save(modelPath + 'model_%s.pt' % str(modelID))\n",
    "    \n",
    "            run[\"best_test_loss\"] =  bestTestLoss\n",
    "            run[\"best_test_epoch\"] = t\n",
    "            print(\"\\nSaved a new best model!\\n\")\n",
    "        else:\n",
    "            noImprovementCount = noImprovementCount + 1\n",
    "\n",
    "        run[\"train/loss\"].append(train_loss)\n",
    "        run[\"test/loss\"].append(test_loss)\n",
    "\n",
    "        if noImprovementCount >= patience:   \n",
    "            print(\"Early stopping invoked....\")\n",
    "            break\n",
    "\n",
    "    run.stop()\n",
    "    print(\"Done!\")\n",
    "except:\n",
    "    run.stop()\n",
    "    print(\"Training aborted...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12a577",
   "metadata": {},
   "source": [
    "# LOAD SAVED MODEL (TORCHSCRIPT) FOR INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe26a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelID = '982815'\n",
    "\n",
    "model = torch.jit.load(modelPath + 'model_%s.pt' % str(modelID))\n",
    "if validFlag:\n",
    "    bestTestLoss = sdm.test(validDataLoader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3474b",
   "metadata": {},
   "source": [
    "# PLOT RESULTS OF FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a858773f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT PREDICTION VERSUS TRUTH\n",
    "\n",
    "trainPlotFlag = True\n",
    "    \n",
    "if trainPlotFlag:\n",
    "    x = trainXTensor\n",
    "    trainTitle = 'train'\n",
    "else:\n",
    "    x = validXTensor\n",
    "    trainTitle = 'valididation'\n",
    "\n",
    "model.to('cpu')\n",
    "predict = model(x).cpu().detach().numpy()\n",
    "model.to(device)\n",
    "\n",
    "if predict.shape[1] == 1:\n",
    "    yPred = predict[:,0]\n",
    "    if trainPlotFlag:\n",
    "        yTrue = yTrainTimeDomain[:,0]\n",
    "    else:\n",
    "        yTrue = yValidTimeDomain[:,0]\n",
    "else:\n",
    "    _, yPred = realSTFTtoTimeSeries(predict)\n",
    "    if trainPlotFlag:\n",
    "        y = y_trainRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "    else:\n",
    "        y = y_validRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "        \n",
    "\n",
    "lossTemp = loss_fn(torch.tensor(yPred), torch.tensor(yTrue)).item()\n",
    "title = 'Data: ' + trainTitle + ' (loss: %s)' % str(lossTemp)\n",
    "plt.figure()\n",
    "plt.plot(yPred, label='predict')\n",
    "plt.plot(yTrue, label='true')\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1901be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE yTRUE and yPRED for conversion to EDF\n",
    "\n",
    "arraySavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/predictionResults/numpy/results_31_Wake_ME1.npz'\n",
    "np.savez(arraySavePath, yTrue=yTrue, yPred=yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc1e38",
   "metadata": {},
   "source": [
    "# GET BEST MODEL DATA FROM NEPTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2888482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys/id</th>\n",
       "      <th>best_test_loss</th>\n",
       "      <th>parameters/modelID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRED-67</td>\n",
       "      <td>0.508105</td>\n",
       "      <td>279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRED-66</td>\n",
       "      <td>0.389803</td>\n",
       "      <td>982815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRED-65</td>\n",
       "      <td>0.677281</td>\n",
       "      <td>228338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRED-64</td>\n",
       "      <td>0.648604</td>\n",
       "      <td>64693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRED-63</td>\n",
       "      <td>0.665345</td>\n",
       "      <td>64693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRED-62</td>\n",
       "      <td>0.676881</td>\n",
       "      <td>64693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRED-61</td>\n",
       "      <td>0.666001</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRED-60</td>\n",
       "      <td>0.674732</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRED-59</td>\n",
       "      <td>0.391365</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRED-54</td>\n",
       "      <td>0.391573</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRED-53</td>\n",
       "      <td>0.423721</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRED-46</td>\n",
       "      <td>0.40543</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PRED-43</td>\n",
       "      <td>0.390877</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRED-38</td>\n",
       "      <td>0.398955</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRED-35</td>\n",
       "      <td>0.403722</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRED-34</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRED-32</td>\n",
       "      <td>0.408214</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRED-31</td>\n",
       "      <td>0.40969</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRED-58</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRED-57</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRED-56</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRED-55</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sys/id best_test_loss  parameters/modelID\n",
       "0   PRED-67       0.508105              279144\n",
       "1   PRED-66       0.389803              982815\n",
       "2   PRED-65       0.677281              228338\n",
       "3   PRED-64       0.648604               64693\n",
       "4   PRED-63       0.665345               64693\n",
       "5   PRED-62       0.676881               64693\n",
       "6   PRED-61       0.666001                  -1\n",
       "7   PRED-60       0.674732                  -1\n",
       "8   PRED-59       0.391365                  -1\n",
       "13  PRED-54       0.391573                  -1\n",
       "14  PRED-53       0.423721                  -1\n",
       "15  PRED-46        0.40543                  -1\n",
       "16  PRED-43       0.390877                  -1\n",
       "17  PRED-38       0.398955                  -1\n",
       "18  PRED-35       0.403722                  -1\n",
       "19  PRED-34       0.417772                  -1\n",
       "20  PRED-32       0.408214                  -1\n",
       "21  PRED-31        0.40969                  -1\n",
       "9   PRED-58             -1                  -1\n",
       "10  PRED-57             -1                  -1\n",
       "11  PRED-56             -1                  -1\n",
       "12  PRED-55             -1                  -1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdm.neptuneBestRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671c8d3",
   "metadata": {},
   "source": [
    "# SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c14b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "fs = 1\n",
    "nperseg = 32\n",
    "noverlap = 31\n",
    "#windowType = ('tukey', .25)\n",
    "windowType = np.ones(nperseg)\n",
    "\n",
    "\n",
    "a = np.random.rand(100)\n",
    "f, t, S = stft(a, fs=fs, window=windowType, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "b = torch.stft(torch.tensor(a), \n",
    "               n_fft = nperseg, \n",
    "               hop_length = 1, \n",
    "               return_complex=True, \n",
    "               normalized=False, \n",
    "               onesided=True, \n",
    "               pad_mode='constant').numpy()\n",
    "\n",
    "np.abs(np.divide(b,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d95ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import get_window\n",
    "a = get_window(('tukey', .25), nperseg)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        return loss\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, layerOrderedDict):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(layerOrderedDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# GIVEN A LIST OF LAYER SIZES MAKE AN ORDERED DICTIONARY FOR INITIALIZING A PYTORCH NET\n",
    "\n",
    "def listToOrderedDict(sizeList):\n",
    "    n = len(sizeList)\n",
    "    tupleList = []\n",
    "    for i in range(n - 1):\n",
    "        tupleList.append(('bn%s' % str(i), nn.BatchNorm1d(sizeList[i])))\n",
    "        tupleList.append(('l%s' % str(i), nn.Linear(sizeList[i], sizeList[i+1])))\n",
    "        tupleList.append(('r%s' % str(i), nn.ReLU()))\n",
    "    return OrderedDict(tupleList[:-1])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "'''\n",
    "\n",
    "'''\n",
    "    layerSizeList = [trainXTensor.shape[1]] + hiddenLayerSizes + [trainYTensor.shape[1]]\n",
    "    layerOrderedDict = sdm.listToOrderedDict(layerSizeList)\n",
    "    model = sdm.NeuralNetwork(layerOrderedDict)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.13",
   "language": "python",
   "name": "pytorch-1.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
