{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "O7KOU3RctXpJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import cuml\n",
    "from cuml import KMeans\n",
    "from cuml.cluster import KMeans\n",
    "import cudf\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "timeZone = pytz.timezone('America/Los_Angeles')\n",
    "\n",
    "import torch\n",
    "\n",
    "import myUtils\n",
    "import torchModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct(toPredict, predictor, kmeansModel, nStack):\n",
    "    predicted = np.zeros_like(toPredict)\n",
    "    predicted[:,1] = toPredict[:,1]\n",
    "\n",
    "    #stackedSamples, _ = residualStack.shape\n",
    "    _, nSamples = toPredict.shape\n",
    "    counter = 1\n",
    "\n",
    "    while counter + nStack <= nSamples:\n",
    "        if counter % 100000 == 0:\n",
    "            myPrint(\"predicting sample: \" + str(counter))\n",
    "\n",
    "        thisToPredict = toPredict[:, counter:counter + nStack].flatten(order='F')\n",
    "        thisPredictor = np.repeat(predicted[:, counter - 1], nStack)\n",
    "        thisResidual = thisToPredict - thisPredictor\n",
    "        \n",
    "        #kmeansModel.fit(np.expand_dims(thisResidual,0))\n",
    "        \n",
    "        index = int(kmeans.predict(np.expand_dims(thisResidual, 0))[0])\n",
    "        thisCentroid = centroids[index,:]\n",
    "        for j in range(nStack):\n",
    "            predicted[:, counter] = data[:, counter - 1 - j] + thisCentroid[j * nChannel: (j+1) * nChannel].transpose()\n",
    "            counter += 1\n",
    "            \n",
    "    return predicted, kmeansModel\n",
    "\n",
    "\n",
    "def prepareResiduals(nStack, toPredict, predictor):\n",
    "\n",
    "    _, nSample = toPredict.shape\n",
    "    residualStack = np.zeros((nSample, nStack * nChannel))\n",
    "    counter = 0\n",
    "    for i in range(0, nSample, nStack):\n",
    "        if i + nStack >= nSample:\n",
    "            break\n",
    "        thisPredictor = np.repeat(predictor[:,i].transpose(), nStack)\n",
    "        thisToPredict = toPredict[:,i + 1: i + 1 + nStack].flatten(order='F').transpose()\n",
    "        thisResidual = thisToPredict - thisPredictor\n",
    "        residualStack[counter, :] = thisResidual\n",
    "        counter += 1\n",
    "\n",
    "    residualStack = residualStack[0:counter,:]\n",
    "    return residualStack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNQ1lHLY3Ij4",
    "outputId": "6ab2c55f-12de-4df9-ef9c-eb99a04cb0a4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been moved to GPU\n",
      "(19, 1100367)\n"
     ]
    }
   ],
   "source": [
    "dataMultiply = 10**5\n",
    "sFreq = 256\n",
    "arrayInCompressedFile = 'arr_7'\n",
    "\n",
    "data = np.load('/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/elimPeaksSVD001.npz')[arrayInCompressedFile]\n",
    "nChannel, nSample = data.shape\n",
    "data = (data * dataMultiply).astype('float32')\n",
    "dataTensor = torch.tensor(data)\n",
    "if torch.cuda.is_available():\n",
    "    dataTensor = dataTensor.to('cuda')\n",
    "    print(\"Data has been moved to GPU\")\n",
    "else:\n",
    "    print(\"Data is on CPU\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "modelType = 'kmeans'\n",
    "loadBool = 1\n",
    "modelPath = '/blue/gkalamangalam/jmark.ettinger/eegCompress/models/savedModel_04-16 00:52_-0.023.pt'\n",
    "numSampleInput = 20\n",
    "numSampleOutput = 1\n",
    "\n",
    "path = '/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/kmeansModels/kmeansModel_001_block7_1stack.npz'\n",
    "npzfile = np.load(path)\n",
    "centroids = npzfile['arr_0']\n",
    "initDict = {'kmeansInit': centroids, 'dataTensor': dataTensor, 'numSampleInput':numSampleInput}\n",
    "\n",
    "model, dataset, loss_function = torchModels.makeModel(modelType, initDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centroids = model.kmeans.float().detach().numpy()\n",
    "nCentroids,_ = centroids.shape\n",
    "kmeans = KMeans(n_clusters=nCentroids, init=centroids, n_init=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct the data from stacked residuals and centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-12 13:14: reconstruct iteration: 0\n",
      "04-12 13:17: predicting sample: 100000\n",
      "04-12 13:19: predicting sample: 200000\n",
      "04-12 13:22: predicting sample: 300000\n",
      "04-12 13:24: predicting sample: 400000\n",
      "04-12 13:27: predicting sample: 500000\n",
      "04-12 13:30: predicting sample: 600000\n",
      "04-12 13:32: predicting sample: 700000\n",
      "04-12 13:35: predicting sample: 800000\n",
      "04-12 13:37: predicting sample: 900000\n",
      "04-12 13:40: predicting sample: 1000000\n",
      "04-12 13:42: predicting sample: 1100000\n",
      "04-12 13:42: (0.086687125, 18.781786)\n",
      "04-12 13:43: reconstruct iteration: 1\n",
      "04-12 13:46: predicting sample: 100000\n",
      "04-12 13:48: predicting sample: 200000\n",
      "04-12 13:51: predicting sample: 300000\n",
      "04-12 13:53: predicting sample: 400000\n",
      "04-12 13:56: predicting sample: 500000\n",
      "04-12 13:58: predicting sample: 600000\n",
      "04-12 14:01: predicting sample: 700000\n",
      "04-12 14:03: predicting sample: 800000\n",
      "04-12 14:06: predicting sample: 900000\n",
      "04-12 14:08: predicting sample: 1000000\n",
      "04-12 14:11: predicting sample: 1100000\n",
      "04-12 14:11: (0.10178884, 18.781786)\n",
      "04-12 14:12: reconstruct iteration: 2\n",
      "04-12 14:14: predicting sample: 100000\n",
      "04-12 14:17: predicting sample: 200000\n",
      "04-12 14:19: predicting sample: 300000\n",
      "04-12 14:22: predicting sample: 400000\n",
      "04-12 14:24: predicting sample: 500000\n",
      "04-12 14:27: predicting sample: 600000\n",
      "04-12 14:29: predicting sample: 700000\n",
      "04-12 14:32: predicting sample: 800000\n",
      "04-12 14:34: predicting sample: 900000\n",
      "04-12 14:37: predicting sample: 1000000\n",
      "04-12 14:39: predicting sample: 1100000\n",
      "04-12 14:39: (0.09648703, 18.781786)\n",
      "04-12 14:40: reconstruct iteration: 3\n",
      "04-12 14:43: predicting sample: 100000\n",
      "04-12 14:45: predicting sample: 200000\n",
      "04-12 14:48: predicting sample: 300000\n",
      "04-12 14:50: predicting sample: 400000\n",
      "04-12 14:53: predicting sample: 500000\n",
      "04-12 14:55: predicting sample: 600000\n",
      "04-12 14:58: predicting sample: 700000\n",
      "04-12 15:00: predicting sample: 800000\n",
      "04-12 15:03: predicting sample: 900000\n",
      "04-12 15:05: predicting sample: 1000000\n",
      "04-12 15:08: predicting sample: 1100000\n",
      "04-12 15:08: (0.09305243, 18.781786)\n",
      "04-12 15:08: reconstruct iteration: 4\n",
      "04-12 15:11: predicting sample: 100000\n",
      "04-12 15:13: predicting sample: 200000\n",
      "04-12 15:16: predicting sample: 300000\n",
      "04-12 15:18: predicting sample: 400000\n",
      "04-12 15:21: predicting sample: 500000\n",
      "04-12 15:23: predicting sample: 600000\n",
      "04-12 15:26: predicting sample: 700000\n",
      "04-12 15:28: predicting sample: 800000\n",
      "04-12 15:31: predicting sample: 900000\n",
      "04-12 15:33: predicting sample: 1000000\n",
      "04-12 15:36: predicting sample: 1100000\n",
      "04-12 15:36: (0.09900447, 18.781786)\n",
      "CPU times: user 1h 56min 39s, sys: 24min 34s, total: 2h 21min 13s\n",
      "Wall time: 2h 22min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iterations = 5\n",
    "nStack = 1\n",
    "\n",
    "for i in range(iterations):\n",
    "    myPrint(\"reconstruct iteration: \" + str(i))\n",
    "    predicted, kmeans = reconstruct(data, predicted, kmeans, nStack)\n",
    "    \n",
    "    myPrint(str((np.mean(np.abs(data - predicted)), np.max(np.abs(data - predicted)))))\n",
    "    \n",
    "    '''\n",
    "    residuals = (data[:,1:] - predicted[:,0:-1]).transpose()\n",
    "    if i == 0:\n",
    "        residuals = residuals[n_clusters,:]\n",
    "    '''\n",
    "    \n",
    "    kmeans.fit(residuals)\n",
    "    \n",
    "    # save kmeans model\n",
    "    directory = '/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/kmeansModels/'\n",
    "    time = str(datetime.datetime.now().astimezone(timeZone).strftime('%m-%d %H:%M'))\n",
    "    filename = 'kmeansModel_stack' + str(nStack) + '_' +  time + '.npz'\n",
    "    path = directory + filename\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    labels = kmeans.labels_\n",
    "    np.savez(path, centroids, labels)\n",
    "    \n",
    "    # save reconstructed data\n",
    "    filename = 'predicted_' +  time + '.npz'\n",
    "    path = directory + filename\n",
    "    np.savez(path, predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(np.abs(data - predicted)), np.max(np.abs(data - predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " current best: (0.044626124, 0.6939485)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(predicted[channel,:], label='predicted')\n",
    "plt.plot(data[channel,:], label='original')\n",
    "residual = data - predicted\n",
    "#plt.plot(residual[channel,:])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save original and predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vImqGqzJS8Dh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/origAndPredictedLossy.npz'\n",
    "dataToSaveList = [data[:,0:failureIndex], predicted[:, 0:failureIndex]]\n",
    "np.savez_compressed(path, *dataToSaveList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaK1mJneWd4k"
   },
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rapidsAndPytorch",
   "language": "python",
   "name": "rapidsandpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
