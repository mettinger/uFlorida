{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "O7KOU3RctXpJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "\n",
    "import cuml\n",
    "\n",
    "from cuml import KMeans\n",
    "from cuml.cluster import KMeans\n",
    "import cudf\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "timeZone = pytz.timezone('America/Los_Angeles')\n",
    "\n",
    "import torch\n",
    "\n",
    "import myUtils\n",
    "import torchModels\n",
    "import eegUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNQ1lHLY3Ij4",
    "outputId": "6ab2c55f-12de-4df9-ef9c-eb99a04cb0a4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been moved to GPU\n",
      "(19, 1100367)\n"
     ]
    }
   ],
   "source": [
    "dataMultiply = 10**5\n",
    "sFreq = 256\n",
    "arrayInCompressedFile = 'arr_7'\n",
    "\n",
    "data = np.load('/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/elimPeaksSVD001.npz')[arrayInCompressedFile]\n",
    "nChannel, nSample = data.shape\n",
    "data = (data * dataMultiply).astype('float32')\n",
    "dataTensor = torch.tensor(data)\n",
    "if torch.cuda.is_available():\n",
    "    dataTensor = dataTensor.to('cuda')\n",
    "    print(\"Data has been moved to GPU\")\n",
    "else:\n",
    "    print(\"Data is on CPU\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "modelType = 'kmeans'\n",
    "loadBool = 1\n",
    "modelPath = '/blue/gkalamangalam/jmark.ettinger/eegCompress/models/savedModel_04-16 00:52_-0.023.pt'\n",
    "numSampleInput = 20\n",
    "numSampleOutput = 1\n",
    "\n",
    "path = '/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/kmeansModels/kmeansModel_001_block7_1stack.npz'\n",
    "npzfile = np.load(path)\n",
    "centroids = npzfile['arr_0']\n",
    "initDict = {'kmeansInit': centroids, 'dataTensor': dataTensor, 'numSampleInput':numSampleInput}\n",
    "\n",
    "model, dataset, loss_function = torchModels.makeModel(modelType, initDict)\n",
    "model = model.to('cuda')\n",
    "numSampleInput = model.numSampleInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centroids = model.kmeans.float().detach().cpu().numpy()\n",
    "nCentroids,_ = centroids.shape\n",
    "kmeans = KMeans(n_clusters=nCentroids, init=centroids, n_init=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct the data from predictions and centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "toPredict = data\n",
    "predictionModel = model\n",
    "kmeansModel = kmeans\n",
    "\n",
    "model.eval()\n",
    "predicted = np.zeros_like(toPredict)\n",
    "predicted[:,0:numSampleInput] = toPredict[:,0:numSampleInput]\n",
    "\n",
    "for counter in range(numSampleInput, nSample):\n",
    "    if counter % 100000 == 0:\n",
    "        myUtils.myPrint(counter)\n",
    "        \n",
    "    thisBlock = torch.unsqueeze(torch.tensor(predicted[:,counter - numSampleInput: counter]), 0).cuda()\n",
    "    label = torch.tensor(data[:,counter]).cuda()\n",
    "        \n",
    "    thisPrediction = predictionModel(thisBlock)\n",
    "    thisResidual = (label - thisPrediction).detach().cpu().numpy().transpose()\n",
    "    \n",
    "    index = int(kmeans.predict(np.expand_dims(thisResidual, 0))[0])\n",
    "    thisCentroid = centroids[index,:]\n",
    "    predicted[:,counter] = thisPrediction.detach().cpu().numpy() + thisCentroid\n",
    "    \n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.69562300833727), np.float64(120.5650463104248))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(data - predicted)), np.max(np.abs(data - predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " current best: (0.044626124, 0.6939485)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(predicted[channel,:], label='predicted')\n",
    "plt.plot(data[channel,:], label='original')\n",
    "residual = data - predicted\n",
    "#plt.plot(residual[channel,:])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save original and predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vImqGqzJS8Dh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/origAndPredictedLossy.npz'\n",
    "dataToSaveList = [data[:,0:failureIndex], predicted[:, 0:failureIndex]]\n",
    "np.savez_compressed(path, *dataToSaveList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaK1mJneWd4k"
   },
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rapidsAndPytorch",
   "language": "python",
   "name": "rapidsandpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
