{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O7KOU3RctXpJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cuml\n",
    "from cuml import KMeans\n",
    "from cuml.cluster import KMeans\n",
    "import cudf\n",
    "\n",
    "import sys\n",
    "#sys.path.append('//content/drive/MyDrive/Colab Notebooks/')\n",
    "#from eegUtils import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNQ1lHLY3Ij4",
    "outputId": "6ab2c55f-12de-4df9-ef9c-eb99a04cb0a4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1100367)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndataTensor = torch.tensor(data)\\nif torch.cuda.is_available():\\n  dataTensor = dataTensor.to(\\'cuda\\')\\n  print(\"Data has been moved to GPU\")\\nelse:\\n  print(\"Data is on CPU\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedData = np.load('/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/origAndPredictedSVD001_block7.npz')\n",
    "data = processedData['arr_0']\n",
    "predicted = processedData['arr_1']\n",
    "residual = predicted - data\n",
    "nChannel, nSample = data.shape\n",
    "print(data.shape)\n",
    "residual = residual.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c8xR-z_pxB6j",
    "outputId": "c37b4d79-96dc-4902-f5c4-36c579ef8bec",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "CPU times: user 42min 28s, sys: 15.6 s, total: 42min 44s\n",
      "Wall time: 42min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_clusters = 2**16\n",
    "kmeans = KMeans(n_clusters=n_clusters, verbose=6)\n",
    "kmeans.fit(residual)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(kmeans.n_iter_)\n",
    "#kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxAXnCxXSVAy"
   },
   "source": [
    "# Save KMeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v8ZQrFT2Re_U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/centroids_001_block7.npy'\n",
    "np.save(path, centroids)\n",
    "\n",
    "path = '/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/labels_001_block7.npy'\n",
    "np.save(path, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYJq6wgVSX9O"
   },
   "source": [
    "# Load CUML KMeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8PvZ3vNRJyB"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/NeuroResearch/Data/eegCompress/processedData/centroids_001_block7.npy'\n",
    "centroids = np.load(path)\n",
    "nCentroids,_ = centroids.shape\n",
    "kmeansCuml = KMeans(n_clusters=nCentroids, init=centroids, n_init=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f66AgjvxRzzz"
   },
   "outputs": [],
   "source": [
    "#kmeans.predict(residual[:,0:2].transpose())   # CUML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nuo2KzlTTDqP",
    "outputId": "a730a2cf-8c48-49db-dbe9-a6d3204499c6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n  thisInput = torch.unsqueeze(torch.tensor(predicted[:,i-numSampleInput:i]),0)\\n  with torch.no_grad():\\n    if torch.cuda.is_available():\\n      thisInput = thisInput.to(\\'cuda\\')\\n    thisOutput = model(thisInput).detach().cpu().numpy().squeeze()\\n    if np.any(np.isnan(thisOutput)):\\n      print(\"nan: \" + str(i))\\n      break\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numSampleInput = 20\n",
    "numSampleOutput = 1\n",
    "_,failureIndex = data.shape\n",
    "\n",
    "predicted = np.zeros_like(data)\n",
    "predicted[:,0:numSampleInput] = data[:,0:numSampleInput]\n",
    "\n",
    "for i in range(numSampleInput, nSample):\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    thisOutput = predicted[:,i-1]\n",
    "    thisResidual = data[:,i] - thisOutput\n",
    "    #_, index = kmeans.index.search(np.expand_dims(residual,0),1)\n",
    "    #index = int(index[0][0])\n",
    "    index = int(kmeans.predict(np.expand_dims(thisResidual, 0))[0])\n",
    "    predicted[:,i] = thisOutput + centroids[index,:]\n",
    "    if np.any(np.isnan(predicted[:,i])):\n",
    "        failureIndex = i\n",
    "        print(\"nan: \" + str(failureIndex))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "vImqGqzJS8Dh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/blue/gkalamangalam/jmark.ettinger/eegCompress/processedData/origAndPredictedLossy.npz'\n",
    "dataToSaveList = [data[:,0:failureIndex], predicted[:, 0:failureIndex]]\n",
    "np.savez_compressed(path, *dataToSaveList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaK1mJneWd4k"
   },
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "RAPIDSai-24.08",
   "language": "python",
   "name": "rapidsai-24.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
