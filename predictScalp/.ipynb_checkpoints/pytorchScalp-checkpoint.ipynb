{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d3475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef38d8",
   "metadata": {},
   "source": [
    "# PARAMETERS - GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f63db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "stftSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/freqRTheta.npz'\n",
    "timeDomainSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeDomain.npz'\n",
    "timeFreqSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeFreqRTheta.npz'\n",
    "\n",
    "modelPath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth'\n",
    "\n",
    "neptuneProject = 'jettinger35/predictScalp'\n",
    "api_token = os.environ.get('NEPTUNE_API_TOKEN')\n",
    "\n",
    "subsampleFreq = 128   # FINAL FREQUENCY IN HERTZ AFTER SUBSAMPLING\n",
    "secondsInWindow = 1\n",
    "nperseg = subsampleFreq * secondsInWindow\n",
    "noverlap = nperseg - 1\n",
    "window = ('tukey', .25)\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7fce9",
   "metadata": {},
   "source": [
    "# PARAMETERS - TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224077ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 1024\n",
    "learningRate = 1e-3\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "optChoice = 'adam'\n",
    "\n",
    "patience = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6db8c0",
   "metadata": {},
   "source": [
    "# UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7e2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT STFT FROM R,THETA TO COMPLEX\n",
    "# dim(z) = (# timesteps, # freq bins x 2 (2 reals = 1 complex))\n",
    "\n",
    "def rThetaToComplex(z):\n",
    "    rows, cols = z.shape\n",
    "    shortTermFourier = np.zeros((rows, cols // 2), dtype=np.csingle)\n",
    "    for i in range(rows):\n",
    "        for k in range(cols // 2):\n",
    "            r = z[i,k]\n",
    "            theta = z[i, (k + cols // 2)]\n",
    "            shortTermFourier[i,k] =  r * np.exp(complex(0, theta))\n",
    "    return shortTermFourier.transpose() # dim = (# freq bins, # timepoints)\n",
    "\n",
    "# CONVERT REAL STFT TO COMPLEX STFT, INVERT TO GET THE ISTFT (I.E. TIME SERIES), THEN PLOT\n",
    "\n",
    "def realSTFTtoTimeSeries(realSTFT):\n",
    "    shortTermFourierComplex = rThetaToComplex(realSTFT)\n",
    "    times, inverseShortFourier = istft(shortTermFourierComplex, \n",
    "                                       fs=subsampleFreq, \n",
    "                                       window=window, \n",
    "                                       nperseg=nperseg, \n",
    "                                       noverlap=noverlap)\n",
    "    return times, inverseShortFourier\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        return loss\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, layerOrderedDict):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(layerOrderedDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# GIVEN A LIST OF LAYER SIZES MAKE AN ORDERED DICTIONARY FOR INITIALIZING A PYTORCH NET\n",
    "\n",
    "def listToOrderedDict(sizeList):\n",
    "    n = len(sizeList)\n",
    "    tupleList = []\n",
    "    for i in range(n - 1):\n",
    "        tupleList.append(('bn%s' % str(i), nn.BatchNorm1d(sizeList[i])))\n",
    "        tupleList.append(('l%s' % str(i), nn.Linear(sizeList[i], sizeList[i+1])))\n",
    "        tupleList.append(('r%s' % str(i), nn.ReLU()))\n",
    "    return OrderedDict(tupleList[:-1])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbd749",
   "metadata": {},
   "source": [
    "# LOAD NUMPY DATA ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba4b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSwitch = 'time'\n",
    "\n",
    "if dataSwitch == 'freq':\n",
    "    # STFT DATA\n",
    "\n",
    "    npzfile = np.load(stftSavePath)\n",
    "    x_trainRTheta = npzfile['x_trainRTheta']\n",
    "    x_validRTheta = npzfile['x_validRTheta'] \n",
    "    y_trainRTheta = npzfile['y_trainRTheta'] \n",
    "    y_validRTheta = npzfile['y_validRTheta']\n",
    "\n",
    "    trainXTensor = torch.Tensor(x_trainRTheta)\n",
    "    trainYTensor = torch.Tensor(y_trainRTheta)\n",
    "    validXTensor = torch.Tensor(x_validRTheta)\n",
    "    validYTensor = torch.Tensor(y_validRTheta)\n",
    "\n",
    "elif dataSwitch == 'time':\n",
    "    # TIME DOMAIN DATA\n",
    "\n",
    "    npzfile = np.load(timeDomainSavePath)\n",
    "    xTrainTimeDomain = npzfile['xTrainTimeDomain']\n",
    "    xValidTimeDomain = npzfile['xValidTimeDomain'] \n",
    "    yTrainTimeDomain = npzfile['yTrainTimeDomain'] \n",
    "    yValidTimeDomain = npzfile['yValidTimeDomain']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrainTimeDomain)\n",
    "    trainYTensor = torch.Tensor(yTrainTimeDomain)\n",
    "    validXTensor = torch.Tensor(xValidTimeDomain)\n",
    "    validYTensor = torch.Tensor(yValidTimeDomain)\n",
    "    \n",
    "elif dataSwitch == 'timeFreq':\n",
    "    \n",
    "    npzfile = np.load(timeFreqSavePath)\n",
    "    xTrain = npzfile['x_trainTimeFreq']\n",
    "    xValid = npzfile['x_validTimeFreq'] \n",
    "    yTrain = npzfile['y_trainTimeFreq'] \n",
    "    yValid = npzfile['y_validTimeFreq']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrain)\n",
    "    trainYTensor = torch.Tensor(yTrain)\n",
    "    validXTensor = torch.Tensor(xValid)\n",
    "    validYTensor = torch.Tensor(yValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedd53c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 1]) torch.float32\n",
      "\n",
      "test: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# CREATE PYTORCH DATALOADERS\n",
    "\n",
    "trainDataset = TensorDataset(trainXTensor,trainYTensor)\n",
    "trainDataLoader = DataLoader(trainDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validDataset = TensorDataset(validXTensor,validYTensor)\n",
    "validDataLoader = DataLoader(validDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"train: \")\n",
    "for X, y in trainDataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "print(\"\\ntest: \")\n",
    "for X, y in validDataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243c05c",
   "metadata": {},
   "source": [
    "# DEFINE OR LOAD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeaad9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  3963439\n",
      "NeuralNetwork(\n",
      "  (model): Sequential(\n",
      "    (bn0): BatchNorm1d(5655, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (l0): Linear(in_features=5655, out_features=512, bias=True)\n",
      "    (r0): ReLU()\n",
      "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (l1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (r1): ReLU()\n",
      "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (l2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (r2): ReLU()\n",
      "    (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (l3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (r3): ReLU()\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (l4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (r4): ReLU()\n",
      "    (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (l5): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "modelLoadFlag = False\n",
    "\n",
    "if modelLoadFlag == True:\n",
    "    model = torch.load(modelPath)\n",
    "    bestTestLoss = test(validDataLoader, model, loss_fn)\n",
    "else:\n",
    "    # DEFINE ARCHITECTURE HERE\n",
    "    hiddenLayerSizes = [512,512,512,512,512]\n",
    "    \n",
    "    layerSizeList = [trainXTensor.shape[1]] + hiddenLayerSizes + [trainYTensor.shape[1]]\n",
    "    layerOrderedDict = listToOrderedDict(layerSizeList)\n",
    "    \n",
    "    model = NeuralNetwork(layerOrderedDict)\n",
    "    bestTestLoss = float('inf')\n",
    "    \n",
    "print(\"Number of parameters: \", count_parameters(model))\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68e5ed",
   "metadata": {},
   "source": [
    "# TRAIN (LOG DATA TO NEPTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c6012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-38\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.785791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.671459 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.798394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.703098 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.949186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.694761 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.776859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.659208 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.810638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.654525 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.708198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.643646 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.630915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.632530 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.605462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.619408 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.599026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.609313 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.568933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.612454 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.519398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.614229 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.545914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.582783 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.518834  [ 1024/176128]\n",
      "File /blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth changed during upload, restarting upload.\n",
      "Test Error: \n",
      " Avg loss: 0.569061 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "File /blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth changed during upload, restarting upload.\n",
      "loss: 0.496670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.565703 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.491970  [ 1024/176128]\n",
      "File /blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth changed during upload, restarting upload.\n",
      "Test Error: \n",
      " Avg loss: 0.556236 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.493933  [ 1024/176128]\n",
      "File /blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth changed during upload, restarting upload.\n",
      "Test Error: \n",
      " Avg loss: 0.575041 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.503037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.579026 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.500832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.559074 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.472294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525728 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.445641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.515722 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.474064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.504672 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.437803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.490759 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.455896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.494620 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.462876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.509972 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.426437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.509917 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.460489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.497480 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.472598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.470695 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.418356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.458995 \n",
      "\n",
      "File /blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth changed during upload, restarting upload.\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.417974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.460317 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.441155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.461487 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.418184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.465192 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.430960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.458580 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.397163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.473777 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.412854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.489876 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.424124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.469442 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.427473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.490328 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.407701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.524060 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.429672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.489558 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.386867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.460984 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.384722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.479462 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.422993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.484244 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.431983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.471246 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.383901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.466165 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.426712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.465883 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.407970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.479456 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.385673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.477236 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.388520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.463850 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.396524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.460622 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.424108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.467102 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.407169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.459358 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.385267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.466610 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.385664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.470371 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.397181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.456070 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.402933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446735 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.383461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451098 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.374184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.457996 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.384904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.466591 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.386100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.452167 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.383385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442717 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.367052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.462158 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.397831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.464106 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.390153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448773 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.400637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.452204 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.393628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443944 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.344715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443354 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.372647  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.449590 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.389150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450930 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.375273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445318 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.381710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446418 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.397980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448903 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.355734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446134 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.368665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.457553 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.384515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.457716 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.390388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446457 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.365209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447293 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.379728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441809 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.345130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442763 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.358664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446136 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.384446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442289 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.344093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433786 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.350202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450177 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.372671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.467292 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.358868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446809 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.363243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446788 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.345864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448785 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.344031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435486 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.355411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431010 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.349504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438755 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.358244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433000 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.350654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430041 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.357283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428333 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.360047  [ 1024/176128]\n",
      "File /blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth changed during upload, restarting upload.\n",
      "Test Error: \n",
      " Avg loss: 0.428275 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.349871  [ 1024/176128]\n",
      "File /blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth changed during upload, restarting upload.\n",
      "Test Error: \n",
      " Avg loss: 0.432872 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.340251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438122 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.344104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445686 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.363789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441021 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.364809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434114 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.346368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439816 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.336255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447990 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.329835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450103 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.358172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426316 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.358923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441822 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.328616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449755 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.340040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438028 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.335214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427930 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.325779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437088 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.324058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442193 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.351934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437305 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.343428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430416 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.330686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427919 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.333042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429245 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.319369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428255 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.328060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422265 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.318294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423614 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.327373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429907 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.338141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426627 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.326891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439734 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.318162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447955 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.347887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433335 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.319808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434004 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.351051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442665 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.301729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439972 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.341091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424510 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.320162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428224 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.326896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436139 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.330239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441471 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.322709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.463633 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.333959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.468750 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.345218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447471 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.336744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432180 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.309909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436685 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.331095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434193 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.312181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432207 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.332579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433558 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.321965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445860 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.349235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435607 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.318493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426891 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.310367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437869 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.326474  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.444657 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.320114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443278 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.324964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431989 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.295382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442085 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.317445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442030 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.309708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440049 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.319654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451621 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.335003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440925 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.302831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.456185 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.319612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.471013 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.333275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443099 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.313689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431301 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.312940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.458454 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.327468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.467819 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.337837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449052 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.314500  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443052 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.302988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.468901 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.363924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.466116 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.358961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442872 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.301629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445826 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.319584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.457387 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.317518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445830 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.334324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429193 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.316508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431797 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.333006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433403 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.304602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439924 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.316380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449042 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.300548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449767 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.295191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436365 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.310970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432972 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.303885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432696 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.302705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428651 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.290837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428217 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.315359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432447 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.299271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441645 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.318016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447660 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.305663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438839 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.307519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431141 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.284927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435342 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.281870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440798 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.310025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431707 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.286993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421639 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.305111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421616 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.338308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419876 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.307260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429878 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.302396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.452530 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.313439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.456424 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.280730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.454369 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.295929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442154 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.285262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436240 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.330716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429963 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.297754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421068 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.285759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439993 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.329145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435604 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.305793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428033 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.288282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439335 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.287754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445657 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.279685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432012 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.275633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423613 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.284662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429352 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.285447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430256 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.271537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423464 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.284388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422834 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.276010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416327 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.285502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416145 \n",
      "\n",
      "File /blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/model.pth changed during upload, restarting upload.\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.266468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421462 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.290492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425088 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.297478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427473 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.284622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431109 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.269444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428684 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.280124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430425 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.268945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434817 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.286540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433069 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.283170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428902 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.269865  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.427216 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.284873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424280 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.284874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428494 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.294687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430328 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.259541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431326 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.274872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441163 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.300072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442284 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.290209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442110 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.277450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447465 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.296263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420851 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.274245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417835 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.291397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425814 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.278494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434766 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.279381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447531 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.293651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.455803 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.292666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436447 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.293777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422690 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.284774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421054 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.267989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431459 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.297547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435463 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.295549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430990 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.283381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425670 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.278057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430888 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.283355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435515 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.266765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441356 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.273022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436298 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.264638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426514 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.270677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428476 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.286825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436763 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.291261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430678 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.268439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421074 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.266385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419379 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.275231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418663 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.263539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417952 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.264177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424230 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.263590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434611 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.244244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439348 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.253693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432183 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.277519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428026 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.279189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436924 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.279012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435629 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.268747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425287 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.266699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421238 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.272237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427319 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.282995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427088 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.266109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419968 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.262282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419170 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.268360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425547 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.247212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420247 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.253882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416002 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.262066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418800 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.261849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421214 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.262952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422597 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.264533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421163 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.261573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418193 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.260312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429284 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.252563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439158 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.267294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424952 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.253877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429440 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.262000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434811 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.281876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428200 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.257099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439451 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.271333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447966 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.260239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439120 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.276771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434576 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.250286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427955 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.238189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428370 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.260659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430405 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.254635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432435 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.243207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432116 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.247759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435118 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.269690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426814 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.252890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423152 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.275535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438025 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.267175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438470 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.289305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427143 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.268291  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.435879 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.253830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445693 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.268470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450919 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.268768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449884 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.253484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451789 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.262866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.454556 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.269376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.456553 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.262425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.455581 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.296194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432332 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.258738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417903 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.252898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445546 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.257580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448013 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.287403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441026 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.277093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.454919 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.296064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.460134 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.262929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.458253 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.268899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451474 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.272667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436901 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.264096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433764 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.293392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428182 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.274742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424990 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.249315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436283 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.276093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444977 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.248737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436636 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.279610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435888 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.259420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440193 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.279379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436464 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.261846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428009 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.256745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421906 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.247238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427691 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.247135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431670 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.247019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433807 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.258278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438487 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.232413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435979 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.262383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431907 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.240459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431779 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.230323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438757 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.243017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438702 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.242074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437114 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.250080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436080 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.243213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440075 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.269833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437646 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.233611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446448 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.279244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438535 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.273433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423188 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.239742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424579 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.248229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436597 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.270084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433467 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.258992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429294 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.216858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441820 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.247782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446899 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.251246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436714 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.236573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433300 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.249708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435022 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.257203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438448 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.252211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436935 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.227711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435597 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.250709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447965 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.251184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.453976 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.262086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438745 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.250094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431927 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.225884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430158 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.250287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431207 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.227815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435453 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.273442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439122 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.253835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434921 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.230739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434425 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.256856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435127 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.242201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430462 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.234392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424000 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.240635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425486 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.244128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436159 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.242617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441535 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.268104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429111 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.233367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431033 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.268508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441524 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.249622  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.431998 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.239950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434813 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.248537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435667 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.242548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438722 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.242686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440368 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.245840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447765 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.254146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440764 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.251678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438535 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.245620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.452647 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.258068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.458303 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.256306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449209 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.249030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448948 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.249940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444613 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.236827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435104 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.257186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432278 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.252649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447169 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.240398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.459673 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.240382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451094 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.231553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432313 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.229120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426802 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.249517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426240 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.243610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424593 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.246407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431160 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.225963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438516 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.230526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436596 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.226643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437301 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.252030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432494 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.245276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425744 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.222258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423802 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.230434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442290 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.237396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.456151 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.250659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443892 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.247271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442612 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.234677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447604 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.237953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449092 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.226933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446369 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.244914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440939 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.237781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440118 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.250947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439811 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.228081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434786 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.222851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435143 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.229148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437748 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.231207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438218 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.222940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441758 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.229837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441522 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.240345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429345 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.224958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425819 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.208227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427634 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.226217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429047 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.240328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430062 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.210390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433293 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.208726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443079 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.223077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450900 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.238040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436791 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.252589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425956 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.242284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428177 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.232610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441441 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.247996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446071 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.247195  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444810 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.234767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444565 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.249267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442979 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.239828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435621 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.235342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428955 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.219254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433513 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.220359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441992 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.249936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437188 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.236850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424492 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.241532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426309 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.219477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431125 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.230634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431154 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.223345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438896 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.219375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446363 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.232339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441333 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.246764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434510 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.232717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432811 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.239437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434823 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.242600  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.431669 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.216975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428032 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.226260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426094 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.225602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428637 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.212749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432346 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.211170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427683 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.221471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430941 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.209838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438244 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.220357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434989 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.230520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425635 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.218952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424059 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.206468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428510 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.235565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428220 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.213498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439801 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.215246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450761 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.224470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442599 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.221995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429327 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.228456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424406 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.235373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425701 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.226718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423913 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.223812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426181 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.217963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430660 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.230706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426490 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.210491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435262 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.218094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445306 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.252389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438315 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.235171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437967 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.221783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449032 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.228049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.455716 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.206986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450455 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.212381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444674 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.211539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441428 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.216548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435745 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.227771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430659 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.223567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441706 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.210497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438494 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.209980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429230 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.215824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424979 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.215396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433445 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.211096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441292 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.233330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432839 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.219151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434762 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.211554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432523 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.217108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434056 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.220610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433906 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.214705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437052 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.226723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441463 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.216204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442229 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.215858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434842 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.220659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429306 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.213638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432269 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.222122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432746 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.203147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436722 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.210262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446250 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.234937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445654 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.228194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436870 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.214416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437029 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.203254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433204 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.203379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428936 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.220777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430690 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.223907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435595 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.219312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438662 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.230121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432560 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.217048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428642 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.202352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433808 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.214673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438125 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.205267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438300 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.210679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435707 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.214714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434005 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.203469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438747 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.211656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433672 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.232060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441582 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.215733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445604 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.228250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448058 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.216536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443906 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.221161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439845 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.214644  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.436579 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.218296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432867 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.200213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438601 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.210870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440955 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.239245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429293 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.207692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421125 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.221346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421364 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.207417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427429 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.214976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427898 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.203220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432818 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.204925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440566 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.208163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432812 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.201980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426889 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.200218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449073 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.225931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447654 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.221710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431387 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.202191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438460 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.205617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443399 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.207104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443687 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.216643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444204 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.201472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442932 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.207113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431186 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.206350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428079 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.224661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425838 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.199290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423256 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.211932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430210 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.217311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430458 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.216418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432562 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.232659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430648 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.207020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437963 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.198063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450553 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.221767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451664 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.205578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441846 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.213576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430528 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.216994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430320 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.196126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432008 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.208696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432508 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.253942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427332 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.216903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421096 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.195243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433633 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.225513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446289 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.234329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438443 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.223193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431781 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.207087  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433213 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.217474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435992 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.210684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437046 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.210587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432997 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.209495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422398 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.230746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424776 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.206271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435730 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.204872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446294 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.220116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448862 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.225479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436934 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.209350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430877 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.196440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429317 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.197760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429908 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.225279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433641 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.216252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437427 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.208016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433166 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.186094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430567 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.191626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436179 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.207683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437629 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.211462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438720 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.209684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450605 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.205646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.467815 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.227732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.466093 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.200630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.456978 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.211309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449202 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.223882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441468 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.206485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431947 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.207095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431579 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.194124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438811 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.197480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439337 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.197692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439624 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.200495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436078 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.187988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431017 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.195652  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.422674 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.183154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418199 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.191963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427070 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.184497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428829 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.192561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425303 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.194530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427660 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.206102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428492 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.205702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421696 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.202257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414489 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.208108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418501 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.192381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422316 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.204092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423308 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.206344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423725 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.200406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428569 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.194299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429124 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.189033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424462 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.193790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422152 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.176954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428379 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.202808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436325 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.187678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442448 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.201135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432448 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.196798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428354 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.207115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432650 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.202799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429524 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.208120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427229 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.194246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434519 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.218938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431912 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.201049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432688 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.205645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435566 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.199143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440094 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.192866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432368 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.192137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425837 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.194761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433747 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.201036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444849 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.217465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437768 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.193377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432501 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.190047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433926 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.201021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429080 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.209137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422722 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.204960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433612 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.209343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438155 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.207714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431334 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.193553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421600 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.188079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421726 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.187419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432925 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.195570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441716 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.201373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441287 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.194627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439038 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.196281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444139 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.197014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445627 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.192659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440237 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.199879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429877 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.184217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421768 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.185623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419770 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.187712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422434 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.177092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425855 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.181502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424584 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.189185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427330 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.219322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428840 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.205069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434594 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.184686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440477 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.201002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438265 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.194582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433555 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.199638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428562 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.182139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427855 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.191913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428167 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.195958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424794 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.190286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423078 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.181923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431819 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.195559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443055 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.198083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444514 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.187541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443362 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.187876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442572 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.183978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436162 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.186900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429490 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.194938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424646 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.204844  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.424096 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.188484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424863 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.182601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430158 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.172430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434591 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.186775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439654 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.188390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442608 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.193349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432895 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.202286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427469 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.190328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429188 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.200970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430225 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.196655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428684 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.207203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428939 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.199822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432347 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.197512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435444 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.214077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430142 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.182401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427244 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.187118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435179 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.205616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436455 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.221011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429485 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.175455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428667 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.196234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436930 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.195983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.455585 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.199034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.465751 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.200136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450764 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.198122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426684 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.170912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426360 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.192798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440663 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.194752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448056 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.191996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448194 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.182267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440953 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.201721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436339 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.194706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431723 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.203066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426765 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.178682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432311 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.183105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439804 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.200816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434336 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.191595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434304 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.201279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437063 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.195161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438857 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.186806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445931 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.195977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.452169 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.190897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.448021 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.191643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430847 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.182447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430872 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.171994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.450423 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.187424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.461210 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.201030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.457165 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.196001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.449241 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.171157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446945 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.182359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440025 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.184435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434278 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.189901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435839 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.165974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436435 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.188097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433820 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.172634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430575 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.176675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431185 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.183107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431630 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.179929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439519 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.179421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447746 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.206757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446346 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.190818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439866 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.176107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430336 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.175022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422169 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.179909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420286 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.191325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421881 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.183145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424242 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.182605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427194 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.180336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432705 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.176579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442539 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.182318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445395 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.188725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438605 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.191405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429430 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.181045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421319 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.185295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419730 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.178149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419660 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.183211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423377 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.179710  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.427440 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.197350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423839 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.184767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424756 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.182609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434243 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.185167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436005 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.179861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428940 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.178168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421936 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.187545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417902 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.178779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417815 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.175325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417533 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.193459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414833 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.183471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417427 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.182863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423520 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.181604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429809 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.181242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433977 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.182584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436390 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.193022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436411 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.178959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431733 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.183986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425988 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.178084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425679 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.176175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424477 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.177485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425374 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.197145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430859 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.188260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429666 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.191602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434578 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.192631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444083 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.188698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440081 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.193859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432615 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.199022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439567 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.186666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438851 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.211601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428498 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.171064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430267 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.172076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438065 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.180805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433913 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.195593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435018 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.165802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.459018 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.194659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.464498 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.196639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438454 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.172779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429480 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.173815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443096 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.190037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451527 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.201059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443147 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.191687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444821 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.169063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451036 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.183958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442311 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.202864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430102 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.174590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430180 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.182981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427813 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.188702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429177 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.177323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438224 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.196200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442821 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.182068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439012 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.191710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429704 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.189384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432294 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.187084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441777 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.198534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431614 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.203559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423001 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.170190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426985 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.192544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430885 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.174338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425819 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.199405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423377 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.175495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429206 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.190494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425813 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.174452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419437 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.177265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417117 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.164615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416537 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.185061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417266 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.174781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421761 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.168906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428195 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.177738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429377 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.168211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436398 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.182045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438907 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.170870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432868 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.182747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429660 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.175947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427076 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.179799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427947 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.179507  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.430616 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.171545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439273 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.180478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443657 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.173128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437322 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.185712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432462 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.162115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431447 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.182252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427272 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.179003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423864 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.177867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422300 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.163318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425350 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.171322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425914 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.173958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424549 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.175354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424722 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.179386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423282 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.195036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418420 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.164526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421939 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.172043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422780 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.169367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428336 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.183928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437615 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.167455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442043 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.176758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437866 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.196214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426866 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.174145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430408 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.169421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434473 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.199622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435044 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.192926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436566 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.200544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430614 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.181510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427252 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.178427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434920 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.187369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438939 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.168312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439344 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.196381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434038 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.191182  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430984 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.173874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428053 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.184160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431446 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.176505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435654 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.180222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432419 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.176833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428983 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.169922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435315 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.194804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437006 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.188011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434652 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.192320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439681 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.193538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443138 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.196739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431270 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.201216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422482 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.177147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427951 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.178774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428014 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.206529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420739 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.175849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425318 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.167157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433637 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.172189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435666 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.166395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437747 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.163652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438702 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.168364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434394 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.167492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430037 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.158559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424278 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.180488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420011 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.160255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420008 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.166579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430410 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.168793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436072 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.173916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435533 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.170589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432235 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.156346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429916 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.168516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426725 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.162702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424846 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.169193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423964 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.158748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425894 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.176631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428931 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.159798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430860 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.176585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426135 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.166964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427865 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.166137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429668 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.169402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431827 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.161530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435258 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.194215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436005 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.171080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434335 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.171868  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.432592 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.176533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429280 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.166706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421145 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.171213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418850 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.181665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425380 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.187751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431377 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.174396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432648 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.168103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433304 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.182755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432330 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.174494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425170 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.165471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416981 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.178162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416500 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.176365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418640 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.179110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423032 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.160315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429551 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.172615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428680 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.165690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426168 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.169147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423565 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.152939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422395 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.173108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421780 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.173149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420891 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.168328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422578 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.165813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427447 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.167685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435955 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.166348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437294 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.164332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433712 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.178094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428349 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.177893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421604 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.156544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414763 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.164127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411323 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.173788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411420 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.178306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413398 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.166096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417350 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.162797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424860 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.172990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421348 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.171944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414768 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.148742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415663 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.164774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420676 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.184031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417184 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.180506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413926 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.175740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418019 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.177378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423916 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.171356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428582 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.159556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431317 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.160713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431187 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.165327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426950 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.165698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427231 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.172200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428855 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.166974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426755 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.159824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423955 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.166301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420032 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.146696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424931 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.185805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428883 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.181268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430631 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.179390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433843 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.176092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427323 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.168638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419685 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.172768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428924 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.179777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429460 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.170288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426867 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.171192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426608 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.174144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425735 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.159587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430685 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.156912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435758 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.171113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432222 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.153247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432203 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.162781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428737 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.163216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418619 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.161572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412962 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.167521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416452 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.161797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422965 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.177470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426033 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.162718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428803 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.176831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428327 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.163172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420062 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.155338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417529 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.160273  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.421442 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.175090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422983 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.175769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422013 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.171246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426556 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.160220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434510 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.157798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438334 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.172008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435303 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.164086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426654 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.149910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421051 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.168482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415171 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.171402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412862 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.172107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419341 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.169324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422198 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.170311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417325 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.166918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419930 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.168445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431672 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.176347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443652 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.165388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.454697 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.188249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442330 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.170734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425160 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.157059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423162 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.176308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425417 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.173928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424031 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.179506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425882 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.178200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424519 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.184073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427673 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.170061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427865 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.171375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434016 \n",
      "\n",
      "Epoch 1001\n",
      "-------------------------------\n",
      "loss: 0.170575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436662 \n",
      "\n",
      "Epoch 1002\n",
      "-------------------------------\n",
      "loss: 0.172007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431636 \n",
      "\n",
      "Epoch 1003\n",
      "-------------------------------\n",
      "loss: 0.175667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425505 \n",
      "\n",
      "Epoch 1004\n",
      "-------------------------------\n",
      "loss: 0.168350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421904 \n",
      "\n",
      "Epoch 1005\n",
      "-------------------------------\n",
      "loss: 0.145347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420475 \n",
      "\n",
      "Epoch 1006\n",
      "-------------------------------\n",
      "loss: 0.186375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421481 \n",
      "\n",
      "Epoch 1007\n",
      "-------------------------------\n",
      "loss: 0.168798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421987 \n",
      "\n",
      "Epoch 1008\n",
      "-------------------------------\n",
      "loss: 0.176845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419849 \n",
      "\n",
      "Epoch 1009\n",
      "-------------------------------\n",
      "loss: 0.161067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418713 \n",
      "\n",
      "Epoch 1010\n",
      "-------------------------------\n",
      "loss: 0.163224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423971 \n",
      "\n",
      "Epoch 1011\n",
      "-------------------------------\n",
      "loss: 0.154758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427066 \n",
      "\n",
      "Epoch 1012\n",
      "-------------------------------\n",
      "loss: 0.155096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430475 \n",
      "\n",
      "Epoch 1013\n",
      "-------------------------------\n",
      "loss: 0.169973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431161 \n",
      "\n",
      "Epoch 1014\n",
      "-------------------------------\n",
      "loss: 0.155187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435445 \n",
      "\n",
      "Epoch 1015\n",
      "-------------------------------\n",
      "loss: 0.160448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435674 \n",
      "\n",
      "Epoch 1016\n",
      "-------------------------------\n",
      "loss: 0.167444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429303 \n",
      "\n",
      "Epoch 1017\n",
      "-------------------------------\n",
      "loss: 0.164525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427564 \n",
      "\n",
      "Epoch 1018\n",
      "-------------------------------\n",
      "loss: 0.156574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431129 \n",
      "\n",
      "Epoch 1019\n",
      "-------------------------------\n",
      "loss: 0.191788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430207 \n",
      "\n",
      "Epoch 1020\n",
      "-------------------------------\n",
      "loss: 0.158571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430345 \n",
      "\n",
      "Epoch 1021\n",
      "-------------------------------\n",
      "loss: 0.155896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430716 \n",
      "\n",
      "Epoch 1022\n",
      "-------------------------------\n",
      "loss: 0.173474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430580 \n",
      "\n",
      "Epoch 1023\n",
      "-------------------------------\n",
      "loss: 0.161317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427408 \n",
      "\n",
      "Epoch 1024\n",
      "-------------------------------\n",
      "loss: 0.174911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419348 \n",
      "\n",
      "Epoch 1025\n",
      "-------------------------------\n",
      "loss: 0.158985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415036 \n",
      "\n",
      "Epoch 1026\n",
      "-------------------------------\n",
      "loss: 0.169577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418095 \n",
      "\n",
      "Epoch 1027\n",
      "-------------------------------\n",
      "loss: 0.156575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421014 \n",
      "\n",
      "Epoch 1028\n",
      "-------------------------------\n",
      "loss: 0.165668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420800 \n",
      "\n",
      "Epoch 1029\n",
      "-------------------------------\n",
      "loss: 0.166284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423926 \n",
      "\n",
      "Epoch 1030\n",
      "-------------------------------\n",
      "loss: 0.165488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429748 \n",
      "\n",
      "Epoch 1031\n",
      "-------------------------------\n",
      "loss: 0.172938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433617 \n",
      "\n",
      "Epoch 1032\n",
      "-------------------------------\n",
      "loss: 0.159219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433429 \n",
      "\n",
      "Epoch 1033\n",
      "-------------------------------\n",
      "loss: 0.172636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427635 \n",
      "\n",
      "Epoch 1034\n",
      "-------------------------------\n",
      "loss: 0.163471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418774 \n",
      "\n",
      "Epoch 1035\n",
      "-------------------------------\n",
      "loss: 0.157328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419737 \n",
      "\n",
      "Epoch 1036\n",
      "-------------------------------\n",
      "loss: 0.174975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420482 \n",
      "\n",
      "Epoch 1037\n",
      "-------------------------------\n",
      "loss: 0.155316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423552 \n",
      "\n",
      "Epoch 1038\n",
      "-------------------------------\n",
      "loss: 0.153749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428117 \n",
      "\n",
      "Epoch 1039\n",
      "-------------------------------\n",
      "loss: 0.168531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430419 \n",
      "\n",
      "Epoch 1040\n",
      "-------------------------------\n",
      "loss: 0.158544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432652 \n",
      "\n",
      "Epoch 1041\n",
      "-------------------------------\n",
      "loss: 0.150326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434766 \n",
      "\n",
      "Epoch 1042\n",
      "-------------------------------\n",
      "loss: 0.160205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434479 \n",
      "\n",
      "Epoch 1043\n",
      "-------------------------------\n",
      "loss: 0.160460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438645 \n",
      "\n",
      "Epoch 1044\n",
      "-------------------------------\n",
      "loss: 0.144042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445896 \n",
      "\n",
      "Epoch 1045\n",
      "-------------------------------\n",
      "loss: 0.161738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438115 \n",
      "\n",
      "Epoch 1046\n",
      "-------------------------------\n",
      "loss: 0.158567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427051 \n",
      "\n",
      "Epoch 1047\n",
      "-------------------------------\n",
      "loss: 0.153721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422554 \n",
      "\n",
      "Epoch 1048\n",
      "-------------------------------\n",
      "loss: 0.162901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420803 \n",
      "\n",
      "Epoch 1049\n",
      "-------------------------------\n",
      "loss: 0.174395  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.420810 \n",
      "\n",
      "Epoch 1050\n",
      "-------------------------------\n",
      "loss: 0.168744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419323 \n",
      "\n",
      "Epoch 1051\n",
      "-------------------------------\n",
      "loss: 0.175445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419946 \n",
      "\n",
      "Epoch 1052\n",
      "-------------------------------\n",
      "loss: 0.167165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421642 \n",
      "\n",
      "Epoch 1053\n",
      "-------------------------------\n",
      "loss: 0.162105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419766 \n",
      "\n",
      "Epoch 1054\n",
      "-------------------------------\n",
      "loss: 0.162652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421751 \n",
      "\n",
      "Epoch 1055\n",
      "-------------------------------\n",
      "loss: 0.172453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428838 \n",
      "\n",
      "Epoch 1056\n",
      "-------------------------------\n",
      "loss: 0.165781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429174 \n",
      "\n",
      "Epoch 1057\n",
      "-------------------------------\n",
      "loss: 0.159444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419349 \n",
      "\n",
      "Epoch 1058\n",
      "-------------------------------\n",
      "loss: 0.177274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419794 \n",
      "\n",
      "Epoch 1059\n",
      "-------------------------------\n",
      "loss: 0.159741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433265 \n",
      "\n",
      "Epoch 1060\n",
      "-------------------------------\n",
      "loss: 0.172429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437325 \n",
      "\n",
      "Epoch 1061\n",
      "-------------------------------\n",
      "loss: 0.173223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428728 \n",
      "\n",
      "Epoch 1062\n",
      "-------------------------------\n",
      "loss: 0.158335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424390 \n",
      "\n",
      "Epoch 1063\n",
      "-------------------------------\n",
      "loss: 0.163458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426436 \n",
      "\n",
      "Epoch 1064\n",
      "-------------------------------\n",
      "loss: 0.185266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422305 \n",
      "\n",
      "Epoch 1065\n",
      "-------------------------------\n",
      "loss: 0.158426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414607 \n",
      "\n",
      "Epoch 1066\n",
      "-------------------------------\n",
      "loss: 0.172707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408960 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 1067\n",
      "-------------------------------\n",
      "loss: 0.152573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415619 \n",
      "\n",
      "Epoch 1068\n",
      "-------------------------------\n",
      "loss: 0.187526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419519 \n",
      "\n",
      "Epoch 1069\n",
      "-------------------------------\n",
      "loss: 0.154235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423188 \n",
      "\n",
      "Epoch 1070\n",
      "-------------------------------\n",
      "loss: 0.149008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427314 \n",
      "\n",
      "Epoch 1071\n",
      "-------------------------------\n",
      "loss: 0.164246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427842 \n",
      "\n",
      "Epoch 1072\n",
      "-------------------------------\n",
      "loss: 0.156805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424135 \n",
      "\n",
      "Epoch 1073\n",
      "-------------------------------\n",
      "loss: 0.157485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416769 \n",
      "\n",
      "Epoch 1074\n",
      "-------------------------------\n",
      "loss: 0.151623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417509 \n",
      "\n",
      "Epoch 1075\n",
      "-------------------------------\n",
      "loss: 0.148505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420811 \n",
      "\n",
      "Epoch 1076\n",
      "-------------------------------\n",
      "loss: 0.164532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420562 \n",
      "\n",
      "Epoch 1077\n",
      "-------------------------------\n",
      "loss: 0.167233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419419 \n",
      "\n",
      "Epoch 1078\n",
      "-------------------------------\n",
      "loss: 0.163236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422702 \n",
      "\n",
      "Epoch 1079\n",
      "-------------------------------\n",
      "loss: 0.151576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422497 \n",
      "\n",
      "Epoch 1080\n",
      "-------------------------------\n",
      "loss: 0.146771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425258 \n",
      "\n",
      "Epoch 1081\n",
      "-------------------------------\n",
      "loss: 0.166567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424965 \n",
      "\n",
      "Epoch 1082\n",
      "-------------------------------\n",
      "loss: 0.165336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425038 \n",
      "\n",
      "Epoch 1083\n",
      "-------------------------------\n",
      "loss: 0.151165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424410 \n",
      "\n",
      "Epoch 1084\n",
      "-------------------------------\n",
      "loss: 0.151950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421013 \n",
      "\n",
      "Epoch 1085\n",
      "-------------------------------\n",
      "loss: 0.169524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418804 \n",
      "\n",
      "Epoch 1086\n",
      "-------------------------------\n",
      "loss: 0.159458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418419 \n",
      "\n",
      "Epoch 1087\n",
      "-------------------------------\n",
      "loss: 0.169914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420610 \n",
      "\n",
      "Epoch 1088\n",
      "-------------------------------\n",
      "loss: 0.159072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420008 \n",
      "\n",
      "Epoch 1089\n",
      "-------------------------------\n",
      "loss: 0.155474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417524 \n",
      "\n",
      "Epoch 1090\n",
      "-------------------------------\n",
      "loss: 0.163074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416563 \n",
      "\n",
      "Epoch 1091\n",
      "-------------------------------\n",
      "loss: 0.178415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421764 \n",
      "\n",
      "Epoch 1092\n",
      "-------------------------------\n",
      "loss: 0.147946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425883 \n",
      "\n",
      "Epoch 1093\n",
      "-------------------------------\n",
      "loss: 0.165795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423577 \n",
      "\n",
      "Epoch 1094\n",
      "-------------------------------\n",
      "loss: 0.153571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419812 \n",
      "\n",
      "Epoch 1095\n",
      "-------------------------------\n",
      "loss: 0.145962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420888 \n",
      "\n",
      "Epoch 1096\n",
      "-------------------------------\n",
      "loss: 0.170405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425732 \n",
      "\n",
      "Epoch 1097\n",
      "-------------------------------\n",
      "loss: 0.149977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424770 \n",
      "\n",
      "Epoch 1098\n",
      "-------------------------------\n",
      "loss: 0.146316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421157 \n",
      "\n",
      "Epoch 1099\n",
      "-------------------------------\n",
      "loss: 0.166848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422459 \n",
      "\n",
      "Epoch 1100\n",
      "-------------------------------\n",
      "loss: 0.157247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433644 \n",
      "\n",
      "Epoch 1101\n",
      "-------------------------------\n",
      "loss: 0.161220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436577 \n",
      "\n",
      "Epoch 1102\n",
      "-------------------------------\n",
      "loss: 0.173359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423248 \n",
      "\n",
      "Epoch 1103\n",
      "-------------------------------\n",
      "loss: 0.152714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420506 \n",
      "\n",
      "Epoch 1104\n",
      "-------------------------------\n",
      "loss: 0.154642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430083 \n",
      "\n",
      "Epoch 1105\n",
      "-------------------------------\n",
      "loss: 0.159236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432535 \n",
      "\n",
      "Epoch 1106\n",
      "-------------------------------\n",
      "loss: 0.153956  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428054 \n",
      "\n",
      "Epoch 1107\n",
      "-------------------------------\n",
      "loss: 0.153715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420093 \n",
      "\n",
      "Epoch 1108\n",
      "-------------------------------\n",
      "loss: 0.163291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415125 \n",
      "\n",
      "Epoch 1109\n",
      "-------------------------------\n",
      "loss: 0.156291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418057 \n",
      "\n",
      "Epoch 1110\n",
      "-------------------------------\n",
      "loss: 0.150136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421050 \n",
      "\n",
      "Epoch 1111\n",
      "-------------------------------\n",
      "loss: 0.168746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416002 \n",
      "\n",
      "Epoch 1112\n",
      "-------------------------------\n",
      "loss: 0.159761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410880 \n",
      "\n",
      "Epoch 1113\n",
      "-------------------------------\n",
      "loss: 0.157259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414717 \n",
      "\n",
      "Epoch 1114\n",
      "-------------------------------\n",
      "loss: 0.168107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418012 \n",
      "\n",
      "Epoch 1115\n",
      "-------------------------------\n",
      "loss: 0.154278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424845 \n",
      "\n",
      "Epoch 1116\n",
      "-------------------------------\n",
      "loss: 0.155578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425821 \n",
      "\n",
      "Epoch 1117\n",
      "-------------------------------\n",
      "loss: 0.152420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427672 \n",
      "\n",
      "Epoch 1118\n",
      "-------------------------------\n",
      "loss: 0.166471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423242 \n",
      "\n",
      "Epoch 1119\n",
      "-------------------------------\n",
      "loss: 0.155771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425220 \n",
      "\n",
      "Epoch 1120\n",
      "-------------------------------\n",
      "loss: 0.165037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428255 \n",
      "\n",
      "Epoch 1121\n",
      "-------------------------------\n",
      "loss: 0.176583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431374 \n",
      "\n",
      "Epoch 1122\n",
      "-------------------------------\n",
      "loss: 0.146651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435052 \n",
      "\n",
      "Epoch 1123\n",
      "-------------------------------\n",
      "loss: 0.169178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430398 \n",
      "\n",
      "Epoch 1124\n",
      "-------------------------------\n",
      "loss: 0.165335  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.422242 \n",
      "\n",
      "Epoch 1125\n",
      "-------------------------------\n",
      "loss: 0.157197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418191 \n",
      "\n",
      "Epoch 1126\n",
      "-------------------------------\n",
      "loss: 0.150813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417847 \n",
      "\n",
      "Epoch 1127\n",
      "-------------------------------\n",
      "loss: 0.154003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415103 \n",
      "\n",
      "Epoch 1128\n",
      "-------------------------------\n",
      "loss: 0.167062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414540 \n",
      "\n",
      "Epoch 1129\n",
      "-------------------------------\n",
      "loss: 0.159669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420969 \n",
      "\n",
      "Epoch 1130\n",
      "-------------------------------\n",
      "loss: 0.177370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422230 \n",
      "\n",
      "Epoch 1131\n",
      "-------------------------------\n",
      "loss: 0.177372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424874 \n",
      "\n",
      "Epoch 1132\n",
      "-------------------------------\n",
      "loss: 0.178258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427206 \n",
      "\n",
      "Epoch 1133\n",
      "-------------------------------\n",
      "loss: 0.158526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424838 \n",
      "\n",
      "Epoch 1134\n",
      "-------------------------------\n",
      "loss: 0.155812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418105 \n",
      "\n",
      "Epoch 1135\n",
      "-------------------------------\n",
      "loss: 0.168118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420374 \n",
      "\n",
      "Epoch 1136\n",
      "-------------------------------\n",
      "loss: 0.172547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426090 \n",
      "\n",
      "Epoch 1137\n",
      "-------------------------------\n",
      "loss: 0.166814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428234 \n",
      "\n",
      "Epoch 1138\n",
      "-------------------------------\n",
      "loss: 0.163828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430407 \n",
      "\n",
      "Epoch 1139\n",
      "-------------------------------\n",
      "loss: 0.146803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433514 \n",
      "\n",
      "Epoch 1140\n",
      "-------------------------------\n",
      "loss: 0.157251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435687 \n",
      "\n",
      "Epoch 1141\n",
      "-------------------------------\n",
      "loss: 0.146665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440110 \n",
      "\n",
      "Epoch 1142\n",
      "-------------------------------\n",
      "loss: 0.155292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439119 \n",
      "\n",
      "Epoch 1143\n",
      "-------------------------------\n",
      "loss: 0.149959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441737 \n",
      "\n",
      "Epoch 1144\n",
      "-------------------------------\n",
      "loss: 0.151409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441155 \n",
      "\n",
      "Epoch 1145\n",
      "-------------------------------\n",
      "loss: 0.153710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435996 \n",
      "\n",
      "Epoch 1146\n",
      "-------------------------------\n",
      "loss: 0.166231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427341 \n",
      "\n",
      "Epoch 1147\n",
      "-------------------------------\n",
      "loss: 0.164384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420296 \n",
      "\n",
      "Epoch 1148\n",
      "-------------------------------\n",
      "loss: 0.165255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417412 \n",
      "\n",
      "Epoch 1149\n",
      "-------------------------------\n",
      "loss: 0.162968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424749 \n",
      "\n",
      "Epoch 1150\n",
      "-------------------------------\n",
      "loss: 0.155054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434053 \n",
      "\n",
      "Epoch 1151\n",
      "-------------------------------\n",
      "loss: 0.155183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435925 \n",
      "\n",
      "Epoch 1152\n",
      "-------------------------------\n",
      "loss: 0.163201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433530 \n",
      "\n",
      "Epoch 1153\n",
      "-------------------------------\n",
      "loss: 0.163546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430283 \n",
      "\n",
      "Epoch 1154\n",
      "-------------------------------\n",
      "loss: 0.157659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424514 \n",
      "\n",
      "Epoch 1155\n",
      "-------------------------------\n",
      "loss: 0.150097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415856 \n",
      "\n",
      "Epoch 1156\n",
      "-------------------------------\n",
      "loss: 0.136073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413939 \n",
      "\n",
      "Epoch 1157\n",
      "-------------------------------\n",
      "loss: 0.157919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415596 \n",
      "\n",
      "Epoch 1158\n",
      "-------------------------------\n",
      "loss: 0.165433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416214 \n",
      "\n",
      "Epoch 1159\n",
      "-------------------------------\n",
      "loss: 0.154046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419282 \n",
      "\n",
      "Epoch 1160\n",
      "-------------------------------\n",
      "loss: 0.162543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424976 \n",
      "\n",
      "Epoch 1161\n",
      "-------------------------------\n",
      "loss: 0.172018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424820 \n",
      "\n",
      "Epoch 1162\n",
      "-------------------------------\n",
      "loss: 0.148293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425695 \n",
      "\n",
      "Epoch 1163\n",
      "-------------------------------\n",
      "loss: 0.147247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427510 \n",
      "\n",
      "Epoch 1164\n",
      "-------------------------------\n",
      "loss: 0.152725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428099 \n",
      "\n",
      "Epoch 1165\n",
      "-------------------------------\n",
      "loss: 0.162409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423624 \n",
      "\n",
      "Epoch 1166\n",
      "-------------------------------\n",
      "loss: 0.150926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419495 \n",
      "\n",
      "Epoch 1167\n",
      "-------------------------------\n",
      "loss: 0.147427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420071 \n",
      "\n",
      "Epoch 1168\n",
      "-------------------------------\n",
      "loss: 0.153527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430182 \n",
      "\n",
      "Epoch 1169\n",
      "-------------------------------\n",
      "loss: 0.175362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432320 \n",
      "\n",
      "Epoch 1170\n",
      "-------------------------------\n",
      "loss: 0.163614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428312 \n",
      "\n",
      "Epoch 1171\n",
      "-------------------------------\n",
      "loss: 0.155400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431601 \n",
      "\n",
      "Epoch 1172\n",
      "-------------------------------\n",
      "loss: 0.173996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436035 \n",
      "\n",
      "Epoch 1173\n",
      "-------------------------------\n",
      "loss: 0.175148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433034 \n",
      "\n",
      "Epoch 1174\n",
      "-------------------------------\n",
      "loss: 0.178306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421714 \n",
      "\n",
      "Epoch 1175\n",
      "-------------------------------\n",
      "loss: 0.162973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419150 \n",
      "\n",
      "Epoch 1176\n",
      "-------------------------------\n",
      "loss: 0.167441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424455 \n",
      "\n",
      "Epoch 1177\n",
      "-------------------------------\n",
      "loss: 0.152138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429153 \n",
      "\n",
      "Epoch 1178\n",
      "-------------------------------\n",
      "loss: 0.162850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425587 \n",
      "\n",
      "Epoch 1179\n",
      "-------------------------------\n",
      "loss: 0.167585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420577 \n",
      "\n",
      "Epoch 1180\n",
      "-------------------------------\n",
      "loss: 0.169025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426654 \n",
      "\n",
      "Epoch 1181\n",
      "-------------------------------\n",
      "loss: 0.155430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433866 \n",
      "\n",
      "Epoch 1182\n",
      "-------------------------------\n",
      "loss: 0.168196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432800 \n",
      "\n",
      "Epoch 1183\n",
      "-------------------------------\n",
      "loss: 0.180509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431423 \n",
      "\n",
      "Epoch 1184\n",
      "-------------------------------\n",
      "loss: 0.162683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430031 \n",
      "\n",
      "Epoch 1185\n",
      "-------------------------------\n",
      "loss: 0.162392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431326 \n",
      "\n",
      "Epoch 1186\n",
      "-------------------------------\n",
      "loss: 0.152980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435612 \n",
      "\n",
      "Epoch 1187\n",
      "-------------------------------\n",
      "loss: 0.160940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435262 \n",
      "\n",
      "Epoch 1188\n",
      "-------------------------------\n",
      "loss: 0.152119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430291 \n",
      "\n",
      "Epoch 1189\n",
      "-------------------------------\n",
      "loss: 0.161647  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421767 \n",
      "\n",
      "Epoch 1190\n",
      "-------------------------------\n",
      "loss: 0.152314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417105 \n",
      "\n",
      "Epoch 1191\n",
      "-------------------------------\n",
      "loss: 0.163991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419096 \n",
      "\n",
      "Epoch 1192\n",
      "-------------------------------\n",
      "loss: 0.142673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422846 \n",
      "\n",
      "Epoch 1193\n",
      "-------------------------------\n",
      "loss: 0.166955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423464 \n",
      "\n",
      "Epoch 1194\n",
      "-------------------------------\n",
      "loss: 0.157780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421974 \n",
      "\n",
      "Epoch 1195\n",
      "-------------------------------\n",
      "loss: 0.150265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420046 \n",
      "\n",
      "Epoch 1196\n",
      "-------------------------------\n",
      "loss: 0.158970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421631 \n",
      "\n",
      "Epoch 1197\n",
      "-------------------------------\n",
      "loss: 0.153210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427779 \n",
      "\n",
      "Epoch 1198\n",
      "-------------------------------\n",
      "loss: 0.153189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425400 \n",
      "\n",
      "Epoch 1199\n",
      "-------------------------------\n",
      "loss: 0.163129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420294 \n",
      "\n",
      "Epoch 1200\n",
      "-------------------------------\n",
      "loss: 0.155646  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.420393 \n",
      "\n",
      "Epoch 1201\n",
      "-------------------------------\n",
      "loss: 0.153771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423028 \n",
      "\n",
      "Epoch 1202\n",
      "-------------------------------\n",
      "loss: 0.148642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430280 \n",
      "\n",
      "Epoch 1203\n",
      "-------------------------------\n",
      "loss: 0.164922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436423 \n",
      "\n",
      "Epoch 1204\n",
      "-------------------------------\n",
      "loss: 0.156044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432864 \n",
      "\n",
      "Epoch 1205\n",
      "-------------------------------\n",
      "loss: 0.170166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422788 \n",
      "\n",
      "Epoch 1206\n",
      "-------------------------------\n",
      "loss: 0.157097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416275 \n",
      "\n",
      "Epoch 1207\n",
      "-------------------------------\n",
      "loss: 0.159012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414700 \n",
      "\n",
      "Epoch 1208\n",
      "-------------------------------\n",
      "loss: 0.152723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419165 \n",
      "\n",
      "Epoch 1209\n",
      "-------------------------------\n",
      "loss: 0.172096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417371 \n",
      "\n",
      "Epoch 1210\n",
      "-------------------------------\n",
      "loss: 0.169097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417833 \n",
      "\n",
      "Epoch 1211\n",
      "-------------------------------\n",
      "loss: 0.153650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428233 \n",
      "\n",
      "Epoch 1212\n",
      "-------------------------------\n",
      "loss: 0.148044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438271 \n",
      "\n",
      "Epoch 1213\n",
      "-------------------------------\n",
      "loss: 0.165972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434793 \n",
      "\n",
      "Epoch 1214\n",
      "-------------------------------\n",
      "loss: 0.149855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431441 \n",
      "\n",
      "Epoch 1215\n",
      "-------------------------------\n",
      "loss: 0.153924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429386 \n",
      "\n",
      "Epoch 1216\n",
      "-------------------------------\n",
      "loss: 0.150451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429409 \n",
      "\n",
      "Epoch 1217\n",
      "-------------------------------\n",
      "loss: 0.156349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429959 \n",
      "\n",
      "Epoch 1218\n",
      "-------------------------------\n",
      "loss: 0.155924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429362 \n",
      "\n",
      "Epoch 1219\n",
      "-------------------------------\n",
      "loss: 0.152922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427412 \n",
      "\n",
      "Epoch 1220\n",
      "-------------------------------\n",
      "loss: 0.154597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422529 \n",
      "\n",
      "Epoch 1221\n",
      "-------------------------------\n",
      "loss: 0.151249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421467 \n",
      "\n",
      "Epoch 1222\n",
      "-------------------------------\n",
      "loss: 0.144265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422976 \n",
      "\n",
      "Epoch 1223\n",
      "-------------------------------\n",
      "loss: 0.142973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425507 \n",
      "\n",
      "Epoch 1224\n",
      "-------------------------------\n",
      "loss: 0.166818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425615 \n",
      "\n",
      "Epoch 1225\n",
      "-------------------------------\n",
      "loss: 0.156228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422746 \n",
      "\n",
      "Epoch 1226\n",
      "-------------------------------\n",
      "loss: 0.159390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418765 \n",
      "\n",
      "Epoch 1227\n",
      "-------------------------------\n",
      "loss: 0.154092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418633 \n",
      "\n",
      "Epoch 1228\n",
      "-------------------------------\n",
      "loss: 0.145227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422617 \n",
      "\n",
      "Epoch 1229\n",
      "-------------------------------\n",
      "loss: 0.144505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425677 \n",
      "\n",
      "Epoch 1230\n",
      "-------------------------------\n",
      "loss: 0.137503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429278 \n",
      "\n",
      "Epoch 1231\n",
      "-------------------------------\n",
      "loss: 0.152181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428481 \n",
      "\n",
      "Epoch 1232\n",
      "-------------------------------\n",
      "loss: 0.171504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422196 \n",
      "\n",
      "Epoch 1233\n",
      "-------------------------------\n",
      "loss: 0.144291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422702 \n",
      "\n",
      "Epoch 1234\n",
      "-------------------------------\n",
      "loss: 0.146814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425213 \n",
      "\n",
      "Epoch 1235\n",
      "-------------------------------\n",
      "loss: 0.148109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424631 \n",
      "\n",
      "Epoch 1236\n",
      "-------------------------------\n",
      "loss: 0.180788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425055 \n",
      "\n",
      "Epoch 1237\n",
      "-------------------------------\n",
      "loss: 0.147731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426364 \n",
      "\n",
      "Epoch 1238\n",
      "-------------------------------\n",
      "loss: 0.155151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426414 \n",
      "\n",
      "Epoch 1239\n",
      "-------------------------------\n",
      "loss: 0.158830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421070 \n",
      "\n",
      "Epoch 1240\n",
      "-------------------------------\n",
      "loss: 0.149545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421553 \n",
      "\n",
      "Epoch 1241\n",
      "-------------------------------\n",
      "loss: 0.155663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431413 \n",
      "\n",
      "Epoch 1242\n",
      "-------------------------------\n",
      "loss: 0.168640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430742 \n",
      "\n",
      "Epoch 1243\n",
      "-------------------------------\n",
      "loss: 0.163184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427400 \n",
      "\n",
      "Epoch 1244\n",
      "-------------------------------\n",
      "loss: 0.167308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427628 \n",
      "\n",
      "Epoch 1245\n",
      "-------------------------------\n",
      "loss: 0.164068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432146 \n",
      "\n",
      "Epoch 1246\n",
      "-------------------------------\n",
      "loss: 0.164958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426097 \n",
      "\n",
      "Epoch 1247\n",
      "-------------------------------\n",
      "loss: 0.159608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415771 \n",
      "\n",
      "Epoch 1248\n",
      "-------------------------------\n",
      "loss: 0.161773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414825 \n",
      "\n",
      "Epoch 1249\n",
      "-------------------------------\n",
      "loss: 0.163383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423457 \n",
      "\n",
      "Epoch 1250\n",
      "-------------------------------\n",
      "loss: 0.178556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426749 \n",
      "\n",
      "Epoch 1251\n",
      "-------------------------------\n",
      "loss: 0.178164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423595 \n",
      "\n",
      "Epoch 1252\n",
      "-------------------------------\n",
      "loss: 0.158870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422067 \n",
      "\n",
      "Epoch 1253\n",
      "-------------------------------\n",
      "loss: 0.140905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424694 \n",
      "\n",
      "Epoch 1254\n",
      "-------------------------------\n",
      "loss: 0.156357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423874 \n",
      "\n",
      "Epoch 1255\n",
      "-------------------------------\n",
      "loss: 0.150455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419420 \n",
      "\n",
      "Epoch 1256\n",
      "-------------------------------\n",
      "loss: 0.147026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420631 \n",
      "\n",
      "Epoch 1257\n",
      "-------------------------------\n",
      "loss: 0.155749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421203 \n",
      "\n",
      "Epoch 1258\n",
      "-------------------------------\n",
      "loss: 0.148397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418408 \n",
      "\n",
      "Epoch 1259\n",
      "-------------------------------\n",
      "loss: 0.153068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413518 \n",
      "\n",
      "Epoch 1260\n",
      "-------------------------------\n",
      "loss: 0.141474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409774 \n",
      "\n",
      "Epoch 1261\n",
      "-------------------------------\n",
      "loss: 0.152336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411694 \n",
      "\n",
      "Epoch 1262\n",
      "-------------------------------\n",
      "loss: 0.162052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421283 \n",
      "\n",
      "Epoch 1263\n",
      "-------------------------------\n",
      "loss: 0.154130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432616 \n",
      "\n",
      "Epoch 1264\n",
      "-------------------------------\n",
      "loss: 0.157588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439891 \n",
      "\n",
      "Epoch 1265\n",
      "-------------------------------\n",
      "loss: 0.157401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441344 \n",
      "\n",
      "Epoch 1266\n",
      "-------------------------------\n",
      "loss: 0.155242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431936 \n",
      "\n",
      "Epoch 1267\n",
      "-------------------------------\n",
      "loss: 0.151334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423449 \n",
      "\n",
      "Epoch 1268\n",
      "-------------------------------\n",
      "loss: 0.139997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419279 \n",
      "\n",
      "Epoch 1269\n",
      "-------------------------------\n",
      "loss: 0.156668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420292 \n",
      "\n",
      "Epoch 1270\n",
      "-------------------------------\n",
      "loss: 0.145315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422670 \n",
      "\n",
      "Epoch 1271\n",
      "-------------------------------\n",
      "loss: 0.157748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433059 \n",
      "\n",
      "Epoch 1272\n",
      "-------------------------------\n",
      "loss: 0.160960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437721 \n",
      "\n",
      "Epoch 1273\n",
      "-------------------------------\n",
      "loss: 0.144550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438813 \n",
      "\n",
      "Epoch 1274\n",
      "-------------------------------\n",
      "loss: 0.150028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433300 \n",
      "\n",
      "Epoch 1275\n",
      "-------------------------------\n",
      "loss: 0.162522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430329 \n",
      "\n",
      "Epoch 1276\n",
      "-------------------------------\n",
      "loss: 0.147947  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.426506 \n",
      "\n",
      "Epoch 1277\n",
      "-------------------------------\n",
      "loss: 0.160131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426464 \n",
      "\n",
      "Epoch 1278\n",
      "-------------------------------\n",
      "loss: 0.152761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430502 \n",
      "\n",
      "Epoch 1279\n",
      "-------------------------------\n",
      "loss: 0.146123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429856 \n",
      "\n",
      "Epoch 1280\n",
      "-------------------------------\n",
      "loss: 0.159075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426552 \n",
      "\n",
      "Epoch 1281\n",
      "-------------------------------\n",
      "loss: 0.150989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422564 \n",
      "\n",
      "Epoch 1282\n",
      "-------------------------------\n",
      "loss: 0.159125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419744 \n",
      "\n",
      "Epoch 1283\n",
      "-------------------------------\n",
      "loss: 0.140955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423446 \n",
      "\n",
      "Epoch 1284\n",
      "-------------------------------\n",
      "loss: 0.155521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424565 \n",
      "\n",
      "Epoch 1285\n",
      "-------------------------------\n",
      "loss: 0.150875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423421 \n",
      "\n",
      "Epoch 1286\n",
      "-------------------------------\n",
      "loss: 0.141159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420644 \n",
      "\n",
      "Epoch 1287\n",
      "-------------------------------\n",
      "loss: 0.147241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419264 \n",
      "\n",
      "Epoch 1288\n",
      "-------------------------------\n",
      "loss: 0.139400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425348 \n",
      "\n",
      "Epoch 1289\n",
      "-------------------------------\n",
      "loss: 0.138430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435860 \n",
      "\n",
      "Epoch 1290\n",
      "-------------------------------\n",
      "loss: 0.181999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429601 \n",
      "\n",
      "Epoch 1291\n",
      "-------------------------------\n",
      "loss: 0.161466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424054 \n",
      "\n",
      "Epoch 1292\n",
      "-------------------------------\n",
      "loss: 0.154917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428221 \n",
      "\n",
      "Epoch 1293\n",
      "-------------------------------\n",
      "loss: 0.171493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423229 \n",
      "\n",
      "Epoch 1294\n",
      "-------------------------------\n",
      "loss: 0.149799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423546 \n",
      "\n",
      "Epoch 1295\n",
      "-------------------------------\n",
      "loss: 0.173040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426197 \n",
      "\n",
      "Epoch 1296\n",
      "-------------------------------\n",
      "loss: 0.150996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422512 \n",
      "\n",
      "Epoch 1297\n",
      "-------------------------------\n",
      "loss: 0.159657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416459 \n",
      "\n",
      "Epoch 1298\n",
      "-------------------------------\n",
      "loss: 0.155547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413300 \n",
      "\n",
      "Epoch 1299\n",
      "-------------------------------\n",
      "loss: 0.152697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411034 \n",
      "\n",
      "Epoch 1300\n",
      "-------------------------------\n",
      "loss: 0.147628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418590 \n",
      "\n",
      "Epoch 1301\n",
      "-------------------------------\n",
      "loss: 0.156869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426565 \n",
      "\n",
      "Epoch 1302\n",
      "-------------------------------\n",
      "loss: 0.163399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425463 \n",
      "\n",
      "Epoch 1303\n",
      "-------------------------------\n",
      "loss: 0.155364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422117 \n",
      "\n",
      "Epoch 1304\n",
      "-------------------------------\n",
      "loss: 0.147085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422020 \n",
      "\n",
      "Epoch 1305\n",
      "-------------------------------\n",
      "loss: 0.161756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422703 \n",
      "\n",
      "Epoch 1306\n",
      "-------------------------------\n",
      "loss: 0.140428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429200 \n",
      "\n",
      "Epoch 1307\n",
      "-------------------------------\n",
      "loss: 0.153460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436232 \n",
      "\n",
      "Epoch 1308\n",
      "-------------------------------\n",
      "loss: 0.147679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436647 \n",
      "\n",
      "Epoch 1309\n",
      "-------------------------------\n",
      "loss: 0.145316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425415 \n",
      "\n",
      "Epoch 1310\n",
      "-------------------------------\n",
      "loss: 0.149245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412606 \n",
      "\n",
      "Epoch 1311\n",
      "-------------------------------\n",
      "loss: 0.139305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419535 \n",
      "\n",
      "Epoch 1312\n",
      "-------------------------------\n",
      "loss: 0.140146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422368 \n",
      "\n",
      "Epoch 1313\n",
      "-------------------------------\n",
      "loss: 0.162746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419084 \n",
      "\n",
      "Epoch 1314\n",
      "-------------------------------\n",
      "loss: 0.141217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415190 \n",
      "\n",
      "Epoch 1315\n",
      "-------------------------------\n",
      "loss: 0.139650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418347 \n",
      "\n",
      "Epoch 1316\n",
      "-------------------------------\n",
      "loss: 0.148845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422657 \n",
      "\n",
      "Epoch 1317\n",
      "-------------------------------\n",
      "loss: 0.150637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421562 \n",
      "\n",
      "Epoch 1318\n",
      "-------------------------------\n",
      "loss: 0.147514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421288 \n",
      "\n",
      "Epoch 1319\n",
      "-------------------------------\n",
      "loss: 0.145596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416627 \n",
      "\n",
      "Epoch 1320\n",
      "-------------------------------\n",
      "loss: 0.150299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413958 \n",
      "\n",
      "Epoch 1321\n",
      "-------------------------------\n",
      "loss: 0.146255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418424 \n",
      "\n",
      "Epoch 1322\n",
      "-------------------------------\n",
      "loss: 0.147631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418422 \n",
      "\n",
      "Epoch 1323\n",
      "-------------------------------\n",
      "loss: 0.136014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417316 \n",
      "\n",
      "Epoch 1324\n",
      "-------------------------------\n",
      "loss: 0.158127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421804 \n",
      "\n",
      "Epoch 1325\n",
      "-------------------------------\n",
      "loss: 0.160293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424613 \n",
      "\n",
      "Epoch 1326\n",
      "-------------------------------\n",
      "loss: 0.148799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426241 \n",
      "\n",
      "Epoch 1327\n",
      "-------------------------------\n",
      "loss: 0.150226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419377 \n",
      "\n",
      "Epoch 1328\n",
      "-------------------------------\n",
      "loss: 0.145963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415129 \n",
      "\n",
      "Epoch 1329\n",
      "-------------------------------\n",
      "loss: 0.153339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411644 \n",
      "\n",
      "Epoch 1330\n",
      "-------------------------------\n",
      "loss: 0.134700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412471 \n",
      "\n",
      "Epoch 1331\n",
      "-------------------------------\n",
      "loss: 0.141265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416178 \n",
      "\n",
      "Epoch 1332\n",
      "-------------------------------\n",
      "loss: 0.145042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416049 \n",
      "\n",
      "Epoch 1333\n",
      "-------------------------------\n",
      "loss: 0.140414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417844 \n",
      "\n",
      "Epoch 1334\n",
      "-------------------------------\n",
      "loss: 0.145571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417549 \n",
      "\n",
      "Epoch 1335\n",
      "-------------------------------\n",
      "loss: 0.150952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425786 \n",
      "\n",
      "Epoch 1336\n",
      "-------------------------------\n",
      "loss: 0.148752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428470 \n",
      "\n",
      "Epoch 1337\n",
      "-------------------------------\n",
      "loss: 0.147724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424377 \n",
      "\n",
      "Epoch 1338\n",
      "-------------------------------\n",
      "loss: 0.141317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421114 \n",
      "\n",
      "Epoch 1339\n",
      "-------------------------------\n",
      "loss: 0.139159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419451 \n",
      "\n",
      "Epoch 1340\n",
      "-------------------------------\n",
      "loss: 0.145111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417945 \n",
      "\n",
      "Epoch 1341\n",
      "-------------------------------\n",
      "loss: 0.134161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419040 \n",
      "\n",
      "Epoch 1342\n",
      "-------------------------------\n",
      "loss: 0.136466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417479 \n",
      "\n",
      "Epoch 1343\n",
      "-------------------------------\n",
      "loss: 0.151591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418494 \n",
      "\n",
      "Epoch 1344\n",
      "-------------------------------\n",
      "loss: 0.147456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419470 \n",
      "\n",
      "Epoch 1345\n",
      "-------------------------------\n",
      "loss: 0.137301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423336 \n",
      "\n",
      "Epoch 1346\n",
      "-------------------------------\n",
      "loss: 0.140730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425910 \n",
      "\n",
      "Epoch 1347\n",
      "-------------------------------\n",
      "loss: 0.146337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424950 \n",
      "\n",
      "Epoch 1348\n",
      "-------------------------------\n",
      "loss: 0.157363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417122 \n",
      "\n",
      "Epoch 1349\n",
      "-------------------------------\n",
      "loss: 0.136804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414468 \n",
      "\n",
      "Epoch 1350\n",
      "-------------------------------\n",
      "loss: 0.144302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417219 \n",
      "\n",
      "Epoch 1351\n",
      "-------------------------------\n",
      "loss: 0.138819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427999 \n",
      "\n",
      "Epoch 1352\n",
      "-------------------------------\n",
      "loss: 0.142235  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.442375 \n",
      "\n",
      "Epoch 1353\n",
      "-------------------------------\n",
      "loss: 0.161074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443429 \n",
      "\n",
      "Epoch 1354\n",
      "-------------------------------\n",
      "loss: 0.150619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431215 \n",
      "\n",
      "Epoch 1355\n",
      "-------------------------------\n",
      "loss: 0.157542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426028 \n",
      "\n",
      "Epoch 1356\n",
      "-------------------------------\n",
      "loss: 0.148741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426475 \n",
      "\n",
      "Epoch 1357\n",
      "-------------------------------\n",
      "loss: 0.150875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430575 \n",
      "\n",
      "Epoch 1358\n",
      "-------------------------------\n",
      "loss: 0.149247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437191 \n",
      "\n",
      "Epoch 1359\n",
      "-------------------------------\n",
      "loss: 0.141487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438981 \n",
      "\n",
      "Epoch 1360\n",
      "-------------------------------\n",
      "loss: 0.147265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430286 \n",
      "\n",
      "Epoch 1361\n",
      "-------------------------------\n",
      "loss: 0.150743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427231 \n",
      "\n",
      "Epoch 1362\n",
      "-------------------------------\n",
      "loss: 0.142070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423871 \n",
      "\n",
      "Epoch 1363\n",
      "-------------------------------\n",
      "loss: 0.143217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419955 \n",
      "\n",
      "Epoch 1364\n",
      "-------------------------------\n",
      "loss: 0.154207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420874 \n",
      "\n",
      "Epoch 1365\n",
      "-------------------------------\n",
      "loss: 0.148997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426955 \n",
      "\n",
      "Epoch 1366\n",
      "-------------------------------\n",
      "loss: 0.174647  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435304 \n",
      "\n",
      "Epoch 1367\n",
      "-------------------------------\n",
      "loss: 0.154455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433252 \n",
      "\n",
      "Epoch 1368\n",
      "-------------------------------\n",
      "loss: 0.156230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429221 \n",
      "\n",
      "Epoch 1369\n",
      "-------------------------------\n",
      "loss: 0.151669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428423 \n",
      "\n",
      "Epoch 1370\n",
      "-------------------------------\n",
      "loss: 0.149474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429911 \n",
      "\n",
      "Epoch 1371\n",
      "-------------------------------\n",
      "loss: 0.159021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425930 \n",
      "\n",
      "Epoch 1372\n",
      "-------------------------------\n",
      "loss: 0.146775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422539 \n",
      "\n",
      "Epoch 1373\n",
      "-------------------------------\n",
      "loss: 0.155431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418694 \n",
      "\n",
      "Epoch 1374\n",
      "-------------------------------\n",
      "loss: 0.141180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417245 \n",
      "\n",
      "Epoch 1375\n",
      "-------------------------------\n",
      "loss: 0.155640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423464 \n",
      "\n",
      "Epoch 1376\n",
      "-------------------------------\n",
      "loss: 0.155004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434988 \n",
      "\n",
      "Epoch 1377\n",
      "-------------------------------\n",
      "loss: 0.176476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438131 \n",
      "\n",
      "Epoch 1378\n",
      "-------------------------------\n",
      "loss: 0.145724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428911 \n",
      "\n",
      "Epoch 1379\n",
      "-------------------------------\n",
      "loss: 0.157033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429379 \n",
      "\n",
      "Epoch 1380\n",
      "-------------------------------\n",
      "loss: 0.148406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436829 \n",
      "\n",
      "Epoch 1381\n",
      "-------------------------------\n",
      "loss: 0.152541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436141 \n",
      "\n",
      "Epoch 1382\n",
      "-------------------------------\n",
      "loss: 0.157196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426694 \n",
      "\n",
      "Epoch 1383\n",
      "-------------------------------\n",
      "loss: 0.148004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419980 \n",
      "\n",
      "Epoch 1384\n",
      "-------------------------------\n",
      "loss: 0.158284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419737 \n",
      "\n",
      "Epoch 1385\n",
      "-------------------------------\n",
      "loss: 0.139528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430893 \n",
      "\n",
      "Epoch 1386\n",
      "-------------------------------\n",
      "loss: 0.151929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443568 \n",
      "\n",
      "Epoch 1387\n",
      "-------------------------------\n",
      "loss: 0.154282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440207 \n",
      "\n",
      "Epoch 1388\n",
      "-------------------------------\n",
      "loss: 0.137079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427386 \n",
      "\n",
      "Epoch 1389\n",
      "-------------------------------\n",
      "loss: 0.144285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417776 \n",
      "\n",
      "Epoch 1390\n",
      "-------------------------------\n",
      "loss: 0.156264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419454 \n",
      "\n",
      "Epoch 1391\n",
      "-------------------------------\n",
      "loss: 0.149570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425055 \n",
      "\n",
      "Epoch 1392\n",
      "-------------------------------\n",
      "loss: 0.152847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419000 \n",
      "\n",
      "Epoch 1393\n",
      "-------------------------------\n",
      "loss: 0.134107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414908 \n",
      "\n",
      "Epoch 1394\n",
      "-------------------------------\n",
      "loss: 0.138314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415788 \n",
      "\n",
      "Epoch 1395\n",
      "-------------------------------\n",
      "loss: 0.155841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418821 \n",
      "\n",
      "Epoch 1396\n",
      "-------------------------------\n",
      "loss: 0.146329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422522 \n",
      "\n",
      "Epoch 1397\n",
      "-------------------------------\n",
      "loss: 0.155470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422151 \n",
      "\n",
      "Epoch 1398\n",
      "-------------------------------\n",
      "loss: 0.146695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417877 \n",
      "\n",
      "Epoch 1399\n",
      "-------------------------------\n",
      "loss: 0.144939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413541 \n",
      "\n",
      "Epoch 1400\n",
      "-------------------------------\n",
      "loss: 0.131096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411463 \n",
      "\n",
      "Epoch 1401\n",
      "-------------------------------\n",
      "loss: 0.141304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412596 \n",
      "\n",
      "Epoch 1402\n",
      "-------------------------------\n",
      "loss: 0.160047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416582 \n",
      "\n",
      "Epoch 1403\n",
      "-------------------------------\n",
      "loss: 0.152591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417409 \n",
      "\n",
      "Epoch 1404\n",
      "-------------------------------\n",
      "loss: 0.145366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415482 \n",
      "\n",
      "Epoch 1405\n",
      "-------------------------------\n",
      "loss: 0.145600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418824 \n",
      "\n",
      "Epoch 1406\n",
      "-------------------------------\n",
      "loss: 0.142811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425402 \n",
      "\n",
      "Epoch 1407\n",
      "-------------------------------\n",
      "loss: 0.137083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426865 \n",
      "\n",
      "Epoch 1408\n",
      "-------------------------------\n",
      "loss: 0.155024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422434 \n",
      "\n",
      "Epoch 1409\n",
      "-------------------------------\n",
      "loss: 0.136827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421586 \n",
      "\n",
      "Epoch 1410\n",
      "-------------------------------\n",
      "loss: 0.159693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422735 \n",
      "\n",
      "Epoch 1411\n",
      "-------------------------------\n",
      "loss: 0.147710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422745 \n",
      "\n",
      "Epoch 1412\n",
      "-------------------------------\n",
      "loss: 0.141807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425416 \n",
      "\n",
      "Epoch 1413\n",
      "-------------------------------\n",
      "loss: 0.162240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425861 \n",
      "\n",
      "Epoch 1414\n",
      "-------------------------------\n",
      "loss: 0.151030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423703 \n",
      "\n",
      "Epoch 1415\n",
      "-------------------------------\n",
      "loss: 0.146176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420802 \n",
      "\n",
      "Epoch 1416\n",
      "-------------------------------\n",
      "loss: 0.138670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421407 \n",
      "\n",
      "Epoch 1417\n",
      "-------------------------------\n",
      "loss: 0.146577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428759 \n",
      "\n",
      "Epoch 1418\n",
      "-------------------------------\n",
      "loss: 0.156338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428015 \n",
      "\n",
      "Epoch 1419\n",
      "-------------------------------\n",
      "loss: 0.158671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420339 \n",
      "\n",
      "Epoch 1420\n",
      "-------------------------------\n",
      "loss: 0.143056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413901 \n",
      "\n",
      "Epoch 1421\n",
      "-------------------------------\n",
      "loss: 0.162735  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412572 \n",
      "\n",
      "Epoch 1422\n",
      "-------------------------------\n",
      "loss: 0.134382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414431 \n",
      "\n",
      "Epoch 1423\n",
      "-------------------------------\n",
      "loss: 0.162386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418849 \n",
      "\n",
      "Epoch 1424\n",
      "-------------------------------\n",
      "loss: 0.152472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421474 \n",
      "\n",
      "Epoch 1425\n",
      "-------------------------------\n",
      "loss: 0.143351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421682 \n",
      "\n",
      "Epoch 1426\n",
      "-------------------------------\n",
      "loss: 0.144669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427827 \n",
      "\n",
      "Epoch 1427\n",
      "-------------------------------\n",
      "loss: 0.138003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435959 \n",
      "\n",
      "Epoch 1428\n",
      "-------------------------------\n",
      "loss: 0.145732  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.439404 \n",
      "\n",
      "Epoch 1429\n",
      "-------------------------------\n",
      "loss: 0.152784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435344 \n",
      "\n",
      "Epoch 1430\n",
      "-------------------------------\n",
      "loss: 0.144740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430065 \n",
      "\n",
      "Epoch 1431\n",
      "-------------------------------\n",
      "loss: 0.147832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422141 \n",
      "\n",
      "Epoch 1432\n",
      "-------------------------------\n",
      "loss: 0.132119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416917 \n",
      "\n",
      "Epoch 1433\n",
      "-------------------------------\n",
      "loss: 0.144784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414187 \n",
      "\n",
      "Epoch 1434\n",
      "-------------------------------\n",
      "loss: 0.148499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414901 \n",
      "\n",
      "Epoch 1435\n",
      "-------------------------------\n",
      "loss: 0.155860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418549 \n",
      "\n",
      "Epoch 1436\n",
      "-------------------------------\n",
      "loss: 0.152219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421397 \n",
      "\n",
      "Epoch 1437\n",
      "-------------------------------\n",
      "loss: 0.142519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422794 \n",
      "\n",
      "Epoch 1438\n",
      "-------------------------------\n",
      "loss: 0.139646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426874 \n",
      "\n",
      "Epoch 1439\n",
      "-------------------------------\n",
      "loss: 0.138424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427863 \n",
      "\n",
      "Epoch 1440\n",
      "-------------------------------\n",
      "loss: 0.129391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421473 \n",
      "\n",
      "Epoch 1441\n",
      "-------------------------------\n",
      "loss: 0.148177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412832 \n",
      "\n",
      "Epoch 1442\n",
      "-------------------------------\n",
      "loss: 0.130113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415216 \n",
      "\n",
      "Epoch 1443\n",
      "-------------------------------\n",
      "loss: 0.130537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421965 \n",
      "\n",
      "Epoch 1444\n",
      "-------------------------------\n",
      "loss: 0.142738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422970 \n",
      "\n",
      "Epoch 1445\n",
      "-------------------------------\n",
      "loss: 0.151384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417120 \n",
      "\n",
      "Epoch 1446\n",
      "-------------------------------\n",
      "loss: 0.150928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420454 \n",
      "\n",
      "Epoch 1447\n",
      "-------------------------------\n",
      "loss: 0.140251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421727 \n",
      "\n",
      "Epoch 1448\n",
      "-------------------------------\n",
      "loss: 0.134281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423262 \n",
      "\n",
      "Epoch 1449\n",
      "-------------------------------\n",
      "loss: 0.137857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421973 \n",
      "\n",
      "Epoch 1450\n",
      "-------------------------------\n",
      "loss: 0.131860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425663 \n",
      "\n",
      "Epoch 1451\n",
      "-------------------------------\n",
      "loss: 0.144428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427500 \n",
      "\n",
      "Epoch 1452\n",
      "-------------------------------\n",
      "loss: 0.153138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424042 \n",
      "\n",
      "Epoch 1453\n",
      "-------------------------------\n",
      "loss: 0.145723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421232 \n",
      "\n",
      "Epoch 1454\n",
      "-------------------------------\n",
      "loss: 0.134156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418313 \n",
      "\n",
      "Epoch 1455\n",
      "-------------------------------\n",
      "loss: 0.130667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419485 \n",
      "\n",
      "Epoch 1456\n",
      "-------------------------------\n",
      "loss: 0.155807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416125 \n",
      "\n",
      "Epoch 1457\n",
      "-------------------------------\n",
      "loss: 0.141948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414837 \n",
      "\n",
      "Epoch 1458\n",
      "-------------------------------\n",
      "loss: 0.141247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418643 \n",
      "\n",
      "Epoch 1459\n",
      "-------------------------------\n",
      "loss: 0.150400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422673 \n",
      "\n",
      "Epoch 1460\n",
      "-------------------------------\n",
      "loss: 0.138246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421997 \n",
      "\n",
      "Epoch 1461\n",
      "-------------------------------\n",
      "loss: 0.160409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415946 \n",
      "\n",
      "Epoch 1462\n",
      "-------------------------------\n",
      "loss: 0.151702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415527 \n",
      "\n",
      "Epoch 1463\n",
      "-------------------------------\n",
      "loss: 0.167434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415668 \n",
      "\n",
      "Epoch 1464\n",
      "-------------------------------\n",
      "loss: 0.132874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413109 \n",
      "\n",
      "Epoch 1465\n",
      "-------------------------------\n",
      "loss: 0.135486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411956 \n",
      "\n",
      "Epoch 1466\n",
      "-------------------------------\n",
      "loss: 0.133930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416130 \n",
      "\n",
      "Epoch 1467\n",
      "-------------------------------\n",
      "loss: 0.152648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421210 \n",
      "\n",
      "Epoch 1468\n",
      "-------------------------------\n",
      "loss: 0.148238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429717 \n",
      "\n",
      "Epoch 1469\n",
      "-------------------------------\n",
      "loss: 0.145855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438252 \n",
      "\n",
      "Epoch 1470\n",
      "-------------------------------\n",
      "loss: 0.133426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440235 \n",
      "\n",
      "Epoch 1471\n",
      "-------------------------------\n",
      "loss: 0.143206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431627 \n",
      "\n",
      "Epoch 1472\n",
      "-------------------------------\n",
      "loss: 0.133605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422567 \n",
      "\n",
      "Epoch 1473\n",
      "-------------------------------\n",
      "loss: 0.145120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419140 \n",
      "\n",
      "Epoch 1474\n",
      "-------------------------------\n",
      "loss: 0.141491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420548 \n",
      "\n",
      "Epoch 1475\n",
      "-------------------------------\n",
      "loss: 0.139926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417664 \n",
      "\n",
      "Epoch 1476\n",
      "-------------------------------\n",
      "loss: 0.135472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411189 \n",
      "\n",
      "Epoch 1477\n",
      "-------------------------------\n",
      "loss: 0.137994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409922 \n",
      "\n",
      "Epoch 1478\n",
      "-------------------------------\n",
      "loss: 0.153974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413286 \n",
      "\n",
      "Epoch 1479\n",
      "-------------------------------\n",
      "loss: 0.152760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413059 \n",
      "\n",
      "Epoch 1480\n",
      "-------------------------------\n",
      "loss: 0.154063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413559 \n",
      "\n",
      "Epoch 1481\n",
      "-------------------------------\n",
      "loss: 0.143814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421569 \n",
      "\n",
      "Epoch 1482\n",
      "-------------------------------\n",
      "loss: 0.129783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428904 \n",
      "\n",
      "Epoch 1483\n",
      "-------------------------------\n",
      "loss: 0.140642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433501 \n",
      "\n",
      "Epoch 1484\n",
      "-------------------------------\n",
      "loss: 0.151205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430393 \n",
      "\n",
      "Epoch 1485\n",
      "-------------------------------\n",
      "loss: 0.151629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423288 \n",
      "\n",
      "Epoch 1486\n",
      "-------------------------------\n",
      "loss: 0.130181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419265 \n",
      "\n",
      "Epoch 1487\n",
      "-------------------------------\n",
      "loss: 0.140199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418298 \n",
      "\n",
      "Epoch 1488\n",
      "-------------------------------\n",
      "loss: 0.131994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418768 \n",
      "\n",
      "Epoch 1489\n",
      "-------------------------------\n",
      "loss: 0.154604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424418 \n",
      "\n",
      "Epoch 1490\n",
      "-------------------------------\n",
      "loss: 0.160148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423602 \n",
      "\n",
      "Epoch 1491\n",
      "-------------------------------\n",
      "loss: 0.145288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419726 \n",
      "\n",
      "Epoch 1492\n",
      "-------------------------------\n",
      "loss: 0.137981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422107 \n",
      "\n",
      "Epoch 1493\n",
      "-------------------------------\n",
      "loss: 0.140806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425039 \n",
      "\n",
      "Epoch 1494\n",
      "-------------------------------\n",
      "loss: 0.143326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425683 \n",
      "\n",
      "Epoch 1495\n",
      "-------------------------------\n",
      "loss: 0.147478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425823 \n",
      "\n",
      "Epoch 1496\n",
      "-------------------------------\n",
      "loss: 0.147287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422532 \n",
      "\n",
      "Epoch 1497\n",
      "-------------------------------\n",
      "loss: 0.139924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415073 \n",
      "\n",
      "Epoch 1498\n",
      "-------------------------------\n",
      "loss: 0.139965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411150 \n",
      "\n",
      "Epoch 1499\n",
      "-------------------------------\n",
      "loss: 0.129509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413373 \n",
      "\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "loss: 0.139846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419984 \n",
      "\n",
      "Epoch 1501\n",
      "-------------------------------\n",
      "loss: 0.128319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426375 \n",
      "\n",
      "Epoch 1502\n",
      "-------------------------------\n",
      "loss: 0.140384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432287 \n",
      "\n",
      "Epoch 1503\n",
      "-------------------------------\n",
      "loss: 0.147179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427089 \n",
      "\n",
      "Epoch 1504\n",
      "-------------------------------\n",
      "loss: 0.147995  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.422306 \n",
      "\n",
      "Epoch 1505\n",
      "-------------------------------\n",
      "loss: 0.141641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417911 \n",
      "\n",
      "Epoch 1506\n",
      "-------------------------------\n",
      "loss: 0.146437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414052 \n",
      "\n",
      "Epoch 1507\n",
      "-------------------------------\n",
      "loss: 0.131264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412640 \n",
      "\n",
      "Epoch 1508\n",
      "-------------------------------\n",
      "loss: 0.140977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418094 \n",
      "\n",
      "Epoch 1509\n",
      "-------------------------------\n",
      "loss: 0.143089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427645 \n",
      "\n",
      "Epoch 1510\n",
      "-------------------------------\n",
      "loss: 0.148638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430334 \n",
      "\n",
      "Epoch 1511\n",
      "-------------------------------\n",
      "loss: 0.141842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433990 \n",
      "\n",
      "Epoch 1512\n",
      "-------------------------------\n",
      "loss: 0.148463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430977 \n",
      "\n",
      "Epoch 1513\n",
      "-------------------------------\n",
      "loss: 0.150443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425689 \n",
      "\n",
      "Epoch 1514\n",
      "-------------------------------\n",
      "loss: 0.169817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424394 \n",
      "\n",
      "Epoch 1515\n",
      "-------------------------------\n",
      "loss: 0.162447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416600 \n",
      "\n",
      "Epoch 1516\n",
      "-------------------------------\n",
      "loss: 0.150147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411207 \n",
      "\n",
      "Epoch 1517\n",
      "-------------------------------\n",
      "loss: 0.145612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417859 \n",
      "\n",
      "Epoch 1518\n",
      "-------------------------------\n",
      "loss: 0.157708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420357 \n",
      "\n",
      "Epoch 1519\n",
      "-------------------------------\n",
      "loss: 0.156395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415744 \n",
      "\n",
      "Epoch 1520\n",
      "-------------------------------\n",
      "loss: 0.138394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415851 \n",
      "\n",
      "Epoch 1521\n",
      "-------------------------------\n",
      "loss: 0.140251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420977 \n",
      "\n",
      "Epoch 1522\n",
      "-------------------------------\n",
      "loss: 0.145583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426404 \n",
      "\n",
      "Epoch 1523\n",
      "-------------------------------\n",
      "loss: 0.161317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425996 \n",
      "\n",
      "Epoch 1524\n",
      "-------------------------------\n",
      "loss: 0.153771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424642 \n",
      "\n",
      "Epoch 1525\n",
      "-------------------------------\n",
      "loss: 0.148963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425336 \n",
      "\n",
      "Epoch 1526\n",
      "-------------------------------\n",
      "loss: 0.142350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418918 \n",
      "\n",
      "Epoch 1527\n",
      "-------------------------------\n",
      "loss: 0.152193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413638 \n",
      "\n",
      "Epoch 1528\n",
      "-------------------------------\n",
      "loss: 0.158250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419162 \n",
      "\n",
      "Epoch 1529\n",
      "-------------------------------\n",
      "loss: 0.137165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426792 \n",
      "\n",
      "Epoch 1530\n",
      "-------------------------------\n",
      "loss: 0.141369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425898 \n",
      "\n",
      "Epoch 1531\n",
      "-------------------------------\n",
      "loss: 0.175436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419897 \n",
      "\n",
      "Epoch 1532\n",
      "-------------------------------\n",
      "loss: 0.147431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425558 \n",
      "\n",
      "Epoch 1533\n",
      "-------------------------------\n",
      "loss: 0.159909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427132 \n",
      "\n",
      "Epoch 1534\n",
      "-------------------------------\n",
      "loss: 0.144176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421494 \n",
      "\n",
      "Epoch 1535\n",
      "-------------------------------\n",
      "loss: 0.130134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420275 \n",
      "\n",
      "Epoch 1536\n",
      "-------------------------------\n",
      "loss: 0.152458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422456 \n",
      "\n",
      "Epoch 1537\n",
      "-------------------------------\n",
      "loss: 0.137060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421110 \n",
      "\n",
      "Epoch 1538\n",
      "-------------------------------\n",
      "loss: 0.152629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417855 \n",
      "\n",
      "Epoch 1539\n",
      "-------------------------------\n",
      "loss: 0.133005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420921 \n",
      "\n",
      "Epoch 1540\n",
      "-------------------------------\n",
      "loss: 0.142638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421663 \n",
      "\n",
      "Epoch 1541\n",
      "-------------------------------\n",
      "loss: 0.147774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417128 \n",
      "\n",
      "Epoch 1542\n",
      "-------------------------------\n",
      "loss: 0.133460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418905 \n",
      "\n",
      "Epoch 1543\n",
      "-------------------------------\n",
      "loss: 0.139073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428895 \n",
      "\n",
      "Epoch 1544\n",
      "-------------------------------\n",
      "loss: 0.152985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432103 \n",
      "\n",
      "Epoch 1545\n",
      "-------------------------------\n",
      "loss: 0.155679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428082 \n",
      "\n",
      "Epoch 1546\n",
      "-------------------------------\n",
      "loss: 0.139368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422921 \n",
      "\n",
      "Epoch 1547\n",
      "-------------------------------\n",
      "loss: 0.140212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419737 \n",
      "\n",
      "Epoch 1548\n",
      "-------------------------------\n",
      "loss: 0.134035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414004 \n",
      "\n",
      "Epoch 1549\n",
      "-------------------------------\n",
      "loss: 0.133284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408768 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 1550\n",
      "-------------------------------\n",
      "loss: 0.142848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409469 \n",
      "\n",
      "Epoch 1551\n",
      "-------------------------------\n",
      "loss: 0.151381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413192 \n",
      "\n",
      "Epoch 1552\n",
      "-------------------------------\n",
      "loss: 0.153088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414372 \n",
      "\n",
      "Epoch 1553\n",
      "-------------------------------\n",
      "loss: 0.146855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417489 \n",
      "\n",
      "Epoch 1554\n",
      "-------------------------------\n",
      "loss: 0.145849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420798 \n",
      "\n",
      "Epoch 1555\n",
      "-------------------------------\n",
      "loss: 0.139864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419599 \n",
      "\n",
      "Epoch 1556\n",
      "-------------------------------\n",
      "loss: 0.140271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417787 \n",
      "\n",
      "Epoch 1557\n",
      "-------------------------------\n",
      "loss: 0.132692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420869 \n",
      "\n",
      "Epoch 1558\n",
      "-------------------------------\n",
      "loss: 0.131217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423131 \n",
      "\n",
      "Epoch 1559\n",
      "-------------------------------\n",
      "loss: 0.138268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425198 \n",
      "\n",
      "Epoch 1560\n",
      "-------------------------------\n",
      "loss: 0.160737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420815 \n",
      "\n",
      "Epoch 1561\n",
      "-------------------------------\n",
      "loss: 0.140473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417587 \n",
      "\n",
      "Epoch 1562\n",
      "-------------------------------\n",
      "loss: 0.129688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417202 \n",
      "\n",
      "Epoch 1563\n",
      "-------------------------------\n",
      "loss: 0.142122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418608 \n",
      "\n",
      "Epoch 1564\n",
      "-------------------------------\n",
      "loss: 0.138700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419269 \n",
      "\n",
      "Epoch 1565\n",
      "-------------------------------\n",
      "loss: 0.140933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420190 \n",
      "\n",
      "Epoch 1566\n",
      "-------------------------------\n",
      "loss: 0.150107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425863 \n",
      "\n",
      "Epoch 1567\n",
      "-------------------------------\n",
      "loss: 0.134012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431920 \n",
      "\n",
      "Epoch 1568\n",
      "-------------------------------\n",
      "loss: 0.129120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437451 \n",
      "\n",
      "Epoch 1569\n",
      "-------------------------------\n",
      "loss: 0.138835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432250 \n",
      "\n",
      "Epoch 1570\n",
      "-------------------------------\n",
      "loss: 0.144841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424699 \n",
      "\n",
      "Epoch 1571\n",
      "-------------------------------\n",
      "loss: 0.141117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416876 \n",
      "\n",
      "Epoch 1572\n",
      "-------------------------------\n",
      "loss: 0.146621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418848 \n",
      "\n",
      "Epoch 1573\n",
      "-------------------------------\n",
      "loss: 0.130899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424698 \n",
      "\n",
      "Epoch 1574\n",
      "-------------------------------\n",
      "loss: 0.147653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428806 \n",
      "\n",
      "Epoch 1575\n",
      "-------------------------------\n",
      "loss: 0.134964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436345 \n",
      "\n",
      "Epoch 1576\n",
      "-------------------------------\n",
      "loss: 0.161695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437602 \n",
      "\n",
      "Epoch 1577\n",
      "-------------------------------\n",
      "loss: 0.159105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432720 \n",
      "\n",
      "Epoch 1578\n",
      "-------------------------------\n",
      "loss: 0.141951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420862 \n",
      "\n",
      "Epoch 1579\n",
      "-------------------------------\n",
      "loss: 0.138350  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.415343 \n",
      "\n",
      "Epoch 1580\n",
      "-------------------------------\n",
      "loss: 0.159521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419419 \n",
      "\n",
      "Epoch 1581\n",
      "-------------------------------\n",
      "loss: 0.139864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427085 \n",
      "\n",
      "Epoch 1582\n",
      "-------------------------------\n",
      "loss: 0.130975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433150 \n",
      "\n",
      "Epoch 1583\n",
      "-------------------------------\n",
      "loss: 0.134719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429076 \n",
      "\n",
      "Epoch 1584\n",
      "-------------------------------\n",
      "loss: 0.136663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428153 \n",
      "\n",
      "Epoch 1585\n",
      "-------------------------------\n",
      "loss: 0.139463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426749 \n",
      "\n",
      "Epoch 1586\n",
      "-------------------------------\n",
      "loss: 0.132446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419733 \n",
      "\n",
      "Epoch 1587\n",
      "-------------------------------\n",
      "loss: 0.147069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418363 \n",
      "\n",
      "Epoch 1588\n",
      "-------------------------------\n",
      "loss: 0.141180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416382 \n",
      "\n",
      "Epoch 1589\n",
      "-------------------------------\n",
      "loss: 0.144945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415054 \n",
      "\n",
      "Epoch 1590\n",
      "-------------------------------\n",
      "loss: 0.142750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414910 \n",
      "\n",
      "Epoch 1591\n",
      "-------------------------------\n",
      "loss: 0.132135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417738 \n",
      "\n",
      "Epoch 1592\n",
      "-------------------------------\n",
      "loss: 0.139380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421055 \n",
      "\n",
      "Epoch 1593\n",
      "-------------------------------\n",
      "loss: 0.133240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423143 \n",
      "\n",
      "Epoch 1594\n",
      "-------------------------------\n",
      "loss: 0.128617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422603 \n",
      "\n",
      "Epoch 1595\n",
      "-------------------------------\n",
      "loss: 0.135081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419615 \n",
      "\n",
      "Epoch 1596\n",
      "-------------------------------\n",
      "loss: 0.127699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419964 \n",
      "\n",
      "Epoch 1597\n",
      "-------------------------------\n",
      "loss: 0.142534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419298 \n",
      "\n",
      "Epoch 1598\n",
      "-------------------------------\n",
      "loss: 0.131705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418619 \n",
      "\n",
      "Epoch 1599\n",
      "-------------------------------\n",
      "loss: 0.129620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421385 \n",
      "\n",
      "Epoch 1600\n",
      "-------------------------------\n",
      "loss: 0.138280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422412 \n",
      "\n",
      "Epoch 1601\n",
      "-------------------------------\n",
      "loss: 0.143148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423563 \n",
      "\n",
      "Epoch 1602\n",
      "-------------------------------\n",
      "loss: 0.133376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422648 \n",
      "\n",
      "Epoch 1603\n",
      "-------------------------------\n",
      "loss: 0.128769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421287 \n",
      "\n",
      "Epoch 1604\n",
      "-------------------------------\n",
      "loss: 0.143624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422700 \n",
      "\n",
      "Epoch 1605\n",
      "-------------------------------\n",
      "loss: 0.131292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422522 \n",
      "\n",
      "Epoch 1606\n",
      "-------------------------------\n",
      "loss: 0.137078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421321 \n",
      "\n",
      "Epoch 1607\n",
      "-------------------------------\n",
      "loss: 0.120896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421207 \n",
      "\n",
      "Epoch 1608\n",
      "-------------------------------\n",
      "loss: 0.156282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418576 \n",
      "\n",
      "Epoch 1609\n",
      "-------------------------------\n",
      "loss: 0.123888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418389 \n",
      "\n",
      "Epoch 1610\n",
      "-------------------------------\n",
      "loss: 0.138159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418991 \n",
      "\n",
      "Epoch 1611\n",
      "-------------------------------\n",
      "loss: 0.126142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422375 \n",
      "\n",
      "Epoch 1612\n",
      "-------------------------------\n",
      "loss: 0.138985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426555 \n",
      "\n",
      "Epoch 1613\n",
      "-------------------------------\n",
      "loss: 0.120871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425917 \n",
      "\n",
      "Epoch 1614\n",
      "-------------------------------\n",
      "loss: 0.139591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419732 \n",
      "\n",
      "Epoch 1615\n",
      "-------------------------------\n",
      "loss: 0.154917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417735 \n",
      "\n",
      "Epoch 1616\n",
      "-------------------------------\n",
      "loss: 0.140426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417334 \n",
      "\n",
      "Epoch 1617\n",
      "-------------------------------\n",
      "loss: 0.132565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417021 \n",
      "\n",
      "Epoch 1618\n",
      "-------------------------------\n",
      "loss: 0.132405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418721 \n",
      "\n",
      "Epoch 1619\n",
      "-------------------------------\n",
      "loss: 0.135559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422580 \n",
      "\n",
      "Epoch 1620\n",
      "-------------------------------\n",
      "loss: 0.141373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423366 \n",
      "\n",
      "Epoch 1621\n",
      "-------------------------------\n",
      "loss: 0.139211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421940 \n",
      "\n",
      "Epoch 1622\n",
      "-------------------------------\n",
      "loss: 0.143897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420086 \n",
      "\n",
      "Epoch 1623\n",
      "-------------------------------\n",
      "loss: 0.140421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417563 \n",
      "\n",
      "Epoch 1624\n",
      "-------------------------------\n",
      "loss: 0.137838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417330 \n",
      "\n",
      "Epoch 1625\n",
      "-------------------------------\n",
      "loss: 0.127405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416534 \n",
      "\n",
      "Epoch 1626\n",
      "-------------------------------\n",
      "loss: 0.130928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417272 \n",
      "\n",
      "Epoch 1627\n",
      "-------------------------------\n",
      "loss: 0.127493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420692 \n",
      "\n",
      "Epoch 1628\n",
      "-------------------------------\n",
      "loss: 0.128935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425874 \n",
      "\n",
      "Epoch 1629\n",
      "-------------------------------\n",
      "loss: 0.138874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426626 \n",
      "\n",
      "Epoch 1630\n",
      "-------------------------------\n",
      "loss: 0.139798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419215 \n",
      "\n",
      "Epoch 1631\n",
      "-------------------------------\n",
      "loss: 0.121601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416822 \n",
      "\n",
      "Epoch 1632\n",
      "-------------------------------\n",
      "loss: 0.138788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417070 \n",
      "\n",
      "Epoch 1633\n",
      "-------------------------------\n",
      "loss: 0.142119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415531 \n",
      "\n",
      "Epoch 1634\n",
      "-------------------------------\n",
      "loss: 0.151363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416582 \n",
      "\n",
      "Epoch 1635\n",
      "-------------------------------\n",
      "loss: 0.131525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419868 \n",
      "\n",
      "Epoch 1636\n",
      "-------------------------------\n",
      "loss: 0.133790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424950 \n",
      "\n",
      "Epoch 1637\n",
      "-------------------------------\n",
      "loss: 0.134607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429359 \n",
      "\n",
      "Epoch 1638\n",
      "-------------------------------\n",
      "loss: 0.131741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427085 \n",
      "\n",
      "Epoch 1639\n",
      "-------------------------------\n",
      "loss: 0.147582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419055 \n",
      "\n",
      "Epoch 1640\n",
      "-------------------------------\n",
      "loss: 0.141384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413355 \n",
      "\n",
      "Epoch 1641\n",
      "-------------------------------\n",
      "loss: 0.125283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411877 \n",
      "\n",
      "Epoch 1642\n",
      "-------------------------------\n",
      "loss: 0.128167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414805 \n",
      "\n",
      "Epoch 1643\n",
      "-------------------------------\n",
      "loss: 0.132191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422546 \n",
      "\n",
      "Epoch 1644\n",
      "-------------------------------\n",
      "loss: 0.148348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428380 \n",
      "\n",
      "Epoch 1645\n",
      "-------------------------------\n",
      "loss: 0.137299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429686 \n",
      "\n",
      "Epoch 1646\n",
      "-------------------------------\n",
      "loss: 0.150495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428457 \n",
      "\n",
      "Epoch 1647\n",
      "-------------------------------\n",
      "loss: 0.141889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421653 \n",
      "\n",
      "Epoch 1648\n",
      "-------------------------------\n",
      "loss: 0.141080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420039 \n",
      "\n",
      "Epoch 1649\n",
      "-------------------------------\n",
      "loss: 0.148352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431547 \n",
      "\n",
      "Epoch 1650\n",
      "-------------------------------\n",
      "loss: 0.138528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435058 \n",
      "\n",
      "Epoch 1651\n",
      "-------------------------------\n",
      "loss: 0.144738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424213 \n",
      "\n",
      "Epoch 1652\n",
      "-------------------------------\n",
      "loss: 0.136973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416638 \n",
      "\n",
      "Epoch 1653\n",
      "-------------------------------\n",
      "loss: 0.129286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415266 \n",
      "\n",
      "Epoch 1654\n",
      "-------------------------------\n",
      "loss: 0.139542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421496 \n",
      "\n",
      "Epoch 1655\n",
      "-------------------------------\n",
      "loss: 0.138648  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.423728 \n",
      "\n",
      "Epoch 1656\n",
      "-------------------------------\n",
      "loss: 0.131267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421769 \n",
      "\n",
      "Epoch 1657\n",
      "-------------------------------\n",
      "loss: 0.141944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416412 \n",
      "\n",
      "Epoch 1658\n",
      "-------------------------------\n",
      "loss: 0.143620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410880 \n",
      "\n",
      "Epoch 1659\n",
      "-------------------------------\n",
      "loss: 0.136297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411411 \n",
      "\n",
      "Epoch 1660\n",
      "-------------------------------\n",
      "loss: 0.138907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417741 \n",
      "\n",
      "Epoch 1661\n",
      "-------------------------------\n",
      "loss: 0.144487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420620 \n",
      "\n",
      "Epoch 1662\n",
      "-------------------------------\n",
      "loss: 0.141255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420420 \n",
      "\n",
      "Epoch 1663\n",
      "-------------------------------\n",
      "loss: 0.149405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423490 \n",
      "\n",
      "Epoch 1664\n",
      "-------------------------------\n",
      "loss: 0.140939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424756 \n",
      "\n",
      "Epoch 1665\n",
      "-------------------------------\n",
      "loss: 0.141010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424449 \n",
      "\n",
      "Epoch 1666\n",
      "-------------------------------\n",
      "loss: 0.141948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427217 \n",
      "\n",
      "Epoch 1667\n",
      "-------------------------------\n",
      "loss: 0.134010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430816 \n",
      "\n",
      "Epoch 1668\n",
      "-------------------------------\n",
      "loss: 0.141467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428050 \n",
      "\n",
      "Epoch 1669\n",
      "-------------------------------\n",
      "loss: 0.134778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425919 \n",
      "\n",
      "Epoch 1670\n",
      "-------------------------------\n",
      "loss: 0.147689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425764 \n",
      "\n",
      "Epoch 1671\n",
      "-------------------------------\n",
      "loss: 0.142461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425701 \n",
      "\n",
      "Epoch 1672\n",
      "-------------------------------\n",
      "loss: 0.151708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425296 \n",
      "\n",
      "Epoch 1673\n",
      "-------------------------------\n",
      "loss: 0.133880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426697 \n",
      "\n",
      "Epoch 1674\n",
      "-------------------------------\n",
      "loss: 0.134673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427265 \n",
      "\n",
      "Epoch 1675\n",
      "-------------------------------\n",
      "loss: 0.148994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431373 \n",
      "\n",
      "Epoch 1676\n",
      "-------------------------------\n",
      "loss: 0.139813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433813 \n",
      "\n",
      "Epoch 1677\n",
      "-------------------------------\n",
      "loss: 0.157866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429542 \n",
      "\n",
      "Epoch 1678\n",
      "-------------------------------\n",
      "loss: 0.146398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418547 \n",
      "\n",
      "Epoch 1679\n",
      "-------------------------------\n",
      "loss: 0.140656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414097 \n",
      "\n",
      "Epoch 1680\n",
      "-------------------------------\n",
      "loss: 0.120178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420275 \n",
      "\n",
      "Epoch 1681\n",
      "-------------------------------\n",
      "loss: 0.145073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422013 \n",
      "\n",
      "Epoch 1682\n",
      "-------------------------------\n",
      "loss: 0.142730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424959 \n",
      "\n",
      "Epoch 1683\n",
      "-------------------------------\n",
      "loss: 0.141515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430531 \n",
      "\n",
      "Epoch 1684\n",
      "-------------------------------\n",
      "loss: 0.150974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428421 \n",
      "\n",
      "Epoch 1685\n",
      "-------------------------------\n",
      "loss: 0.134881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430586 \n",
      "\n",
      "Epoch 1686\n",
      "-------------------------------\n",
      "loss: 0.140312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431521 \n",
      "\n",
      "Epoch 1687\n",
      "-------------------------------\n",
      "loss: 0.162511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429335 \n",
      "\n",
      "Epoch 1688\n",
      "-------------------------------\n",
      "loss: 0.138795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424293 \n",
      "\n",
      "Epoch 1689\n",
      "-------------------------------\n",
      "loss: 0.136162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419827 \n",
      "\n",
      "Epoch 1690\n",
      "-------------------------------\n",
      "loss: 0.136872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419469 \n",
      "\n",
      "Epoch 1691\n",
      "-------------------------------\n",
      "loss: 0.137273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422551 \n",
      "\n",
      "Epoch 1692\n",
      "-------------------------------\n",
      "loss: 0.146870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427837 \n",
      "\n",
      "Epoch 1693\n",
      "-------------------------------\n",
      "loss: 0.157429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426954 \n",
      "\n",
      "Epoch 1694\n",
      "-------------------------------\n",
      "loss: 0.136972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420612 \n",
      "\n",
      "Epoch 1695\n",
      "-------------------------------\n",
      "loss: 0.132344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422235 \n",
      "\n",
      "Epoch 1696\n",
      "-------------------------------\n",
      "loss: 0.145314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422951 \n",
      "\n",
      "Epoch 1697\n",
      "-------------------------------\n",
      "loss: 0.146500  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422046 \n",
      "\n",
      "Epoch 1698\n",
      "-------------------------------\n",
      "loss: 0.139939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420145 \n",
      "\n",
      "Epoch 1699\n",
      "-------------------------------\n",
      "loss: 0.144015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419640 \n",
      "\n",
      "Epoch 1700\n",
      "-------------------------------\n",
      "loss: 0.144124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425132 \n",
      "\n",
      "Epoch 1701\n",
      "-------------------------------\n",
      "loss: 0.137381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428313 \n",
      "\n",
      "Epoch 1702\n",
      "-------------------------------\n",
      "loss: 0.147141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424922 \n",
      "\n",
      "Epoch 1703\n",
      "-------------------------------\n",
      "loss: 0.128714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423625 \n",
      "\n",
      "Epoch 1704\n",
      "-------------------------------\n",
      "loss: 0.138439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421606 \n",
      "\n",
      "Epoch 1705\n",
      "-------------------------------\n",
      "loss: 0.136517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412720 \n",
      "\n",
      "Epoch 1706\n",
      "-------------------------------\n",
      "loss: 0.120167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405750 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 1707\n",
      "-------------------------------\n",
      "loss: 0.134497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402835 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 1708\n",
      "-------------------------------\n",
      "loss: 0.133347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402440 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 1709\n",
      "-------------------------------\n",
      "loss: 0.161441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405195 \n",
      "\n",
      "Epoch 1710\n",
      "-------------------------------\n",
      "loss: 0.143651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410909 \n",
      "\n",
      "Epoch 1711\n",
      "-------------------------------\n",
      "loss: 0.141228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420587 \n",
      "\n",
      "Epoch 1712\n",
      "-------------------------------\n",
      "loss: 0.129744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426637 \n",
      "\n",
      "Epoch 1713\n",
      "-------------------------------\n",
      "loss: 0.136233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434063 \n",
      "\n",
      "Epoch 1714\n",
      "-------------------------------\n",
      "loss: 0.146100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435754 \n",
      "\n",
      "Epoch 1715\n",
      "-------------------------------\n",
      "loss: 0.142507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426177 \n",
      "\n",
      "Epoch 1716\n",
      "-------------------------------\n",
      "loss: 0.135996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417525 \n",
      "\n",
      "Epoch 1717\n",
      "-------------------------------\n",
      "loss: 0.125401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415545 \n",
      "\n",
      "Epoch 1718\n",
      "-------------------------------\n",
      "loss: 0.147799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415411 \n",
      "\n",
      "Epoch 1719\n",
      "-------------------------------\n",
      "loss: 0.142335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419705 \n",
      "\n",
      "Epoch 1720\n",
      "-------------------------------\n",
      "loss: 0.139458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424765 \n",
      "\n",
      "Epoch 1721\n",
      "-------------------------------\n",
      "loss: 0.133579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430246 \n",
      "\n",
      "Epoch 1722\n",
      "-------------------------------\n",
      "loss: 0.139099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431814 \n",
      "\n",
      "Epoch 1723\n",
      "-------------------------------\n",
      "loss: 0.132484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432622 \n",
      "\n",
      "Epoch 1724\n",
      "-------------------------------\n",
      "loss: 0.134683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428320 \n",
      "\n",
      "Epoch 1725\n",
      "-------------------------------\n",
      "loss: 0.144303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420195 \n",
      "\n",
      "Epoch 1726\n",
      "-------------------------------\n",
      "loss: 0.123654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416947 \n",
      "\n",
      "Epoch 1727\n",
      "-------------------------------\n",
      "loss: 0.138672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419870 \n",
      "\n",
      "Epoch 1728\n",
      "-------------------------------\n",
      "loss: 0.145120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427419 \n",
      "\n",
      "Epoch 1729\n",
      "-------------------------------\n",
      "loss: 0.131071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432221 \n",
      "\n",
      "Epoch 1730\n",
      "-------------------------------\n",
      "loss: 0.146824  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.429475 \n",
      "\n",
      "Epoch 1731\n",
      "-------------------------------\n",
      "loss: 0.152076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422738 \n",
      "\n",
      "Epoch 1732\n",
      "-------------------------------\n",
      "loss: 0.143110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421076 \n",
      "\n",
      "Epoch 1733\n",
      "-------------------------------\n",
      "loss: 0.139100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419654 \n",
      "\n",
      "Epoch 1734\n",
      "-------------------------------\n",
      "loss: 0.133527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418435 \n",
      "\n",
      "Epoch 1735\n",
      "-------------------------------\n",
      "loss: 0.137427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414539 \n",
      "\n",
      "Epoch 1736\n",
      "-------------------------------\n",
      "loss: 0.134603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412671 \n",
      "\n",
      "Epoch 1737\n",
      "-------------------------------\n",
      "loss: 0.125986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414710 \n",
      "\n",
      "Epoch 1738\n",
      "-------------------------------\n",
      "loss: 0.123743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417912 \n",
      "\n",
      "Epoch 1739\n",
      "-------------------------------\n",
      "loss: 0.146791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417619 \n",
      "\n",
      "Epoch 1740\n",
      "-------------------------------\n",
      "loss: 0.142106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413548 \n",
      "\n",
      "Epoch 1741\n",
      "-------------------------------\n",
      "loss: 0.138593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412039 \n",
      "\n",
      "Epoch 1742\n",
      "-------------------------------\n",
      "loss: 0.159794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415023 \n",
      "\n",
      "Epoch 1743\n",
      "-------------------------------\n",
      "loss: 0.140600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419112 \n",
      "\n",
      "Epoch 1744\n",
      "-------------------------------\n",
      "loss: 0.141944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426810 \n",
      "\n",
      "Epoch 1745\n",
      "-------------------------------\n",
      "loss: 0.131461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441744 \n",
      "\n",
      "Epoch 1746\n",
      "-------------------------------\n",
      "loss: 0.147455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443978 \n",
      "\n",
      "Epoch 1747\n",
      "-------------------------------\n",
      "loss: 0.146898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435763 \n",
      "\n",
      "Epoch 1748\n",
      "-------------------------------\n",
      "loss: 0.136694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425391 \n",
      "\n",
      "Epoch 1749\n",
      "-------------------------------\n",
      "loss: 0.141016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415867 \n",
      "\n",
      "Epoch 1750\n",
      "-------------------------------\n",
      "loss: 0.143105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412153 \n",
      "\n",
      "Epoch 1751\n",
      "-------------------------------\n",
      "loss: 0.132611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411477 \n",
      "\n",
      "Epoch 1752\n",
      "-------------------------------\n",
      "loss: 0.158290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411088 \n",
      "\n",
      "Epoch 1753\n",
      "-------------------------------\n",
      "loss: 0.130758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413713 \n",
      "\n",
      "Epoch 1754\n",
      "-------------------------------\n",
      "loss: 0.122749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419387 \n",
      "\n",
      "Epoch 1755\n",
      "-------------------------------\n",
      "loss: 0.137506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422719 \n",
      "\n",
      "Epoch 1756\n",
      "-------------------------------\n",
      "loss: 0.132366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424384 \n",
      "\n",
      "Epoch 1757\n",
      "-------------------------------\n",
      "loss: 0.138283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422922 \n",
      "\n",
      "Epoch 1758\n",
      "-------------------------------\n",
      "loss: 0.131585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418104 \n",
      "\n",
      "Epoch 1759\n",
      "-------------------------------\n",
      "loss: 0.136626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419655 \n",
      "\n",
      "Epoch 1760\n",
      "-------------------------------\n",
      "loss: 0.131716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427832 \n",
      "\n",
      "Epoch 1761\n",
      "-------------------------------\n",
      "loss: 0.149674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432055 \n",
      "\n",
      "Epoch 1762\n",
      "-------------------------------\n",
      "loss: 0.156991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431028 \n",
      "\n",
      "Epoch 1763\n",
      "-------------------------------\n",
      "loss: 0.140981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428000 \n",
      "\n",
      "Epoch 1764\n",
      "-------------------------------\n",
      "loss: 0.137247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424307 \n",
      "\n",
      "Epoch 1765\n",
      "-------------------------------\n",
      "loss: 0.126938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424166 \n",
      "\n",
      "Epoch 1766\n",
      "-------------------------------\n",
      "loss: 0.130413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423681 \n",
      "\n",
      "Epoch 1767\n",
      "-------------------------------\n",
      "loss: 0.133496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419867 \n",
      "\n",
      "Epoch 1768\n",
      "-------------------------------\n",
      "loss: 0.140842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416173 \n",
      "\n",
      "Epoch 1769\n",
      "-------------------------------\n",
      "loss: 0.137043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417167 \n",
      "\n",
      "Epoch 1770\n",
      "-------------------------------\n",
      "loss: 0.148803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423467 \n",
      "\n",
      "Epoch 1771\n",
      "-------------------------------\n",
      "loss: 0.139364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428057 \n",
      "\n",
      "Epoch 1772\n",
      "-------------------------------\n",
      "loss: 0.137937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432800 \n",
      "\n",
      "Epoch 1773\n",
      "-------------------------------\n",
      "loss: 0.143230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429891 \n",
      "\n",
      "Epoch 1774\n",
      "-------------------------------\n",
      "loss: 0.142143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424651 \n",
      "\n",
      "Epoch 1775\n",
      "-------------------------------\n",
      "loss: 0.144033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425042 \n",
      "\n",
      "Epoch 1776\n",
      "-------------------------------\n",
      "loss: 0.149413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423172 \n",
      "\n",
      "Epoch 1777\n",
      "-------------------------------\n",
      "loss: 0.124717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420970 \n",
      "\n",
      "Epoch 1778\n",
      "-------------------------------\n",
      "loss: 0.135606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419763 \n",
      "\n",
      "Epoch 1779\n",
      "-------------------------------\n",
      "loss: 0.124256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421183 \n",
      "\n",
      "Epoch 1780\n",
      "-------------------------------\n",
      "loss: 0.123490  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425197 \n",
      "\n",
      "Epoch 1781\n",
      "-------------------------------\n",
      "loss: 0.133750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423166 \n",
      "\n",
      "Epoch 1782\n",
      "-------------------------------\n",
      "loss: 0.124444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420079 \n",
      "\n",
      "Epoch 1783\n",
      "-------------------------------\n",
      "loss: 0.130494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416849 \n",
      "\n",
      "Epoch 1784\n",
      "-------------------------------\n",
      "loss: 0.130113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412926 \n",
      "\n",
      "Epoch 1785\n",
      "-------------------------------\n",
      "loss: 0.123641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415986 \n",
      "\n",
      "Epoch 1786\n",
      "-------------------------------\n",
      "loss: 0.128030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420657 \n",
      "\n",
      "Epoch 1787\n",
      "-------------------------------\n",
      "loss: 0.134317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420724 \n",
      "\n",
      "Epoch 1788\n",
      "-------------------------------\n",
      "loss: 0.130385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418976 \n",
      "\n",
      "Epoch 1789\n",
      "-------------------------------\n",
      "loss: 0.127386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413037 \n",
      "\n",
      "Epoch 1790\n",
      "-------------------------------\n",
      "loss: 0.117769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410688 \n",
      "\n",
      "Epoch 1791\n",
      "-------------------------------\n",
      "loss: 0.117624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415358 \n",
      "\n",
      "Epoch 1792\n",
      "-------------------------------\n",
      "loss: 0.137795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417235 \n",
      "\n",
      "Epoch 1793\n",
      "-------------------------------\n",
      "loss: 0.127721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417135 \n",
      "\n",
      "Epoch 1794\n",
      "-------------------------------\n",
      "loss: 0.120272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418929 \n",
      "\n",
      "Epoch 1795\n",
      "-------------------------------\n",
      "loss: 0.143672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418478 \n",
      "\n",
      "Epoch 1796\n",
      "-------------------------------\n",
      "loss: 0.119653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417767 \n",
      "\n",
      "Epoch 1797\n",
      "-------------------------------\n",
      "loss: 0.130162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415620 \n",
      "\n",
      "Epoch 1798\n",
      "-------------------------------\n",
      "loss: 0.120559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417666 \n",
      "\n",
      "Epoch 1799\n",
      "-------------------------------\n",
      "loss: 0.135127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418297 \n",
      "\n",
      "Epoch 1800\n",
      "-------------------------------\n",
      "loss: 0.129532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419696 \n",
      "\n",
      "Epoch 1801\n",
      "-------------------------------\n",
      "loss: 0.134491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424560 \n",
      "\n",
      "Epoch 1802\n",
      "-------------------------------\n",
      "loss: 0.133711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429906 \n",
      "\n",
      "Epoch 1803\n",
      "-------------------------------\n",
      "loss: 0.147547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419854 \n",
      "\n",
      "Epoch 1804\n",
      "-------------------------------\n",
      "loss: 0.148538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410211 \n",
      "\n",
      "Epoch 1805\n",
      "-------------------------------\n",
      "loss: 0.142961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411399 \n",
      "\n",
      "Epoch 1806\n",
      "-------------------------------\n",
      "loss: 0.155626  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.413167 \n",
      "\n",
      "Epoch 1807\n",
      "-------------------------------\n",
      "loss: 0.143372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412271 \n",
      "\n",
      "Epoch 1808\n",
      "-------------------------------\n",
      "loss: 0.128681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414690 \n",
      "\n",
      "Epoch 1809\n",
      "-------------------------------\n",
      "loss: 0.131262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418301 \n",
      "\n",
      "Epoch 1810\n",
      "-------------------------------\n",
      "loss: 0.134179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421536 \n",
      "\n",
      "Epoch 1811\n",
      "-------------------------------\n",
      "loss: 0.142531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421207 \n",
      "\n",
      "Epoch 1812\n",
      "-------------------------------\n",
      "loss: 0.137528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421206 \n",
      "\n",
      "Epoch 1813\n",
      "-------------------------------\n",
      "loss: 0.143185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420838 \n",
      "\n",
      "Epoch 1814\n",
      "-------------------------------\n",
      "loss: 0.156217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421172 \n",
      "\n",
      "Epoch 1815\n",
      "-------------------------------\n",
      "loss: 0.131290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420229 \n",
      "\n",
      "Epoch 1816\n",
      "-------------------------------\n",
      "loss: 0.141703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423154 \n",
      "\n",
      "Epoch 1817\n",
      "-------------------------------\n",
      "loss: 0.143420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426574 \n",
      "\n",
      "Epoch 1818\n",
      "-------------------------------\n",
      "loss: 0.138053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425511 \n",
      "\n",
      "Epoch 1819\n",
      "-------------------------------\n",
      "loss: 0.136953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421024 \n",
      "\n",
      "Epoch 1820\n",
      "-------------------------------\n",
      "loss: 0.128579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418610 \n",
      "\n",
      "Epoch 1821\n",
      "-------------------------------\n",
      "loss: 0.135831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416145 \n",
      "\n",
      "Epoch 1822\n",
      "-------------------------------\n",
      "loss: 0.134601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415246 \n",
      "\n",
      "Epoch 1823\n",
      "-------------------------------\n",
      "loss: 0.134114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413007 \n",
      "\n",
      "Epoch 1824\n",
      "-------------------------------\n",
      "loss: 0.140452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410267 \n",
      "\n",
      "Epoch 1825\n",
      "-------------------------------\n",
      "loss: 0.143890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409672 \n",
      "\n",
      "Epoch 1826\n",
      "-------------------------------\n",
      "loss: 0.134241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410854 \n",
      "\n",
      "Epoch 1827\n",
      "-------------------------------\n",
      "loss: 0.132647  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415974 \n",
      "\n",
      "Epoch 1828\n",
      "-------------------------------\n",
      "loss: 0.143727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416122 \n",
      "\n",
      "Epoch 1829\n",
      "-------------------------------\n",
      "loss: 0.131140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416594 \n",
      "\n",
      "Epoch 1830\n",
      "-------------------------------\n",
      "loss: 0.127293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418074 \n",
      "\n",
      "Epoch 1831\n",
      "-------------------------------\n",
      "loss: 0.145175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415876 \n",
      "\n",
      "Epoch 1832\n",
      "-------------------------------\n",
      "loss: 0.135939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411408 \n",
      "\n",
      "Epoch 1833\n",
      "-------------------------------\n",
      "loss: 0.129143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413654 \n",
      "\n",
      "Epoch 1834\n",
      "-------------------------------\n",
      "loss: 0.138818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420355 \n",
      "\n",
      "Epoch 1835\n",
      "-------------------------------\n",
      "loss: 0.135393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419586 \n",
      "\n",
      "Epoch 1836\n",
      "-------------------------------\n",
      "loss: 0.148636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414936 \n",
      "\n",
      "Epoch 1837\n",
      "-------------------------------\n",
      "loss: 0.139572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415165 \n",
      "\n",
      "Epoch 1838\n",
      "-------------------------------\n",
      "loss: 0.121814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423246 \n",
      "\n",
      "Epoch 1839\n",
      "-------------------------------\n",
      "loss: 0.135347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428603 \n",
      "\n",
      "Epoch 1840\n",
      "-------------------------------\n",
      "loss: 0.147295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425820 \n",
      "\n",
      "Epoch 1841\n",
      "-------------------------------\n",
      "loss: 0.138157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421299 \n",
      "\n",
      "Epoch 1842\n",
      "-------------------------------\n",
      "loss: 0.120424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421582 \n",
      "\n",
      "Epoch 1843\n",
      "-------------------------------\n",
      "loss: 0.131645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428399 \n",
      "\n",
      "Epoch 1844\n",
      "-------------------------------\n",
      "loss: 0.128030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428943 \n",
      "\n",
      "Epoch 1845\n",
      "-------------------------------\n",
      "loss: 0.137545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423455 \n",
      "\n",
      "Epoch 1846\n",
      "-------------------------------\n",
      "loss: 0.120913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419661 \n",
      "\n",
      "Epoch 1847\n",
      "-------------------------------\n",
      "loss: 0.122530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418990 \n",
      "\n",
      "Epoch 1848\n",
      "-------------------------------\n",
      "loss: 0.141565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411941 \n",
      "\n",
      "Epoch 1849\n",
      "-------------------------------\n",
      "loss: 0.121599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408180 \n",
      "\n",
      "Epoch 1850\n",
      "-------------------------------\n",
      "loss: 0.123944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409050 \n",
      "\n",
      "Epoch 1851\n",
      "-------------------------------\n",
      "loss: 0.130966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408937 \n",
      "\n",
      "Epoch 1852\n",
      "-------------------------------\n",
      "loss: 0.131123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409132 \n",
      "\n",
      "Epoch 1853\n",
      "-------------------------------\n",
      "loss: 0.133156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417817 \n",
      "\n",
      "Epoch 1854\n",
      "-------------------------------\n",
      "loss: 0.140094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425783 \n",
      "\n",
      "Epoch 1855\n",
      "-------------------------------\n",
      "loss: 0.150457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421662 \n",
      "\n",
      "Epoch 1856\n",
      "-------------------------------\n",
      "loss: 0.137900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416762 \n",
      "\n",
      "Epoch 1857\n",
      "-------------------------------\n",
      "loss: 0.125542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416935 \n",
      "\n",
      "Epoch 1858\n",
      "-------------------------------\n",
      "loss: 0.144625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418637 \n",
      "\n",
      "Epoch 1859\n",
      "-------------------------------\n",
      "loss: 0.126882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419635 \n",
      "\n",
      "Epoch 1860\n",
      "-------------------------------\n",
      "loss: 0.129420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418961 \n",
      "\n",
      "Epoch 1861\n",
      "-------------------------------\n",
      "loss: 0.124476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425070 \n",
      "\n",
      "Epoch 1862\n",
      "-------------------------------\n",
      "loss: 0.128973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425051 \n",
      "\n",
      "Epoch 1863\n",
      "-------------------------------\n",
      "loss: 0.130676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421139 \n",
      "\n",
      "Epoch 1864\n",
      "-------------------------------\n",
      "loss: 0.134568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419663 \n",
      "\n",
      "Epoch 1865\n",
      "-------------------------------\n",
      "loss: 0.135465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420844 \n",
      "\n",
      "Epoch 1866\n",
      "-------------------------------\n",
      "loss: 0.139662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417676 \n",
      "\n",
      "Epoch 1867\n",
      "-------------------------------\n",
      "loss: 0.142249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419949 \n",
      "\n",
      "Epoch 1868\n",
      "-------------------------------\n",
      "loss: 0.120973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426116 \n",
      "\n",
      "Epoch 1869\n",
      "-------------------------------\n",
      "loss: 0.154293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422021 \n",
      "\n",
      "Epoch 1870\n",
      "-------------------------------\n",
      "loss: 0.124312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416793 \n",
      "\n",
      "Epoch 1871\n",
      "-------------------------------\n",
      "loss: 0.132683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414688 \n",
      "\n",
      "Epoch 1872\n",
      "-------------------------------\n",
      "loss: 0.120827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418722 \n",
      "\n",
      "Epoch 1873\n",
      "-------------------------------\n",
      "loss: 0.123715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425606 \n",
      "\n",
      "Epoch 1874\n",
      "-------------------------------\n",
      "loss: 0.145215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429423 \n",
      "\n",
      "Epoch 1875\n",
      "-------------------------------\n",
      "loss: 0.127415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434377 \n",
      "\n",
      "Epoch 1876\n",
      "-------------------------------\n",
      "loss: 0.126278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436100 \n",
      "\n",
      "Epoch 1877\n",
      "-------------------------------\n",
      "loss: 0.141603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427912 \n",
      "\n",
      "Epoch 1878\n",
      "-------------------------------\n",
      "loss: 0.125401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418347 \n",
      "\n",
      "Epoch 1879\n",
      "-------------------------------\n",
      "loss: 0.118211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418617 \n",
      "\n",
      "Epoch 1880\n",
      "-------------------------------\n",
      "loss: 0.134385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423017 \n",
      "\n",
      "Epoch 1881\n",
      "-------------------------------\n",
      "loss: 0.148497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423203 \n",
      "\n",
      "Epoch 1882\n",
      "-------------------------------\n",
      "loss: 0.126565  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.419567 \n",
      "\n",
      "Epoch 1883\n",
      "-------------------------------\n",
      "loss: 0.138113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418024 \n",
      "\n",
      "Epoch 1884\n",
      "-------------------------------\n",
      "loss: 0.124883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426726 \n",
      "\n",
      "Epoch 1885\n",
      "-------------------------------\n",
      "loss: 0.130474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435061 \n",
      "\n",
      "Epoch 1886\n",
      "-------------------------------\n",
      "loss: 0.135565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430587 \n",
      "\n",
      "Epoch 1887\n",
      "-------------------------------\n",
      "loss: 0.128984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420521 \n",
      "\n",
      "Epoch 1888\n",
      "-------------------------------\n",
      "loss: 0.145465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415265 \n",
      "\n",
      "Epoch 1889\n",
      "-------------------------------\n",
      "loss: 0.121599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414361 \n",
      "\n",
      "Epoch 1890\n",
      "-------------------------------\n",
      "loss: 0.139055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413291 \n",
      "\n",
      "Epoch 1891\n",
      "-------------------------------\n",
      "loss: 0.125326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413526 \n",
      "\n",
      "Epoch 1892\n",
      "-------------------------------\n",
      "loss: 0.135844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415851 \n",
      "\n",
      "Epoch 1893\n",
      "-------------------------------\n",
      "loss: 0.124512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417888 \n",
      "\n",
      "Epoch 1894\n",
      "-------------------------------\n",
      "loss: 0.134726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420756 \n",
      "\n",
      "Epoch 1895\n",
      "-------------------------------\n",
      "loss: 0.131221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422712 \n",
      "\n",
      "Epoch 1896\n",
      "-------------------------------\n",
      "loss: 0.128066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423102 \n",
      "\n",
      "Epoch 1897\n",
      "-------------------------------\n",
      "loss: 0.141206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421399 \n",
      "\n",
      "Epoch 1898\n",
      "-------------------------------\n",
      "loss: 0.129924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421511 \n",
      "\n",
      "Epoch 1899\n",
      "-------------------------------\n",
      "loss: 0.125294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420968 \n",
      "\n",
      "Epoch 1900\n",
      "-------------------------------\n",
      "loss: 0.125662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420335 \n",
      "\n",
      "Epoch 1901\n",
      "-------------------------------\n",
      "loss: 0.135411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419930 \n",
      "\n",
      "Epoch 1902\n",
      "-------------------------------\n",
      "loss: 0.139395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423234 \n",
      "\n",
      "Epoch 1903\n",
      "-------------------------------\n",
      "loss: 0.123613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425021 \n",
      "\n",
      "Epoch 1904\n",
      "-------------------------------\n",
      "loss: 0.137635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425923 \n",
      "\n",
      "Epoch 1905\n",
      "-------------------------------\n",
      "loss: 0.128480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426051 \n",
      "\n",
      "Epoch 1906\n",
      "-------------------------------\n",
      "loss: 0.133264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420165 \n",
      "\n",
      "Epoch 1907\n",
      "-------------------------------\n",
      "loss: 0.130437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413182 \n",
      "\n",
      "Epoch 1908\n",
      "-------------------------------\n",
      "loss: 0.132583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413209 \n",
      "\n",
      "Epoch 1909\n",
      "-------------------------------\n",
      "loss: 0.126677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418146 \n",
      "\n",
      "Epoch 1910\n",
      "-------------------------------\n",
      "loss: 0.119692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422523 \n",
      "\n",
      "Epoch 1911\n",
      "-------------------------------\n",
      "loss: 0.140699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422711 \n",
      "\n",
      "Epoch 1912\n",
      "-------------------------------\n",
      "loss: 0.128914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419884 \n",
      "\n",
      "Epoch 1913\n",
      "-------------------------------\n",
      "loss: 0.145412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424892 \n",
      "\n",
      "Epoch 1914\n",
      "-------------------------------\n",
      "loss: 0.130525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442117 \n",
      "\n",
      "Epoch 1915\n",
      "-------------------------------\n",
      "loss: 0.146727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.443986 \n",
      "\n",
      "Epoch 1916\n",
      "-------------------------------\n",
      "loss: 0.129561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433373 \n",
      "\n",
      "Epoch 1917\n",
      "-------------------------------\n",
      "loss: 0.133948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421060 \n",
      "\n",
      "Epoch 1918\n",
      "-------------------------------\n",
      "loss: 0.131516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419034 \n",
      "\n",
      "Epoch 1919\n",
      "-------------------------------\n",
      "loss: 0.150027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416868 \n",
      "\n",
      "Epoch 1920\n",
      "-------------------------------\n",
      "loss: 0.144656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417388 \n",
      "\n",
      "Epoch 1921\n",
      "-------------------------------\n",
      "loss: 0.124741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423289 \n",
      "\n",
      "Epoch 1922\n",
      "-------------------------------\n",
      "loss: 0.130815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426073 \n",
      "\n",
      "Epoch 1923\n",
      "-------------------------------\n",
      "loss: 0.136376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422928 \n",
      "\n",
      "Epoch 1924\n",
      "-------------------------------\n",
      "loss: 0.135998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415714 \n",
      "\n",
      "Epoch 1925\n",
      "-------------------------------\n",
      "loss: 0.125735  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411758 \n",
      "\n",
      "Epoch 1926\n",
      "-------------------------------\n",
      "loss: 0.127332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413749 \n",
      "\n",
      "Epoch 1927\n",
      "-------------------------------\n",
      "loss: 0.151887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417230 \n",
      "\n",
      "Epoch 1928\n",
      "-------------------------------\n",
      "loss: 0.142194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421889 \n",
      "\n",
      "Epoch 1929\n",
      "-------------------------------\n",
      "loss: 0.124276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427396 \n",
      "\n",
      "Epoch 1930\n",
      "-------------------------------\n",
      "loss: 0.136105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428375 \n",
      "\n",
      "Epoch 1931\n",
      "-------------------------------\n",
      "loss: 0.125957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426011 \n",
      "\n",
      "Epoch 1932\n",
      "-------------------------------\n",
      "loss: 0.133846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423877 \n",
      "\n",
      "Epoch 1933\n",
      "-------------------------------\n",
      "loss: 0.128159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422598 \n",
      "\n",
      "Epoch 1934\n",
      "-------------------------------\n",
      "loss: 0.132022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421878 \n",
      "\n",
      "Epoch 1935\n",
      "-------------------------------\n",
      "loss: 0.139673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419086 \n",
      "\n",
      "Epoch 1936\n",
      "-------------------------------\n",
      "loss: 0.128122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417881 \n",
      "\n",
      "Epoch 1937\n",
      "-------------------------------\n",
      "loss: 0.128073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424588 \n",
      "\n",
      "Epoch 1938\n",
      "-------------------------------\n",
      "loss: 0.141325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426038 \n",
      "\n",
      "Epoch 1939\n",
      "-------------------------------\n",
      "loss: 0.133855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424243 \n",
      "\n",
      "Epoch 1940\n",
      "-------------------------------\n",
      "loss: 0.131097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422780 \n",
      "\n",
      "Epoch 1941\n",
      "-------------------------------\n",
      "loss: 0.122649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421894 \n",
      "\n",
      "Epoch 1942\n",
      "-------------------------------\n",
      "loss: 0.132431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417709 \n",
      "\n",
      "Epoch 1943\n",
      "-------------------------------\n",
      "loss: 0.131207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416190 \n",
      "\n",
      "Epoch 1944\n",
      "-------------------------------\n",
      "loss: 0.152316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417014 \n",
      "\n",
      "Epoch 1945\n",
      "-------------------------------\n",
      "loss: 0.133385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415363 \n",
      "\n",
      "Epoch 1946\n",
      "-------------------------------\n",
      "loss: 0.133739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416254 \n",
      "\n",
      "Epoch 1947\n",
      "-------------------------------\n",
      "loss: 0.128238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424165 \n",
      "\n",
      "Epoch 1948\n",
      "-------------------------------\n",
      "loss: 0.125671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428870 \n",
      "\n",
      "Epoch 1949\n",
      "-------------------------------\n",
      "loss: 0.130486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424883 \n",
      "\n",
      "Epoch 1950\n",
      "-------------------------------\n",
      "loss: 0.128318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427338 \n",
      "\n",
      "Epoch 1951\n",
      "-------------------------------\n",
      "loss: 0.123257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428849 \n",
      "\n",
      "Epoch 1952\n",
      "-------------------------------\n",
      "loss: 0.119925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421135 \n",
      "\n",
      "Epoch 1953\n",
      "-------------------------------\n",
      "loss: 0.126813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418736 \n",
      "\n",
      "Epoch 1954\n",
      "-------------------------------\n",
      "loss: 0.125222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415224 \n",
      "\n",
      "Epoch 1955\n",
      "-------------------------------\n",
      "loss: 0.125725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413205 \n",
      "\n",
      "Epoch 1956\n",
      "-------------------------------\n",
      "loss: 0.135129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416903 \n",
      "\n",
      "Epoch 1957\n",
      "-------------------------------\n",
      "loss: 0.136925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422476 \n",
      "\n",
      "Epoch 1958\n",
      "-------------------------------\n",
      "loss: 0.121218  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.426014 \n",
      "\n",
      "Epoch 1959\n",
      "-------------------------------\n",
      "loss: 0.128814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422451 \n",
      "\n",
      "Epoch 1960\n",
      "-------------------------------\n",
      "loss: 0.131650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416936 \n",
      "\n",
      "Epoch 1961\n",
      "-------------------------------\n",
      "loss: 0.121746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413120 \n",
      "\n",
      "Epoch 1962\n",
      "-------------------------------\n",
      "loss: 0.126216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412769 \n",
      "\n",
      "Epoch 1963\n",
      "-------------------------------\n",
      "loss: 0.128330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411435 \n",
      "\n",
      "Epoch 1964\n",
      "-------------------------------\n",
      "loss: 0.128667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413804 \n",
      "\n",
      "Epoch 1965\n",
      "-------------------------------\n",
      "loss: 0.122628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421297 \n",
      "\n",
      "Epoch 1966\n",
      "-------------------------------\n",
      "loss: 0.117555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426610 \n",
      "\n",
      "Epoch 1967\n",
      "-------------------------------\n",
      "loss: 0.145231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424938 \n",
      "\n",
      "Epoch 1968\n",
      "-------------------------------\n",
      "loss: 0.126488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424584 \n",
      "\n",
      "Epoch 1969\n",
      "-------------------------------\n",
      "loss: 0.143786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422515 \n",
      "\n",
      "Epoch 1970\n",
      "-------------------------------\n",
      "loss: 0.133753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417550 \n",
      "\n",
      "Epoch 1971\n",
      "-------------------------------\n",
      "loss: 0.124528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415577 \n",
      "\n",
      "Epoch 1972\n",
      "-------------------------------\n",
      "loss: 0.125821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417985 \n",
      "\n",
      "Epoch 1973\n",
      "-------------------------------\n",
      "loss: 0.148324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418251 \n",
      "\n",
      "Epoch 1974\n",
      "-------------------------------\n",
      "loss: 0.142229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419241 \n",
      "\n",
      "Epoch 1975\n",
      "-------------------------------\n",
      "loss: 0.128634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420031 \n",
      "\n",
      "Epoch 1976\n",
      "-------------------------------\n",
      "loss: 0.143920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423968 \n",
      "\n",
      "Epoch 1977\n",
      "-------------------------------\n",
      "loss: 0.124793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427255 \n",
      "\n",
      "Epoch 1978\n",
      "-------------------------------\n",
      "loss: 0.140277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426171 \n",
      "\n",
      "Epoch 1979\n",
      "-------------------------------\n",
      "loss: 0.141891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425368 \n",
      "\n",
      "Epoch 1980\n",
      "-------------------------------\n",
      "loss: 0.128897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425123 \n",
      "\n",
      "Epoch 1981\n",
      "-------------------------------\n",
      "loss: 0.134717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424540 \n",
      "\n",
      "Epoch 1982\n",
      "-------------------------------\n",
      "loss: 0.143541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418222 \n",
      "\n",
      "Epoch 1983\n",
      "-------------------------------\n",
      "loss: 0.134390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409056 \n",
      "\n",
      "Epoch 1984\n",
      "-------------------------------\n",
      "loss: 0.129813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406598 \n",
      "\n",
      "Epoch 1985\n",
      "-------------------------------\n",
      "loss: 0.142301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413330 \n",
      "\n",
      "Epoch 1986\n",
      "-------------------------------\n",
      "loss: 0.135826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417798 \n",
      "\n",
      "Epoch 1987\n",
      "-------------------------------\n",
      "loss: 0.127179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422377 \n",
      "\n",
      "Epoch 1988\n",
      "-------------------------------\n",
      "loss: 0.135913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428576 \n",
      "\n",
      "Epoch 1989\n",
      "-------------------------------\n",
      "loss: 0.141585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426103 \n",
      "\n",
      "Epoch 1990\n",
      "-------------------------------\n",
      "loss: 0.123402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421705 \n",
      "\n",
      "Epoch 1991\n",
      "-------------------------------\n",
      "loss: 0.124901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417160 \n",
      "\n",
      "Epoch 1992\n",
      "-------------------------------\n",
      "loss: 0.125753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415391 \n",
      "\n",
      "Epoch 1993\n",
      "-------------------------------\n",
      "loss: 0.152011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418146 \n",
      "\n",
      "Epoch 1994\n",
      "-------------------------------\n",
      "loss: 0.126338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421189 \n",
      "\n",
      "Epoch 1995\n",
      "-------------------------------\n",
      "loss: 0.136447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423363 \n",
      "\n",
      "Epoch 1996\n",
      "-------------------------------\n",
      "loss: 0.128263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421312 \n",
      "\n",
      "Epoch 1997\n",
      "-------------------------------\n",
      "loss: 0.141015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418379 \n",
      "\n",
      "Epoch 1998\n",
      "-------------------------------\n",
      "loss: 0.126162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420599 \n",
      "\n",
      "Epoch 1999\n",
      "-------------------------------\n",
      "loss: 0.124832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420204 \n",
      "\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "loss: 0.125086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415740 \n",
      "\n",
      "Epoch 2001\n",
      "-------------------------------\n",
      "loss: 0.127875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410888 \n",
      "\n",
      "Epoch 2002\n",
      "-------------------------------\n",
      "loss: 0.125464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409486 \n",
      "\n",
      "Epoch 2003\n",
      "-------------------------------\n",
      "loss: 0.124153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410161 \n",
      "\n",
      "Epoch 2004\n",
      "-------------------------------\n",
      "loss: 0.128953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413213 \n",
      "\n",
      "Epoch 2005\n",
      "-------------------------------\n",
      "loss: 0.121044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426010 \n",
      "\n",
      "Epoch 2006\n",
      "-------------------------------\n",
      "loss: 0.129074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435222 \n",
      "\n",
      "Epoch 2007\n",
      "-------------------------------\n",
      "loss: 0.135920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435554 \n",
      "\n",
      "Epoch 2008\n",
      "-------------------------------\n",
      "loss: 0.132333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429337 \n",
      "\n",
      "Epoch 2009\n",
      "-------------------------------\n",
      "loss: 0.122962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425782 \n",
      "\n",
      "Epoch 2010\n",
      "-------------------------------\n",
      "loss: 0.138782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419532 \n",
      "\n",
      "Epoch 2011\n",
      "-------------------------------\n",
      "loss: 0.153476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410770 \n",
      "\n",
      "Epoch 2012\n",
      "-------------------------------\n",
      "loss: 0.138171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409091 \n",
      "\n",
      "Epoch 2013\n",
      "-------------------------------\n",
      "loss: 0.133955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417323 \n",
      "\n",
      "Epoch 2014\n",
      "-------------------------------\n",
      "loss: 0.127047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425853 \n",
      "\n",
      "Epoch 2015\n",
      "-------------------------------\n",
      "loss: 0.138869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428401 \n",
      "\n",
      "Epoch 2016\n",
      "-------------------------------\n",
      "loss: 0.126880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426489 \n",
      "\n",
      "Epoch 2017\n",
      "-------------------------------\n",
      "loss: 0.134510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422813 \n",
      "\n",
      "Epoch 2018\n",
      "-------------------------------\n",
      "loss: 0.126750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416271 \n",
      "\n",
      "Epoch 2019\n",
      "-------------------------------\n",
      "loss: 0.131678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413052 \n",
      "\n",
      "Epoch 2020\n",
      "-------------------------------\n",
      "loss: 0.140238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414603 \n",
      "\n",
      "Epoch 2021\n",
      "-------------------------------\n",
      "loss: 0.143242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417586 \n",
      "\n",
      "Epoch 2022\n",
      "-------------------------------\n",
      "loss: 0.121136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420831 \n",
      "\n",
      "Epoch 2023\n",
      "-------------------------------\n",
      "loss: 0.132864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422644 \n",
      "\n",
      "Epoch 2024\n",
      "-------------------------------\n",
      "loss: 0.133622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421598 \n",
      "\n",
      "Epoch 2025\n",
      "-------------------------------\n",
      "loss: 0.126611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419396 \n",
      "\n",
      "Epoch 2026\n",
      "-------------------------------\n",
      "loss: 0.130623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420050 \n",
      "\n",
      "Epoch 2027\n",
      "-------------------------------\n",
      "loss: 0.126960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415315 \n",
      "\n",
      "Epoch 2028\n",
      "-------------------------------\n",
      "loss: 0.118774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414169 \n",
      "\n",
      "Epoch 2029\n",
      "-------------------------------\n",
      "loss: 0.122566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418622 \n",
      "\n",
      "Epoch 2030\n",
      "-------------------------------\n",
      "loss: 0.121018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419840 \n",
      "\n",
      "Epoch 2031\n",
      "-------------------------------\n",
      "loss: 0.114982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423735 \n",
      "\n",
      "Epoch 2032\n",
      "-------------------------------\n",
      "loss: 0.123135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423717 \n",
      "\n",
      "Epoch 2033\n",
      "-------------------------------\n",
      "loss: 0.132694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422140 \n",
      "\n",
      "Epoch 2034\n",
      "-------------------------------\n",
      "loss: 0.123616  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.418651 \n",
      "\n",
      "Epoch 2035\n",
      "-------------------------------\n",
      "loss: 0.123987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417421 \n",
      "\n",
      "Epoch 2036\n",
      "-------------------------------\n",
      "loss: 0.140948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416868 \n",
      "\n",
      "Epoch 2037\n",
      "-------------------------------\n",
      "loss: 0.126545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415559 \n",
      "\n",
      "Epoch 2038\n",
      "-------------------------------\n",
      "loss: 0.118691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417330 \n",
      "\n",
      "Epoch 2039\n",
      "-------------------------------\n",
      "loss: 0.120146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420723 \n",
      "\n",
      "Epoch 2040\n",
      "-------------------------------\n",
      "loss: 0.128691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421637 \n",
      "\n",
      "Epoch 2041\n",
      "-------------------------------\n",
      "loss: 0.146502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418624 \n",
      "\n",
      "Epoch 2042\n",
      "-------------------------------\n",
      "loss: 0.129839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420989 \n",
      "\n",
      "Epoch 2043\n",
      "-------------------------------\n",
      "loss: 0.140395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421505 \n",
      "\n",
      "Epoch 2044\n",
      "-------------------------------\n",
      "loss: 0.135990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420944 \n",
      "\n",
      "Epoch 2045\n",
      "-------------------------------\n",
      "loss: 0.133411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423165 \n",
      "\n",
      "Epoch 2046\n",
      "-------------------------------\n",
      "loss: 0.134723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430788 \n",
      "\n",
      "Epoch 2047\n",
      "-------------------------------\n",
      "loss: 0.160662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427127 \n",
      "\n",
      "Epoch 2048\n",
      "-------------------------------\n",
      "loss: 0.119538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421723 \n",
      "\n",
      "Epoch 2049\n",
      "-------------------------------\n",
      "loss: 0.129770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420820 \n",
      "\n",
      "Epoch 2050\n",
      "-------------------------------\n",
      "loss: 0.130351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425058 \n",
      "\n",
      "Epoch 2051\n",
      "-------------------------------\n",
      "loss: 0.141386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424973 \n",
      "\n",
      "Epoch 2052\n",
      "-------------------------------\n",
      "loss: 0.131485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420753 \n",
      "\n",
      "Epoch 2053\n",
      "-------------------------------\n",
      "loss: 0.132666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423587 \n",
      "\n",
      "Epoch 2054\n",
      "-------------------------------\n",
      "loss: 0.134838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429379 \n",
      "\n",
      "Epoch 2055\n",
      "-------------------------------\n",
      "loss: 0.145930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429316 \n",
      "\n",
      "Epoch 2056\n",
      "-------------------------------\n",
      "loss: 0.125986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425685 \n",
      "\n",
      "Epoch 2057\n",
      "-------------------------------\n",
      "loss: 0.122910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421303 \n",
      "\n",
      "Epoch 2058\n",
      "-------------------------------\n",
      "loss: 0.131846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417876 \n",
      "\n",
      "Epoch 2059\n",
      "-------------------------------\n",
      "loss: 0.133827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413633 \n",
      "\n",
      "Epoch 2060\n",
      "-------------------------------\n",
      "loss: 0.131326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410927 \n",
      "\n",
      "Epoch 2061\n",
      "-------------------------------\n",
      "loss: 0.114403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409038 \n",
      "\n",
      "Epoch 2062\n",
      "-------------------------------\n",
      "loss: 0.137821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409545 \n",
      "\n",
      "Epoch 2063\n",
      "-------------------------------\n",
      "loss: 0.123651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413674 \n",
      "\n",
      "Epoch 2064\n",
      "-------------------------------\n",
      "loss: 0.117206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418488 \n",
      "\n",
      "Epoch 2065\n",
      "-------------------------------\n",
      "loss: 0.131219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426307 \n",
      "\n",
      "Epoch 2066\n",
      "-------------------------------\n",
      "loss: 0.133294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433343 \n",
      "\n",
      "Epoch 2067\n",
      "-------------------------------\n",
      "loss: 0.139915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430728 \n",
      "\n",
      "Epoch 2068\n",
      "-------------------------------\n",
      "loss: 0.137709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422910 \n",
      "\n",
      "Epoch 2069\n",
      "-------------------------------\n",
      "loss: 0.130168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414481 \n",
      "\n",
      "Epoch 2070\n",
      "-------------------------------\n",
      "loss: 0.116057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411349 \n",
      "\n",
      "Epoch 2071\n",
      "-------------------------------\n",
      "loss: 0.148819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408278 \n",
      "\n",
      "Epoch 2072\n",
      "-------------------------------\n",
      "loss: 0.133270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408851 \n",
      "\n",
      "Epoch 2073\n",
      "-------------------------------\n",
      "loss: 0.140544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413940 \n",
      "\n",
      "Epoch 2074\n",
      "-------------------------------\n",
      "loss: 0.125558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416355 \n",
      "\n",
      "Epoch 2075\n",
      "-------------------------------\n",
      "loss: 0.142601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418370 \n",
      "\n",
      "Epoch 2076\n",
      "-------------------------------\n",
      "loss: 0.131428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423335 \n",
      "\n",
      "Epoch 2077\n",
      "-------------------------------\n",
      "loss: 0.125670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431363 \n",
      "\n",
      "Epoch 2078\n",
      "-------------------------------\n",
      "loss: 0.144755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435589 \n",
      "\n",
      "Epoch 2079\n",
      "-------------------------------\n",
      "loss: 0.142803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426718 \n",
      "\n",
      "Epoch 2080\n",
      "-------------------------------\n",
      "loss: 0.129192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418482 \n",
      "\n",
      "Epoch 2081\n",
      "-------------------------------\n",
      "loss: 0.128211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418112 \n",
      "\n",
      "Epoch 2082\n",
      "-------------------------------\n",
      "loss: 0.119577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422309 \n",
      "\n",
      "Epoch 2083\n",
      "-------------------------------\n",
      "loss: 0.127728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420008 \n",
      "\n",
      "Epoch 2084\n",
      "-------------------------------\n",
      "loss: 0.138473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416051 \n",
      "\n",
      "Epoch 2085\n",
      "-------------------------------\n",
      "loss: 0.121269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416679 \n",
      "\n",
      "Epoch 2086\n",
      "-------------------------------\n",
      "loss: 0.131916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420742 \n",
      "\n",
      "Epoch 2087\n",
      "-------------------------------\n",
      "loss: 0.131090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422495 \n",
      "\n",
      "Epoch 2088\n",
      "-------------------------------\n",
      "loss: 0.123378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422733 \n",
      "\n",
      "Epoch 2089\n",
      "-------------------------------\n",
      "loss: 0.126142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421424 \n",
      "\n",
      "Epoch 2090\n",
      "-------------------------------\n",
      "loss: 0.115613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420296 \n",
      "\n",
      "Epoch 2091\n",
      "-------------------------------\n",
      "loss: 0.122547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420491 \n",
      "\n",
      "Epoch 2092\n",
      "-------------------------------\n",
      "loss: 0.132821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417929 \n",
      "\n",
      "Epoch 2093\n",
      "-------------------------------\n",
      "loss: 0.127833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412238 \n",
      "\n",
      "Epoch 2094\n",
      "-------------------------------\n",
      "loss: 0.129798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411635 \n",
      "\n",
      "Epoch 2095\n",
      "-------------------------------\n",
      "loss: 0.125839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415873 \n",
      "\n",
      "Epoch 2096\n",
      "-------------------------------\n",
      "loss: 0.145293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420929 \n",
      "\n",
      "Epoch 2097\n",
      "-------------------------------\n",
      "loss: 0.133411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423457 \n",
      "\n",
      "Epoch 2098\n",
      "-------------------------------\n",
      "loss: 0.132949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423358 \n",
      "\n",
      "Epoch 2099\n",
      "-------------------------------\n",
      "loss: 0.129393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421161 \n",
      "\n",
      "Epoch 2100\n",
      "-------------------------------\n",
      "loss: 0.121112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420067 \n",
      "\n",
      "Epoch 2101\n",
      "-------------------------------\n",
      "loss: 0.122369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422421 \n",
      "\n",
      "Epoch 2102\n",
      "-------------------------------\n",
      "loss: 0.127804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424837 \n",
      "\n",
      "Epoch 2103\n",
      "-------------------------------\n",
      "loss: 0.134609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421757 \n",
      "\n",
      "Epoch 2104\n",
      "-------------------------------\n",
      "loss: 0.130074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418864 \n",
      "\n",
      "Epoch 2105\n",
      "-------------------------------\n",
      "loss: 0.125429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419892 \n",
      "\n",
      "Epoch 2106\n",
      "-------------------------------\n",
      "loss: 0.131890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428980 \n",
      "\n",
      "Epoch 2107\n",
      "-------------------------------\n",
      "loss: 0.118940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436140 \n",
      "\n",
      "Epoch 2108\n",
      "-------------------------------\n",
      "loss: 0.129713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438710 \n",
      "\n",
      "Epoch 2109\n",
      "-------------------------------\n",
      "loss: 0.127759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435295 \n",
      "\n",
      "Epoch 2110\n",
      "-------------------------------\n",
      "loss: 0.134496  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.426751 \n",
      "\n",
      "Epoch 2111\n",
      "-------------------------------\n",
      "loss: 0.149016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424675 \n",
      "\n",
      "Epoch 2112\n",
      "-------------------------------\n",
      "loss: 0.129631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426175 \n",
      "\n",
      "Epoch 2113\n",
      "-------------------------------\n",
      "loss: 0.124181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425720 \n",
      "\n",
      "Epoch 2114\n",
      "-------------------------------\n",
      "loss: 0.124380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421725 \n",
      "\n",
      "Epoch 2115\n",
      "-------------------------------\n",
      "loss: 0.120576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415587 \n",
      "\n",
      "Epoch 2116\n",
      "-------------------------------\n",
      "loss: 0.122922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411476 \n",
      "\n",
      "Epoch 2117\n",
      "-------------------------------\n",
      "loss: 0.137460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413537 \n",
      "\n",
      "Epoch 2118\n",
      "-------------------------------\n",
      "loss: 0.132732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413732 \n",
      "\n",
      "Epoch 2119\n",
      "-------------------------------\n",
      "loss: 0.137259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413837 \n",
      "\n",
      "Epoch 2120\n",
      "-------------------------------\n",
      "loss: 0.126335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417061 \n",
      "\n",
      "Epoch 2121\n",
      "-------------------------------\n",
      "loss: 0.120909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423762 \n",
      "\n",
      "Epoch 2122\n",
      "-------------------------------\n",
      "loss: 0.136334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431854 \n",
      "\n",
      "Epoch 2123\n",
      "-------------------------------\n",
      "loss: 0.124016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438228 \n",
      "\n",
      "Epoch 2124\n",
      "-------------------------------\n",
      "loss: 0.123983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439176 \n",
      "\n",
      "Epoch 2125\n",
      "-------------------------------\n",
      "loss: 0.123324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432134 \n",
      "\n",
      "Epoch 2126\n",
      "-------------------------------\n",
      "loss: 0.141069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422284 \n",
      "\n",
      "Epoch 2127\n",
      "-------------------------------\n",
      "loss: 0.126604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419779 \n",
      "\n",
      "Epoch 2128\n",
      "-------------------------------\n",
      "loss: 0.127889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427741 \n",
      "\n",
      "Epoch 2129\n",
      "-------------------------------\n",
      "loss: 0.137190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430004 \n",
      "\n",
      "Epoch 2130\n",
      "-------------------------------\n",
      "loss: 0.134739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428010 \n",
      "\n",
      "Epoch 2131\n",
      "-------------------------------\n",
      "loss: 0.130856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429001 \n",
      "\n",
      "Epoch 2132\n",
      "-------------------------------\n",
      "loss: 0.140935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428593 \n",
      "\n",
      "Epoch 2133\n",
      "-------------------------------\n",
      "loss: 0.134280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425988 \n",
      "\n",
      "Epoch 2134\n",
      "-------------------------------\n",
      "loss: 0.119961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422133 \n",
      "\n",
      "Epoch 2135\n",
      "-------------------------------\n",
      "loss: 0.116578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421678 \n",
      "\n",
      "Epoch 2136\n",
      "-------------------------------\n",
      "loss: 0.121207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425319 \n",
      "\n",
      "Epoch 2137\n",
      "-------------------------------\n",
      "loss: 0.138242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425008 \n",
      "\n",
      "Epoch 2138\n",
      "-------------------------------\n",
      "loss: 0.117188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425116 \n",
      "\n",
      "Epoch 2139\n",
      "-------------------------------\n",
      "loss: 0.119719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425496 \n",
      "\n",
      "Epoch 2140\n",
      "-------------------------------\n",
      "loss: 0.125689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424130 \n",
      "\n",
      "Epoch 2141\n",
      "-------------------------------\n",
      "loss: 0.122163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418266 \n",
      "\n",
      "Epoch 2142\n",
      "-------------------------------\n",
      "loss: 0.123175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415208 \n",
      "\n",
      "Epoch 2143\n",
      "-------------------------------\n",
      "loss: 0.124509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415566 \n",
      "\n",
      "Epoch 2144\n",
      "-------------------------------\n",
      "loss: 0.113369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416076 \n",
      "\n",
      "Epoch 2145\n",
      "-------------------------------\n",
      "loss: 0.117563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417231 \n",
      "\n",
      "Epoch 2146\n",
      "-------------------------------\n",
      "loss: 0.132764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416124 \n",
      "\n",
      "Epoch 2147\n",
      "-------------------------------\n",
      "loss: 0.120783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412660 \n",
      "\n",
      "Epoch 2148\n",
      "-------------------------------\n",
      "loss: 0.121122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416142 \n",
      "\n",
      "Epoch 2149\n",
      "-------------------------------\n",
      "loss: 0.115389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420310 \n",
      "\n",
      "Epoch 2150\n",
      "-------------------------------\n",
      "loss: 0.125415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420980 \n",
      "\n",
      "Epoch 2151\n",
      "-------------------------------\n",
      "loss: 0.138924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419830 \n",
      "\n",
      "Epoch 2152\n",
      "-------------------------------\n",
      "loss: 0.119141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417110 \n",
      "\n",
      "Epoch 2153\n",
      "-------------------------------\n",
      "loss: 0.119334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419644 \n",
      "\n",
      "Epoch 2154\n",
      "-------------------------------\n",
      "loss: 0.116439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425359 \n",
      "\n",
      "Epoch 2155\n",
      "-------------------------------\n",
      "loss: 0.117226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425317 \n",
      "\n",
      "Epoch 2156\n",
      "-------------------------------\n",
      "loss: 0.124971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424183 \n",
      "\n",
      "Epoch 2157\n",
      "-------------------------------\n",
      "loss: 0.125928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417591 \n",
      "\n",
      "Epoch 2158\n",
      "-------------------------------\n",
      "loss: 0.124694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416667 \n",
      "\n",
      "Epoch 2159\n",
      "-------------------------------\n",
      "loss: 0.119809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422113 \n",
      "\n",
      "Epoch 2160\n",
      "-------------------------------\n",
      "loss: 0.115287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429077 \n",
      "\n",
      "Epoch 2161\n",
      "-------------------------------\n",
      "loss: 0.125202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431741 \n",
      "\n",
      "Epoch 2162\n",
      "-------------------------------\n",
      "loss: 0.138320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428114 \n",
      "\n",
      "Epoch 2163\n",
      "-------------------------------\n",
      "loss: 0.133288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420555 \n",
      "\n",
      "Epoch 2164\n",
      "-------------------------------\n",
      "loss: 0.119544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416778 \n",
      "\n",
      "Epoch 2165\n",
      "-------------------------------\n",
      "loss: 0.123699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417632 \n",
      "\n",
      "Epoch 2166\n",
      "-------------------------------\n",
      "loss: 0.126551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421389 \n",
      "\n",
      "Epoch 2167\n",
      "-------------------------------\n",
      "loss: 0.133107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421672 \n",
      "\n",
      "Epoch 2168\n",
      "-------------------------------\n",
      "loss: 0.136316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418096 \n",
      "\n",
      "Epoch 2169\n",
      "-------------------------------\n",
      "loss: 0.118931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414253 \n",
      "\n",
      "Epoch 2170\n",
      "-------------------------------\n",
      "loss: 0.114615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414941 \n",
      "\n",
      "Epoch 2171\n",
      "-------------------------------\n",
      "loss: 0.132724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418173 \n",
      "\n",
      "Epoch 2172\n",
      "-------------------------------\n",
      "loss: 0.137719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418650 \n",
      "\n",
      "Epoch 2173\n",
      "-------------------------------\n",
      "loss: 0.121357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420245 \n",
      "\n",
      "Epoch 2174\n",
      "-------------------------------\n",
      "loss: 0.122659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420253 \n",
      "\n",
      "Epoch 2175\n",
      "-------------------------------\n",
      "loss: 0.141693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417932 \n",
      "\n",
      "Epoch 2176\n",
      "-------------------------------\n",
      "loss: 0.110557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417454 \n",
      "\n",
      "Epoch 2177\n",
      "-------------------------------\n",
      "loss: 0.126138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415760 \n",
      "\n",
      "Epoch 2178\n",
      "-------------------------------\n",
      "loss: 0.127428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409551 \n",
      "\n",
      "Epoch 2179\n",
      "-------------------------------\n",
      "loss: 0.112164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407461 \n",
      "\n",
      "Epoch 2180\n",
      "-------------------------------\n",
      "loss: 0.121645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408962 \n",
      "\n",
      "Epoch 2181\n",
      "-------------------------------\n",
      "loss: 0.117112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410876 \n",
      "\n",
      "Epoch 2182\n",
      "-------------------------------\n",
      "loss: 0.139036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410983 \n",
      "\n",
      "Epoch 2183\n",
      "-------------------------------\n",
      "loss: 0.129074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415060 \n",
      "\n",
      "Epoch 2184\n",
      "-------------------------------\n",
      "loss: 0.124695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423618 \n",
      "\n",
      "Epoch 2185\n",
      "-------------------------------\n",
      "loss: 0.119925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433244 \n",
      "\n",
      "Epoch 2186\n",
      "-------------------------------\n",
      "loss: 0.132008  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.436602 \n",
      "\n",
      "Epoch 2187\n",
      "-------------------------------\n",
      "loss: 0.124389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433913 \n",
      "\n",
      "Epoch 2188\n",
      "-------------------------------\n",
      "loss: 0.127136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420577 \n",
      "\n",
      "Epoch 2189\n",
      "-------------------------------\n",
      "loss: 0.140066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411633 \n",
      "\n",
      "Epoch 2190\n",
      "-------------------------------\n",
      "loss: 0.128806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408940 \n",
      "\n",
      "Epoch 2191\n",
      "-------------------------------\n",
      "loss: 0.125384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410537 \n",
      "\n",
      "Epoch 2192\n",
      "-------------------------------\n",
      "loss: 0.129202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410935 \n",
      "\n",
      "Epoch 2193\n",
      "-------------------------------\n",
      "loss: 0.134432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412656 \n",
      "\n",
      "Epoch 2194\n",
      "-------------------------------\n",
      "loss: 0.130852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417883 \n",
      "\n",
      "Epoch 2195\n",
      "-------------------------------\n",
      "loss: 0.120800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424471 \n",
      "\n",
      "Epoch 2196\n",
      "-------------------------------\n",
      "loss: 0.121168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429088 \n",
      "\n",
      "Epoch 2197\n",
      "-------------------------------\n",
      "loss: 0.119852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429005 \n",
      "\n",
      "Epoch 2198\n",
      "-------------------------------\n",
      "loss: 0.129429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427248 \n",
      "\n",
      "Epoch 2199\n",
      "-------------------------------\n",
      "loss: 0.140149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419980 \n",
      "\n",
      "Epoch 2200\n",
      "-------------------------------\n",
      "loss: 0.121740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413626 \n",
      "\n",
      "Epoch 2201\n",
      "-------------------------------\n",
      "loss: 0.120591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411828 \n",
      "\n",
      "Epoch 2202\n",
      "-------------------------------\n",
      "loss: 0.119237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411122 \n",
      "\n",
      "Epoch 2203\n",
      "-------------------------------\n",
      "loss: 0.123089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413154 \n",
      "\n",
      "Epoch 2204\n",
      "-------------------------------\n",
      "loss: 0.131526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415325 \n",
      "\n",
      "Epoch 2205\n",
      "-------------------------------\n",
      "loss: 0.122869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417944 \n",
      "\n",
      "Epoch 2206\n",
      "-------------------------------\n",
      "loss: 0.118246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418688 \n",
      "\n",
      "Epoch 2207\n",
      "-------------------------------\n",
      "loss: 0.123046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417030 \n",
      "\n",
      "Epoch 2208\n",
      "-------------------------------\n",
      "loss: 0.118648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414997 \n",
      "\n",
      "Epoch 2209\n",
      "-------------------------------\n",
      "loss: 0.111270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415992 \n",
      "\n",
      "Epoch 2210\n",
      "-------------------------------\n",
      "loss: 0.121434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414664 \n",
      "\n",
      "Epoch 2211\n",
      "-------------------------------\n",
      "loss: 0.137238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410623 \n",
      "\n",
      "Epoch 2212\n",
      "-------------------------------\n",
      "loss: 0.124313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411498 \n",
      "\n",
      "Epoch 2213\n",
      "-------------------------------\n",
      "loss: 0.116832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416571 \n",
      "\n",
      "Epoch 2214\n",
      "-------------------------------\n",
      "loss: 0.129249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416267 \n",
      "\n",
      "Epoch 2215\n",
      "-------------------------------\n",
      "loss: 0.122356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420073 \n",
      "\n",
      "Epoch 2216\n",
      "-------------------------------\n",
      "loss: 0.113746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427238 \n",
      "\n",
      "Epoch 2217\n",
      "-------------------------------\n",
      "loss: 0.139479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426124 \n",
      "\n",
      "Epoch 2218\n",
      "-------------------------------\n",
      "loss: 0.125037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420298 \n",
      "\n",
      "Epoch 2219\n",
      "-------------------------------\n",
      "loss: 0.122241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417405 \n",
      "\n",
      "Epoch 2220\n",
      "-------------------------------\n",
      "loss: 0.124663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419664 \n",
      "\n",
      "Epoch 2221\n",
      "-------------------------------\n",
      "loss: 0.140279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421732 \n",
      "\n",
      "Epoch 2222\n",
      "-------------------------------\n",
      "loss: 0.142017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422531 \n",
      "\n",
      "Epoch 2223\n",
      "-------------------------------\n",
      "loss: 0.130674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421640 \n",
      "\n",
      "Epoch 2224\n",
      "-------------------------------\n",
      "loss: 0.126789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423873 \n",
      "\n",
      "Epoch 2225\n",
      "-------------------------------\n",
      "loss: 0.136898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428625 \n",
      "\n",
      "Epoch 2226\n",
      "-------------------------------\n",
      "loss: 0.126051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430436 \n",
      "\n",
      "Epoch 2227\n",
      "-------------------------------\n",
      "loss: 0.124211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423871 \n",
      "\n",
      "Epoch 2228\n",
      "-------------------------------\n",
      "loss: 0.123734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417936 \n",
      "\n",
      "Epoch 2229\n",
      "-------------------------------\n",
      "loss: 0.123540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416896 \n",
      "\n",
      "Epoch 2230\n",
      "-------------------------------\n",
      "loss: 0.127724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416094 \n",
      "\n",
      "Epoch 2231\n",
      "-------------------------------\n",
      "loss: 0.112874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418918 \n",
      "\n",
      "Epoch 2232\n",
      "-------------------------------\n",
      "loss: 0.122116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423708 \n",
      "\n",
      "Epoch 2233\n",
      "-------------------------------\n",
      "loss: 0.116156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426051 \n",
      "\n",
      "Epoch 2234\n",
      "-------------------------------\n",
      "loss: 0.135530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425291 \n",
      "\n",
      "Epoch 2235\n",
      "-------------------------------\n",
      "loss: 0.126138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418319 \n",
      "\n",
      "Epoch 2236\n",
      "-------------------------------\n",
      "loss: 0.128465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413296 \n",
      "\n",
      "Epoch 2237\n",
      "-------------------------------\n",
      "loss: 0.127521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411102 \n",
      "\n",
      "Epoch 2238\n",
      "-------------------------------\n",
      "loss: 0.120440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411086 \n",
      "\n",
      "Epoch 2239\n",
      "-------------------------------\n",
      "loss: 0.123088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411583 \n",
      "\n",
      "Epoch 2240\n",
      "-------------------------------\n",
      "loss: 0.123113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413969 \n",
      "\n",
      "Epoch 2241\n",
      "-------------------------------\n",
      "loss: 0.116932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416814 \n",
      "\n",
      "Epoch 2242\n",
      "-------------------------------\n",
      "loss: 0.141699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420145 \n",
      "\n",
      "Epoch 2243\n",
      "-------------------------------\n",
      "loss: 0.138235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419967 \n",
      "\n",
      "Epoch 2244\n",
      "-------------------------------\n",
      "loss: 0.114872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418810 \n",
      "\n",
      "Epoch 2245\n",
      "-------------------------------\n",
      "loss: 0.147529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418961 \n",
      "\n",
      "Epoch 2246\n",
      "-------------------------------\n",
      "loss: 0.130974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418365 \n",
      "\n",
      "Epoch 2247\n",
      "-------------------------------\n",
      "loss: 0.123053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418555 \n",
      "\n",
      "Epoch 2248\n",
      "-------------------------------\n",
      "loss: 0.125960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420569 \n",
      "\n",
      "Epoch 2249\n",
      "-------------------------------\n",
      "loss: 0.126810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426680 \n",
      "\n",
      "Epoch 2250\n",
      "-------------------------------\n",
      "loss: 0.117459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425772 \n",
      "\n",
      "Epoch 2251\n",
      "-------------------------------\n",
      "loss: 0.138746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420479 \n",
      "\n",
      "Epoch 2252\n",
      "-------------------------------\n",
      "loss: 0.133829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415516 \n",
      "\n",
      "Epoch 2253\n",
      "-------------------------------\n",
      "loss: 0.121026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415697 \n",
      "\n",
      "Epoch 2254\n",
      "-------------------------------\n",
      "loss: 0.122873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422038 \n",
      "\n",
      "Epoch 2255\n",
      "-------------------------------\n",
      "loss: 0.133141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424184 \n",
      "\n",
      "Epoch 2256\n",
      "-------------------------------\n",
      "loss: 0.132464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421014 \n",
      "\n",
      "Epoch 2257\n",
      "-------------------------------\n",
      "loss: 0.133539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419795 \n",
      "\n",
      "Epoch 2258\n",
      "-------------------------------\n",
      "loss: 0.120307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428110 \n",
      "\n",
      "Epoch 2259\n",
      "-------------------------------\n",
      "loss: 0.126043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426205 \n",
      "\n",
      "Epoch 2260\n",
      "-------------------------------\n",
      "loss: 0.139438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417229 \n",
      "\n",
      "Epoch 2261\n",
      "-------------------------------\n",
      "loss: 0.117491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414875 \n",
      "\n",
      "Epoch 2262\n",
      "-------------------------------\n",
      "loss: 0.128831  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.417321 \n",
      "\n",
      "Epoch 2263\n",
      "-------------------------------\n",
      "loss: 0.126603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416346 \n",
      "\n",
      "Epoch 2264\n",
      "-------------------------------\n",
      "loss: 0.126176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412562 \n",
      "\n",
      "Epoch 2265\n",
      "-------------------------------\n",
      "loss: 0.126641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412177 \n",
      "\n",
      "Epoch 2266\n",
      "-------------------------------\n",
      "loss: 0.126496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419693 \n",
      "\n",
      "Epoch 2267\n",
      "-------------------------------\n",
      "loss: 0.121392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429027 \n",
      "\n",
      "Epoch 2268\n",
      "-------------------------------\n",
      "loss: 0.120936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430534 \n",
      "\n",
      "Epoch 2269\n",
      "-------------------------------\n",
      "loss: 0.140424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427309 \n",
      "\n",
      "Epoch 2270\n",
      "-------------------------------\n",
      "loss: 0.136720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422686 \n",
      "\n",
      "Epoch 2271\n",
      "-------------------------------\n",
      "loss: 0.119425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419468 \n",
      "\n",
      "Epoch 2272\n",
      "-------------------------------\n",
      "loss: 0.127322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421844 \n",
      "\n",
      "Epoch 2273\n",
      "-------------------------------\n",
      "loss: 0.133814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426439 \n",
      "\n",
      "Epoch 2274\n",
      "-------------------------------\n",
      "loss: 0.120575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429177 \n",
      "\n",
      "Epoch 2275\n",
      "-------------------------------\n",
      "loss: 0.127192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427772 \n",
      "\n",
      "Epoch 2276\n",
      "-------------------------------\n",
      "loss: 0.131997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424994 \n",
      "\n",
      "Epoch 2277\n",
      "-------------------------------\n",
      "loss: 0.131627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419153 \n",
      "\n",
      "Epoch 2278\n",
      "-------------------------------\n",
      "loss: 0.140322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413286 \n",
      "\n",
      "Epoch 2279\n",
      "-------------------------------\n",
      "loss: 0.124767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418093 \n",
      "\n",
      "Epoch 2280\n",
      "-------------------------------\n",
      "loss: 0.122304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424389 \n",
      "\n",
      "Epoch 2281\n",
      "-------------------------------\n",
      "loss: 0.138793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423268 \n",
      "\n",
      "Epoch 2282\n",
      "-------------------------------\n",
      "loss: 0.131310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420213 \n",
      "\n",
      "Epoch 2283\n",
      "-------------------------------\n",
      "loss: 0.124998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420712 \n",
      "\n",
      "Epoch 2284\n",
      "-------------------------------\n",
      "loss: 0.129269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424202 \n",
      "\n",
      "Epoch 2285\n",
      "-------------------------------\n",
      "loss: 0.140137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425855 \n",
      "\n",
      "Epoch 2286\n",
      "-------------------------------\n",
      "loss: 0.127390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426933 \n",
      "\n",
      "Epoch 2287\n",
      "-------------------------------\n",
      "loss: 0.131315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421780 \n",
      "\n",
      "Epoch 2288\n",
      "-------------------------------\n",
      "loss: 0.125899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413413 \n",
      "\n",
      "Epoch 2289\n",
      "-------------------------------\n",
      "loss: 0.128116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409238 \n",
      "\n",
      "Epoch 2290\n",
      "-------------------------------\n",
      "loss: 0.132595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411248 \n",
      "\n",
      "Epoch 2291\n",
      "-------------------------------\n",
      "loss: 0.141012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413637 \n",
      "\n",
      "Epoch 2292\n",
      "-------------------------------\n",
      "loss: 0.132752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417717 \n",
      "\n",
      "Epoch 2293\n",
      "-------------------------------\n",
      "loss: 0.128827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419227 \n",
      "\n",
      "Epoch 2294\n",
      "-------------------------------\n",
      "loss: 0.133916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417741 \n",
      "\n",
      "Epoch 2295\n",
      "-------------------------------\n",
      "loss: 0.126331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414061 \n",
      "\n",
      "Epoch 2296\n",
      "-------------------------------\n",
      "loss: 0.130502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411707 \n",
      "\n",
      "Epoch 2297\n",
      "-------------------------------\n",
      "loss: 0.135797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411560 \n",
      "\n",
      "Epoch 2298\n",
      "-------------------------------\n",
      "loss: 0.135283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411283 \n",
      "\n",
      "Epoch 2299\n",
      "-------------------------------\n",
      "loss: 0.131887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412337 \n",
      "\n",
      "Epoch 2300\n",
      "-------------------------------\n",
      "loss: 0.130859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416407 \n",
      "\n",
      "Epoch 2301\n",
      "-------------------------------\n",
      "loss: 0.113309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421755 \n",
      "\n",
      "Epoch 2302\n",
      "-------------------------------\n",
      "loss: 0.152673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429897 \n",
      "\n",
      "Epoch 2303\n",
      "-------------------------------\n",
      "loss: 0.118108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440177 \n",
      "\n",
      "Epoch 2304\n",
      "-------------------------------\n",
      "loss: 0.129660  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445548 \n",
      "\n",
      "Epoch 2305\n",
      "-------------------------------\n",
      "loss: 0.131427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441705 \n",
      "\n",
      "Epoch 2306\n",
      "-------------------------------\n",
      "loss: 0.117738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432055 \n",
      "\n",
      "Epoch 2307\n",
      "-------------------------------\n",
      "loss: 0.127536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427143 \n",
      "\n",
      "Epoch 2308\n",
      "-------------------------------\n",
      "loss: 0.131255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422909 \n",
      "\n",
      "Epoch 2309\n",
      "-------------------------------\n",
      "loss: 0.133851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417080 \n",
      "\n",
      "Epoch 2310\n",
      "-------------------------------\n",
      "loss: 0.126472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415548 \n",
      "\n",
      "Epoch 2311\n",
      "-------------------------------\n",
      "loss: 0.112244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420422 \n",
      "\n",
      "Epoch 2312\n",
      "-------------------------------\n",
      "loss: 0.121809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426390 \n",
      "\n",
      "Epoch 2313\n",
      "-------------------------------\n",
      "loss: 0.126419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422010 \n",
      "\n",
      "Epoch 2314\n",
      "-------------------------------\n",
      "loss: 0.118569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418113 \n",
      "\n",
      "Epoch 2315\n",
      "-------------------------------\n",
      "loss: 0.115940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421886 \n",
      "\n",
      "Epoch 2316\n",
      "-------------------------------\n",
      "loss: 0.117835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427375 \n",
      "\n",
      "Epoch 2317\n",
      "-------------------------------\n",
      "loss: 0.126205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425762 \n",
      "\n",
      "Epoch 2318\n",
      "-------------------------------\n",
      "loss: 0.133410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423189 \n",
      "\n",
      "Epoch 2319\n",
      "-------------------------------\n",
      "loss: 0.143640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428040 \n",
      "\n",
      "Epoch 2320\n",
      "-------------------------------\n",
      "loss: 0.124391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430287 \n",
      "\n",
      "Epoch 2321\n",
      "-------------------------------\n",
      "loss: 0.124884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426655 \n",
      "\n",
      "Epoch 2322\n",
      "-------------------------------\n",
      "loss: 0.125512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419606 \n",
      "\n",
      "Epoch 2323\n",
      "-------------------------------\n",
      "loss: 0.149055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413671 \n",
      "\n",
      "Epoch 2324\n",
      "-------------------------------\n",
      "loss: 0.134286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414172 \n",
      "\n",
      "Epoch 2325\n",
      "-------------------------------\n",
      "loss: 0.123967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420946 \n",
      "\n",
      "Epoch 2326\n",
      "-------------------------------\n",
      "loss: 0.126320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424770 \n",
      "\n",
      "Epoch 2327\n",
      "-------------------------------\n",
      "loss: 0.125971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421086 \n",
      "\n",
      "Epoch 2328\n",
      "-------------------------------\n",
      "loss: 0.124292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416364 \n",
      "\n",
      "Epoch 2329\n",
      "-------------------------------\n",
      "loss: 0.121872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413678 \n",
      "\n",
      "Epoch 2330\n",
      "-------------------------------\n",
      "loss: 0.126293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415270 \n",
      "\n",
      "Epoch 2331\n",
      "-------------------------------\n",
      "loss: 0.130678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417266 \n",
      "\n",
      "Epoch 2332\n",
      "-------------------------------\n",
      "loss: 0.126285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414011 \n",
      "\n",
      "Epoch 2333\n",
      "-------------------------------\n",
      "loss: 0.118520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410320 \n",
      "\n",
      "Epoch 2334\n",
      "-------------------------------\n",
      "loss: 0.119894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408855 \n",
      "\n",
      "Epoch 2335\n",
      "-------------------------------\n",
      "loss: 0.134671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408359 \n",
      "\n",
      "Epoch 2336\n",
      "-------------------------------\n",
      "loss: 0.139913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413692 \n",
      "\n",
      "Epoch 2337\n",
      "-------------------------------\n",
      "loss: 0.112949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418947 \n",
      "\n",
      "Epoch 2338\n",
      "-------------------------------\n",
      "loss: 0.126563  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.421143 \n",
      "\n",
      "Epoch 2339\n",
      "-------------------------------\n",
      "loss: 0.121332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420262 \n",
      "\n",
      "Epoch 2340\n",
      "-------------------------------\n",
      "loss: 0.115868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423261 \n",
      "\n",
      "Epoch 2341\n",
      "-------------------------------\n",
      "loss: 0.121392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424580 \n",
      "\n",
      "Epoch 2342\n",
      "-------------------------------\n",
      "loss: 0.140842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425281 \n",
      "\n",
      "Epoch 2343\n",
      "-------------------------------\n",
      "loss: 0.125997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421561 \n",
      "\n",
      "Epoch 2344\n",
      "-------------------------------\n",
      "loss: 0.130249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419753 \n",
      "\n",
      "Epoch 2345\n",
      "-------------------------------\n",
      "loss: 0.106237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418384 \n",
      "\n",
      "Epoch 2346\n",
      "-------------------------------\n",
      "loss: 0.109794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415226 \n",
      "\n",
      "Epoch 2347\n",
      "-------------------------------\n",
      "loss: 0.116051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415269 \n",
      "\n",
      "Epoch 2348\n",
      "-------------------------------\n",
      "loss: 0.134886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410735 \n",
      "\n",
      "Epoch 2349\n",
      "-------------------------------\n",
      "loss: 0.123824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405066 \n",
      "\n",
      "Epoch 2350\n",
      "-------------------------------\n",
      "loss: 0.128976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409479 \n",
      "\n",
      "Epoch 2351\n",
      "-------------------------------\n",
      "loss: 0.120648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419615 \n",
      "\n",
      "Epoch 2352\n",
      "-------------------------------\n",
      "loss: 0.126985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426049 \n",
      "\n",
      "Epoch 2353\n",
      "-------------------------------\n",
      "loss: 0.122530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427624 \n",
      "\n",
      "Epoch 2354\n",
      "-------------------------------\n",
      "loss: 0.122515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423743 \n",
      "\n",
      "Epoch 2355\n",
      "-------------------------------\n",
      "loss: 0.119788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417537 \n",
      "\n",
      "Epoch 2356\n",
      "-------------------------------\n",
      "loss: 0.129812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414116 \n",
      "\n",
      "Epoch 2357\n",
      "-------------------------------\n",
      "loss: 0.110343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415774 \n",
      "\n",
      "Epoch 2358\n",
      "-------------------------------\n",
      "loss: 0.134646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415507 \n",
      "\n",
      "Epoch 2359\n",
      "-------------------------------\n",
      "loss: 0.122679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413307 \n",
      "\n",
      "Epoch 2360\n",
      "-------------------------------\n",
      "loss: 0.131074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412190 \n",
      "\n",
      "Epoch 2361\n",
      "-------------------------------\n",
      "loss: 0.126788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413079 \n",
      "\n",
      "Epoch 2362\n",
      "-------------------------------\n",
      "loss: 0.115746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418144 \n",
      "\n",
      "Epoch 2363\n",
      "-------------------------------\n",
      "loss: 0.120899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421058 \n",
      "\n",
      "Epoch 2364\n",
      "-------------------------------\n",
      "loss: 0.124984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421337 \n",
      "\n",
      "Epoch 2365\n",
      "-------------------------------\n",
      "loss: 0.131551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418411 \n",
      "\n",
      "Epoch 2366\n",
      "-------------------------------\n",
      "loss: 0.123916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415183 \n",
      "\n",
      "Epoch 2367\n",
      "-------------------------------\n",
      "loss: 0.111654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413095 \n",
      "\n",
      "Epoch 2368\n",
      "-------------------------------\n",
      "loss: 0.121682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414955 \n",
      "\n",
      "Epoch 2369\n",
      "-------------------------------\n",
      "loss: 0.150715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412352 \n",
      "\n",
      "Epoch 2370\n",
      "-------------------------------\n",
      "loss: 0.117016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415442 \n",
      "\n",
      "Epoch 2371\n",
      "-------------------------------\n",
      "loss: 0.115602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420283 \n",
      "\n",
      "Epoch 2372\n",
      "-------------------------------\n",
      "loss: 0.106196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427056 \n",
      "\n",
      "Epoch 2373\n",
      "-------------------------------\n",
      "loss: 0.131352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428291 \n",
      "\n",
      "Epoch 2374\n",
      "-------------------------------\n",
      "loss: 0.132675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425125 \n",
      "\n",
      "Epoch 2375\n",
      "-------------------------------\n",
      "loss: 0.127444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421597 \n",
      "\n",
      "Epoch 2376\n",
      "-------------------------------\n",
      "loss: 0.118760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426473 \n",
      "\n",
      "Epoch 2377\n",
      "-------------------------------\n",
      "loss: 0.127586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430494 \n",
      "\n",
      "Epoch 2378\n",
      "-------------------------------\n",
      "loss: 0.120801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424509 \n",
      "\n",
      "Epoch 2379\n",
      "-------------------------------\n",
      "loss: 0.130102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415035 \n",
      "\n",
      "Epoch 2380\n",
      "-------------------------------\n",
      "loss: 0.124212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412172 \n",
      "\n",
      "Epoch 2381\n",
      "-------------------------------\n",
      "loss: 0.137615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416558 \n",
      "\n",
      "Epoch 2382\n",
      "-------------------------------\n",
      "loss: 0.144432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415117 \n",
      "\n",
      "Epoch 2383\n",
      "-------------------------------\n",
      "loss: 0.147765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408591 \n",
      "\n",
      "Epoch 2384\n",
      "-------------------------------\n",
      "loss: 0.132985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407380 \n",
      "\n",
      "Epoch 2385\n",
      "-------------------------------\n",
      "loss: 0.114470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414485 \n",
      "\n",
      "Epoch 2386\n",
      "-------------------------------\n",
      "loss: 0.128514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422280 \n",
      "\n",
      "Epoch 2387\n",
      "-------------------------------\n",
      "loss: 0.129096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428771 \n",
      "\n",
      "Epoch 2388\n",
      "-------------------------------\n",
      "loss: 0.124112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435037 \n",
      "\n",
      "Epoch 2389\n",
      "-------------------------------\n",
      "loss: 0.124519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435976 \n",
      "\n",
      "Epoch 2390\n",
      "-------------------------------\n",
      "loss: 0.134185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429723 \n",
      "\n",
      "Epoch 2391\n",
      "-------------------------------\n",
      "loss: 0.119180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417378 \n",
      "\n",
      "Epoch 2392\n",
      "-------------------------------\n",
      "loss: 0.115018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410240 \n",
      "\n",
      "Epoch 2393\n",
      "-------------------------------\n",
      "loss: 0.114489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409226 \n",
      "\n",
      "Epoch 2394\n",
      "-------------------------------\n",
      "loss: 0.117026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409793 \n",
      "\n",
      "Epoch 2395\n",
      "-------------------------------\n",
      "loss: 0.118960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411401 \n",
      "\n",
      "Epoch 2396\n",
      "-------------------------------\n",
      "loss: 0.120054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411889 \n",
      "\n",
      "Epoch 2397\n",
      "-------------------------------\n",
      "loss: 0.119999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412024 \n",
      "\n",
      "Epoch 2398\n",
      "-------------------------------\n",
      "loss: 0.119021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414167 \n",
      "\n",
      "Epoch 2399\n",
      "-------------------------------\n",
      "loss: 0.120121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417677 \n",
      "\n",
      "Epoch 2400\n",
      "-------------------------------\n",
      "loss: 0.135594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419903 \n",
      "\n",
      "Epoch 2401\n",
      "-------------------------------\n",
      "loss: 0.130795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421602 \n",
      "\n",
      "Epoch 2402\n",
      "-------------------------------\n",
      "loss: 0.137545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421455 \n",
      "\n",
      "Epoch 2403\n",
      "-------------------------------\n",
      "loss: 0.122221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422930 \n",
      "\n",
      "Epoch 2404\n",
      "-------------------------------\n",
      "loss: 0.120481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416791 \n",
      "\n",
      "Epoch 2405\n",
      "-------------------------------\n",
      "loss: 0.116090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412974 \n",
      "\n",
      "Epoch 2406\n",
      "-------------------------------\n",
      "loss: 0.113991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412041 \n",
      "\n",
      "Epoch 2407\n",
      "-------------------------------\n",
      "loss: 0.132988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411082 \n",
      "\n",
      "Epoch 2408\n",
      "-------------------------------\n",
      "loss: 0.133216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413269 \n",
      "\n",
      "Epoch 2409\n",
      "-------------------------------\n",
      "loss: 0.118907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415825 \n",
      "\n",
      "Epoch 2410\n",
      "-------------------------------\n",
      "loss: 0.129599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420234 \n",
      "\n",
      "Epoch 2411\n",
      "-------------------------------\n",
      "loss: 0.133194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422538 \n",
      "\n",
      "Epoch 2412\n",
      "-------------------------------\n",
      "loss: 0.123707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421267 \n",
      "\n",
      "Epoch 2413\n",
      "-------------------------------\n",
      "loss: 0.139880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418358 \n",
      "\n",
      "Epoch 2414\n",
      "-------------------------------\n",
      "loss: 0.133859  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.415352 \n",
      "\n",
      "Epoch 2415\n",
      "-------------------------------\n",
      "loss: 0.123890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413756 \n",
      "\n",
      "Epoch 2416\n",
      "-------------------------------\n",
      "loss: 0.116434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418102 \n",
      "\n",
      "Epoch 2417\n",
      "-------------------------------\n",
      "loss: 0.117440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422085 \n",
      "\n",
      "Epoch 2418\n",
      "-------------------------------\n",
      "loss: 0.122905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421369 \n",
      "\n",
      "Epoch 2419\n",
      "-------------------------------\n",
      "loss: 0.134611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418318 \n",
      "\n",
      "Epoch 2420\n",
      "-------------------------------\n",
      "loss: 0.127760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415688 \n",
      "\n",
      "Epoch 2421\n",
      "-------------------------------\n",
      "loss: 0.122701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417558 \n",
      "\n",
      "Epoch 2422\n",
      "-------------------------------\n",
      "loss: 0.121748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420356 \n",
      "\n",
      "Epoch 2423\n",
      "-------------------------------\n",
      "loss: 0.131368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424776 \n",
      "\n",
      "Epoch 2424\n",
      "-------------------------------\n",
      "loss: 0.126422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425861 \n",
      "\n",
      "Epoch 2425\n",
      "-------------------------------\n",
      "loss: 0.113450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435023 \n",
      "\n",
      "Epoch 2426\n",
      "-------------------------------\n",
      "loss: 0.129464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437269 \n",
      "\n",
      "Epoch 2427\n",
      "-------------------------------\n",
      "loss: 0.127564  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426881 \n",
      "\n",
      "Epoch 2428\n",
      "-------------------------------\n",
      "loss: 0.118225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415386 \n",
      "\n",
      "Epoch 2429\n",
      "-------------------------------\n",
      "loss: 0.134131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409803 \n",
      "\n",
      "Epoch 2430\n",
      "-------------------------------\n",
      "loss: 0.126633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409717 \n",
      "\n",
      "Epoch 2431\n",
      "-------------------------------\n",
      "loss: 0.117707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412882 \n",
      "\n",
      "Epoch 2432\n",
      "-------------------------------\n",
      "loss: 0.126586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415171 \n",
      "\n",
      "Epoch 2433\n",
      "-------------------------------\n",
      "loss: 0.126248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416625 \n",
      "\n",
      "Epoch 2434\n",
      "-------------------------------\n",
      "loss: 0.123196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418354 \n",
      "\n",
      "Epoch 2435\n",
      "-------------------------------\n",
      "loss: 0.115198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418116 \n",
      "\n",
      "Epoch 2436\n",
      "-------------------------------\n",
      "loss: 0.120159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419472 \n",
      "\n",
      "Epoch 2437\n",
      "-------------------------------\n",
      "loss: 0.117862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421706 \n",
      "\n",
      "Epoch 2438\n",
      "-------------------------------\n",
      "loss: 0.122770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424056 \n",
      "\n",
      "Epoch 2439\n",
      "-------------------------------\n",
      "loss: 0.113477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424036 \n",
      "\n",
      "Epoch 2440\n",
      "-------------------------------\n",
      "loss: 0.109549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423876 \n",
      "\n",
      "Epoch 2441\n",
      "-------------------------------\n",
      "loss: 0.116875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422671 \n",
      "\n",
      "Epoch 2442\n",
      "-------------------------------\n",
      "loss: 0.115855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418769 \n",
      "\n",
      "Epoch 2443\n",
      "-------------------------------\n",
      "loss: 0.115192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415244 \n",
      "\n",
      "Epoch 2444\n",
      "-------------------------------\n",
      "loss: 0.119470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413490 \n",
      "\n",
      "Epoch 2445\n",
      "-------------------------------\n",
      "loss: 0.123841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413833 \n",
      "\n",
      "Epoch 2446\n",
      "-------------------------------\n",
      "loss: 0.109575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414652 \n",
      "\n",
      "Epoch 2447\n",
      "-------------------------------\n",
      "loss: 0.118664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415706 \n",
      "\n",
      "Epoch 2448\n",
      "-------------------------------\n",
      "loss: 0.118858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417577 \n",
      "\n",
      "Epoch 2449\n",
      "-------------------------------\n",
      "loss: 0.109235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420564 \n",
      "\n",
      "Epoch 2450\n",
      "-------------------------------\n",
      "loss: 0.117625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421299 \n",
      "\n",
      "Epoch 2451\n",
      "-------------------------------\n",
      "loss: 0.112993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419104 \n",
      "\n",
      "Epoch 2452\n",
      "-------------------------------\n",
      "loss: 0.131376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417978 \n",
      "\n",
      "Epoch 2453\n",
      "-------------------------------\n",
      "loss: 0.130715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419095 \n",
      "\n",
      "Epoch 2454\n",
      "-------------------------------\n",
      "loss: 0.116921  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418224 \n",
      "\n",
      "Epoch 2455\n",
      "-------------------------------\n",
      "loss: 0.113690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415542 \n",
      "\n",
      "Epoch 2456\n",
      "-------------------------------\n",
      "loss: 0.127855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413865 \n",
      "\n",
      "Epoch 2457\n",
      "-------------------------------\n",
      "loss: 0.115364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415628 \n",
      "\n",
      "Epoch 2458\n",
      "-------------------------------\n",
      "loss: 0.127617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415749 \n",
      "\n",
      "Epoch 2459\n",
      "-------------------------------\n",
      "loss: 0.121744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416032 \n",
      "\n",
      "Epoch 2460\n",
      "-------------------------------\n",
      "loss: 0.125387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417894 \n",
      "\n",
      "Epoch 2461\n",
      "-------------------------------\n",
      "loss: 0.135533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422748 \n",
      "\n",
      "Epoch 2462\n",
      "-------------------------------\n",
      "loss: 0.127953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422724 \n",
      "\n",
      "Epoch 2463\n",
      "-------------------------------\n",
      "loss: 0.121601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419095 \n",
      "\n",
      "Epoch 2464\n",
      "-------------------------------\n",
      "loss: 0.138961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413126 \n",
      "\n",
      "Epoch 2465\n",
      "-------------------------------\n",
      "loss: 0.116923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412083 \n",
      "\n",
      "Epoch 2466\n",
      "-------------------------------\n",
      "loss: 0.117965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415414 \n",
      "\n",
      "Epoch 2467\n",
      "-------------------------------\n",
      "loss: 0.120161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417960 \n",
      "\n",
      "Epoch 2468\n",
      "-------------------------------\n",
      "loss: 0.127125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415589 \n",
      "\n",
      "Epoch 2469\n",
      "-------------------------------\n",
      "loss: 0.122308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413116 \n",
      "\n",
      "Epoch 2470\n",
      "-------------------------------\n",
      "loss: 0.118665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412888 \n",
      "\n",
      "Epoch 2471\n",
      "-------------------------------\n",
      "loss: 0.117375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416763 \n",
      "\n",
      "Epoch 2472\n",
      "-------------------------------\n",
      "loss: 0.147220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420543 \n",
      "\n",
      "Epoch 2473\n",
      "-------------------------------\n",
      "loss: 0.121669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420005 \n",
      "\n",
      "Epoch 2474\n",
      "-------------------------------\n",
      "loss: 0.123303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416616 \n",
      "\n",
      "Epoch 2475\n",
      "-------------------------------\n",
      "loss: 0.124121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412626 \n",
      "\n",
      "Epoch 2476\n",
      "-------------------------------\n",
      "loss: 0.121950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410377 \n",
      "\n",
      "Epoch 2477\n",
      "-------------------------------\n",
      "loss: 0.127997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413960 \n",
      "\n",
      "Epoch 2478\n",
      "-------------------------------\n",
      "loss: 0.136075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416168 \n",
      "\n",
      "Epoch 2479\n",
      "-------------------------------\n",
      "loss: 0.127352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417695 \n",
      "\n",
      "Epoch 2480\n",
      "-------------------------------\n",
      "loss: 0.111293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417541 \n",
      "\n",
      "Epoch 2481\n",
      "-------------------------------\n",
      "loss: 0.118959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418450 \n",
      "\n",
      "Epoch 2482\n",
      "-------------------------------\n",
      "loss: 0.119668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420710 \n",
      "\n",
      "Epoch 2483\n",
      "-------------------------------\n",
      "loss: 0.121529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418782 \n",
      "\n",
      "Epoch 2484\n",
      "-------------------------------\n",
      "loss: 0.120282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415803 \n",
      "\n",
      "Epoch 2485\n",
      "-------------------------------\n",
      "loss: 0.148764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413103 \n",
      "\n",
      "Epoch 2486\n",
      "-------------------------------\n",
      "loss: 0.109304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407734 \n",
      "\n",
      "Epoch 2487\n",
      "-------------------------------\n",
      "loss: 0.111060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406409 \n",
      "\n",
      "Epoch 2488\n",
      "-------------------------------\n",
      "loss: 0.124204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408664 \n",
      "\n",
      "Epoch 2489\n",
      "-------------------------------\n",
      "loss: 0.110382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410815 \n",
      "\n",
      "Epoch 2490\n",
      "-------------------------------\n",
      "loss: 0.122265  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.415687 \n",
      "\n",
      "Epoch 2491\n",
      "-------------------------------\n",
      "loss: 0.114354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422875 \n",
      "\n",
      "Epoch 2492\n",
      "-------------------------------\n",
      "loss: 0.118883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430214 \n",
      "\n",
      "Epoch 2493\n",
      "-------------------------------\n",
      "loss: 0.120227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432472 \n",
      "\n",
      "Epoch 2494\n",
      "-------------------------------\n",
      "loss: 0.129393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429547 \n",
      "\n",
      "Epoch 2495\n",
      "-------------------------------\n",
      "loss: 0.121293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425943 \n",
      "\n",
      "Epoch 2496\n",
      "-------------------------------\n",
      "loss: 0.117016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421142 \n",
      "\n",
      "Epoch 2497\n",
      "-------------------------------\n",
      "loss: 0.128984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417071 \n",
      "\n",
      "Epoch 2498\n",
      "-------------------------------\n",
      "loss: 0.114961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414699 \n",
      "\n",
      "Epoch 2499\n",
      "-------------------------------\n",
      "loss: 0.115553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414956 \n",
      "\n",
      "Epoch 2500\n",
      "-------------------------------\n",
      "loss: 0.119834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417027 \n",
      "\n",
      "Epoch 2501\n",
      "-------------------------------\n",
      "loss: 0.109862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420337 \n",
      "\n",
      "Epoch 2502\n",
      "-------------------------------\n",
      "loss: 0.120942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421511 \n",
      "\n",
      "Epoch 2503\n",
      "-------------------------------\n",
      "loss: 0.124731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420349 \n",
      "\n",
      "Epoch 2504\n",
      "-------------------------------\n",
      "loss: 0.116562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418394 \n",
      "\n",
      "Epoch 2505\n",
      "-------------------------------\n",
      "loss: 0.114650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416322 \n",
      "\n",
      "Epoch 2506\n",
      "-------------------------------\n",
      "loss: 0.112451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413901 \n",
      "\n",
      "Epoch 2507\n",
      "-------------------------------\n",
      "loss: 0.124307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414536 \n",
      "\n",
      "Epoch 2508\n",
      "-------------------------------\n",
      "loss: 0.116193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417969 \n",
      "\n",
      "Epoch 2509\n",
      "-------------------------------\n",
      "loss: 0.116195  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416212 \n",
      "\n",
      "Epoch 2510\n",
      "-------------------------------\n",
      "loss: 0.132966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411878 \n",
      "\n",
      "Epoch 2511\n",
      "-------------------------------\n",
      "loss: 0.117608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409783 \n",
      "\n",
      "Epoch 2512\n",
      "-------------------------------\n",
      "loss: 0.121040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410632 \n",
      "\n",
      "Epoch 2513\n",
      "-------------------------------\n",
      "loss: 0.137527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413380 \n",
      "\n",
      "Epoch 2514\n",
      "-------------------------------\n",
      "loss: 0.110460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420097 \n",
      "\n",
      "Epoch 2515\n",
      "-------------------------------\n",
      "loss: 0.112557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426013 \n",
      "\n",
      "Epoch 2516\n",
      "-------------------------------\n",
      "loss: 0.120541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429105 \n",
      "\n",
      "Epoch 2517\n",
      "-------------------------------\n",
      "loss: 0.132790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428261 \n",
      "\n",
      "Epoch 2518\n",
      "-------------------------------\n",
      "loss: 0.121718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423147 \n",
      "\n",
      "Epoch 2519\n",
      "-------------------------------\n",
      "loss: 0.112637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421046 \n",
      "\n",
      "Epoch 2520\n",
      "-------------------------------\n",
      "loss: 0.111110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421193 \n",
      "\n",
      "Epoch 2521\n",
      "-------------------------------\n",
      "loss: 0.111651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414716 \n",
      "\n",
      "Epoch 2522\n",
      "-------------------------------\n",
      "loss: 0.112481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407923 \n",
      "\n",
      "Epoch 2523\n",
      "-------------------------------\n",
      "loss: 0.116862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403844 \n",
      "\n",
      "Epoch 2524\n",
      "-------------------------------\n",
      "loss: 0.129454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403718 \n",
      "\n",
      "Epoch 2525\n",
      "-------------------------------\n",
      "loss: 0.138177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409451 \n",
      "\n",
      "Epoch 2526\n",
      "-------------------------------\n",
      "loss: 0.116571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415780 \n",
      "\n",
      "Epoch 2527\n",
      "-------------------------------\n",
      "loss: 0.122708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419365 \n",
      "\n",
      "Epoch 2528\n",
      "-------------------------------\n",
      "loss: 0.128829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419359 \n",
      "\n",
      "Epoch 2529\n",
      "-------------------------------\n",
      "loss: 0.150212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415818 \n",
      "\n",
      "Epoch 2530\n",
      "-------------------------------\n",
      "loss: 0.126792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408155 \n",
      "\n",
      "Epoch 2531\n",
      "-------------------------------\n",
      "loss: 0.111481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405851 \n",
      "\n",
      "Epoch 2532\n",
      "-------------------------------\n",
      "loss: 0.119712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403115 \n",
      "\n",
      "Epoch 2533\n",
      "-------------------------------\n",
      "loss: 0.120926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405008 \n",
      "\n",
      "Epoch 2534\n",
      "-------------------------------\n",
      "loss: 0.118726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410509 \n",
      "\n",
      "Epoch 2535\n",
      "-------------------------------\n",
      "loss: 0.126476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412762 \n",
      "\n",
      "Epoch 2536\n",
      "-------------------------------\n",
      "loss: 0.116049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415961 \n",
      "\n",
      "Epoch 2537\n",
      "-------------------------------\n",
      "loss: 0.118707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417133 \n",
      "\n",
      "Epoch 2538\n",
      "-------------------------------\n",
      "loss: 0.129497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416759 \n",
      "\n",
      "Epoch 2539\n",
      "-------------------------------\n",
      "loss: 0.135344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417735 \n",
      "\n",
      "Epoch 2540\n",
      "-------------------------------\n",
      "loss: 0.120078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422006 \n",
      "\n",
      "Epoch 2541\n",
      "-------------------------------\n",
      "loss: 0.133182  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425141 \n",
      "\n",
      "Epoch 2542\n",
      "-------------------------------\n",
      "loss: 0.119868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423068 \n",
      "\n",
      "Epoch 2543\n",
      "-------------------------------\n",
      "loss: 0.121154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419768 \n",
      "\n",
      "Epoch 2544\n",
      "-------------------------------\n",
      "loss: 0.120230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416705 \n",
      "\n",
      "Epoch 2545\n",
      "-------------------------------\n",
      "loss: 0.116043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417810 \n",
      "\n",
      "Epoch 2546\n",
      "-------------------------------\n",
      "loss: 0.118236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417830 \n",
      "\n",
      "Epoch 2547\n",
      "-------------------------------\n",
      "loss: 0.133321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414284 \n",
      "\n",
      "Epoch 2548\n",
      "-------------------------------\n",
      "loss: 0.117512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411691 \n",
      "\n",
      "Epoch 2549\n",
      "-------------------------------\n",
      "loss: 0.107473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407345 \n",
      "\n",
      "Epoch 2550\n",
      "-------------------------------\n",
      "loss: 0.107454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406091 \n",
      "\n",
      "Epoch 2551\n",
      "-------------------------------\n",
      "loss: 0.109772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402825 \n",
      "\n",
      "Epoch 2552\n",
      "-------------------------------\n",
      "loss: 0.113955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405253 \n",
      "\n",
      "Epoch 2553\n",
      "-------------------------------\n",
      "loss: 0.115429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409801 \n",
      "\n",
      "Epoch 2554\n",
      "-------------------------------\n",
      "loss: 0.122398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417305 \n",
      "\n",
      "Epoch 2555\n",
      "-------------------------------\n",
      "loss: 0.119756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424371 \n",
      "\n",
      "Epoch 2556\n",
      "-------------------------------\n",
      "loss: 0.107925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428224 \n",
      "\n",
      "Epoch 2557\n",
      "-------------------------------\n",
      "loss: 0.109303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426394 \n",
      "\n",
      "Epoch 2558\n",
      "-------------------------------\n",
      "loss: 0.112968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421054 \n",
      "\n",
      "Epoch 2559\n",
      "-------------------------------\n",
      "loss: 0.116060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415792 \n",
      "\n",
      "Epoch 2560\n",
      "-------------------------------\n",
      "loss: 0.126274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414627 \n",
      "\n",
      "Epoch 2561\n",
      "-------------------------------\n",
      "loss: 0.116104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412854 \n",
      "\n",
      "Epoch 2562\n",
      "-------------------------------\n",
      "loss: 0.118626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409126 \n",
      "\n",
      "Epoch 2563\n",
      "-------------------------------\n",
      "loss: 0.122139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407648 \n",
      "\n",
      "Epoch 2564\n",
      "-------------------------------\n",
      "loss: 0.126692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412441 \n",
      "\n",
      "Epoch 2565\n",
      "-------------------------------\n",
      "loss: 0.122538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420739 \n",
      "\n",
      "Epoch 2566\n",
      "-------------------------------\n",
      "loss: 0.139264  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.421372 \n",
      "\n",
      "Epoch 2567\n",
      "-------------------------------\n",
      "loss: 0.112800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419009 \n",
      "\n",
      "Epoch 2568\n",
      "-------------------------------\n",
      "loss: 0.122088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415483 \n",
      "\n",
      "Epoch 2569\n",
      "-------------------------------\n",
      "loss: 0.126089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412949 \n",
      "\n",
      "Epoch 2570\n",
      "-------------------------------\n",
      "loss: 0.133890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413100 \n",
      "\n",
      "Epoch 2571\n",
      "-------------------------------\n",
      "loss: 0.122269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413489 \n",
      "\n",
      "Epoch 2572\n",
      "-------------------------------\n",
      "loss: 0.116027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413374 \n",
      "\n",
      "Epoch 2573\n",
      "-------------------------------\n",
      "loss: 0.122789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412905 \n",
      "\n",
      "Epoch 2574\n",
      "-------------------------------\n",
      "loss: 0.116454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412115 \n",
      "\n",
      "Epoch 2575\n",
      "-------------------------------\n",
      "loss: 0.112263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412802 \n",
      "\n",
      "Epoch 2576\n",
      "-------------------------------\n",
      "loss: 0.114167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412733 \n",
      "\n",
      "Epoch 2577\n",
      "-------------------------------\n",
      "loss: 0.134972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413530 \n",
      "\n",
      "Epoch 2578\n",
      "-------------------------------\n",
      "loss: 0.121361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414134 \n",
      "\n",
      "Epoch 2579\n",
      "-------------------------------\n",
      "loss: 0.117916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415063 \n",
      "\n",
      "Epoch 2580\n",
      "-------------------------------\n",
      "loss: 0.116026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415202 \n",
      "\n",
      "Epoch 2581\n",
      "-------------------------------\n",
      "loss: 0.123947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414847 \n",
      "\n",
      "Epoch 2582\n",
      "-------------------------------\n",
      "loss: 0.137512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415548 \n",
      "\n",
      "Epoch 2583\n",
      "-------------------------------\n",
      "loss: 0.120991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414476 \n",
      "\n",
      "Epoch 2584\n",
      "-------------------------------\n",
      "loss: 0.121328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417913 \n",
      "\n",
      "Epoch 2585\n",
      "-------------------------------\n",
      "loss: 0.119068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417473 \n",
      "\n",
      "Epoch 2586\n",
      "-------------------------------\n",
      "loss: 0.139404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414253 \n",
      "\n",
      "Epoch 2587\n",
      "-------------------------------\n",
      "loss: 0.117671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411795 \n",
      "\n",
      "Epoch 2588\n",
      "-------------------------------\n",
      "loss: 0.131172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412350 \n",
      "\n",
      "Epoch 2589\n",
      "-------------------------------\n",
      "loss: 0.118574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413841 \n",
      "\n",
      "Epoch 2590\n",
      "-------------------------------\n",
      "loss: 0.123089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416147 \n",
      "\n",
      "Epoch 2591\n",
      "-------------------------------\n",
      "loss: 0.101935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417744 \n",
      "\n",
      "Epoch 2592\n",
      "-------------------------------\n",
      "loss: 0.114324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414756 \n",
      "\n",
      "Epoch 2593\n",
      "-------------------------------\n",
      "loss: 0.111145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415268 \n",
      "\n",
      "Epoch 2594\n",
      "-------------------------------\n",
      "loss: 0.108493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418497 \n",
      "\n",
      "Epoch 2595\n",
      "-------------------------------\n",
      "loss: 0.126841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420096 \n",
      "\n",
      "Epoch 2596\n",
      "-------------------------------\n",
      "loss: 0.143527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418556 \n",
      "\n",
      "Epoch 2597\n",
      "-------------------------------\n",
      "loss: 0.114153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416554 \n",
      "\n",
      "Epoch 2598\n",
      "-------------------------------\n",
      "loss: 0.119736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415578 \n",
      "\n",
      "Epoch 2599\n",
      "-------------------------------\n",
      "loss: 0.133037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419944 \n",
      "\n",
      "Epoch 2600\n",
      "-------------------------------\n",
      "loss: 0.107728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429529 \n",
      "\n",
      "Epoch 2601\n",
      "-------------------------------\n",
      "loss: 0.133543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432323 \n",
      "\n",
      "Epoch 2602\n",
      "-------------------------------\n",
      "loss: 0.127496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428840 \n",
      "\n",
      "Epoch 2603\n",
      "-------------------------------\n",
      "loss: 0.113976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422361 \n",
      "\n",
      "Epoch 2604\n",
      "-------------------------------\n",
      "loss: 0.124499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416727 \n",
      "\n",
      "Epoch 2605\n",
      "-------------------------------\n",
      "loss: 0.129705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413819 \n",
      "\n",
      "Epoch 2606\n",
      "-------------------------------\n",
      "loss: 0.126394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412221 \n",
      "\n",
      "Epoch 2607\n",
      "-------------------------------\n",
      "loss: 0.120710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417932 \n",
      "\n",
      "Epoch 2608\n",
      "-------------------------------\n",
      "loss: 0.121394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426289 \n",
      "\n",
      "Epoch 2609\n",
      "-------------------------------\n",
      "loss: 0.118513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426177 \n",
      "\n",
      "Epoch 2610\n",
      "-------------------------------\n",
      "loss: 0.109858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426114 \n",
      "\n",
      "Epoch 2611\n",
      "-------------------------------\n",
      "loss: 0.125049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419468 \n",
      "\n",
      "Epoch 2612\n",
      "-------------------------------\n",
      "loss: 0.104937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418900 \n",
      "\n",
      "Epoch 2613\n",
      "-------------------------------\n",
      "loss: 0.108554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418788 \n",
      "\n",
      "Epoch 2614\n",
      "-------------------------------\n",
      "loss: 0.112723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418673 \n",
      "\n",
      "Epoch 2615\n",
      "-------------------------------\n",
      "loss: 0.123355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420090 \n",
      "\n",
      "Epoch 2616\n",
      "-------------------------------\n",
      "loss: 0.106291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421251 \n",
      "\n",
      "Epoch 2617\n",
      "-------------------------------\n",
      "loss: 0.108507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420991 \n",
      "\n",
      "Epoch 2618\n",
      "-------------------------------\n",
      "loss: 0.121257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420506 \n",
      "\n",
      "Epoch 2619\n",
      "-------------------------------\n",
      "loss: 0.125980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418760 \n",
      "\n",
      "Epoch 2620\n",
      "-------------------------------\n",
      "loss: 0.115793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416912 \n",
      "\n",
      "Epoch 2621\n",
      "-------------------------------\n",
      "loss: 0.127072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417850 \n",
      "\n",
      "Epoch 2622\n",
      "-------------------------------\n",
      "loss: 0.120377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418286 \n",
      "\n",
      "Epoch 2623\n",
      "-------------------------------\n",
      "loss: 0.134731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412314 \n",
      "\n",
      "Epoch 2624\n",
      "-------------------------------\n",
      "loss: 0.107818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411933 \n",
      "\n",
      "Epoch 2625\n",
      "-------------------------------\n",
      "loss: 0.120883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418277 \n",
      "\n",
      "Epoch 2626\n",
      "-------------------------------\n",
      "loss: 0.123697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418681 \n",
      "\n",
      "Epoch 2627\n",
      "-------------------------------\n",
      "loss: 0.123618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422254 \n",
      "\n",
      "Epoch 2628\n",
      "-------------------------------\n",
      "loss: 0.116240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426110 \n",
      "\n",
      "Epoch 2629\n",
      "-------------------------------\n",
      "loss: 0.140770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428753 \n",
      "\n",
      "Epoch 2630\n",
      "-------------------------------\n",
      "loss: 0.125258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424064 \n",
      "\n",
      "Epoch 2631\n",
      "-------------------------------\n",
      "loss: 0.119222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422291 \n",
      "\n",
      "Epoch 2632\n",
      "-------------------------------\n",
      "loss: 0.116141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418862 \n",
      "\n",
      "Epoch 2633\n",
      "-------------------------------\n",
      "loss: 0.140680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417360 \n",
      "\n",
      "Epoch 2634\n",
      "-------------------------------\n",
      "loss: 0.126304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415849 \n",
      "\n",
      "Epoch 2635\n",
      "-------------------------------\n",
      "loss: 0.117631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415157 \n",
      "\n",
      "Epoch 2636\n",
      "-------------------------------\n",
      "loss: 0.129676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417948 \n",
      "\n",
      "Epoch 2637\n",
      "-------------------------------\n",
      "loss: 0.142775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423395 \n",
      "\n",
      "Epoch 2638\n",
      "-------------------------------\n",
      "loss: 0.121455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430519 \n",
      "\n",
      "Epoch 2639\n",
      "-------------------------------\n",
      "loss: 0.130431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435432 \n",
      "\n",
      "Epoch 2640\n",
      "-------------------------------\n",
      "loss: 0.123699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434734 \n",
      "\n",
      "Epoch 2641\n",
      "-------------------------------\n",
      "loss: 0.130251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427758 \n",
      "\n",
      "Epoch 2642\n",
      "-------------------------------\n",
      "loss: 0.121720  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.415647 \n",
      "\n",
      "Epoch 2643\n",
      "-------------------------------\n",
      "loss: 0.119890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405805 \n",
      "\n",
      "Epoch 2644\n",
      "-------------------------------\n",
      "loss: 0.127560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407261 \n",
      "\n",
      "Epoch 2645\n",
      "-------------------------------\n",
      "loss: 0.119586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415660 \n",
      "\n",
      "Epoch 2646\n",
      "-------------------------------\n",
      "loss: 0.114595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425410 \n",
      "\n",
      "Epoch 2647\n",
      "-------------------------------\n",
      "loss: 0.119769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428788 \n",
      "\n",
      "Epoch 2648\n",
      "-------------------------------\n",
      "loss: 0.125562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422276 \n",
      "\n",
      "Epoch 2649\n",
      "-------------------------------\n",
      "loss: 0.118096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413334 \n",
      "\n",
      "Epoch 2650\n",
      "-------------------------------\n",
      "loss: 0.129352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409612 \n",
      "\n",
      "Epoch 2651\n",
      "-------------------------------\n",
      "loss: 0.112756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410479 \n",
      "\n",
      "Epoch 2652\n",
      "-------------------------------\n",
      "loss: 0.110845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411085 \n",
      "\n",
      "Epoch 2653\n",
      "-------------------------------\n",
      "loss: 0.135068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412834 \n",
      "\n",
      "Epoch 2654\n",
      "-------------------------------\n",
      "loss: 0.114082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413552 \n",
      "\n",
      "Epoch 2655\n",
      "-------------------------------\n",
      "loss: 0.124962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412855 \n",
      "\n",
      "Epoch 2656\n",
      "-------------------------------\n",
      "loss: 0.120246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411637 \n",
      "\n",
      "Epoch 2657\n",
      "-------------------------------\n",
      "loss: 0.115016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414217 \n",
      "\n",
      "Epoch 2658\n",
      "-------------------------------\n",
      "loss: 0.134799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413200 \n",
      "\n",
      "Epoch 2659\n",
      "-------------------------------\n",
      "loss: 0.115196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410485 \n",
      "\n",
      "Epoch 2660\n",
      "-------------------------------\n",
      "loss: 0.112559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410464 \n",
      "\n",
      "Epoch 2661\n",
      "-------------------------------\n",
      "loss: 0.123994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414989 \n",
      "\n",
      "Epoch 2662\n",
      "-------------------------------\n",
      "loss: 0.117664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417217 \n",
      "\n",
      "Epoch 2663\n",
      "-------------------------------\n",
      "loss: 0.121865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416148 \n",
      "\n",
      "Epoch 2664\n",
      "-------------------------------\n",
      "loss: 0.112861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418228 \n",
      "\n",
      "Epoch 2665\n",
      "-------------------------------\n",
      "loss: 0.114097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422328 \n",
      "\n",
      "Epoch 2666\n",
      "-------------------------------\n",
      "loss: 0.120607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416190 \n",
      "\n",
      "Epoch 2667\n",
      "-------------------------------\n",
      "loss: 0.117086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414621 \n",
      "\n",
      "Epoch 2668\n",
      "-------------------------------\n",
      "loss: 0.107161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416838 \n",
      "\n",
      "Epoch 2669\n",
      "-------------------------------\n",
      "loss: 0.117134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414299 \n",
      "\n",
      "Epoch 2670\n",
      "-------------------------------\n",
      "loss: 0.120240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411449 \n",
      "\n",
      "Epoch 2671\n",
      "-------------------------------\n",
      "loss: 0.106549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415881 \n",
      "\n",
      "Epoch 2672\n",
      "-------------------------------\n",
      "loss: 0.112581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422186 \n",
      "\n",
      "Epoch 2673\n",
      "-------------------------------\n",
      "loss: 0.125651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423002 \n",
      "\n",
      "Epoch 2674\n",
      "-------------------------------\n",
      "loss: 0.126578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418804 \n",
      "\n",
      "Epoch 2675\n",
      "-------------------------------\n",
      "loss: 0.117132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414195 \n",
      "\n",
      "Epoch 2676\n",
      "-------------------------------\n",
      "loss: 0.114750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412283 \n",
      "\n",
      "Epoch 2677\n",
      "-------------------------------\n",
      "loss: 0.110140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412350 \n",
      "\n",
      "Epoch 2678\n",
      "-------------------------------\n",
      "loss: 0.110836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411232 \n",
      "\n",
      "Epoch 2679\n",
      "-------------------------------\n",
      "loss: 0.121807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409050 \n",
      "\n",
      "Epoch 2680\n",
      "-------------------------------\n",
      "loss: 0.118327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409599 \n",
      "\n",
      "Epoch 2681\n",
      "-------------------------------\n",
      "loss: 0.113772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411572 \n",
      "\n",
      "Epoch 2682\n",
      "-------------------------------\n",
      "loss: 0.115280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415820 \n",
      "\n",
      "Epoch 2683\n",
      "-------------------------------\n",
      "loss: 0.125403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419110 \n",
      "\n",
      "Epoch 2684\n",
      "-------------------------------\n",
      "loss: 0.113217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419079 \n",
      "\n",
      "Epoch 2685\n",
      "-------------------------------\n",
      "loss: 0.110020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419083 \n",
      "\n",
      "Epoch 2686\n",
      "-------------------------------\n",
      "loss: 0.114625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426255 \n",
      "\n",
      "Epoch 2687\n",
      "-------------------------------\n",
      "loss: 0.117669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430649 \n",
      "\n",
      "Epoch 2688\n",
      "-------------------------------\n",
      "loss: 0.120490  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431197 \n",
      "\n",
      "Epoch 2689\n",
      "-------------------------------\n",
      "loss: 0.111588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430601 \n",
      "\n",
      "Epoch 2690\n",
      "-------------------------------\n",
      "loss: 0.125569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426384 \n",
      "\n",
      "Epoch 2691\n",
      "-------------------------------\n",
      "loss: 0.123446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421212 \n",
      "\n",
      "Epoch 2692\n",
      "-------------------------------\n",
      "loss: 0.124395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416389 \n",
      "\n",
      "Epoch 2693\n",
      "-------------------------------\n",
      "loss: 0.125696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418708 \n",
      "\n",
      "Epoch 2694\n",
      "-------------------------------\n",
      "loss: 0.108354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426675 \n",
      "\n",
      "Epoch 2695\n",
      "-------------------------------\n",
      "loss: 0.126618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428149 \n",
      "\n",
      "Epoch 2696\n",
      "-------------------------------\n",
      "loss: 0.111079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427655 \n",
      "\n",
      "Epoch 2697\n",
      "-------------------------------\n",
      "loss: 0.125626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428145 \n",
      "\n",
      "Epoch 2698\n",
      "-------------------------------\n",
      "loss: 0.128180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428929 \n",
      "\n",
      "Epoch 2699\n",
      "-------------------------------\n",
      "loss: 0.124744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423926 \n",
      "\n",
      "Epoch 2700\n",
      "-------------------------------\n",
      "loss: 0.129995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416171 \n",
      "\n",
      "Epoch 2701\n",
      "-------------------------------\n",
      "loss: 0.124880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416576 \n",
      "\n",
      "Epoch 2702\n",
      "-------------------------------\n",
      "loss: 0.116485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420212 \n",
      "\n",
      "Epoch 2703\n",
      "-------------------------------\n",
      "loss: 0.113215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421512 \n",
      "\n",
      "Epoch 2704\n",
      "-------------------------------\n",
      "loss: 0.117626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422658 \n",
      "\n",
      "Epoch 2705\n",
      "-------------------------------\n",
      "loss: 0.118303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421985 \n",
      "\n",
      "Epoch 2706\n",
      "-------------------------------\n",
      "loss: 0.124789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421637 \n",
      "\n",
      "Epoch 2707\n",
      "-------------------------------\n",
      "loss: 0.127728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420412 \n",
      "\n",
      "Epoch 2708\n",
      "-------------------------------\n",
      "loss: 0.111025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419069 \n",
      "\n",
      "Epoch 2709\n",
      "-------------------------------\n",
      "loss: 0.119548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416417 \n",
      "\n",
      "Epoch 2710\n",
      "-------------------------------\n",
      "loss: 0.118668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412859 \n",
      "\n",
      "Epoch 2711\n",
      "-------------------------------\n",
      "loss: 0.120455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410559 \n",
      "\n",
      "Epoch 2712\n",
      "-------------------------------\n",
      "loss: 0.114341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410702 \n",
      "\n",
      "Epoch 2713\n",
      "-------------------------------\n",
      "loss: 0.122035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414229 \n",
      "\n",
      "Epoch 2714\n",
      "-------------------------------\n",
      "loss: 0.116595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417422 \n",
      "\n",
      "Epoch 2715\n",
      "-------------------------------\n",
      "loss: 0.127407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418813 \n",
      "\n",
      "Epoch 2716\n",
      "-------------------------------\n",
      "loss: 0.107659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420910 \n",
      "\n",
      "Epoch 2717\n",
      "-------------------------------\n",
      "loss: 0.116685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423439 \n",
      "\n",
      "Epoch 2718\n",
      "-------------------------------\n",
      "loss: 0.116891  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.423525 \n",
      "\n",
      "Epoch 2719\n",
      "-------------------------------\n",
      "loss: 0.112946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419600 \n",
      "\n",
      "Epoch 2720\n",
      "-------------------------------\n",
      "loss: 0.123878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414055 \n",
      "\n",
      "Epoch 2721\n",
      "-------------------------------\n",
      "loss: 0.106725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411459 \n",
      "\n",
      "Epoch 2722\n",
      "-------------------------------\n",
      "loss: 0.124894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412363 \n",
      "\n",
      "Epoch 2723\n",
      "-------------------------------\n",
      "loss: 0.117033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415515 \n",
      "\n",
      "Epoch 2724\n",
      "-------------------------------\n",
      "loss: 0.127480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417799 \n",
      "\n",
      "Epoch 2725\n",
      "-------------------------------\n",
      "loss: 0.115678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420292 \n",
      "\n",
      "Epoch 2726\n",
      "-------------------------------\n",
      "loss: 0.124116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422778 \n",
      "\n",
      "Epoch 2727\n",
      "-------------------------------\n",
      "loss: 0.115303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420791 \n",
      "\n",
      "Epoch 2728\n",
      "-------------------------------\n",
      "loss: 0.110366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418619 \n",
      "\n",
      "Epoch 2729\n",
      "-------------------------------\n",
      "loss: 0.115124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419506 \n",
      "\n",
      "Epoch 2730\n",
      "-------------------------------\n",
      "loss: 0.121589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419516 \n",
      "\n",
      "Epoch 2731\n",
      "-------------------------------\n",
      "loss: 0.109295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419840 \n",
      "\n",
      "Epoch 2732\n",
      "-------------------------------\n",
      "loss: 0.122967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422145 \n",
      "\n",
      "Epoch 2733\n",
      "-------------------------------\n",
      "loss: 0.120360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420046 \n",
      "\n",
      "Epoch 2734\n",
      "-------------------------------\n",
      "loss: 0.130515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414117 \n",
      "\n",
      "Epoch 2735\n",
      "-------------------------------\n",
      "loss: 0.113675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411550 \n",
      "\n",
      "Epoch 2736\n",
      "-------------------------------\n",
      "loss: 0.131640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413154 \n",
      "\n",
      "Epoch 2737\n",
      "-------------------------------\n",
      "loss: 0.107250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418920 \n",
      "\n",
      "Epoch 2738\n",
      "-------------------------------\n",
      "loss: 0.108779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422149 \n",
      "\n",
      "Epoch 2739\n",
      "-------------------------------\n",
      "loss: 0.119731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421371 \n",
      "\n",
      "Epoch 2740\n",
      "-------------------------------\n",
      "loss: 0.116554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420249 \n",
      "\n",
      "Epoch 2741\n",
      "-------------------------------\n",
      "loss: 0.119973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417875 \n",
      "\n",
      "Epoch 2742\n",
      "-------------------------------\n",
      "loss: 0.111433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416131 \n",
      "\n",
      "Epoch 2743\n",
      "-------------------------------\n",
      "loss: 0.120200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415181 \n",
      "\n",
      "Epoch 2744\n",
      "-------------------------------\n",
      "loss: 0.135916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414849 \n",
      "\n",
      "Epoch 2745\n",
      "-------------------------------\n",
      "loss: 0.121936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418675 \n",
      "\n",
      "Epoch 2746\n",
      "-------------------------------\n",
      "loss: 0.112768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422526 \n",
      "\n",
      "Epoch 2747\n",
      "-------------------------------\n",
      "loss: 0.116512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429658 \n",
      "\n",
      "Epoch 2748\n",
      "-------------------------------\n",
      "loss: 0.112432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429479 \n",
      "\n",
      "Epoch 2749\n",
      "-------------------------------\n",
      "loss: 0.116007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422673 \n",
      "\n",
      "Epoch 2750\n",
      "-------------------------------\n",
      "loss: 0.120239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415740 \n",
      "\n",
      "Epoch 2751\n",
      "-------------------------------\n",
      "loss: 0.119186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411198 \n",
      "\n",
      "Epoch 2752\n",
      "-------------------------------\n",
      "loss: 0.115127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407516 \n",
      "\n",
      "Epoch 2753\n",
      "-------------------------------\n",
      "loss: 0.122199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406969 \n",
      "\n",
      "Epoch 2754\n",
      "-------------------------------\n",
      "loss: 0.117752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411056 \n",
      "\n",
      "Epoch 2755\n",
      "-------------------------------\n",
      "loss: 0.120693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417221 \n",
      "\n",
      "Epoch 2756\n",
      "-------------------------------\n",
      "loss: 0.130441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422790 \n",
      "\n",
      "Epoch 2757\n",
      "-------------------------------\n",
      "loss: 0.120199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422011 \n",
      "\n",
      "Epoch 2758\n",
      "-------------------------------\n",
      "loss: 0.124651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420968 \n",
      "\n",
      "Epoch 2759\n",
      "-------------------------------\n",
      "loss: 0.118397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421808 \n",
      "\n",
      "Epoch 2760\n",
      "-------------------------------\n",
      "loss: 0.136904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422567 \n",
      "\n",
      "Epoch 2761\n",
      "-------------------------------\n",
      "loss: 0.144622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416482 \n",
      "\n",
      "Epoch 2762\n",
      "-------------------------------\n",
      "loss: 0.124008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416170 \n",
      "\n",
      "Epoch 2763\n",
      "-------------------------------\n",
      "loss: 0.128797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424119 \n",
      "\n",
      "Epoch 2764\n",
      "-------------------------------\n",
      "loss: 0.111959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426318 \n",
      "\n",
      "Epoch 2765\n",
      "-------------------------------\n",
      "loss: 0.120685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428627 \n",
      "\n",
      "Epoch 2766\n",
      "-------------------------------\n",
      "loss: 0.127492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427673 \n",
      "\n",
      "Epoch 2767\n",
      "-------------------------------\n",
      "loss: 0.131424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418299 \n",
      "\n",
      "Epoch 2768\n",
      "-------------------------------\n",
      "loss: 0.123758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416536 \n",
      "\n",
      "Epoch 2769\n",
      "-------------------------------\n",
      "loss: 0.132478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421012 \n",
      "\n",
      "Epoch 2770\n",
      "-------------------------------\n",
      "loss: 0.139891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418050 \n",
      "\n",
      "Epoch 2771\n",
      "-------------------------------\n",
      "loss: 0.124380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415219 \n",
      "\n",
      "Epoch 2772\n",
      "-------------------------------\n",
      "loss: 0.112012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418194 \n",
      "\n",
      "Epoch 2773\n",
      "-------------------------------\n",
      "loss: 0.124344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422424 \n",
      "\n",
      "Epoch 2774\n",
      "-------------------------------\n",
      "loss: 0.112263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422373 \n",
      "\n",
      "Epoch 2775\n",
      "-------------------------------\n",
      "loss: 0.122119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419503 \n",
      "\n",
      "Epoch 2776\n",
      "-------------------------------\n",
      "loss: 0.103415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417538 \n",
      "\n",
      "Epoch 2777\n",
      "-------------------------------\n",
      "loss: 0.119484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415478 \n",
      "\n",
      "Epoch 2778\n",
      "-------------------------------\n",
      "loss: 0.113849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413482 \n",
      "\n",
      "Epoch 2779\n",
      "-------------------------------\n",
      "loss: 0.110869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415778 \n",
      "\n",
      "Epoch 2780\n",
      "-------------------------------\n",
      "loss: 0.105632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415301 \n",
      "\n",
      "Epoch 2781\n",
      "-------------------------------\n",
      "loss: 0.102075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415001 \n",
      "\n",
      "Epoch 2782\n",
      "-------------------------------\n",
      "loss: 0.112278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415019 \n",
      "\n",
      "Epoch 2783\n",
      "-------------------------------\n",
      "loss: 0.122407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414977 \n",
      "\n",
      "Epoch 2784\n",
      "-------------------------------\n",
      "loss: 0.107008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416228 \n",
      "\n",
      "Epoch 2785\n",
      "-------------------------------\n",
      "loss: 0.108888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413680 \n",
      "\n",
      "Epoch 2786\n",
      "-------------------------------\n",
      "loss: 0.106379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410506 \n",
      "\n",
      "Epoch 2787\n",
      "-------------------------------\n",
      "loss: 0.113889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408524 \n",
      "\n",
      "Epoch 2788\n",
      "-------------------------------\n",
      "loss: 0.104186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410133 \n",
      "\n",
      "Epoch 2789\n",
      "-------------------------------\n",
      "loss: 0.113511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412043 \n",
      "\n",
      "Epoch 2790\n",
      "-------------------------------\n",
      "loss: 0.111484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413747 \n",
      "\n",
      "Epoch 2791\n",
      "-------------------------------\n",
      "loss: 0.116246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416593 \n",
      "\n",
      "Epoch 2792\n",
      "-------------------------------\n",
      "loss: 0.109726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417760 \n",
      "\n",
      "Epoch 2793\n",
      "-------------------------------\n",
      "loss: 0.109790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422145 \n",
      "\n",
      "Epoch 2794\n",
      "-------------------------------\n",
      "loss: 0.111807  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.423214 \n",
      "\n",
      "Epoch 2795\n",
      "-------------------------------\n",
      "loss: 0.125896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419119 \n",
      "\n",
      "Epoch 2796\n",
      "-------------------------------\n",
      "loss: 0.109424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416976 \n",
      "\n",
      "Epoch 2797\n",
      "-------------------------------\n",
      "loss: 0.120855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414031 \n",
      "\n",
      "Epoch 2798\n",
      "-------------------------------\n",
      "loss: 0.109381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413085 \n",
      "\n",
      "Epoch 2799\n",
      "-------------------------------\n",
      "loss: 0.123868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411147 \n",
      "\n",
      "Epoch 2800\n",
      "-------------------------------\n",
      "loss: 0.111729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416387 \n",
      "\n",
      "Epoch 2801\n",
      "-------------------------------\n",
      "loss: 0.111164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423065 \n",
      "\n",
      "Epoch 2802\n",
      "-------------------------------\n",
      "loss: 0.112755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425208 \n",
      "\n",
      "Epoch 2803\n",
      "-------------------------------\n",
      "loss: 0.109383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425661 \n",
      "\n",
      "Epoch 2804\n",
      "-------------------------------\n",
      "loss: 0.118764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423879 \n",
      "\n",
      "Epoch 2805\n",
      "-------------------------------\n",
      "loss: 0.108098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420884 \n",
      "\n",
      "Epoch 2806\n",
      "-------------------------------\n",
      "loss: 0.101099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417763 \n",
      "\n",
      "Epoch 2807\n",
      "-------------------------------\n",
      "loss: 0.120731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414304 \n",
      "\n",
      "Epoch 2808\n",
      "-------------------------------\n",
      "loss: 0.123328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411275 \n",
      "\n",
      "Epoch 2809\n",
      "-------------------------------\n",
      "loss: 0.114397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408329 \n",
      "\n",
      "Epoch 2810\n",
      "-------------------------------\n",
      "loss: 0.111984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406352 \n",
      "\n",
      "Epoch 2811\n",
      "-------------------------------\n",
      "loss: 0.128232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407895 \n",
      "\n",
      "Epoch 2812\n",
      "-------------------------------\n",
      "loss: 0.107519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411317 \n",
      "\n",
      "Epoch 2813\n",
      "-------------------------------\n",
      "loss: 0.135014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419879 \n",
      "\n",
      "Epoch 2814\n",
      "-------------------------------\n",
      "loss: 0.124019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424778 \n",
      "\n",
      "Epoch 2815\n",
      "-------------------------------\n",
      "loss: 0.130366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427529 \n",
      "\n",
      "Epoch 2816\n",
      "-------------------------------\n",
      "loss: 0.135537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425797 \n",
      "\n",
      "Epoch 2817\n",
      "-------------------------------\n",
      "loss: 0.112507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424031 \n",
      "\n",
      "Epoch 2818\n",
      "-------------------------------\n",
      "loss: 0.121645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421080 \n",
      "\n",
      "Epoch 2819\n",
      "-------------------------------\n",
      "loss: 0.118542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422546 \n",
      "\n",
      "Epoch 2820\n",
      "-------------------------------\n",
      "loss: 0.113541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420746 \n",
      "\n",
      "Epoch 2821\n",
      "-------------------------------\n",
      "loss: 0.127398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421417 \n",
      "\n",
      "Epoch 2822\n",
      "-------------------------------\n",
      "loss: 0.139686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422703 \n",
      "\n",
      "Epoch 2823\n",
      "-------------------------------\n",
      "loss: 0.119325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425744 \n",
      "\n",
      "Epoch 2824\n",
      "-------------------------------\n",
      "loss: 0.113916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435502 \n",
      "\n",
      "Epoch 2825\n",
      "-------------------------------\n",
      "loss: 0.122385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433659 \n",
      "\n",
      "Epoch 2826\n",
      "-------------------------------\n",
      "loss: 0.114756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427058 \n",
      "\n",
      "Epoch 2827\n",
      "-------------------------------\n",
      "loss: 0.115821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421467 \n",
      "\n",
      "Epoch 2828\n",
      "-------------------------------\n",
      "loss: 0.123100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422937 \n",
      "\n",
      "Epoch 2829\n",
      "-------------------------------\n",
      "loss: 0.108269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426540 \n",
      "\n",
      "Epoch 2830\n",
      "-------------------------------\n",
      "loss: 0.103748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425581 \n",
      "\n",
      "Epoch 2831\n",
      "-------------------------------\n",
      "loss: 0.120688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417682 \n",
      "\n",
      "Epoch 2832\n",
      "-------------------------------\n",
      "loss: 0.105761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407867 \n",
      "\n",
      "Epoch 2833\n",
      "-------------------------------\n",
      "loss: 0.113525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402157 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 2834\n",
      "-------------------------------\n",
      "loss: 0.118548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406942 \n",
      "\n",
      "Epoch 2835\n",
      "-------------------------------\n",
      "loss: 0.105848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418273 \n",
      "\n",
      "Epoch 2836\n",
      "-------------------------------\n",
      "loss: 0.123461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425814 \n",
      "\n",
      "Epoch 2837\n",
      "-------------------------------\n",
      "loss: 0.129669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428824 \n",
      "\n",
      "Epoch 2838\n",
      "-------------------------------\n",
      "loss: 0.125942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427509 \n",
      "\n",
      "Epoch 2839\n",
      "-------------------------------\n",
      "loss: 0.117425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426486 \n",
      "\n",
      "Epoch 2840\n",
      "-------------------------------\n",
      "loss: 0.109370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424607 \n",
      "\n",
      "Epoch 2841\n",
      "-------------------------------\n",
      "loss: 0.119795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421968 \n",
      "\n",
      "Epoch 2842\n",
      "-------------------------------\n",
      "loss: 0.116292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420247 \n",
      "\n",
      "Epoch 2843\n",
      "-------------------------------\n",
      "loss: 0.118943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420513 \n",
      "\n",
      "Epoch 2844\n",
      "-------------------------------\n",
      "loss: 0.103945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422610 \n",
      "\n",
      "Epoch 2845\n",
      "-------------------------------\n",
      "loss: 0.104806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422992 \n",
      "\n",
      "Epoch 2846\n",
      "-------------------------------\n",
      "loss: 0.131416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418105 \n",
      "\n",
      "Epoch 2847\n",
      "-------------------------------\n",
      "loss: 0.118975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411944 \n",
      "\n",
      "Epoch 2848\n",
      "-------------------------------\n",
      "loss: 0.117059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409490 \n",
      "\n",
      "Epoch 2849\n",
      "-------------------------------\n",
      "loss: 0.104108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414101 \n",
      "\n",
      "Epoch 2850\n",
      "-------------------------------\n",
      "loss: 0.114960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419720 \n",
      "\n",
      "Epoch 2851\n",
      "-------------------------------\n",
      "loss: 0.110836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422823 \n",
      "\n",
      "Epoch 2852\n",
      "-------------------------------\n",
      "loss: 0.117006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425447 \n",
      "\n",
      "Epoch 2853\n",
      "-------------------------------\n",
      "loss: 0.107738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423975 \n",
      "\n",
      "Epoch 2854\n",
      "-------------------------------\n",
      "loss: 0.109563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418556 \n",
      "\n",
      "Epoch 2855\n",
      "-------------------------------\n",
      "loss: 0.110924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411543 \n",
      "\n",
      "Epoch 2856\n",
      "-------------------------------\n",
      "loss: 0.114959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411634 \n",
      "\n",
      "Epoch 2857\n",
      "-------------------------------\n",
      "loss: 0.111412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412363 \n",
      "\n",
      "Epoch 2858\n",
      "-------------------------------\n",
      "loss: 0.109207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413693 \n",
      "\n",
      "Epoch 2859\n",
      "-------------------------------\n",
      "loss: 0.114234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415743 \n",
      "\n",
      "Epoch 2860\n",
      "-------------------------------\n",
      "loss: 0.133432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420796 \n",
      "\n",
      "Epoch 2861\n",
      "-------------------------------\n",
      "loss: 0.116578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424937 \n",
      "\n",
      "Epoch 2862\n",
      "-------------------------------\n",
      "loss: 0.108815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431162 \n",
      "\n",
      "Epoch 2863\n",
      "-------------------------------\n",
      "loss: 0.107188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432032 \n",
      "\n",
      "Epoch 2864\n",
      "-------------------------------\n",
      "loss: 0.126910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429211 \n",
      "\n",
      "Epoch 2865\n",
      "-------------------------------\n",
      "loss: 0.122849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424991 \n",
      "\n",
      "Epoch 2866\n",
      "-------------------------------\n",
      "loss: 0.108313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419754 \n",
      "\n",
      "Epoch 2867\n",
      "-------------------------------\n",
      "loss: 0.112647  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417706 \n",
      "\n",
      "Epoch 2868\n",
      "-------------------------------\n",
      "loss: 0.100873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417365 \n",
      "\n",
      "Epoch 2869\n",
      "-------------------------------\n",
      "loss: 0.117857  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.416911 \n",
      "\n",
      "Epoch 2870\n",
      "-------------------------------\n",
      "loss: 0.119671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416667 \n",
      "\n",
      "Epoch 2871\n",
      "-------------------------------\n",
      "loss: 0.109653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413427 \n",
      "\n",
      "Epoch 2872\n",
      "-------------------------------\n",
      "loss: 0.109121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410470 \n",
      "\n",
      "Epoch 2873\n",
      "-------------------------------\n",
      "loss: 0.111549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406942 \n",
      "\n",
      "Epoch 2874\n",
      "-------------------------------\n",
      "loss: 0.113067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406554 \n",
      "\n",
      "Epoch 2875\n",
      "-------------------------------\n",
      "loss: 0.113150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407697 \n",
      "\n",
      "Epoch 2876\n",
      "-------------------------------\n",
      "loss: 0.111110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408512 \n",
      "\n",
      "Epoch 2877\n",
      "-------------------------------\n",
      "loss: 0.110340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408981 \n",
      "\n",
      "Epoch 2878\n",
      "-------------------------------\n",
      "loss: 0.115189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409116 \n",
      "\n",
      "Epoch 2879\n",
      "-------------------------------\n",
      "loss: 0.100805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411316 \n",
      "\n",
      "Epoch 2880\n",
      "-------------------------------\n",
      "loss: 0.107437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410898 \n",
      "\n",
      "Epoch 2881\n",
      "-------------------------------\n",
      "loss: 0.105126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408364 \n",
      "\n",
      "Epoch 2882\n",
      "-------------------------------\n",
      "loss: 0.114888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406961 \n",
      "\n",
      "Epoch 2883\n",
      "-------------------------------\n",
      "loss: 0.134561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408274 \n",
      "\n",
      "Epoch 2884\n",
      "-------------------------------\n",
      "loss: 0.113936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412728 \n",
      "\n",
      "Epoch 2885\n",
      "-------------------------------\n",
      "loss: 0.118361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420302 \n",
      "\n",
      "Epoch 2886\n",
      "-------------------------------\n",
      "loss: 0.115256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425065 \n",
      "\n",
      "Epoch 2887\n",
      "-------------------------------\n",
      "loss: 0.118459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426436 \n",
      "\n",
      "Epoch 2888\n",
      "-------------------------------\n",
      "loss: 0.130894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421458 \n",
      "\n",
      "Epoch 2889\n",
      "-------------------------------\n",
      "loss: 0.113906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416462 \n",
      "\n",
      "Epoch 2890\n",
      "-------------------------------\n",
      "loss: 0.120589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413073 \n",
      "\n",
      "Epoch 2891\n",
      "-------------------------------\n",
      "loss: 0.125154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409976 \n",
      "\n",
      "Epoch 2892\n",
      "-------------------------------\n",
      "loss: 0.112260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409758 \n",
      "\n",
      "Epoch 2893\n",
      "-------------------------------\n",
      "loss: 0.110430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411407 \n",
      "\n",
      "Epoch 2894\n",
      "-------------------------------\n",
      "loss: 0.105922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413539 \n",
      "\n",
      "Epoch 2895\n",
      "-------------------------------\n",
      "loss: 0.112673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417107 \n",
      "\n",
      "Epoch 2896\n",
      "-------------------------------\n",
      "loss: 0.112041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417861 \n",
      "\n",
      "Epoch 2897\n",
      "-------------------------------\n",
      "loss: 0.117190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415144 \n",
      "\n",
      "Epoch 2898\n",
      "-------------------------------\n",
      "loss: 0.127574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410782 \n",
      "\n",
      "Epoch 2899\n",
      "-------------------------------\n",
      "loss: 0.111528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410419 \n",
      "\n",
      "Epoch 2900\n",
      "-------------------------------\n",
      "loss: 0.115389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413291 \n",
      "\n",
      "Epoch 2901\n",
      "-------------------------------\n",
      "loss: 0.114674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415678 \n",
      "\n",
      "Epoch 2902\n",
      "-------------------------------\n",
      "loss: 0.119887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420837 \n",
      "\n",
      "Epoch 2903\n",
      "-------------------------------\n",
      "loss: 0.104953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421588 \n",
      "\n",
      "Epoch 2904\n",
      "-------------------------------\n",
      "loss: 0.111673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417257 \n",
      "\n",
      "Epoch 2905\n",
      "-------------------------------\n",
      "loss: 0.109558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414425 \n",
      "\n",
      "Epoch 2906\n",
      "-------------------------------\n",
      "loss: 0.112755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414737 \n",
      "\n",
      "Epoch 2907\n",
      "-------------------------------\n",
      "loss: 0.116909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417144 \n",
      "\n",
      "Epoch 2908\n",
      "-------------------------------\n",
      "loss: 0.113859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417745 \n",
      "\n",
      "Epoch 2909\n",
      "-------------------------------\n",
      "loss: 0.114671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415862 \n",
      "\n",
      "Epoch 2910\n",
      "-------------------------------\n",
      "loss: 0.113461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419386 \n",
      "\n",
      "Epoch 2911\n",
      "-------------------------------\n",
      "loss: 0.120538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423168 \n",
      "\n",
      "Epoch 2912\n",
      "-------------------------------\n",
      "loss: 0.125857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420886 \n",
      "\n",
      "Epoch 2913\n",
      "-------------------------------\n",
      "loss: 0.136323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415543 \n",
      "\n",
      "Epoch 2914\n",
      "-------------------------------\n",
      "loss: 0.112379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413470 \n",
      "\n",
      "Epoch 2915\n",
      "-------------------------------\n",
      "loss: 0.110622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411828 \n",
      "\n",
      "Epoch 2916\n",
      "-------------------------------\n",
      "loss: 0.107224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411972 \n",
      "\n",
      "Epoch 2917\n",
      "-------------------------------\n",
      "loss: 0.128206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415913 \n",
      "\n",
      "Epoch 2918\n",
      "-------------------------------\n",
      "loss: 0.106282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420847 \n",
      "\n",
      "Epoch 2919\n",
      "-------------------------------\n",
      "loss: 0.128336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423884 \n",
      "\n",
      "Epoch 2920\n",
      "-------------------------------\n",
      "loss: 0.116575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426425 \n",
      "\n",
      "Epoch 2921\n",
      "-------------------------------\n",
      "loss: 0.125449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428596 \n",
      "\n",
      "Epoch 2922\n",
      "-------------------------------\n",
      "loss: 0.132030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426849 \n",
      "\n",
      "Epoch 2923\n",
      "-------------------------------\n",
      "loss: 0.119833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420888 \n",
      "\n",
      "Epoch 2924\n",
      "-------------------------------\n",
      "loss: 0.143819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415674 \n",
      "\n",
      "Epoch 2925\n",
      "-------------------------------\n",
      "loss: 0.120321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412415 \n",
      "\n",
      "Epoch 2926\n",
      "-------------------------------\n",
      "loss: 0.112987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413516 \n",
      "\n",
      "Epoch 2927\n",
      "-------------------------------\n",
      "loss: 0.105692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415532 \n",
      "\n",
      "Epoch 2928\n",
      "-------------------------------\n",
      "loss: 0.116914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414262 \n",
      "\n",
      "Epoch 2929\n",
      "-------------------------------\n",
      "loss: 0.127539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412019 \n",
      "\n",
      "Epoch 2930\n",
      "-------------------------------\n",
      "loss: 0.119220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412195 \n",
      "\n",
      "Epoch 2931\n",
      "-------------------------------\n",
      "loss: 0.110860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415958 \n",
      "\n",
      "Epoch 2932\n",
      "-------------------------------\n",
      "loss: 0.114378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422309 \n",
      "\n",
      "Epoch 2933\n",
      "-------------------------------\n",
      "loss: 0.117727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421315 \n",
      "\n",
      "Epoch 2934\n",
      "-------------------------------\n",
      "loss: 0.118097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417108 \n",
      "\n",
      "Epoch 2935\n",
      "-------------------------------\n",
      "loss: 0.114501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414400 \n",
      "\n",
      "Epoch 2936\n",
      "-------------------------------\n",
      "loss: 0.111155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416864 \n",
      "\n",
      "Epoch 2937\n",
      "-------------------------------\n",
      "loss: 0.101924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420036 \n",
      "\n",
      "Epoch 2938\n",
      "-------------------------------\n",
      "loss: 0.127807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423880 \n",
      "\n",
      "Epoch 2939\n",
      "-------------------------------\n",
      "loss: 0.113552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421940 \n",
      "\n",
      "Epoch 2940\n",
      "-------------------------------\n",
      "loss: 0.116439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416249 \n",
      "\n",
      "Epoch 2941\n",
      "-------------------------------\n",
      "loss: 0.107008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412172 \n",
      "\n",
      "Epoch 2942\n",
      "-------------------------------\n",
      "loss: 0.122883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412204 \n",
      "\n",
      "Epoch 2943\n",
      "-------------------------------\n",
      "loss: 0.112943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412323 \n",
      "\n",
      "Epoch 2944\n",
      "-------------------------------\n",
      "loss: 0.110213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411479 \n",
      "\n",
      "Epoch 2945\n",
      "-------------------------------\n",
      "loss: 0.121114  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.411240 \n",
      "\n",
      "Epoch 2946\n",
      "-------------------------------\n",
      "loss: 0.127873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416807 \n",
      "\n",
      "Epoch 2947\n",
      "-------------------------------\n",
      "loss: 0.118514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419316 \n",
      "\n",
      "Epoch 2948\n",
      "-------------------------------\n",
      "loss: 0.123450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416876 \n",
      "\n",
      "Epoch 2949\n",
      "-------------------------------\n",
      "loss: 0.123018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415258 \n",
      "\n",
      "Epoch 2950\n",
      "-------------------------------\n",
      "loss: 0.126710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413486 \n",
      "\n",
      "Epoch 2951\n",
      "-------------------------------\n",
      "loss: 0.118566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413403 \n",
      "\n",
      "Epoch 2952\n",
      "-------------------------------\n",
      "loss: 0.124237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414334 \n",
      "\n",
      "Epoch 2953\n",
      "-------------------------------\n",
      "loss: 0.125362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414935 \n",
      "\n",
      "Epoch 2954\n",
      "-------------------------------\n",
      "loss: 0.113091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414574 \n",
      "\n",
      "Epoch 2955\n",
      "-------------------------------\n",
      "loss: 0.106499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415139 \n",
      "\n",
      "Epoch 2956\n",
      "-------------------------------\n",
      "loss: 0.125058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414469 \n",
      "\n",
      "Epoch 2957\n",
      "-------------------------------\n",
      "loss: 0.111476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414946 \n",
      "\n",
      "Epoch 2958\n",
      "-------------------------------\n",
      "loss: 0.110421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417155 \n",
      "\n",
      "Epoch 2959\n",
      "-------------------------------\n",
      "loss: 0.116681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419559 \n",
      "\n",
      "Epoch 2960\n",
      "-------------------------------\n",
      "loss: 0.119415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424531 \n",
      "\n",
      "Epoch 2961\n",
      "-------------------------------\n",
      "loss: 0.129448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430299 \n",
      "\n",
      "Epoch 2962\n",
      "-------------------------------\n",
      "loss: 0.105605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434627 \n",
      "\n",
      "Epoch 2963\n",
      "-------------------------------\n",
      "loss: 0.127064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432639 \n",
      "\n",
      "Epoch 2964\n",
      "-------------------------------\n",
      "loss: 0.120432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425785 \n",
      "\n",
      "Epoch 2965\n",
      "-------------------------------\n",
      "loss: 0.113711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417493 \n",
      "\n",
      "Epoch 2966\n",
      "-------------------------------\n",
      "loss: 0.109294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412604 \n",
      "\n",
      "Epoch 2967\n",
      "-------------------------------\n",
      "loss: 0.106538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413659 \n",
      "\n",
      "Epoch 2968\n",
      "-------------------------------\n",
      "loss: 0.113823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415837 \n",
      "\n",
      "Epoch 2969\n",
      "-------------------------------\n",
      "loss: 0.109422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414412 \n",
      "\n",
      "Epoch 2970\n",
      "-------------------------------\n",
      "loss: 0.121332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413795 \n",
      "\n",
      "Epoch 2971\n",
      "-------------------------------\n",
      "loss: 0.107681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415123 \n",
      "\n",
      "Epoch 2972\n",
      "-------------------------------\n",
      "loss: 0.104920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418820 \n",
      "\n",
      "Epoch 2973\n",
      "-------------------------------\n",
      "loss: 0.107642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422771 \n",
      "\n",
      "Epoch 2974\n",
      "-------------------------------\n",
      "loss: 0.101875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421493 \n",
      "\n",
      "Epoch 2975\n",
      "-------------------------------\n",
      "loss: 0.108568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417836 \n",
      "\n",
      "Epoch 2976\n",
      "-------------------------------\n",
      "loss: 0.096960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414752 \n",
      "\n",
      "Epoch 2977\n",
      "-------------------------------\n",
      "loss: 0.114591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412941 \n",
      "\n",
      "Epoch 2978\n",
      "-------------------------------\n",
      "loss: 0.106363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412003 \n",
      "\n",
      "Epoch 2979\n",
      "-------------------------------\n",
      "loss: 0.103657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411998 \n",
      "\n",
      "Epoch 2980\n",
      "-------------------------------\n",
      "loss: 0.128889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412473 \n",
      "\n",
      "Epoch 2981\n",
      "-------------------------------\n",
      "loss: 0.106396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412853 \n",
      "\n",
      "Epoch 2982\n",
      "-------------------------------\n",
      "loss: 0.110269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414311 \n",
      "\n",
      "Epoch 2983\n",
      "-------------------------------\n",
      "loss: 0.108206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414458 \n",
      "\n",
      "Epoch 2984\n",
      "-------------------------------\n",
      "loss: 0.108475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415622 \n",
      "\n",
      "Epoch 2985\n",
      "-------------------------------\n",
      "loss: 0.109340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421511 \n",
      "\n",
      "Epoch 2986\n",
      "-------------------------------\n",
      "loss: 0.118185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418987 \n",
      "\n",
      "Epoch 2987\n",
      "-------------------------------\n",
      "loss: 0.115552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414016 \n",
      "\n",
      "Epoch 2988\n",
      "-------------------------------\n",
      "loss: 0.097272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411984 \n",
      "\n",
      "Epoch 2989\n",
      "-------------------------------\n",
      "loss: 0.117392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409693 \n",
      "\n",
      "Epoch 2990\n",
      "-------------------------------\n",
      "loss: 0.108144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408667 \n",
      "\n",
      "Epoch 2991\n",
      "-------------------------------\n",
      "loss: 0.114200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409315 \n",
      "\n",
      "Epoch 2992\n",
      "-------------------------------\n",
      "loss: 0.103259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413599 \n",
      "\n",
      "Epoch 2993\n",
      "-------------------------------\n",
      "loss: 0.106218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422701 \n",
      "\n",
      "Epoch 2994\n",
      "-------------------------------\n",
      "loss: 0.125294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421478 \n",
      "\n",
      "Epoch 2995\n",
      "-------------------------------\n",
      "loss: 0.104092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420085 \n",
      "\n",
      "Epoch 2996\n",
      "-------------------------------\n",
      "loss: 0.111849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417061 \n",
      "\n",
      "Epoch 2997\n",
      "-------------------------------\n",
      "loss: 0.110763  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413082 \n",
      "\n",
      "Epoch 2998\n",
      "-------------------------------\n",
      "loss: 0.117339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412236 \n",
      "\n",
      "Epoch 2999\n",
      "-------------------------------\n",
      "loss: 0.097576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414828 \n",
      "\n",
      "Epoch 3000\n",
      "-------------------------------\n",
      "loss: 0.106710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419016 \n",
      "\n",
      "Epoch 3001\n",
      "-------------------------------\n",
      "loss: 0.114004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422113 \n",
      "\n",
      "Epoch 3002\n",
      "-------------------------------\n",
      "loss: 0.133997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423567 \n",
      "\n",
      "Epoch 3003\n",
      "-------------------------------\n",
      "loss: 0.109071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424603 \n",
      "\n",
      "Epoch 3004\n",
      "-------------------------------\n",
      "loss: 0.119652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425641 \n",
      "\n",
      "Epoch 3005\n",
      "-------------------------------\n",
      "loss: 0.125912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417807 \n",
      "\n",
      "Epoch 3006\n",
      "-------------------------------\n",
      "loss: 0.116534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410608 \n",
      "\n",
      "Epoch 3007\n",
      "-------------------------------\n",
      "loss: 0.114977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412078 \n",
      "\n",
      "Epoch 3008\n",
      "-------------------------------\n",
      "loss: 0.122991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413824 \n",
      "\n",
      "Epoch 3009\n",
      "-------------------------------\n",
      "loss: 0.122417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413967 \n",
      "\n",
      "Epoch 3010\n",
      "-------------------------------\n",
      "loss: 0.110156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418713 \n",
      "\n",
      "Epoch 3011\n",
      "-------------------------------\n",
      "loss: 0.120764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424012 \n",
      "\n",
      "Epoch 3012\n",
      "-------------------------------\n",
      "loss: 0.115675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422741 \n",
      "\n",
      "Epoch 3013\n",
      "-------------------------------\n",
      "loss: 0.123048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415866 \n",
      "\n",
      "Epoch 3014\n",
      "-------------------------------\n",
      "loss: 0.108232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413886 \n",
      "\n",
      "Epoch 3015\n",
      "-------------------------------\n",
      "loss: 0.116242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416007 \n",
      "\n",
      "Epoch 3016\n",
      "-------------------------------\n",
      "loss: 0.110254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415173 \n",
      "\n",
      "Epoch 3017\n",
      "-------------------------------\n",
      "loss: 0.103795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412980 \n",
      "\n",
      "Epoch 3018\n",
      "-------------------------------\n",
      "loss: 0.098868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415784 \n",
      "\n",
      "Epoch 3019\n",
      "-------------------------------\n",
      "loss: 0.100496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418108 \n",
      "\n",
      "Epoch 3020\n",
      "-------------------------------\n",
      "loss: 0.113160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416316 \n",
      "\n",
      "Epoch 3021\n",
      "-------------------------------\n",
      "loss: 0.114884  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.413527 \n",
      "\n",
      "Epoch 3022\n",
      "-------------------------------\n",
      "loss: 0.103038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417092 \n",
      "\n",
      "Epoch 3023\n",
      "-------------------------------\n",
      "loss: 0.117403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414114 \n",
      "\n",
      "Epoch 3024\n",
      "-------------------------------\n",
      "loss: 0.127097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412636 \n",
      "\n",
      "Epoch 3025\n",
      "-------------------------------\n",
      "loss: 0.107967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415755 \n",
      "\n",
      "Epoch 3026\n",
      "-------------------------------\n",
      "loss: 0.110607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417616 \n",
      "\n",
      "Epoch 3027\n",
      "-------------------------------\n",
      "loss: 0.121551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417458 \n",
      "\n",
      "Epoch 3028\n",
      "-------------------------------\n",
      "loss: 0.122579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416926 \n",
      "\n",
      "Epoch 3029\n",
      "-------------------------------\n",
      "loss: 0.106112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420408 \n",
      "\n",
      "Epoch 3030\n",
      "-------------------------------\n",
      "loss: 0.120089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417569 \n",
      "\n",
      "Epoch 3031\n",
      "-------------------------------\n",
      "loss: 0.100456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412519 \n",
      "\n",
      "Epoch 3032\n",
      "-------------------------------\n",
      "loss: 0.113090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410538 \n",
      "\n",
      "Epoch 3033\n",
      "-------------------------------\n",
      "loss: 0.129232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411536 \n",
      "\n",
      "Epoch 3034\n",
      "-------------------------------\n",
      "loss: 0.112994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412909 \n",
      "\n",
      "Epoch 3035\n",
      "-------------------------------\n",
      "loss: 0.110175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412076 \n",
      "\n",
      "Epoch 3036\n",
      "-------------------------------\n",
      "loss: 0.115721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411379 \n",
      "\n",
      "Epoch 3037\n",
      "-------------------------------\n",
      "loss: 0.119230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413446 \n",
      "\n",
      "Epoch 3038\n",
      "-------------------------------\n",
      "loss: 0.113865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417099 \n",
      "\n",
      "Epoch 3039\n",
      "-------------------------------\n",
      "loss: 0.118010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415005 \n",
      "\n",
      "Epoch 3040\n",
      "-------------------------------\n",
      "loss: 0.113442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413310 \n",
      "\n",
      "Epoch 3041\n",
      "-------------------------------\n",
      "loss: 0.107513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412699 \n",
      "\n",
      "Epoch 3042\n",
      "-------------------------------\n",
      "loss: 0.120131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411927 \n",
      "\n",
      "Epoch 3043\n",
      "-------------------------------\n",
      "loss: 0.111553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410176 \n",
      "\n",
      "Epoch 3044\n",
      "-------------------------------\n",
      "loss: 0.111005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407866 \n",
      "\n",
      "Epoch 3045\n",
      "-------------------------------\n",
      "loss: 0.113629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407429 \n",
      "\n",
      "Epoch 3046\n",
      "-------------------------------\n",
      "loss: 0.105322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409999 \n",
      "\n",
      "Epoch 3047\n",
      "-------------------------------\n",
      "loss: 0.107536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419137 \n",
      "\n",
      "Epoch 3048\n",
      "-------------------------------\n",
      "loss: 0.113972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422027 \n",
      "\n",
      "Epoch 3049\n",
      "-------------------------------\n",
      "loss: 0.110954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418073 \n",
      "\n",
      "Epoch 3050\n",
      "-------------------------------\n",
      "loss: 0.132558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413005 \n",
      "\n",
      "Epoch 3051\n",
      "-------------------------------\n",
      "loss: 0.116252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415869 \n",
      "\n",
      "Epoch 3052\n",
      "-------------------------------\n",
      "loss: 0.122484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421022 \n",
      "\n",
      "Epoch 3053\n",
      "-------------------------------\n",
      "loss: 0.129209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422103 \n",
      "\n",
      "Epoch 3054\n",
      "-------------------------------\n",
      "loss: 0.109573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423067 \n",
      "\n",
      "Epoch 3055\n",
      "-------------------------------\n",
      "loss: 0.116490  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422834 \n",
      "\n",
      "Epoch 3056\n",
      "-------------------------------\n",
      "loss: 0.107155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421947 \n",
      "\n",
      "Epoch 3057\n",
      "-------------------------------\n",
      "loss: 0.106867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421319 \n",
      "\n",
      "Epoch 3058\n",
      "-------------------------------\n",
      "loss: 0.111917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419581 \n",
      "\n",
      "Epoch 3059\n",
      "-------------------------------\n",
      "loss: 0.117711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416936 \n",
      "\n",
      "Epoch 3060\n",
      "-------------------------------\n",
      "loss: 0.100352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417163 \n",
      "\n",
      "Epoch 3061\n",
      "-------------------------------\n",
      "loss: 0.126388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419572 \n",
      "\n",
      "Epoch 3062\n",
      "-------------------------------\n",
      "loss: 0.103683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424717 \n",
      "\n",
      "Epoch 3063\n",
      "-------------------------------\n",
      "loss: 0.132633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431538 \n",
      "\n",
      "Epoch 3064\n",
      "-------------------------------\n",
      "loss: 0.124450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427499 \n",
      "\n",
      "Epoch 3065\n",
      "-------------------------------\n",
      "loss: 0.119510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418920 \n",
      "\n",
      "Epoch 3066\n",
      "-------------------------------\n",
      "loss: 0.110343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415876 \n",
      "\n",
      "Epoch 3067\n",
      "-------------------------------\n",
      "loss: 0.108013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413133 \n",
      "\n",
      "Epoch 3068\n",
      "-------------------------------\n",
      "loss: 0.111200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409398 \n",
      "\n",
      "Epoch 3069\n",
      "-------------------------------\n",
      "loss: 0.112209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410439 \n",
      "\n",
      "Epoch 3070\n",
      "-------------------------------\n",
      "loss: 0.108332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412245 \n",
      "\n",
      "Epoch 3071\n",
      "-------------------------------\n",
      "loss: 0.115322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415855 \n",
      "\n",
      "Epoch 3072\n",
      "-------------------------------\n",
      "loss: 0.107123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417141 \n",
      "\n",
      "Epoch 3073\n",
      "-------------------------------\n",
      "loss: 0.111742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412387 \n",
      "\n",
      "Epoch 3074\n",
      "-------------------------------\n",
      "loss: 0.117859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410105 \n",
      "\n",
      "Epoch 3075\n",
      "-------------------------------\n",
      "loss: 0.117485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407528 \n",
      "\n",
      "Epoch 3076\n",
      "-------------------------------\n",
      "loss: 0.096101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406835 \n",
      "\n",
      "Epoch 3077\n",
      "-------------------------------\n",
      "loss: 0.110026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405257 \n",
      "\n",
      "Epoch 3078\n",
      "-------------------------------\n",
      "loss: 0.100254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405013 \n",
      "\n",
      "Epoch 3079\n",
      "-------------------------------\n",
      "loss: 0.125330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404246 \n",
      "\n",
      "Epoch 3080\n",
      "-------------------------------\n",
      "loss: 0.110394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405664 \n",
      "\n",
      "Epoch 3081\n",
      "-------------------------------\n",
      "loss: 0.102252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411380 \n",
      "\n",
      "Epoch 3082\n",
      "-------------------------------\n",
      "loss: 0.104595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414432 \n",
      "\n",
      "Epoch 3083\n",
      "-------------------------------\n",
      "loss: 0.104581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415496 \n",
      "\n",
      "Epoch 3084\n",
      "-------------------------------\n",
      "loss: 0.111194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417134 \n",
      "\n",
      "Epoch 3085\n",
      "-------------------------------\n",
      "loss: 0.105463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416181 \n",
      "\n",
      "Epoch 3086\n",
      "-------------------------------\n",
      "loss: 0.129422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413976 \n",
      "\n",
      "Epoch 3087\n",
      "-------------------------------\n",
      "loss: 0.127507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414336 \n",
      "\n",
      "Epoch 3088\n",
      "-------------------------------\n",
      "loss: 0.119708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415204 \n",
      "\n",
      "Epoch 3089\n",
      "-------------------------------\n",
      "loss: 0.126563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409517 \n",
      "\n",
      "Epoch 3090\n",
      "-------------------------------\n",
      "loss: 0.117589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407659 \n",
      "\n",
      "Epoch 3091\n",
      "-------------------------------\n",
      "loss: 0.111017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411197 \n",
      "\n",
      "Epoch 3092\n",
      "-------------------------------\n",
      "loss: 0.127310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417178 \n",
      "\n",
      "Epoch 3093\n",
      "-------------------------------\n",
      "loss: 0.120907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418468 \n",
      "\n",
      "Epoch 3094\n",
      "-------------------------------\n",
      "loss: 0.112192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421463 \n",
      "\n",
      "Epoch 3095\n",
      "-------------------------------\n",
      "loss: 0.110307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425191 \n",
      "\n",
      "Epoch 3096\n",
      "-------------------------------\n",
      "loss: 0.108847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425591 \n",
      "\n",
      "Epoch 3097\n",
      "-------------------------------\n",
      "loss: 0.118712  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.419352 \n",
      "\n",
      "Epoch 3098\n",
      "-------------------------------\n",
      "loss: 0.117486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417032 \n",
      "\n",
      "Epoch 3099\n",
      "-------------------------------\n",
      "loss: 0.105778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421775 \n",
      "\n",
      "Epoch 3100\n",
      "-------------------------------\n",
      "loss: 0.118985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422712 \n",
      "\n",
      "Epoch 3101\n",
      "-------------------------------\n",
      "loss: 0.110382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418484 \n",
      "\n",
      "Epoch 3102\n",
      "-------------------------------\n",
      "loss: 0.109108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416722 \n",
      "\n",
      "Epoch 3103\n",
      "-------------------------------\n",
      "loss: 0.107647  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414987 \n",
      "\n",
      "Epoch 3104\n",
      "-------------------------------\n",
      "loss: 0.114359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414078 \n",
      "\n",
      "Epoch 3105\n",
      "-------------------------------\n",
      "loss: 0.113744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419085 \n",
      "\n",
      "Epoch 3106\n",
      "-------------------------------\n",
      "loss: 0.111402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424942 \n",
      "\n",
      "Epoch 3107\n",
      "-------------------------------\n",
      "loss: 0.108289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426740 \n",
      "\n",
      "Epoch 3108\n",
      "-------------------------------\n",
      "loss: 0.113439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424788 \n",
      "\n",
      "Epoch 3109\n",
      "-------------------------------\n",
      "loss: 0.104630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424018 \n",
      "\n",
      "Epoch 3110\n",
      "-------------------------------\n",
      "loss: 0.108773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419589 \n",
      "\n",
      "Epoch 3111\n",
      "-------------------------------\n",
      "loss: 0.108799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417610 \n",
      "\n",
      "Epoch 3112\n",
      "-------------------------------\n",
      "loss: 0.109793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420732 \n",
      "\n",
      "Epoch 3113\n",
      "-------------------------------\n",
      "loss: 0.097323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422711 \n",
      "\n",
      "Epoch 3114\n",
      "-------------------------------\n",
      "loss: 0.114722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420328 \n",
      "\n",
      "Epoch 3115\n",
      "-------------------------------\n",
      "loss: 0.127387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414299 \n",
      "\n",
      "Epoch 3116\n",
      "-------------------------------\n",
      "loss: 0.126903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412252 \n",
      "\n",
      "Epoch 3117\n",
      "-------------------------------\n",
      "loss: 0.113639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412324 \n",
      "\n",
      "Epoch 3118\n",
      "-------------------------------\n",
      "loss: 0.113493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414385 \n",
      "\n",
      "Epoch 3119\n",
      "-------------------------------\n",
      "loss: 0.105551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415982 \n",
      "\n",
      "Epoch 3120\n",
      "-------------------------------\n",
      "loss: 0.116239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414615 \n",
      "\n",
      "Epoch 3121\n",
      "-------------------------------\n",
      "loss: 0.125079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411953 \n",
      "\n",
      "Epoch 3122\n",
      "-------------------------------\n",
      "loss: 0.108844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412424 \n",
      "\n",
      "Epoch 3123\n",
      "-------------------------------\n",
      "loss: 0.105866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415686 \n",
      "\n",
      "Epoch 3124\n",
      "-------------------------------\n",
      "loss: 0.107360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416578 \n",
      "\n",
      "Epoch 3125\n",
      "-------------------------------\n",
      "loss: 0.124841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413978 \n",
      "\n",
      "Epoch 3126\n",
      "-------------------------------\n",
      "loss: 0.112946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412036 \n",
      "\n",
      "Epoch 3127\n",
      "-------------------------------\n",
      "loss: 0.113033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412348 \n",
      "\n",
      "Epoch 3128\n",
      "-------------------------------\n",
      "loss: 0.109031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416619 \n",
      "\n",
      "Epoch 3129\n",
      "-------------------------------\n",
      "loss: 0.116187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421374 \n",
      "\n",
      "Epoch 3130\n",
      "-------------------------------\n",
      "loss: 0.110718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424308 \n",
      "\n",
      "Epoch 3131\n",
      "-------------------------------\n",
      "loss: 0.127217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424775 \n",
      "\n",
      "Epoch 3132\n",
      "-------------------------------\n",
      "loss: 0.117467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421474 \n",
      "\n",
      "Epoch 3133\n",
      "-------------------------------\n",
      "loss: 0.101224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420362 \n",
      "\n",
      "Epoch 3134\n",
      "-------------------------------\n",
      "loss: 0.103560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419359 \n",
      "\n",
      "Epoch 3135\n",
      "-------------------------------\n",
      "loss: 0.113248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416395 \n",
      "\n",
      "Epoch 3136\n",
      "-------------------------------\n",
      "loss: 0.115349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415127 \n",
      "\n",
      "Epoch 3137\n",
      "-------------------------------\n",
      "loss: 0.122071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414827 \n",
      "\n",
      "Epoch 3138\n",
      "-------------------------------\n",
      "loss: 0.130865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416808 \n",
      "\n",
      "Epoch 3139\n",
      "-------------------------------\n",
      "loss: 0.108212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421185 \n",
      "\n",
      "Epoch 3140\n",
      "-------------------------------\n",
      "loss: 0.139816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424621 \n",
      "\n",
      "Epoch 3141\n",
      "-------------------------------\n",
      "loss: 0.119503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424017 \n",
      "\n",
      "Epoch 3142\n",
      "-------------------------------\n",
      "loss: 0.135390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419763 \n",
      "\n",
      "Epoch 3143\n",
      "-------------------------------\n",
      "loss: 0.111787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415949 \n",
      "\n",
      "Epoch 3144\n",
      "-------------------------------\n",
      "loss: 0.116542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410322 \n",
      "\n",
      "Epoch 3145\n",
      "-------------------------------\n",
      "loss: 0.120441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411646 \n",
      "\n",
      "Epoch 3146\n",
      "-------------------------------\n",
      "loss: 0.109432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413350 \n",
      "\n",
      "Epoch 3147\n",
      "-------------------------------\n",
      "loss: 0.110983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412749 \n",
      "\n",
      "Epoch 3148\n",
      "-------------------------------\n",
      "loss: 0.123879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411882 \n",
      "\n",
      "Epoch 3149\n",
      "-------------------------------\n",
      "loss: 0.115689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411372 \n",
      "\n",
      "Epoch 3150\n",
      "-------------------------------\n",
      "loss: 0.118604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415975 \n",
      "\n",
      "Epoch 3151\n",
      "-------------------------------\n",
      "loss: 0.101791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419856 \n",
      "\n",
      "Epoch 3152\n",
      "-------------------------------\n",
      "loss: 0.115670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420856 \n",
      "\n",
      "Epoch 3153\n",
      "-------------------------------\n",
      "loss: 0.109656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419592 \n",
      "\n",
      "Epoch 3154\n",
      "-------------------------------\n",
      "loss: 0.111336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419976 \n",
      "\n",
      "Epoch 3155\n",
      "-------------------------------\n",
      "loss: 0.115838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427309 \n",
      "\n",
      "Epoch 3156\n",
      "-------------------------------\n",
      "loss: 0.114988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433439 \n",
      "\n",
      "Epoch 3157\n",
      "-------------------------------\n",
      "loss: 0.113215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428253 \n",
      "\n",
      "Epoch 3158\n",
      "-------------------------------\n",
      "loss: 0.111873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416287 \n",
      "\n",
      "Epoch 3159\n",
      "-------------------------------\n",
      "loss: 0.123724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406770 \n",
      "\n",
      "Epoch 3160\n",
      "-------------------------------\n",
      "loss: 0.110349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406368 \n",
      "\n",
      "Epoch 3161\n",
      "-------------------------------\n",
      "loss: 0.118075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411391 \n",
      "\n",
      "Epoch 3162\n",
      "-------------------------------\n",
      "loss: 0.109160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414733 \n",
      "\n",
      "Epoch 3163\n",
      "-------------------------------\n",
      "loss: 0.122465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419138 \n",
      "\n",
      "Epoch 3164\n",
      "-------------------------------\n",
      "loss: 0.100747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421422 \n",
      "\n",
      "Epoch 3165\n",
      "-------------------------------\n",
      "loss: 0.109832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421079 \n",
      "\n",
      "Epoch 3166\n",
      "-------------------------------\n",
      "loss: 0.118532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417854 \n",
      "\n",
      "Epoch 3167\n",
      "-------------------------------\n",
      "loss: 0.118683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413562 \n",
      "\n",
      "Epoch 3168\n",
      "-------------------------------\n",
      "loss: 0.111585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409637 \n",
      "\n",
      "Epoch 3169\n",
      "-------------------------------\n",
      "loss: 0.102386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408381 \n",
      "\n",
      "Epoch 3170\n",
      "-------------------------------\n",
      "loss: 0.108472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410312 \n",
      "\n",
      "Epoch 3171\n",
      "-------------------------------\n",
      "loss: 0.113037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415465 \n",
      "\n",
      "Epoch 3172\n",
      "-------------------------------\n",
      "loss: 0.109200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416392 \n",
      "\n",
      "Epoch 3173\n",
      "-------------------------------\n",
      "loss: 0.119298  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.415515 \n",
      "\n",
      "Epoch 3174\n",
      "-------------------------------\n",
      "loss: 0.128171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417743 \n",
      "\n",
      "Epoch 3175\n",
      "-------------------------------\n",
      "loss: 0.141582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423300 \n",
      "\n",
      "Epoch 3176\n",
      "-------------------------------\n",
      "loss: 0.110772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429627 \n",
      "\n",
      "Epoch 3177\n",
      "-------------------------------\n",
      "loss: 0.111574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430861 \n",
      "\n",
      "Epoch 3178\n",
      "-------------------------------\n",
      "loss: 0.109789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424580 \n",
      "\n",
      "Epoch 3179\n",
      "-------------------------------\n",
      "loss: 0.110596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416376 \n",
      "\n",
      "Epoch 3180\n",
      "-------------------------------\n",
      "loss: 0.114463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412509 \n",
      "\n",
      "Epoch 3181\n",
      "-------------------------------\n",
      "loss: 0.110280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414819 \n",
      "\n",
      "Epoch 3182\n",
      "-------------------------------\n",
      "loss: 0.104571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418722 \n",
      "\n",
      "Epoch 3183\n",
      "-------------------------------\n",
      "loss: 0.116170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416999 \n",
      "\n",
      "Epoch 3184\n",
      "-------------------------------\n",
      "loss: 0.099624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412842 \n",
      "\n",
      "Epoch 3185\n",
      "-------------------------------\n",
      "loss: 0.118742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412444 \n",
      "\n",
      "Epoch 3186\n",
      "-------------------------------\n",
      "loss: 0.127828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412948 \n",
      "\n",
      "Epoch 3187\n",
      "-------------------------------\n",
      "loss: 0.111822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410883 \n",
      "\n",
      "Epoch 3188\n",
      "-------------------------------\n",
      "loss: 0.113914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408960 \n",
      "\n",
      "Epoch 3189\n",
      "-------------------------------\n",
      "loss: 0.108060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407777 \n",
      "\n",
      "Epoch 3190\n",
      "-------------------------------\n",
      "loss: 0.103679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408873 \n",
      "\n",
      "Epoch 3191\n",
      "-------------------------------\n",
      "loss: 0.116734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409531 \n",
      "\n",
      "Epoch 3192\n",
      "-------------------------------\n",
      "loss: 0.115113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409274 \n",
      "\n",
      "Epoch 3193\n",
      "-------------------------------\n",
      "loss: 0.116881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412575 \n",
      "\n",
      "Epoch 3194\n",
      "-------------------------------\n",
      "loss: 0.112143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416992 \n",
      "\n",
      "Epoch 3195\n",
      "-------------------------------\n",
      "loss: 0.114977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424907 \n",
      "\n",
      "Epoch 3196\n",
      "-------------------------------\n",
      "loss: 0.110667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426151 \n",
      "\n",
      "Epoch 3197\n",
      "-------------------------------\n",
      "loss: 0.108924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426552 \n",
      "\n",
      "Epoch 3198\n",
      "-------------------------------\n",
      "loss: 0.105467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421772 \n",
      "\n",
      "Epoch 3199\n",
      "-------------------------------\n",
      "loss: 0.103141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416949 \n",
      "\n",
      "Epoch 3200\n",
      "-------------------------------\n",
      "loss: 0.113625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413237 \n",
      "\n",
      "Epoch 3201\n",
      "-------------------------------\n",
      "loss: 0.107384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414152 \n",
      "\n",
      "Epoch 3202\n",
      "-------------------------------\n",
      "loss: 0.101217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419814 \n",
      "\n",
      "Epoch 3203\n",
      "-------------------------------\n",
      "loss: 0.106891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424397 \n",
      "\n",
      "Epoch 3204\n",
      "-------------------------------\n",
      "loss: 0.114888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421926 \n",
      "\n",
      "Epoch 3205\n",
      "-------------------------------\n",
      "loss: 0.103544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415773 \n",
      "\n",
      "Epoch 3206\n",
      "-------------------------------\n",
      "loss: 0.097176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413385 \n",
      "\n",
      "Epoch 3207\n",
      "-------------------------------\n",
      "loss: 0.100571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410602 \n",
      "\n",
      "Epoch 3208\n",
      "-------------------------------\n",
      "loss: 0.110359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407910 \n",
      "\n",
      "Epoch 3209\n",
      "-------------------------------\n",
      "loss: 0.123667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404485 \n",
      "\n",
      "Epoch 3210\n",
      "-------------------------------\n",
      "loss: 0.100730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407575 \n",
      "\n",
      "Epoch 3211\n",
      "-------------------------------\n",
      "loss: 0.106601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415514 \n",
      "\n",
      "Epoch 3212\n",
      "-------------------------------\n",
      "loss: 0.113971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414964 \n",
      "\n",
      "Epoch 3213\n",
      "-------------------------------\n",
      "loss: 0.110291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411933 \n",
      "\n",
      "Epoch 3214\n",
      "-------------------------------\n",
      "loss: 0.112084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412391 \n",
      "\n",
      "Epoch 3215\n",
      "-------------------------------\n",
      "loss: 0.107208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416417 \n",
      "\n",
      "Epoch 3216\n",
      "-------------------------------\n",
      "loss: 0.108920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419621 \n",
      "\n",
      "Epoch 3217\n",
      "-------------------------------\n",
      "loss: 0.103960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421806 \n",
      "\n",
      "Epoch 3218\n",
      "-------------------------------\n",
      "loss: 0.119882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420486 \n",
      "\n",
      "Epoch 3219\n",
      "-------------------------------\n",
      "loss: 0.113352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416840 \n",
      "\n",
      "Epoch 3220\n",
      "-------------------------------\n",
      "loss: 0.124987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415875 \n",
      "\n",
      "Epoch 3221\n",
      "-------------------------------\n",
      "loss: 0.103051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415588 \n",
      "\n",
      "Epoch 3222\n",
      "-------------------------------\n",
      "loss: 0.102698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413277 \n",
      "\n",
      "Epoch 3223\n",
      "-------------------------------\n",
      "loss: 0.102384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413867 \n",
      "\n",
      "Epoch 3224\n",
      "-------------------------------\n",
      "loss: 0.114984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416731 \n",
      "\n",
      "Epoch 3225\n",
      "-------------------------------\n",
      "loss: 0.116003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417326 \n",
      "\n",
      "Epoch 3226\n",
      "-------------------------------\n",
      "loss: 0.111844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417702 \n",
      "\n",
      "Epoch 3227\n",
      "-------------------------------\n",
      "loss: 0.106028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419502 \n",
      "\n",
      "Epoch 3228\n",
      "-------------------------------\n",
      "loss: 0.105362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423036 \n",
      "\n",
      "Epoch 3229\n",
      "-------------------------------\n",
      "loss: 0.101313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424227 \n",
      "\n",
      "Epoch 3230\n",
      "-------------------------------\n",
      "loss: 0.126745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418264 \n",
      "\n",
      "Epoch 3231\n",
      "-------------------------------\n",
      "loss: 0.118461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410238 \n",
      "\n",
      "Epoch 3232\n",
      "-------------------------------\n",
      "loss: 0.117975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409713 \n",
      "\n",
      "Epoch 3233\n",
      "-------------------------------\n",
      "loss: 0.108929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424532 \n",
      "\n",
      "Epoch 3234\n",
      "-------------------------------\n",
      "loss: 0.119087  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433739 \n",
      "\n",
      "Epoch 3235\n",
      "-------------------------------\n",
      "loss: 0.115814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435611 \n",
      "\n",
      "Epoch 3236\n",
      "-------------------------------\n",
      "loss: 0.131963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431225 \n",
      "\n",
      "Epoch 3237\n",
      "-------------------------------\n",
      "loss: 0.114118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425385 \n",
      "\n",
      "Epoch 3238\n",
      "-------------------------------\n",
      "loss: 0.110705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427583 \n",
      "\n",
      "Epoch 3239\n",
      "-------------------------------\n",
      "loss: 0.114100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428407 \n",
      "\n",
      "Epoch 3240\n",
      "-------------------------------\n",
      "loss: 0.112131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424757 \n",
      "\n",
      "Epoch 3241\n",
      "-------------------------------\n",
      "loss: 0.116696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422527 \n",
      "\n",
      "Epoch 3242\n",
      "-------------------------------\n",
      "loss: 0.121503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418705 \n",
      "\n",
      "Epoch 3243\n",
      "-------------------------------\n",
      "loss: 0.112812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413234 \n",
      "\n",
      "Epoch 3244\n",
      "-------------------------------\n",
      "loss: 0.109413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410699 \n",
      "\n",
      "Epoch 3245\n",
      "-------------------------------\n",
      "loss: 0.106050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411957 \n",
      "\n",
      "Epoch 3246\n",
      "-------------------------------\n",
      "loss: 0.111128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417358 \n",
      "\n",
      "Epoch 3247\n",
      "-------------------------------\n",
      "loss: 0.104566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420016 \n",
      "\n",
      "Epoch 3248\n",
      "-------------------------------\n",
      "loss: 0.121584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422235 \n",
      "\n",
      "Epoch 3249\n",
      "-------------------------------\n",
      "loss: 0.101804  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.422822 \n",
      "\n",
      "Epoch 3250\n",
      "-------------------------------\n",
      "loss: 0.102187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421964 \n",
      "\n",
      "Epoch 3251\n",
      "-------------------------------\n",
      "loss: 0.110292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418998 \n",
      "\n",
      "Epoch 3252\n",
      "-------------------------------\n",
      "loss: 0.103403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416377 \n",
      "\n",
      "Epoch 3253\n",
      "-------------------------------\n",
      "loss: 0.125196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413702 \n",
      "\n",
      "Epoch 3254\n",
      "-------------------------------\n",
      "loss: 0.101666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410941 \n",
      "\n",
      "Epoch 3255\n",
      "-------------------------------\n",
      "loss: 0.107744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408911 \n",
      "\n",
      "Epoch 3256\n",
      "-------------------------------\n",
      "loss: 0.105096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409376 \n",
      "\n",
      "Epoch 3257\n",
      "-------------------------------\n",
      "loss: 0.104789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412620 \n",
      "\n",
      "Epoch 3258\n",
      "-------------------------------\n",
      "loss: 0.118689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416306 \n",
      "\n",
      "Epoch 3259\n",
      "-------------------------------\n",
      "loss: 0.100891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416043 \n",
      "\n",
      "Epoch 3260\n",
      "-------------------------------\n",
      "loss: 0.109023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414117 \n",
      "\n",
      "Epoch 3261\n",
      "-------------------------------\n",
      "loss: 0.112902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413612 \n",
      "\n",
      "Epoch 3262\n",
      "-------------------------------\n",
      "loss: 0.105561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415978 \n",
      "\n",
      "Epoch 3263\n",
      "-------------------------------\n",
      "loss: 0.099990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417756 \n",
      "\n",
      "Epoch 3264\n",
      "-------------------------------\n",
      "loss: 0.110595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419741 \n",
      "\n",
      "Epoch 3265\n",
      "-------------------------------\n",
      "loss: 0.111317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418398 \n",
      "\n",
      "Epoch 3266\n",
      "-------------------------------\n",
      "loss: 0.107681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417338 \n",
      "\n",
      "Epoch 3267\n",
      "-------------------------------\n",
      "loss: 0.109381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415691 \n",
      "\n",
      "Epoch 3268\n",
      "-------------------------------\n",
      "loss: 0.099073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418329 \n",
      "\n",
      "Epoch 3269\n",
      "-------------------------------\n",
      "loss: 0.120044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422306 \n",
      "\n",
      "Epoch 3270\n",
      "-------------------------------\n",
      "loss: 0.121789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423253 \n",
      "\n",
      "Epoch 3271\n",
      "-------------------------------\n",
      "loss: 0.114846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421405 \n",
      "\n",
      "Epoch 3272\n",
      "-------------------------------\n",
      "loss: 0.104804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417134 \n",
      "\n",
      "Epoch 3273\n",
      "-------------------------------\n",
      "loss: 0.095924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412765 \n",
      "\n",
      "Epoch 3274\n",
      "-------------------------------\n",
      "loss: 0.119557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409716 \n",
      "\n",
      "Epoch 3275\n",
      "-------------------------------\n",
      "loss: 0.110124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408884 \n",
      "\n",
      "Epoch 3276\n",
      "-------------------------------\n",
      "loss: 0.099939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408910 \n",
      "\n",
      "Epoch 3277\n",
      "-------------------------------\n",
      "loss: 0.117779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408501 \n",
      "\n",
      "Epoch 3278\n",
      "-------------------------------\n",
      "loss: 0.111045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410412 \n",
      "\n",
      "Epoch 3279\n",
      "-------------------------------\n",
      "loss: 0.111419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413791 \n",
      "\n",
      "Epoch 3280\n",
      "-------------------------------\n",
      "loss: 0.101006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415689 \n",
      "\n",
      "Epoch 3281\n",
      "-------------------------------\n",
      "loss: 0.112510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412461 \n",
      "\n",
      "Epoch 3282\n",
      "-------------------------------\n",
      "loss: 0.101383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412227 \n",
      "\n",
      "Epoch 3283\n",
      "-------------------------------\n",
      "loss: 0.101958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419119 \n",
      "\n",
      "Epoch 3284\n",
      "-------------------------------\n",
      "loss: 0.102718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429357 \n",
      "\n",
      "Epoch 3285\n",
      "-------------------------------\n",
      "loss: 0.114244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433613 \n",
      "\n",
      "Epoch 3286\n",
      "-------------------------------\n",
      "loss: 0.109820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438951 \n",
      "\n",
      "Epoch 3287\n",
      "-------------------------------\n",
      "loss: 0.122971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433945 \n",
      "\n",
      "Epoch 3288\n",
      "-------------------------------\n",
      "loss: 0.109992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424692 \n",
      "\n",
      "Epoch 3289\n",
      "-------------------------------\n",
      "loss: 0.108905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417632 \n",
      "\n",
      "Epoch 3290\n",
      "-------------------------------\n",
      "loss: 0.115548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417473 \n",
      "\n",
      "Epoch 3291\n",
      "-------------------------------\n",
      "loss: 0.117364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420087 \n",
      "\n",
      "Epoch 3292\n",
      "-------------------------------\n",
      "loss: 0.102979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419631 \n",
      "\n",
      "Epoch 3293\n",
      "-------------------------------\n",
      "loss: 0.115207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415816 \n",
      "\n",
      "Epoch 3294\n",
      "-------------------------------\n",
      "loss: 0.098113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413851 \n",
      "\n",
      "Epoch 3295\n",
      "-------------------------------\n",
      "loss: 0.104520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418446 \n",
      "\n",
      "Epoch 3296\n",
      "-------------------------------\n",
      "loss: 0.129850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424011 \n",
      "\n",
      "Epoch 3297\n",
      "-------------------------------\n",
      "loss: 0.124628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424381 \n",
      "\n",
      "Epoch 3298\n",
      "-------------------------------\n",
      "loss: 0.118236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418337 \n",
      "\n",
      "Epoch 3299\n",
      "-------------------------------\n",
      "loss: 0.118143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413874 \n",
      "\n",
      "Epoch 3300\n",
      "-------------------------------\n",
      "loss: 0.110720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412198 \n",
      "\n",
      "Epoch 3301\n",
      "-------------------------------\n",
      "loss: 0.110181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410412 \n",
      "\n",
      "Epoch 3302\n",
      "-------------------------------\n",
      "loss: 0.112278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410583 \n",
      "\n",
      "Epoch 3303\n",
      "-------------------------------\n",
      "loss: 0.117074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411565 \n",
      "\n",
      "Epoch 3304\n",
      "-------------------------------\n",
      "loss: 0.121521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410460 \n",
      "\n",
      "Epoch 3305\n",
      "-------------------------------\n",
      "loss: 0.105605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409907 \n",
      "\n",
      "Epoch 3306\n",
      "-------------------------------\n",
      "loss: 0.103479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414104 \n",
      "\n",
      "Epoch 3307\n",
      "-------------------------------\n",
      "loss: 0.113234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419820 \n",
      "\n",
      "Epoch 3308\n",
      "-------------------------------\n",
      "loss: 0.101939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421483 \n",
      "\n",
      "Epoch 3309\n",
      "-------------------------------\n",
      "loss: 0.099009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419021 \n",
      "\n",
      "Epoch 3310\n",
      "-------------------------------\n",
      "loss: 0.112266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412917 \n",
      "\n",
      "Epoch 3311\n",
      "-------------------------------\n",
      "loss: 0.120330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412960 \n",
      "\n",
      "Epoch 3312\n",
      "-------------------------------\n",
      "loss: 0.110209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416390 \n",
      "\n",
      "Epoch 3313\n",
      "-------------------------------\n",
      "loss: 0.107163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417415 \n",
      "\n",
      "Epoch 3314\n",
      "-------------------------------\n",
      "loss: 0.106109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417263 \n",
      "\n",
      "Epoch 3315\n",
      "-------------------------------\n",
      "loss: 0.109061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413244 \n",
      "\n",
      "Epoch 3316\n",
      "-------------------------------\n",
      "loss: 0.105139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411197 \n",
      "\n",
      "Epoch 3317\n",
      "-------------------------------\n",
      "loss: 0.106245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417171 \n",
      "\n",
      "Epoch 3318\n",
      "-------------------------------\n",
      "loss: 0.121172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422130 \n",
      "\n",
      "Epoch 3319\n",
      "-------------------------------\n",
      "loss: 0.110217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423774 \n",
      "\n",
      "Epoch 3320\n",
      "-------------------------------\n",
      "loss: 0.099272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423412 \n",
      "\n",
      "Epoch 3321\n",
      "-------------------------------\n",
      "loss: 0.107455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423608 \n",
      "\n",
      "Epoch 3322\n",
      "-------------------------------\n",
      "loss: 0.096813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424514 \n",
      "\n",
      "Epoch 3323\n",
      "-------------------------------\n",
      "loss: 0.116571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421983 \n",
      "\n",
      "Epoch 3324\n",
      "-------------------------------\n",
      "loss: 0.110635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420522 \n",
      "\n",
      "Epoch 3325\n",
      "-------------------------------\n",
      "loss: 0.113493  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.416395 \n",
      "\n",
      "Epoch 3326\n",
      "-------------------------------\n",
      "loss: 0.115171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414538 \n",
      "\n",
      "Epoch 3327\n",
      "-------------------------------\n",
      "loss: 0.101766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416903 \n",
      "\n",
      "Epoch 3328\n",
      "-------------------------------\n",
      "loss: 0.106798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418890 \n",
      "\n",
      "Epoch 3329\n",
      "-------------------------------\n",
      "loss: 0.100052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419554 \n",
      "\n",
      "Epoch 3330\n",
      "-------------------------------\n",
      "loss: 0.118013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419788 \n",
      "\n",
      "Epoch 3331\n",
      "-------------------------------\n",
      "loss: 0.113245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417942 \n",
      "\n",
      "Epoch 3332\n",
      "-------------------------------\n",
      "loss: 0.110495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413976 \n",
      "\n",
      "Epoch 3333\n",
      "-------------------------------\n",
      "loss: 0.106170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410299 \n",
      "\n",
      "Epoch 3334\n",
      "-------------------------------\n",
      "loss: 0.114895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410451 \n",
      "\n",
      "Epoch 3335\n",
      "-------------------------------\n",
      "loss: 0.113602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411759 \n",
      "\n",
      "Epoch 3336\n",
      "-------------------------------\n",
      "loss: 0.097530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413027 \n",
      "\n",
      "Epoch 3337\n",
      "-------------------------------\n",
      "loss: 0.101021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414456 \n",
      "\n",
      "Epoch 3338\n",
      "-------------------------------\n",
      "loss: 0.121205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415762 \n",
      "\n",
      "Epoch 3339\n",
      "-------------------------------\n",
      "loss: 0.107316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416016 \n",
      "\n",
      "Epoch 3340\n",
      "-------------------------------\n",
      "loss: 0.110631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415673 \n",
      "\n",
      "Epoch 3341\n",
      "-------------------------------\n",
      "loss: 0.106401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417396 \n",
      "\n",
      "Epoch 3342\n",
      "-------------------------------\n",
      "loss: 0.106156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419452 \n",
      "\n",
      "Epoch 3343\n",
      "-------------------------------\n",
      "loss: 0.110470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416323 \n",
      "\n",
      "Epoch 3344\n",
      "-------------------------------\n",
      "loss: 0.109616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411048 \n",
      "\n",
      "Epoch 3345\n",
      "-------------------------------\n",
      "loss: 0.100698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410319 \n",
      "\n",
      "Epoch 3346\n",
      "-------------------------------\n",
      "loss: 0.109203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411382 \n",
      "\n",
      "Epoch 3347\n",
      "-------------------------------\n",
      "loss: 0.105441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410008 \n",
      "\n",
      "Epoch 3348\n",
      "-------------------------------\n",
      "loss: 0.098805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409842 \n",
      "\n",
      "Epoch 3349\n",
      "-------------------------------\n",
      "loss: 0.104193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408199 \n",
      "\n",
      "Epoch 3350\n",
      "-------------------------------\n",
      "loss: 0.116439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406221 \n",
      "\n",
      "Epoch 3351\n",
      "-------------------------------\n",
      "loss: 0.101602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408887 \n",
      "\n",
      "Epoch 3352\n",
      "-------------------------------\n",
      "loss: 0.104349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411033 \n",
      "\n",
      "Epoch 3353\n",
      "-------------------------------\n",
      "loss: 0.105314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411892 \n",
      "\n",
      "Epoch 3354\n",
      "-------------------------------\n",
      "loss: 0.105264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411862 \n",
      "\n",
      "Epoch 3355\n",
      "-------------------------------\n",
      "loss: 0.102855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411625 \n",
      "\n",
      "Epoch 3356\n",
      "-------------------------------\n",
      "loss: 0.111513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412268 \n",
      "\n",
      "Epoch 3357\n",
      "-------------------------------\n",
      "loss: 0.104298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416495 \n",
      "\n",
      "Epoch 3358\n",
      "-------------------------------\n",
      "loss: 0.096264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415692 \n",
      "\n",
      "Epoch 3359\n",
      "-------------------------------\n",
      "loss: 0.110852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413762 \n",
      "\n",
      "Epoch 3360\n",
      "-------------------------------\n",
      "loss: 0.107730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411279 \n",
      "\n",
      "Epoch 3361\n",
      "-------------------------------\n",
      "loss: 0.109233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412264 \n",
      "\n",
      "Epoch 3362\n",
      "-------------------------------\n",
      "loss: 0.106777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413223 \n",
      "\n",
      "Epoch 3363\n",
      "-------------------------------\n",
      "loss: 0.107596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412503 \n",
      "\n",
      "Epoch 3364\n",
      "-------------------------------\n",
      "loss: 0.110611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409249 \n",
      "\n",
      "Epoch 3365\n",
      "-------------------------------\n",
      "loss: 0.112011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408268 \n",
      "\n",
      "Epoch 3366\n",
      "-------------------------------\n",
      "loss: 0.108343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408194 \n",
      "\n",
      "Epoch 3367\n",
      "-------------------------------\n",
      "loss: 0.135025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408738 \n",
      "\n",
      "Epoch 3368\n",
      "-------------------------------\n",
      "loss: 0.106041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410065 \n",
      "\n",
      "Epoch 3369\n",
      "-------------------------------\n",
      "loss: 0.110724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415255 \n",
      "\n",
      "Epoch 3370\n",
      "-------------------------------\n",
      "loss: 0.098106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423596 \n",
      "\n",
      "Epoch 3371\n",
      "-------------------------------\n",
      "loss: 0.113468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426331 \n",
      "\n",
      "Epoch 3372\n",
      "-------------------------------\n",
      "loss: 0.107812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421749 \n",
      "\n",
      "Epoch 3373\n",
      "-------------------------------\n",
      "loss: 0.117427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412703 \n",
      "\n",
      "Epoch 3374\n",
      "-------------------------------\n",
      "loss: 0.115907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407186 \n",
      "\n",
      "Epoch 3375\n",
      "-------------------------------\n",
      "loss: 0.102245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407909 \n",
      "\n",
      "Epoch 3376\n",
      "-------------------------------\n",
      "loss: 0.115895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408453 \n",
      "\n",
      "Epoch 3377\n",
      "-------------------------------\n",
      "loss: 0.106876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408680 \n",
      "\n",
      "Epoch 3378\n",
      "-------------------------------\n",
      "loss: 0.121066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415929 \n",
      "\n",
      "Epoch 3379\n",
      "-------------------------------\n",
      "loss: 0.115344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424208 \n",
      "\n",
      "Epoch 3380\n",
      "-------------------------------\n",
      "loss: 0.117991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425508 \n",
      "\n",
      "Epoch 3381\n",
      "-------------------------------\n",
      "loss: 0.102291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425721 \n",
      "\n",
      "Epoch 3382\n",
      "-------------------------------\n",
      "loss: 0.113854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424510 \n",
      "\n",
      "Epoch 3383\n",
      "-------------------------------\n",
      "loss: 0.118326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418693 \n",
      "\n",
      "Epoch 3384\n",
      "-------------------------------\n",
      "loss: 0.106947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411071 \n",
      "\n",
      "Epoch 3385\n",
      "-------------------------------\n",
      "loss: 0.119496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407780 \n",
      "\n",
      "Epoch 3386\n",
      "-------------------------------\n",
      "loss: 0.112214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407425 \n",
      "\n",
      "Epoch 3387\n",
      "-------------------------------\n",
      "loss: 0.117499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410058 \n",
      "\n",
      "Epoch 3388\n",
      "-------------------------------\n",
      "loss: 0.128331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412558 \n",
      "\n",
      "Epoch 3389\n",
      "-------------------------------\n",
      "loss: 0.130664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413522 \n",
      "\n",
      "Epoch 3390\n",
      "-------------------------------\n",
      "loss: 0.125902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412573 \n",
      "\n",
      "Epoch 3391\n",
      "-------------------------------\n",
      "loss: 0.110029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413086 \n",
      "\n",
      "Epoch 3392\n",
      "-------------------------------\n",
      "loss: 0.115197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414862 \n",
      "\n",
      "Epoch 3393\n",
      "-------------------------------\n",
      "loss: 0.111157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412700 \n",
      "\n",
      "Epoch 3394\n",
      "-------------------------------\n",
      "loss: 0.106631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410189 \n",
      "\n",
      "Epoch 3395\n",
      "-------------------------------\n",
      "loss: 0.108097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410189 \n",
      "\n",
      "Epoch 3396\n",
      "-------------------------------\n",
      "loss: 0.108444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412887 \n",
      "\n",
      "Epoch 3397\n",
      "-------------------------------\n",
      "loss: 0.118853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412985 \n",
      "\n",
      "Epoch 3398\n",
      "-------------------------------\n",
      "loss: 0.121722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412014 \n",
      "\n",
      "Epoch 3399\n",
      "-------------------------------\n",
      "loss: 0.110423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416326 \n",
      "\n",
      "Epoch 3400\n",
      "-------------------------------\n",
      "loss: 0.104885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418761 \n",
      "\n",
      "Epoch 3401\n",
      "-------------------------------\n",
      "loss: 0.105328  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.417584 \n",
      "\n",
      "Epoch 3402\n",
      "-------------------------------\n",
      "loss: 0.106096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414788 \n",
      "\n",
      "Epoch 3403\n",
      "-------------------------------\n",
      "loss: 0.102428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411911 \n",
      "\n",
      "Epoch 3404\n",
      "-------------------------------\n",
      "loss: 0.109259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411735 \n",
      "\n",
      "Epoch 3405\n",
      "-------------------------------\n",
      "loss: 0.112281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411928 \n",
      "\n",
      "Epoch 3406\n",
      "-------------------------------\n",
      "loss: 0.093084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411699 \n",
      "\n",
      "Epoch 3407\n",
      "-------------------------------\n",
      "loss: 0.111813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413007 \n",
      "\n",
      "Epoch 3408\n",
      "-------------------------------\n",
      "loss: 0.098773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414307 \n",
      "\n",
      "Epoch 3409\n",
      "-------------------------------\n",
      "loss: 0.102909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416638 \n",
      "\n",
      "Epoch 3410\n",
      "-------------------------------\n",
      "loss: 0.104713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416789 \n",
      "\n",
      "Epoch 3411\n",
      "-------------------------------\n",
      "loss: 0.107249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416012 \n",
      "\n",
      "Epoch 3412\n",
      "-------------------------------\n",
      "loss: 0.109286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416930 \n",
      "\n",
      "Epoch 3413\n",
      "-------------------------------\n",
      "loss: 0.101273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418364 \n",
      "\n",
      "Epoch 3414\n",
      "-------------------------------\n",
      "loss: 0.107165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417298 \n",
      "\n",
      "Epoch 3415\n",
      "-------------------------------\n",
      "loss: 0.122772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417392 \n",
      "\n",
      "Epoch 3416\n",
      "-------------------------------\n",
      "loss: 0.106826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419220 \n",
      "\n",
      "Epoch 3417\n",
      "-------------------------------\n",
      "loss: 0.102004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422181 \n",
      "\n",
      "Epoch 3418\n",
      "-------------------------------\n",
      "loss: 0.108108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423052 \n",
      "\n",
      "Epoch 3419\n",
      "-------------------------------\n",
      "loss: 0.134720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417387 \n",
      "\n",
      "Epoch 3420\n",
      "-------------------------------\n",
      "loss: 0.102446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413995 \n",
      "\n",
      "Epoch 3421\n",
      "-------------------------------\n",
      "loss: 0.120192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414717 \n",
      "\n",
      "Epoch 3422\n",
      "-------------------------------\n",
      "loss: 0.097458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414758 \n",
      "\n",
      "Epoch 3423\n",
      "-------------------------------\n",
      "loss: 0.123384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413346 \n",
      "\n",
      "Epoch 3424\n",
      "-------------------------------\n",
      "loss: 0.107711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423208 \n",
      "\n",
      "Epoch 3425\n",
      "-------------------------------\n",
      "loss: 0.105054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.438597 \n",
      "\n",
      "Epoch 3426\n",
      "-------------------------------\n",
      "loss: 0.106151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442489 \n",
      "\n",
      "Epoch 3427\n",
      "-------------------------------\n",
      "loss: 0.125306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430369 \n",
      "\n",
      "Epoch 3428\n",
      "-------------------------------\n",
      "loss: 0.114679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419636 \n",
      "\n",
      "Epoch 3429\n",
      "-------------------------------\n",
      "loss: 0.123495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414336 \n",
      "\n",
      "Epoch 3430\n",
      "-------------------------------\n",
      "loss: 0.129664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413926 \n",
      "\n",
      "Epoch 3431\n",
      "-------------------------------\n",
      "loss: 0.125575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415737 \n",
      "\n",
      "Epoch 3432\n",
      "-------------------------------\n",
      "loss: 0.121332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418926 \n",
      "\n",
      "Epoch 3433\n",
      "-------------------------------\n",
      "loss: 0.106523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422890 \n",
      "\n",
      "Epoch 3434\n",
      "-------------------------------\n",
      "loss: 0.117426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423074 \n",
      "\n",
      "Epoch 3435\n",
      "-------------------------------\n",
      "loss: 0.101778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422244 \n",
      "\n",
      "Epoch 3436\n",
      "-------------------------------\n",
      "loss: 0.119264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415085 \n",
      "\n",
      "Epoch 3437\n",
      "-------------------------------\n",
      "loss: 0.108364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412325 \n",
      "\n",
      "Epoch 3438\n",
      "-------------------------------\n",
      "loss: 0.111348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413729 \n",
      "\n",
      "Epoch 3439\n",
      "-------------------------------\n",
      "loss: 0.112623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414118 \n",
      "\n",
      "Epoch 3440\n",
      "-------------------------------\n",
      "loss: 0.107477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416334 \n",
      "\n",
      "Epoch 3441\n",
      "-------------------------------\n",
      "loss: 0.111755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416160 \n",
      "\n",
      "Epoch 3442\n",
      "-------------------------------\n",
      "loss: 0.102161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415977 \n",
      "\n",
      "Epoch 3443\n",
      "-------------------------------\n",
      "loss: 0.102155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417020 \n",
      "\n",
      "Epoch 3444\n",
      "-------------------------------\n",
      "loss: 0.103767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417711 \n",
      "\n",
      "Epoch 3445\n",
      "-------------------------------\n",
      "loss: 0.106210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419993 \n",
      "\n",
      "Epoch 3446\n",
      "-------------------------------\n",
      "loss: 0.107031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419265 \n",
      "\n",
      "Epoch 3447\n",
      "-------------------------------\n",
      "loss: 0.103563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418409 \n",
      "\n",
      "Epoch 3448\n",
      "-------------------------------\n",
      "loss: 0.109131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417221 \n",
      "\n",
      "Epoch 3449\n",
      "-------------------------------\n",
      "loss: 0.107935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418198 \n",
      "\n",
      "Epoch 3450\n",
      "-------------------------------\n",
      "loss: 0.108558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420905 \n",
      "\n",
      "Epoch 3451\n",
      "-------------------------------\n",
      "loss: 0.109771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422714 \n",
      "\n",
      "Epoch 3452\n",
      "-------------------------------\n",
      "loss: 0.107422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421612 \n",
      "\n",
      "Epoch 3453\n",
      "-------------------------------\n",
      "loss: 0.106364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417187 \n",
      "\n",
      "Epoch 3454\n",
      "-------------------------------\n",
      "loss: 0.105863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411116 \n",
      "\n",
      "Epoch 3455\n",
      "-------------------------------\n",
      "loss: 0.119002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406979 \n",
      "\n",
      "Epoch 3456\n",
      "-------------------------------\n",
      "loss: 0.107346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403826 \n",
      "\n",
      "Epoch 3457\n",
      "-------------------------------\n",
      "loss: 0.118885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405313 \n",
      "\n",
      "Epoch 3458\n",
      "-------------------------------\n",
      "loss: 0.103571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408691 \n",
      "\n",
      "Epoch 3459\n",
      "-------------------------------\n",
      "loss: 0.103896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412786 \n",
      "\n",
      "Epoch 3460\n",
      "-------------------------------\n",
      "loss: 0.104645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417838 \n",
      "\n",
      "Epoch 3461\n",
      "-------------------------------\n",
      "loss: 0.126932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427272 \n",
      "\n",
      "Epoch 3462\n",
      "-------------------------------\n",
      "loss: 0.117403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429502 \n",
      "\n",
      "Epoch 3463\n",
      "-------------------------------\n",
      "loss: 0.124379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426075 \n",
      "\n",
      "Epoch 3464\n",
      "-------------------------------\n",
      "loss: 0.126663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418635 \n",
      "\n",
      "Epoch 3465\n",
      "-------------------------------\n",
      "loss: 0.121168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408839 \n",
      "\n",
      "Epoch 3466\n",
      "-------------------------------\n",
      "loss: 0.108963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406481 \n",
      "\n",
      "Epoch 3467\n",
      "-------------------------------\n",
      "loss: 0.108963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409666 \n",
      "\n",
      "Epoch 3468\n",
      "-------------------------------\n",
      "loss: 0.110062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414299 \n",
      "\n",
      "Epoch 3469\n",
      "-------------------------------\n",
      "loss: 0.104243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420354 \n",
      "\n",
      "Epoch 3470\n",
      "-------------------------------\n",
      "loss: 0.107483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424182 \n",
      "\n",
      "Epoch 3471\n",
      "-------------------------------\n",
      "loss: 0.104777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423884 \n",
      "\n",
      "Epoch 3472\n",
      "-------------------------------\n",
      "loss: 0.114886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418831 \n",
      "\n",
      "Epoch 3473\n",
      "-------------------------------\n",
      "loss: 0.110284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414704 \n",
      "\n",
      "Epoch 3474\n",
      "-------------------------------\n",
      "loss: 0.109223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413114 \n",
      "\n",
      "Epoch 3475\n",
      "-------------------------------\n",
      "loss: 0.106056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412192 \n",
      "\n",
      "Epoch 3476\n",
      "-------------------------------\n",
      "loss: 0.118074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409971 \n",
      "\n",
      "Epoch 3477\n",
      "-------------------------------\n",
      "loss: 0.111601  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.408856 \n",
      "\n",
      "Epoch 3478\n",
      "-------------------------------\n",
      "loss: 0.104609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408736 \n",
      "\n",
      "Epoch 3479\n",
      "-------------------------------\n",
      "loss: 0.099857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406651 \n",
      "\n",
      "Epoch 3480\n",
      "-------------------------------\n",
      "loss: 0.112783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402522 \n",
      "\n",
      "Epoch 3481\n",
      "-------------------------------\n",
      "loss: 0.104078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403389 \n",
      "\n",
      "Epoch 3482\n",
      "-------------------------------\n",
      "loss: 0.101450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406068 \n",
      "\n",
      "Epoch 3483\n",
      "-------------------------------\n",
      "loss: 0.116620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407282 \n",
      "\n",
      "Epoch 3484\n",
      "-------------------------------\n",
      "loss: 0.123631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409287 \n",
      "\n",
      "Epoch 3485\n",
      "-------------------------------\n",
      "loss: 0.110493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415419 \n",
      "\n",
      "Epoch 3486\n",
      "-------------------------------\n",
      "loss: 0.109740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419384 \n",
      "\n",
      "Epoch 3487\n",
      "-------------------------------\n",
      "loss: 0.111271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421709 \n",
      "\n",
      "Epoch 3488\n",
      "-------------------------------\n",
      "loss: 0.116764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423342 \n",
      "\n",
      "Epoch 3489\n",
      "-------------------------------\n",
      "loss: 0.108341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421720 \n",
      "\n",
      "Epoch 3490\n",
      "-------------------------------\n",
      "loss: 0.101589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423134 \n",
      "\n",
      "Epoch 3491\n",
      "-------------------------------\n",
      "loss: 0.112498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425655 \n",
      "\n",
      "Epoch 3492\n",
      "-------------------------------\n",
      "loss: 0.123487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429131 \n",
      "\n",
      "Epoch 3493\n",
      "-------------------------------\n",
      "loss: 0.115459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429653 \n",
      "\n",
      "Epoch 3494\n",
      "-------------------------------\n",
      "loss: 0.137452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426620 \n",
      "\n",
      "Epoch 3495\n",
      "-------------------------------\n",
      "loss: 0.130312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419607 \n",
      "\n",
      "Epoch 3496\n",
      "-------------------------------\n",
      "loss: 0.117190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411696 \n",
      "\n",
      "Epoch 3497\n",
      "-------------------------------\n",
      "loss: 0.106839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408057 \n",
      "\n",
      "Epoch 3498\n",
      "-------------------------------\n",
      "loss: 0.107873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411643 \n",
      "\n",
      "Epoch 3499\n",
      "-------------------------------\n",
      "loss: 0.142228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411474 \n",
      "\n",
      "Epoch 3500\n",
      "-------------------------------\n",
      "loss: 0.125577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407073 \n",
      "\n",
      "Epoch 3501\n",
      "-------------------------------\n",
      "loss: 0.115987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404467 \n",
      "\n",
      "Epoch 3502\n",
      "-------------------------------\n",
      "loss: 0.106976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408389 \n",
      "\n",
      "Epoch 3503\n",
      "-------------------------------\n",
      "loss: 0.126446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416088 \n",
      "\n",
      "Epoch 3504\n",
      "-------------------------------\n",
      "loss: 0.131275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418893 \n",
      "\n",
      "Epoch 3505\n",
      "-------------------------------\n",
      "loss: 0.112481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418828 \n",
      "\n",
      "Epoch 3506\n",
      "-------------------------------\n",
      "loss: 0.115947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415613 \n",
      "\n",
      "Epoch 3507\n",
      "-------------------------------\n",
      "loss: 0.110648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416162 \n",
      "\n",
      "Epoch 3508\n",
      "-------------------------------\n",
      "loss: 0.118461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417954 \n",
      "\n",
      "Epoch 3509\n",
      "-------------------------------\n",
      "loss: 0.110892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417951 \n",
      "\n",
      "Epoch 3510\n",
      "-------------------------------\n",
      "loss: 0.140981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416251 \n",
      "\n",
      "Epoch 3511\n",
      "-------------------------------\n",
      "loss: 0.132248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414199 \n",
      "\n",
      "Epoch 3512\n",
      "-------------------------------\n",
      "loss: 0.132265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411722 \n",
      "\n",
      "Epoch 3513\n",
      "-------------------------------\n",
      "loss: 0.107016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417137 \n",
      "\n",
      "Epoch 3514\n",
      "-------------------------------\n",
      "loss: 0.111186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424186 \n",
      "\n",
      "Epoch 3515\n",
      "-------------------------------\n",
      "loss: 0.118422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426454 \n",
      "\n",
      "Epoch 3516\n",
      "-------------------------------\n",
      "loss: 0.122559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423323 \n",
      "\n",
      "Epoch 3517\n",
      "-------------------------------\n",
      "loss: 0.113135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417963 \n",
      "\n",
      "Epoch 3518\n",
      "-------------------------------\n",
      "loss: 0.110461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414607 \n",
      "\n",
      "Epoch 3519\n",
      "-------------------------------\n",
      "loss: 0.111669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411400 \n",
      "\n",
      "Epoch 3520\n",
      "-------------------------------\n",
      "loss: 0.126511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409183 \n",
      "\n",
      "Epoch 3521\n",
      "-------------------------------\n",
      "loss: 0.113276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409514 \n",
      "\n",
      "Epoch 3522\n",
      "-------------------------------\n",
      "loss: 0.101253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412107 \n",
      "\n",
      "Epoch 3523\n",
      "-------------------------------\n",
      "loss: 0.110859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412090 \n",
      "\n",
      "Epoch 3524\n",
      "-------------------------------\n",
      "loss: 0.108094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411247 \n",
      "\n",
      "Epoch 3525\n",
      "-------------------------------\n",
      "loss: 0.111112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410157 \n",
      "\n",
      "Epoch 3526\n",
      "-------------------------------\n",
      "loss: 0.112826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408310 \n",
      "\n",
      "Epoch 3527\n",
      "-------------------------------\n",
      "loss: 0.102055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406894 \n",
      "\n",
      "Epoch 3528\n",
      "-------------------------------\n",
      "loss: 0.110303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405849 \n",
      "\n",
      "Epoch 3529\n",
      "-------------------------------\n",
      "loss: 0.124624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405844 \n",
      "\n",
      "Epoch 3530\n",
      "-------------------------------\n",
      "loss: 0.107634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410251 \n",
      "\n",
      "Epoch 3531\n",
      "-------------------------------\n",
      "loss: 0.111502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414262 \n",
      "\n",
      "Epoch 3532\n",
      "-------------------------------\n",
      "loss: 0.112998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413121 \n",
      "\n",
      "Epoch 3533\n",
      "-------------------------------\n",
      "loss: 0.110925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415463 \n",
      "\n",
      "Epoch 3534\n",
      "-------------------------------\n",
      "loss: 0.110815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419546 \n",
      "\n",
      "Epoch 3535\n",
      "-------------------------------\n",
      "loss: 0.106134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422420 \n",
      "\n",
      "Epoch 3536\n",
      "-------------------------------\n",
      "loss: 0.111573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421741 \n",
      "\n",
      "Epoch 3537\n",
      "-------------------------------\n",
      "loss: 0.109152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420796 \n",
      "\n",
      "Epoch 3538\n",
      "-------------------------------\n",
      "loss: 0.105120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418484 \n",
      "\n",
      "Epoch 3539\n",
      "-------------------------------\n",
      "loss: 0.107134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413953 \n",
      "\n",
      "Epoch 3540\n",
      "-------------------------------\n",
      "loss: 0.102662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410279 \n",
      "\n",
      "Epoch 3541\n",
      "-------------------------------\n",
      "loss: 0.120184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408664 \n",
      "\n",
      "Epoch 3542\n",
      "-------------------------------\n",
      "loss: 0.111191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409559 \n",
      "\n",
      "Epoch 3543\n",
      "-------------------------------\n",
      "loss: 0.107386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415143 \n",
      "\n",
      "Epoch 3544\n",
      "-------------------------------\n",
      "loss: 0.100000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417723 \n",
      "\n",
      "Epoch 3545\n",
      "-------------------------------\n",
      "loss: 0.125329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418663 \n",
      "\n",
      "Epoch 3546\n",
      "-------------------------------\n",
      "loss: 0.101295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417852 \n",
      "\n",
      "Epoch 3547\n",
      "-------------------------------\n",
      "loss: 0.106068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417826 \n",
      "\n",
      "Epoch 3548\n",
      "-------------------------------\n",
      "loss: 0.117695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415782 \n",
      "\n",
      "Epoch 3549\n",
      "-------------------------------\n",
      "loss: 0.105684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416523 \n",
      "\n",
      "Epoch 3550\n",
      "-------------------------------\n",
      "loss: 0.105852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419052 \n",
      "\n",
      "Epoch 3551\n",
      "-------------------------------\n",
      "loss: 0.096435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425340 \n",
      "\n",
      "Epoch 3552\n",
      "-------------------------------\n",
      "loss: 0.104696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429642 \n",
      "\n",
      "Epoch 3553\n",
      "-------------------------------\n",
      "loss: 0.112202  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.427632 \n",
      "\n",
      "Epoch 3554\n",
      "-------------------------------\n",
      "loss: 0.117678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421951 \n",
      "\n",
      "Epoch 3555\n",
      "-------------------------------\n",
      "loss: 0.117808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413783 \n",
      "\n",
      "Epoch 3556\n",
      "-------------------------------\n",
      "loss: 0.121335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410279 \n",
      "\n",
      "Epoch 3557\n",
      "-------------------------------\n",
      "loss: 0.109438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413644 \n",
      "\n",
      "Epoch 3558\n",
      "-------------------------------\n",
      "loss: 0.101923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419589 \n",
      "\n",
      "Epoch 3559\n",
      "-------------------------------\n",
      "loss: 0.101877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427040 \n",
      "\n",
      "Epoch 3560\n",
      "-------------------------------\n",
      "loss: 0.111748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430302 \n",
      "\n",
      "Epoch 3561\n",
      "-------------------------------\n",
      "loss: 0.122169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427835 \n",
      "\n",
      "Epoch 3562\n",
      "-------------------------------\n",
      "loss: 0.101095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421663 \n",
      "\n",
      "Epoch 3563\n",
      "-------------------------------\n",
      "loss: 0.119635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419155 \n",
      "\n",
      "Epoch 3564\n",
      "-------------------------------\n",
      "loss: 0.106817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419392 \n",
      "\n",
      "Epoch 3565\n",
      "-------------------------------\n",
      "loss: 0.116704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416266 \n",
      "\n",
      "Epoch 3566\n",
      "-------------------------------\n",
      "loss: 0.120591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409967 \n",
      "\n",
      "Epoch 3567\n",
      "-------------------------------\n",
      "loss: 0.118382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407410 \n",
      "\n",
      "Epoch 3568\n",
      "-------------------------------\n",
      "loss: 0.117780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408633 \n",
      "\n",
      "Epoch 3569\n",
      "-------------------------------\n",
      "loss: 0.110780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413396 \n",
      "\n",
      "Epoch 3570\n",
      "-------------------------------\n",
      "loss: 0.122994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419096 \n",
      "\n",
      "Epoch 3571\n",
      "-------------------------------\n",
      "loss: 0.126821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422142 \n",
      "\n",
      "Epoch 3572\n",
      "-------------------------------\n",
      "loss: 0.140689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422947 \n",
      "\n",
      "Epoch 3573\n",
      "-------------------------------\n",
      "loss: 0.100552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424290 \n",
      "\n",
      "Epoch 3574\n",
      "-------------------------------\n",
      "loss: 0.105039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425006 \n",
      "\n",
      "Epoch 3575\n",
      "-------------------------------\n",
      "loss: 0.116111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424483 \n",
      "\n",
      "Epoch 3576\n",
      "-------------------------------\n",
      "loss: 0.108592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422415 \n",
      "\n",
      "Epoch 3577\n",
      "-------------------------------\n",
      "loss: 0.099877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420101 \n",
      "\n",
      "Epoch 3578\n",
      "-------------------------------\n",
      "loss: 0.113125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418022 \n",
      "\n",
      "Epoch 3579\n",
      "-------------------------------\n",
      "loss: 0.117897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412544 \n",
      "\n",
      "Epoch 3580\n",
      "-------------------------------\n",
      "loss: 0.123327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407852 \n",
      "\n",
      "Epoch 3581\n",
      "-------------------------------\n",
      "loss: 0.119560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408102 \n",
      "\n",
      "Epoch 3582\n",
      "-------------------------------\n",
      "loss: 0.098557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414741 \n",
      "\n",
      "Epoch 3583\n",
      "-------------------------------\n",
      "loss: 0.107438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417276 \n",
      "\n",
      "Epoch 3584\n",
      "-------------------------------\n",
      "loss: 0.117992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417034 \n",
      "\n",
      "Epoch 3585\n",
      "-------------------------------\n",
      "loss: 0.107138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416211 \n",
      "\n",
      "Epoch 3586\n",
      "-------------------------------\n",
      "loss: 0.116740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416207 \n",
      "\n",
      "Epoch 3587\n",
      "-------------------------------\n",
      "loss: 0.116632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414799 \n",
      "\n",
      "Epoch 3588\n",
      "-------------------------------\n",
      "loss: 0.104512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411633 \n",
      "\n",
      "Epoch 3589\n",
      "-------------------------------\n",
      "loss: 0.114239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408367 \n",
      "\n",
      "Epoch 3590\n",
      "-------------------------------\n",
      "loss: 0.119796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410027 \n",
      "\n",
      "Epoch 3591\n",
      "-------------------------------\n",
      "loss: 0.106374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418365 \n",
      "\n",
      "Epoch 3592\n",
      "-------------------------------\n",
      "loss: 0.109438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426904 \n",
      "\n",
      "Epoch 3593\n",
      "-------------------------------\n",
      "loss: 0.112468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431132 \n",
      "\n",
      "Epoch 3594\n",
      "-------------------------------\n",
      "loss: 0.113835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426160 \n",
      "\n",
      "Epoch 3595\n",
      "-------------------------------\n",
      "loss: 0.116437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413860 \n",
      "\n",
      "Epoch 3596\n",
      "-------------------------------\n",
      "loss: 0.118965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413979 \n",
      "\n",
      "Epoch 3597\n",
      "-------------------------------\n",
      "loss: 0.101975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416864 \n",
      "\n",
      "Epoch 3598\n",
      "-------------------------------\n",
      "loss: 0.107678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419285 \n",
      "\n",
      "Epoch 3599\n",
      "-------------------------------\n",
      "loss: 0.123948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421236 \n",
      "\n",
      "Epoch 3600\n",
      "-------------------------------\n",
      "loss: 0.115213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418663 \n",
      "\n",
      "Epoch 3601\n",
      "-------------------------------\n",
      "loss: 0.107736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417954 \n",
      "\n",
      "Epoch 3602\n",
      "-------------------------------\n",
      "loss: 0.098618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419775 \n",
      "\n",
      "Epoch 3603\n",
      "-------------------------------\n",
      "loss: 0.106942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424805 \n",
      "\n",
      "Epoch 3604\n",
      "-------------------------------\n",
      "loss: 0.113047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428537 \n",
      "\n",
      "Epoch 3605\n",
      "-------------------------------\n",
      "loss: 0.102043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428594 \n",
      "\n",
      "Epoch 3606\n",
      "-------------------------------\n",
      "loss: 0.097399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425616 \n",
      "\n",
      "Epoch 3607\n",
      "-------------------------------\n",
      "loss: 0.108095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421106 \n",
      "\n",
      "Epoch 3608\n",
      "-------------------------------\n",
      "loss: 0.125852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416407 \n",
      "\n",
      "Epoch 3609\n",
      "-------------------------------\n",
      "loss: 0.100959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413553 \n",
      "\n",
      "Epoch 3610\n",
      "-------------------------------\n",
      "loss: 0.122377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411908 \n",
      "\n",
      "Epoch 3611\n",
      "-------------------------------\n",
      "loss: 0.105193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410658 \n",
      "\n",
      "Epoch 3612\n",
      "-------------------------------\n",
      "loss: 0.111379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414770 \n",
      "\n",
      "Epoch 3613\n",
      "-------------------------------\n",
      "loss: 0.103553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421678 \n",
      "\n",
      "Epoch 3614\n",
      "-------------------------------\n",
      "loss: 0.122825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422866 \n",
      "\n",
      "Epoch 3615\n",
      "-------------------------------\n",
      "loss: 0.103119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420836 \n",
      "\n",
      "Epoch 3616\n",
      "-------------------------------\n",
      "loss: 0.127943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416943 \n",
      "\n",
      "Epoch 3617\n",
      "-------------------------------\n",
      "loss: 0.107270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419350 \n",
      "\n",
      "Epoch 3618\n",
      "-------------------------------\n",
      "loss: 0.109568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423381 \n",
      "\n",
      "Epoch 3619\n",
      "-------------------------------\n",
      "loss: 0.105320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421741 \n",
      "\n",
      "Epoch 3620\n",
      "-------------------------------\n",
      "loss: 0.107366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416886 \n",
      "\n",
      "Epoch 3621\n",
      "-------------------------------\n",
      "loss: 0.109872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414370 \n",
      "\n",
      "Epoch 3622\n",
      "-------------------------------\n",
      "loss: 0.105809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413690 \n",
      "\n",
      "Epoch 3623\n",
      "-------------------------------\n",
      "loss: 0.110353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409470 \n",
      "\n",
      "Epoch 3624\n",
      "-------------------------------\n",
      "loss: 0.115112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405973 \n",
      "\n",
      "Epoch 3625\n",
      "-------------------------------\n",
      "loss: 0.113695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408919 \n",
      "\n",
      "Epoch 3626\n",
      "-------------------------------\n",
      "loss: 0.121399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414668 \n",
      "\n",
      "Epoch 3627\n",
      "-------------------------------\n",
      "loss: 0.116707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419224 \n",
      "\n",
      "Epoch 3628\n",
      "-------------------------------\n",
      "loss: 0.107929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418797 \n",
      "\n",
      "Epoch 3629\n",
      "-------------------------------\n",
      "loss: 0.110529  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.416474 \n",
      "\n",
      "Epoch 3630\n",
      "-------------------------------\n",
      "loss: 0.118237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414875 \n",
      "\n",
      "Epoch 3631\n",
      "-------------------------------\n",
      "loss: 0.112056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410933 \n",
      "\n",
      "Epoch 3632\n",
      "-------------------------------\n",
      "loss: 0.105646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409052 \n",
      "\n",
      "Epoch 3633\n",
      "-------------------------------\n",
      "loss: 0.096414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412726 \n",
      "\n",
      "Epoch 3634\n",
      "-------------------------------\n",
      "loss: 0.106840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415356 \n",
      "\n",
      "Epoch 3635\n",
      "-------------------------------\n",
      "loss: 0.107098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415937 \n",
      "\n",
      "Epoch 3636\n",
      "-------------------------------\n",
      "loss: 0.110381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416594 \n",
      "\n",
      "Epoch 3637\n",
      "-------------------------------\n",
      "loss: 0.097977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421132 \n",
      "\n",
      "Epoch 3638\n",
      "-------------------------------\n",
      "loss: 0.104311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422526 \n",
      "\n",
      "Epoch 3639\n",
      "-------------------------------\n",
      "loss: 0.106865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423151 \n",
      "\n",
      "Epoch 3640\n",
      "-------------------------------\n",
      "loss: 0.120467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419723 \n",
      "\n",
      "Epoch 3641\n",
      "-------------------------------\n",
      "loss: 0.100324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416321 \n",
      "\n",
      "Epoch 3642\n",
      "-------------------------------\n",
      "loss: 0.109912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414542 \n",
      "\n",
      "Epoch 3643\n",
      "-------------------------------\n",
      "loss: 0.108717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413454 \n",
      "\n",
      "Epoch 3644\n",
      "-------------------------------\n",
      "loss: 0.123293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410335 \n",
      "\n",
      "Epoch 3645\n",
      "-------------------------------\n",
      "loss: 0.099788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408690 \n",
      "\n",
      "Epoch 3646\n",
      "-------------------------------\n",
      "loss: 0.095099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412097 \n",
      "\n",
      "Epoch 3647\n",
      "-------------------------------\n",
      "loss: 0.104131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415589 \n",
      "\n",
      "Epoch 3648\n",
      "-------------------------------\n",
      "loss: 0.096732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419003 \n",
      "\n",
      "Epoch 3649\n",
      "-------------------------------\n",
      "loss: 0.115455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419657 \n",
      "\n",
      "Epoch 3650\n",
      "-------------------------------\n",
      "loss: 0.108769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417311 \n",
      "\n",
      "Epoch 3651\n",
      "-------------------------------\n",
      "loss: 0.103478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414541 \n",
      "\n",
      "Epoch 3652\n",
      "-------------------------------\n",
      "loss: 0.106261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410454 \n",
      "\n",
      "Epoch 3653\n",
      "-------------------------------\n",
      "loss: 0.099352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407876 \n",
      "\n",
      "Epoch 3654\n",
      "-------------------------------\n",
      "loss: 0.119829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411120 \n",
      "\n",
      "Epoch 3655\n",
      "-------------------------------\n",
      "loss: 0.118662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414696 \n",
      "\n",
      "Epoch 3656\n",
      "-------------------------------\n",
      "loss: 0.118351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418323 \n",
      "\n",
      "Epoch 3657\n",
      "-------------------------------\n",
      "loss: 0.117266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419351 \n",
      "\n",
      "Epoch 3658\n",
      "-------------------------------\n",
      "loss: 0.103443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421900 \n",
      "\n",
      "Epoch 3659\n",
      "-------------------------------\n",
      "loss: 0.097802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428538 \n",
      "\n",
      "Epoch 3660\n",
      "-------------------------------\n",
      "loss: 0.111343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428396 \n",
      "\n",
      "Epoch 3661\n",
      "-------------------------------\n",
      "loss: 0.125896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422619 \n",
      "\n",
      "Epoch 3662\n",
      "-------------------------------\n",
      "loss: 0.113050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418828 \n",
      "\n",
      "Epoch 3663\n",
      "-------------------------------\n",
      "loss: 0.110080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415665 \n",
      "\n",
      "Epoch 3664\n",
      "-------------------------------\n",
      "loss: 0.121788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410658 \n",
      "\n",
      "Epoch 3665\n",
      "-------------------------------\n",
      "loss: 0.102603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407043 \n",
      "\n",
      "Epoch 3666\n",
      "-------------------------------\n",
      "loss: 0.105827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409868 \n",
      "\n",
      "Epoch 3667\n",
      "-------------------------------\n",
      "loss: 0.106921  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411841 \n",
      "\n",
      "Epoch 3668\n",
      "-------------------------------\n",
      "loss: 0.107186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411032 \n",
      "\n",
      "Epoch 3669\n",
      "-------------------------------\n",
      "loss: 0.099002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410893 \n",
      "\n",
      "Epoch 3670\n",
      "-------------------------------\n",
      "loss: 0.106683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411459 \n",
      "\n",
      "Epoch 3671\n",
      "-------------------------------\n",
      "loss: 0.105458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410691 \n",
      "\n",
      "Epoch 3672\n",
      "-------------------------------\n",
      "loss: 0.103869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406425 \n",
      "\n",
      "Epoch 3673\n",
      "-------------------------------\n",
      "loss: 0.111747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405607 \n",
      "\n",
      "Epoch 3674\n",
      "-------------------------------\n",
      "loss: 0.102806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405490 \n",
      "\n",
      "Epoch 3675\n",
      "-------------------------------\n",
      "loss: 0.118061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404879 \n",
      "\n",
      "Epoch 3676\n",
      "-------------------------------\n",
      "loss: 0.106621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405215 \n",
      "\n",
      "Epoch 3677\n",
      "-------------------------------\n",
      "loss: 0.103469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410277 \n",
      "\n",
      "Epoch 3678\n",
      "-------------------------------\n",
      "loss: 0.095582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417748 \n",
      "\n",
      "Epoch 3679\n",
      "-------------------------------\n",
      "loss: 0.117641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421273 \n",
      "\n",
      "Epoch 3680\n",
      "-------------------------------\n",
      "loss: 0.110757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419025 \n",
      "\n",
      "Epoch 3681\n",
      "-------------------------------\n",
      "loss: 0.105642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413840 \n",
      "\n",
      "Epoch 3682\n",
      "-------------------------------\n",
      "loss: 0.109828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413038 \n",
      "\n",
      "Epoch 3683\n",
      "-------------------------------\n",
      "loss: 0.099911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412317 \n",
      "\n",
      "Epoch 3684\n",
      "-------------------------------\n",
      "loss: 0.104491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411405 \n",
      "\n",
      "Epoch 3685\n",
      "-------------------------------\n",
      "loss: 0.109381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412039 \n",
      "\n",
      "Epoch 3686\n",
      "-------------------------------\n",
      "loss: 0.104421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412585 \n",
      "\n",
      "Epoch 3687\n",
      "-------------------------------\n",
      "loss: 0.104842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413801 \n",
      "\n",
      "Epoch 3688\n",
      "-------------------------------\n",
      "loss: 0.118109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414579 \n",
      "\n",
      "Epoch 3689\n",
      "-------------------------------\n",
      "loss: 0.126204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415233 \n",
      "\n",
      "Epoch 3690\n",
      "-------------------------------\n",
      "loss: 0.118469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420372 \n",
      "\n",
      "Epoch 3691\n",
      "-------------------------------\n",
      "loss: 0.114017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420450 \n",
      "\n",
      "Epoch 3692\n",
      "-------------------------------\n",
      "loss: 0.115462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417756 \n",
      "\n",
      "Epoch 3693\n",
      "-------------------------------\n",
      "loss: 0.107361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416193 \n",
      "\n",
      "Epoch 3694\n",
      "-------------------------------\n",
      "loss: 0.097480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414565 \n",
      "\n",
      "Epoch 3695\n",
      "-------------------------------\n",
      "loss: 0.095170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412282 \n",
      "\n",
      "Epoch 3696\n",
      "-------------------------------\n",
      "loss: 0.104623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408539 \n",
      "\n",
      "Epoch 3697\n",
      "-------------------------------\n",
      "loss: 0.097846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407237 \n",
      "\n",
      "Epoch 3698\n",
      "-------------------------------\n",
      "loss: 0.110480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408744 \n",
      "\n",
      "Epoch 3699\n",
      "-------------------------------\n",
      "loss: 0.115034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410872 \n",
      "\n",
      "Epoch 3700\n",
      "-------------------------------\n",
      "loss: 0.099405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412021 \n",
      "\n",
      "Epoch 3701\n",
      "-------------------------------\n",
      "loss: 0.110435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414111 \n",
      "\n",
      "Epoch 3702\n",
      "-------------------------------\n",
      "loss: 0.103000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416672 \n",
      "\n",
      "Epoch 3703\n",
      "-------------------------------\n",
      "loss: 0.109706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419263 \n",
      "\n",
      "Epoch 3704\n",
      "-------------------------------\n",
      "loss: 0.114173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417630 \n",
      "\n",
      "Epoch 3705\n",
      "-------------------------------\n",
      "loss: 0.118983  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.413476 \n",
      "\n",
      "Epoch 3706\n",
      "-------------------------------\n",
      "loss: 0.119856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415047 \n",
      "\n",
      "Epoch 3707\n",
      "-------------------------------\n",
      "loss: 0.095260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417795 \n",
      "\n",
      "Epoch 3708\n",
      "-------------------------------\n",
      "loss: 0.110479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420818 \n",
      "\n",
      "Epoch 3709\n",
      "-------------------------------\n",
      "loss: 0.107822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419987 \n",
      "\n",
      "Epoch 3710\n",
      "-------------------------------\n",
      "loss: 0.111077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418036 \n",
      "\n",
      "Epoch 3711\n",
      "-------------------------------\n",
      "loss: 0.102668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416562 \n",
      "\n",
      "Epoch 3712\n",
      "-------------------------------\n",
      "loss: 0.100860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414884 \n",
      "\n",
      "Epoch 3713\n",
      "-------------------------------\n",
      "loss: 0.097679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417058 \n",
      "\n",
      "Epoch 3714\n",
      "-------------------------------\n",
      "loss: 0.118345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416341 \n",
      "\n",
      "Epoch 3715\n",
      "-------------------------------\n",
      "loss: 0.105249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415296 \n",
      "\n",
      "Epoch 3716\n",
      "-------------------------------\n",
      "loss: 0.110374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411991 \n",
      "\n",
      "Epoch 3717\n",
      "-------------------------------\n",
      "loss: 0.132181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415603 \n",
      "\n",
      "Epoch 3718\n",
      "-------------------------------\n",
      "loss: 0.111821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415090 \n",
      "\n",
      "Epoch 3719\n",
      "-------------------------------\n",
      "loss: 0.110943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412818 \n",
      "\n",
      "Epoch 3720\n",
      "-------------------------------\n",
      "loss: 0.116032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411077 \n",
      "\n",
      "Epoch 3721\n",
      "-------------------------------\n",
      "loss: 0.098347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410972 \n",
      "\n",
      "Epoch 3722\n",
      "-------------------------------\n",
      "loss: 0.105630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414473 \n",
      "\n",
      "Epoch 3723\n",
      "-------------------------------\n",
      "loss: 0.110651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420519 \n",
      "\n",
      "Epoch 3724\n",
      "-------------------------------\n",
      "loss: 0.100395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421138 \n",
      "\n",
      "Epoch 3725\n",
      "-------------------------------\n",
      "loss: 0.103119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415418 \n",
      "\n",
      "Epoch 3726\n",
      "-------------------------------\n",
      "loss: 0.108235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411605 \n",
      "\n",
      "Epoch 3727\n",
      "-------------------------------\n",
      "loss: 0.104672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413544 \n",
      "\n",
      "Epoch 3728\n",
      "-------------------------------\n",
      "loss: 0.104371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412950 \n",
      "\n",
      "Epoch 3729\n",
      "-------------------------------\n",
      "loss: 0.121919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413007 \n",
      "\n",
      "Epoch 3730\n",
      "-------------------------------\n",
      "loss: 0.102283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414761 \n",
      "\n",
      "Epoch 3731\n",
      "-------------------------------\n",
      "loss: 0.100830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420858 \n",
      "\n",
      "Epoch 3732\n",
      "-------------------------------\n",
      "loss: 0.115773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421684 \n",
      "\n",
      "Epoch 3733\n",
      "-------------------------------\n",
      "loss: 0.122770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420923 \n",
      "\n",
      "Epoch 3734\n",
      "-------------------------------\n",
      "loss: 0.101131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422542 \n",
      "\n",
      "Epoch 3735\n",
      "-------------------------------\n",
      "loss: 0.105729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422138 \n",
      "\n",
      "Epoch 3736\n",
      "-------------------------------\n",
      "loss: 0.105719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418809 \n",
      "\n",
      "Epoch 3737\n",
      "-------------------------------\n",
      "loss: 0.112899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415212 \n",
      "\n",
      "Epoch 3738\n",
      "-------------------------------\n",
      "loss: 0.110947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409916 \n",
      "\n",
      "Epoch 3739\n",
      "-------------------------------\n",
      "loss: 0.129523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410088 \n",
      "\n",
      "Epoch 3740\n",
      "-------------------------------\n",
      "loss: 0.118002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412884 \n",
      "\n",
      "Epoch 3741\n",
      "-------------------------------\n",
      "loss: 0.104559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414896 \n",
      "\n",
      "Epoch 3742\n",
      "-------------------------------\n",
      "loss: 0.099549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419168 \n",
      "\n",
      "Epoch 3743\n",
      "-------------------------------\n",
      "loss: 0.122434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421840 \n",
      "\n",
      "Epoch 3744\n",
      "-------------------------------\n",
      "loss: 0.112076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418831 \n",
      "\n",
      "Epoch 3745\n",
      "-------------------------------\n",
      "loss: 0.122527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413753 \n",
      "\n",
      "Epoch 3746\n",
      "-------------------------------\n",
      "loss: 0.117842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410539 \n",
      "\n",
      "Epoch 3747\n",
      "-------------------------------\n",
      "loss: 0.102310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410471 \n",
      "\n",
      "Epoch 3748\n",
      "-------------------------------\n",
      "loss: 0.113824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411349 \n",
      "\n",
      "Epoch 3749\n",
      "-------------------------------\n",
      "loss: 0.133372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410767 \n",
      "\n",
      "Epoch 3750\n",
      "-------------------------------\n",
      "loss: 0.108311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411997 \n",
      "\n",
      "Epoch 3751\n",
      "-------------------------------\n",
      "loss: 0.107757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415939 \n",
      "\n",
      "Epoch 3752\n",
      "-------------------------------\n",
      "loss: 0.117272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420284 \n",
      "\n",
      "Epoch 3753\n",
      "-------------------------------\n",
      "loss: 0.110136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423242 \n",
      "\n",
      "Epoch 3754\n",
      "-------------------------------\n",
      "loss: 0.118303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425928 \n",
      "\n",
      "Epoch 3755\n",
      "-------------------------------\n",
      "loss: 0.119219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432114 \n",
      "\n",
      "Epoch 3756\n",
      "-------------------------------\n",
      "loss: 0.112650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434803 \n",
      "\n",
      "Epoch 3757\n",
      "-------------------------------\n",
      "loss: 0.112860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434041 \n",
      "\n",
      "Epoch 3758\n",
      "-------------------------------\n",
      "loss: 0.117022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426517 \n",
      "\n",
      "Epoch 3759\n",
      "-------------------------------\n",
      "loss: 0.094734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414402 \n",
      "\n",
      "Epoch 3760\n",
      "-------------------------------\n",
      "loss: 0.109984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411189 \n",
      "\n",
      "Epoch 3761\n",
      "-------------------------------\n",
      "loss: 0.107076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414460 \n",
      "\n",
      "Epoch 3762\n",
      "-------------------------------\n",
      "loss: 0.098544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421643 \n",
      "\n",
      "Epoch 3763\n",
      "-------------------------------\n",
      "loss: 0.106838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428124 \n",
      "\n",
      "Epoch 3764\n",
      "-------------------------------\n",
      "loss: 0.105036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428140 \n",
      "\n",
      "Epoch 3765\n",
      "-------------------------------\n",
      "loss: 0.112653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423724 \n",
      "\n",
      "Epoch 3766\n",
      "-------------------------------\n",
      "loss: 0.104840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418475 \n",
      "\n",
      "Epoch 3767\n",
      "-------------------------------\n",
      "loss: 0.104918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417217 \n",
      "\n",
      "Epoch 3768\n",
      "-------------------------------\n",
      "loss: 0.096183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418054 \n",
      "\n",
      "Epoch 3769\n",
      "-------------------------------\n",
      "loss: 0.108476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416414 \n",
      "\n",
      "Epoch 3770\n",
      "-------------------------------\n",
      "loss: 0.112055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417499 \n",
      "\n",
      "Epoch 3771\n",
      "-------------------------------\n",
      "loss: 0.097880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423012 \n",
      "\n",
      "Epoch 3772\n",
      "-------------------------------\n",
      "loss: 0.107610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426530 \n",
      "\n",
      "Epoch 3773\n",
      "-------------------------------\n",
      "loss: 0.118217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423232 \n",
      "\n",
      "Epoch 3774\n",
      "-------------------------------\n",
      "loss: 0.119776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418297 \n",
      "\n",
      "Epoch 3775\n",
      "-------------------------------\n",
      "loss: 0.101542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420829 \n",
      "\n",
      "Epoch 3776\n",
      "-------------------------------\n",
      "loss: 0.105638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421872 \n",
      "\n",
      "Epoch 3777\n",
      "-------------------------------\n",
      "loss: 0.097560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421205 \n",
      "\n",
      "Epoch 3778\n",
      "-------------------------------\n",
      "loss: 0.113775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418546 \n",
      "\n",
      "Epoch 3779\n",
      "-------------------------------\n",
      "loss: 0.103501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420221 \n",
      "\n",
      "Epoch 3780\n",
      "-------------------------------\n",
      "loss: 0.111659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421783 \n",
      "\n",
      "Epoch 3781\n",
      "-------------------------------\n",
      "loss: 0.114079  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.417618 \n",
      "\n",
      "Epoch 3782\n",
      "-------------------------------\n",
      "loss: 0.099282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416122 \n",
      "\n",
      "Epoch 3783\n",
      "-------------------------------\n",
      "loss: 0.111279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412623 \n",
      "\n",
      "Epoch 3784\n",
      "-------------------------------\n",
      "loss: 0.105255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410345 \n",
      "\n",
      "Epoch 3785\n",
      "-------------------------------\n",
      "loss: 0.101759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409419 \n",
      "\n",
      "Epoch 3786\n",
      "-------------------------------\n",
      "loss: 0.129503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408600 \n",
      "\n",
      "Epoch 3787\n",
      "-------------------------------\n",
      "loss: 0.114226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410355 \n",
      "\n",
      "Epoch 3788\n",
      "-------------------------------\n",
      "loss: 0.104088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413920 \n",
      "\n",
      "Epoch 3789\n",
      "-------------------------------\n",
      "loss: 0.102370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415091 \n",
      "\n",
      "Epoch 3790\n",
      "-------------------------------\n",
      "loss: 0.113098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415216 \n",
      "\n",
      "Epoch 3791\n",
      "-------------------------------\n",
      "loss: 0.114387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414451 \n",
      "\n",
      "Epoch 3792\n",
      "-------------------------------\n",
      "loss: 0.109729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414243 \n",
      "\n",
      "Epoch 3793\n",
      "-------------------------------\n",
      "loss: 0.115127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413455 \n",
      "\n",
      "Epoch 3794\n",
      "-------------------------------\n",
      "loss: 0.103467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412440 \n",
      "\n",
      "Epoch 3795\n",
      "-------------------------------\n",
      "loss: 0.117734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412505 \n",
      "\n",
      "Epoch 3796\n",
      "-------------------------------\n",
      "loss: 0.118534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410885 \n",
      "\n",
      "Epoch 3797\n",
      "-------------------------------\n",
      "loss: 0.119756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408985 \n",
      "\n",
      "Epoch 3798\n",
      "-------------------------------\n",
      "loss: 0.139860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413481 \n",
      "\n",
      "Epoch 3799\n",
      "-------------------------------\n",
      "loss: 0.105394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420277 \n",
      "\n",
      "Epoch 3800\n",
      "-------------------------------\n",
      "loss: 0.113826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423355 \n",
      "\n",
      "Epoch 3801\n",
      "-------------------------------\n",
      "loss: 0.122900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420779 \n",
      "\n",
      "Epoch 3802\n",
      "-------------------------------\n",
      "loss: 0.121754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415069 \n",
      "\n",
      "Epoch 3803\n",
      "-------------------------------\n",
      "loss: 0.099180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410255 \n",
      "\n",
      "Epoch 3804\n",
      "-------------------------------\n",
      "loss: 0.094376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409930 \n",
      "\n",
      "Epoch 3805\n",
      "-------------------------------\n",
      "loss: 0.102539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414567 \n",
      "\n",
      "Epoch 3806\n",
      "-------------------------------\n",
      "loss: 0.110550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417422 \n",
      "\n",
      "Epoch 3807\n",
      "-------------------------------\n",
      "loss: 0.110357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412620 \n",
      "\n",
      "Epoch 3808\n",
      "-------------------------------\n",
      "loss: 0.120733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408966 \n",
      "\n",
      "Epoch 3809\n",
      "-------------------------------\n",
      "loss: 0.090962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410366 \n",
      "\n",
      "Epoch 3810\n",
      "-------------------------------\n",
      "loss: 0.105449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413218 \n",
      "\n",
      "Epoch 3811\n",
      "-------------------------------\n",
      "loss: 0.118616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414022 \n",
      "\n",
      "Epoch 3812\n",
      "-------------------------------\n",
      "loss: 0.136324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413178 \n",
      "\n",
      "Epoch 3813\n",
      "-------------------------------\n",
      "loss: 0.105596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415319 \n",
      "\n",
      "Epoch 3814\n",
      "-------------------------------\n",
      "loss: 0.107404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418814 \n",
      "\n",
      "Epoch 3815\n",
      "-------------------------------\n",
      "loss: 0.107181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419088 \n",
      "\n",
      "Epoch 3816\n",
      "-------------------------------\n",
      "loss: 0.113764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414949 \n",
      "\n",
      "Epoch 3817\n",
      "-------------------------------\n",
      "loss: 0.106431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410423 \n",
      "\n",
      "Epoch 3818\n",
      "-------------------------------\n",
      "loss: 0.108480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410687 \n",
      "\n",
      "Epoch 3819\n",
      "-------------------------------\n",
      "loss: 0.130787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413396 \n",
      "\n",
      "Epoch 3820\n",
      "-------------------------------\n",
      "loss: 0.122906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419590 \n",
      "\n",
      "Epoch 3821\n",
      "-------------------------------\n",
      "loss: 0.108867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420936 \n",
      "\n",
      "Epoch 3822\n",
      "-------------------------------\n",
      "loss: 0.121884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417970 \n",
      "\n",
      "Epoch 3823\n",
      "-------------------------------\n",
      "loss: 0.115854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412967 \n",
      "\n",
      "Epoch 3824\n",
      "-------------------------------\n",
      "loss: 0.108118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409852 \n",
      "\n",
      "Epoch 3825\n",
      "-------------------------------\n",
      "loss: 0.110972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409503 \n",
      "\n",
      "Epoch 3826\n",
      "-------------------------------\n",
      "loss: 0.107886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409820 \n",
      "\n",
      "Epoch 3827\n",
      "-------------------------------\n",
      "loss: 0.105166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414281 \n",
      "\n",
      "Epoch 3828\n",
      "-------------------------------\n",
      "loss: 0.111511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417783 \n",
      "\n",
      "Epoch 3829\n",
      "-------------------------------\n",
      "loss: 0.095760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419951 \n",
      "\n",
      "Epoch 3830\n",
      "-------------------------------\n",
      "loss: 0.105480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424134 \n",
      "\n",
      "Epoch 3831\n",
      "-------------------------------\n",
      "loss: 0.105379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423819 \n",
      "\n",
      "Epoch 3832\n",
      "-------------------------------\n",
      "loss: 0.113625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421037 \n",
      "\n",
      "Epoch 3833\n",
      "-------------------------------\n",
      "loss: 0.117305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415696 \n",
      "\n",
      "Epoch 3834\n",
      "-------------------------------\n",
      "loss: 0.099974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409425 \n",
      "\n",
      "Epoch 3835\n",
      "-------------------------------\n",
      "loss: 0.098789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407188 \n",
      "\n",
      "Epoch 3836\n",
      "-------------------------------\n",
      "loss: 0.099335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407547 \n",
      "\n",
      "Epoch 3837\n",
      "-------------------------------\n",
      "loss: 0.102053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407511 \n",
      "\n",
      "Epoch 3838\n",
      "-------------------------------\n",
      "loss: 0.105804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410094 \n",
      "\n",
      "Epoch 3839\n",
      "-------------------------------\n",
      "loss: 0.100248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412477 \n",
      "\n",
      "Epoch 3840\n",
      "-------------------------------\n",
      "loss: 0.114589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411404 \n",
      "\n",
      "Epoch 3841\n",
      "-------------------------------\n",
      "loss: 0.109297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413065 \n",
      "\n",
      "Epoch 3842\n",
      "-------------------------------\n",
      "loss: 0.100899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413901 \n",
      "\n",
      "Epoch 3843\n",
      "-------------------------------\n",
      "loss: 0.117491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415624 \n",
      "\n",
      "Epoch 3844\n",
      "-------------------------------\n",
      "loss: 0.130556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417277 \n",
      "\n",
      "Epoch 3845\n",
      "-------------------------------\n",
      "loss: 0.110364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421295 \n",
      "\n",
      "Epoch 3846\n",
      "-------------------------------\n",
      "loss: 0.100485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425208 \n",
      "\n",
      "Epoch 3847\n",
      "-------------------------------\n",
      "loss: 0.107166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424813 \n",
      "\n",
      "Epoch 3848\n",
      "-------------------------------\n",
      "loss: 0.103636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418512 \n",
      "\n",
      "Epoch 3849\n",
      "-------------------------------\n",
      "loss: 0.102196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411251 \n",
      "\n",
      "Epoch 3850\n",
      "-------------------------------\n",
      "loss: 0.101990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407769 \n",
      "\n",
      "Epoch 3851\n",
      "-------------------------------\n",
      "loss: 0.102315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408562 \n",
      "\n",
      "Epoch 3852\n",
      "-------------------------------\n",
      "loss: 0.122065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409160 \n",
      "\n",
      "Epoch 3853\n",
      "-------------------------------\n",
      "loss: 0.106173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415533 \n",
      "\n",
      "Epoch 3854\n",
      "-------------------------------\n",
      "loss: 0.097779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422034 \n",
      "\n",
      "Epoch 3855\n",
      "-------------------------------\n",
      "loss: 0.095456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425476 \n",
      "\n",
      "Epoch 3856\n",
      "-------------------------------\n",
      "loss: 0.108478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421200 \n",
      "\n",
      "Epoch 3857\n",
      "-------------------------------\n",
      "loss: 0.119025  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.412251 \n",
      "\n",
      "Epoch 3858\n",
      "-------------------------------\n",
      "loss: 0.111234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407393 \n",
      "\n",
      "Epoch 3859\n",
      "-------------------------------\n",
      "loss: 0.096164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407246 \n",
      "\n",
      "Epoch 3860\n",
      "-------------------------------\n",
      "loss: 0.101278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409744 \n",
      "\n",
      "Epoch 3861\n",
      "-------------------------------\n",
      "loss: 0.107766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408810 \n",
      "\n",
      "Epoch 3862\n",
      "-------------------------------\n",
      "loss: 0.115639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410960 \n",
      "\n",
      "Epoch 3863\n",
      "-------------------------------\n",
      "loss: 0.109350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416244 \n",
      "\n",
      "Epoch 3864\n",
      "-------------------------------\n",
      "loss: 0.112629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423532 \n",
      "\n",
      "Epoch 3865\n",
      "-------------------------------\n",
      "loss: 0.114746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428661 \n",
      "\n",
      "Epoch 3866\n",
      "-------------------------------\n",
      "loss: 0.113473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428186 \n",
      "\n",
      "Epoch 3867\n",
      "-------------------------------\n",
      "loss: 0.126817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424271 \n",
      "\n",
      "Epoch 3868\n",
      "-------------------------------\n",
      "loss: 0.108996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417871 \n",
      "\n",
      "Epoch 3869\n",
      "-------------------------------\n",
      "loss: 0.100074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411846 \n",
      "\n",
      "Epoch 3870\n",
      "-------------------------------\n",
      "loss: 0.105237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408001 \n",
      "\n",
      "Epoch 3871\n",
      "-------------------------------\n",
      "loss: 0.102406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406761 \n",
      "\n",
      "Epoch 3872\n",
      "-------------------------------\n",
      "loss: 0.110741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407991 \n",
      "\n",
      "Epoch 3873\n",
      "-------------------------------\n",
      "loss: 0.123144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413624 \n",
      "\n",
      "Epoch 3874\n",
      "-------------------------------\n",
      "loss: 0.120113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421358 \n",
      "\n",
      "Epoch 3875\n",
      "-------------------------------\n",
      "loss: 0.103132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428519 \n",
      "\n",
      "Epoch 3876\n",
      "-------------------------------\n",
      "loss: 0.107795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432224 \n",
      "\n",
      "Epoch 3877\n",
      "-------------------------------\n",
      "loss: 0.105779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432206 \n",
      "\n",
      "Epoch 3878\n",
      "-------------------------------\n",
      "loss: 0.107796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428348 \n",
      "\n",
      "Epoch 3879\n",
      "-------------------------------\n",
      "loss: 0.117080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421476 \n",
      "\n",
      "Epoch 3880\n",
      "-------------------------------\n",
      "loss: 0.103917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413773 \n",
      "\n",
      "Epoch 3881\n",
      "-------------------------------\n",
      "loss: 0.105882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409182 \n",
      "\n",
      "Epoch 3882\n",
      "-------------------------------\n",
      "loss: 0.095013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408491 \n",
      "\n",
      "Epoch 3883\n",
      "-------------------------------\n",
      "loss: 0.097467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407129 \n",
      "\n",
      "Epoch 3884\n",
      "-------------------------------\n",
      "loss: 0.117541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408323 \n",
      "\n",
      "Epoch 3885\n",
      "-------------------------------\n",
      "loss: 0.104440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412481 \n",
      "\n",
      "Epoch 3886\n",
      "-------------------------------\n",
      "loss: 0.096480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414742 \n",
      "\n",
      "Epoch 3887\n",
      "-------------------------------\n",
      "loss: 0.117474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416645 \n",
      "\n",
      "Epoch 3888\n",
      "-------------------------------\n",
      "loss: 0.101301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418681 \n",
      "\n",
      "Epoch 3889\n",
      "-------------------------------\n",
      "loss: 0.106034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421102 \n",
      "\n",
      "Epoch 3890\n",
      "-------------------------------\n",
      "loss: 0.103975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420156 \n",
      "\n",
      "Epoch 3891\n",
      "-------------------------------\n",
      "loss: 0.106498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415760 \n",
      "\n",
      "Epoch 3892\n",
      "-------------------------------\n",
      "loss: 0.125091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409279 \n",
      "\n",
      "Epoch 3893\n",
      "-------------------------------\n",
      "loss: 0.108695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410860 \n",
      "\n",
      "Epoch 3894\n",
      "-------------------------------\n",
      "loss: 0.110347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415872 \n",
      "\n",
      "Epoch 3895\n",
      "-------------------------------\n",
      "loss: 0.117239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415745 \n",
      "\n",
      "Epoch 3896\n",
      "-------------------------------\n",
      "loss: 0.103437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413630 \n",
      "\n",
      "Epoch 3897\n",
      "-------------------------------\n",
      "loss: 0.110827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410110 \n",
      "\n",
      "Epoch 3898\n",
      "-------------------------------\n",
      "loss: 0.108957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410550 \n",
      "\n",
      "Epoch 3899\n",
      "-------------------------------\n",
      "loss: 0.112106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415891 \n",
      "\n",
      "Epoch 3900\n",
      "-------------------------------\n",
      "loss: 0.101076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423780 \n",
      "\n",
      "Epoch 3901\n",
      "-------------------------------\n",
      "loss: 0.127731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429230 \n",
      "\n",
      "Epoch 3902\n",
      "-------------------------------\n",
      "loss: 0.098522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434763 \n",
      "\n",
      "Epoch 3903\n",
      "-------------------------------\n",
      "loss: 0.130709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432746 \n",
      "\n",
      "Epoch 3904\n",
      "-------------------------------\n",
      "loss: 0.116027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426716 \n",
      "\n",
      "Epoch 3905\n",
      "-------------------------------\n",
      "loss: 0.105013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417683 \n",
      "\n",
      "Epoch 3906\n",
      "-------------------------------\n",
      "loss: 0.114098  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411835 \n",
      "\n",
      "Epoch 3907\n",
      "-------------------------------\n",
      "loss: 0.105498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410523 \n",
      "\n",
      "Epoch 3908\n",
      "-------------------------------\n",
      "loss: 0.109107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412616 \n",
      "\n",
      "Epoch 3909\n",
      "-------------------------------\n",
      "loss: 0.110196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416010 \n",
      "\n",
      "Epoch 3910\n",
      "-------------------------------\n",
      "loss: 0.135531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417019 \n",
      "\n",
      "Epoch 3911\n",
      "-------------------------------\n",
      "loss: 0.100631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416433 \n",
      "\n",
      "Epoch 3912\n",
      "-------------------------------\n",
      "loss: 0.109252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417723 \n",
      "\n",
      "Epoch 3913\n",
      "-------------------------------\n",
      "loss: 0.099826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418688 \n",
      "\n",
      "Epoch 3914\n",
      "-------------------------------\n",
      "loss: 0.100598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417146 \n",
      "\n",
      "Epoch 3915\n",
      "-------------------------------\n",
      "loss: 0.100169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418397 \n",
      "\n",
      "Epoch 3916\n",
      "-------------------------------\n",
      "loss: 0.106112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420907 \n",
      "\n",
      "Epoch 3917\n",
      "-------------------------------\n",
      "loss: 0.112381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423671 \n",
      "\n",
      "Epoch 3918\n",
      "-------------------------------\n",
      "loss: 0.097056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428204 \n",
      "\n",
      "Epoch 3919\n",
      "-------------------------------\n",
      "loss: 0.116256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426159 \n",
      "\n",
      "Epoch 3920\n",
      "-------------------------------\n",
      "loss: 0.106261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413640 \n",
      "\n",
      "Epoch 3921\n",
      "-------------------------------\n",
      "loss: 0.115068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406995 \n",
      "\n",
      "Epoch 3922\n",
      "-------------------------------\n",
      "loss: 0.095525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410801 \n",
      "\n",
      "Epoch 3923\n",
      "-------------------------------\n",
      "loss: 0.091652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416097 \n",
      "\n",
      "Epoch 3924\n",
      "-------------------------------\n",
      "loss: 0.104135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420241 \n",
      "\n",
      "Epoch 3925\n",
      "-------------------------------\n",
      "loss: 0.101573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420223 \n",
      "\n",
      "Epoch 3926\n",
      "-------------------------------\n",
      "loss: 0.094668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416511 \n",
      "\n",
      "Epoch 3927\n",
      "-------------------------------\n",
      "loss: 0.105391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412043 \n",
      "\n",
      "Epoch 3928\n",
      "-------------------------------\n",
      "loss: 0.111773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407716 \n",
      "\n",
      "Epoch 3929\n",
      "-------------------------------\n",
      "loss: 0.102410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405936 \n",
      "\n",
      "Epoch 3930\n",
      "-------------------------------\n",
      "loss: 0.105659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408174 \n",
      "\n",
      "Epoch 3931\n",
      "-------------------------------\n",
      "loss: 0.098939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412151 \n",
      "\n",
      "Epoch 3932\n",
      "-------------------------------\n",
      "loss: 0.106027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414974 \n",
      "\n",
      "Epoch 3933\n",
      "-------------------------------\n",
      "loss: 0.109339  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.414707 \n",
      "\n",
      "Epoch 3934\n",
      "-------------------------------\n",
      "loss: 0.109928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413320 \n",
      "\n",
      "Epoch 3935\n",
      "-------------------------------\n",
      "loss: 0.108604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414836 \n",
      "\n",
      "Epoch 3936\n",
      "-------------------------------\n",
      "loss: 0.090270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417891 \n",
      "\n",
      "Epoch 3937\n",
      "-------------------------------\n",
      "loss: 0.112637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415511 \n",
      "\n",
      "Epoch 3938\n",
      "-------------------------------\n",
      "loss: 0.100001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415151 \n",
      "\n",
      "Epoch 3939\n",
      "-------------------------------\n",
      "loss: 0.115393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422549 \n",
      "\n",
      "Epoch 3940\n",
      "-------------------------------\n",
      "loss: 0.123380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.434041 \n",
      "\n",
      "Epoch 3941\n",
      "-------------------------------\n",
      "loss: 0.110738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436668 \n",
      "\n",
      "Epoch 3942\n",
      "-------------------------------\n",
      "loss: 0.119297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432227 \n",
      "\n",
      "Epoch 3943\n",
      "-------------------------------\n",
      "loss: 0.100886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424670 \n",
      "\n",
      "Epoch 3944\n",
      "-------------------------------\n",
      "loss: 0.099612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418298 \n",
      "\n",
      "Epoch 3945\n",
      "-------------------------------\n",
      "loss: 0.110468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412175 \n",
      "\n",
      "Epoch 3946\n",
      "-------------------------------\n",
      "loss: 0.108383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409225 \n",
      "\n",
      "Epoch 3947\n",
      "-------------------------------\n",
      "loss: 0.106767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409079 \n",
      "\n",
      "Epoch 3948\n",
      "-------------------------------\n",
      "loss: 0.107719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411204 \n",
      "\n",
      "Epoch 3949\n",
      "-------------------------------\n",
      "loss: 0.098106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415119 \n",
      "\n",
      "Epoch 3950\n",
      "-------------------------------\n",
      "loss: 0.099596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418049 \n",
      "\n",
      "Epoch 3951\n",
      "-------------------------------\n",
      "loss: 0.103024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418247 \n",
      "\n",
      "Epoch 3952\n",
      "-------------------------------\n",
      "loss: 0.102329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416544 \n",
      "\n",
      "Epoch 3953\n",
      "-------------------------------\n",
      "loss: 0.105088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413109 \n",
      "\n",
      "Epoch 3954\n",
      "-------------------------------\n",
      "loss: 0.107537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409049 \n",
      "\n",
      "Epoch 3955\n",
      "-------------------------------\n",
      "loss: 0.101236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410541 \n",
      "\n",
      "Epoch 3956\n",
      "-------------------------------\n",
      "loss: 0.105084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413976 \n",
      "\n",
      "Epoch 3957\n",
      "-------------------------------\n",
      "loss: 0.122099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415113 \n",
      "\n",
      "Epoch 3958\n",
      "-------------------------------\n",
      "loss: 0.119618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418174 \n",
      "\n",
      "Epoch 3959\n",
      "-------------------------------\n",
      "loss: 0.114301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423424 \n",
      "\n",
      "Epoch 3960\n",
      "-------------------------------\n",
      "loss: 0.122633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424101 \n",
      "\n",
      "Epoch 3961\n",
      "-------------------------------\n",
      "loss: 0.121751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418350 \n",
      "\n",
      "Epoch 3962\n",
      "-------------------------------\n",
      "loss: 0.117253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412276 \n",
      "\n",
      "Epoch 3963\n",
      "-------------------------------\n",
      "loss: 0.112982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407731 \n",
      "\n",
      "Epoch 3964\n",
      "-------------------------------\n",
      "loss: 0.112256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408113 \n",
      "\n",
      "Epoch 3965\n",
      "-------------------------------\n",
      "loss: 0.103299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411256 \n",
      "\n",
      "Epoch 3966\n",
      "-------------------------------\n",
      "loss: 0.109127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418309 \n",
      "\n",
      "Epoch 3967\n",
      "-------------------------------\n",
      "loss: 0.102617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423370 \n",
      "\n",
      "Epoch 3968\n",
      "-------------------------------\n",
      "loss: 0.115535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423210 \n",
      "\n",
      "Epoch 3969\n",
      "-------------------------------\n",
      "loss: 0.119536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421616 \n",
      "\n",
      "Epoch 3970\n",
      "-------------------------------\n",
      "loss: 0.120509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421230 \n",
      "\n",
      "Epoch 3971\n",
      "-------------------------------\n",
      "loss: 0.115113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418183 \n",
      "\n",
      "Epoch 3972\n",
      "-------------------------------\n",
      "loss: 0.118708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416189 \n",
      "\n",
      "Epoch 3973\n",
      "-------------------------------\n",
      "loss: 0.122240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414921 \n",
      "\n",
      "Epoch 3974\n",
      "-------------------------------\n",
      "loss: 0.114615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414953 \n",
      "\n",
      "Epoch 3975\n",
      "-------------------------------\n",
      "loss: 0.102298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417881 \n",
      "\n",
      "Epoch 3976\n",
      "-------------------------------\n",
      "loss: 0.111370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422013 \n",
      "\n",
      "Epoch 3977\n",
      "-------------------------------\n",
      "loss: 0.105687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424739 \n",
      "\n",
      "Epoch 3978\n",
      "-------------------------------\n",
      "loss: 0.115729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425314 \n",
      "\n",
      "Epoch 3979\n",
      "-------------------------------\n",
      "loss: 0.125861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427820 \n",
      "\n",
      "Epoch 3980\n",
      "-------------------------------\n",
      "loss: 0.118381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428975 \n",
      "\n",
      "Epoch 3981\n",
      "-------------------------------\n",
      "loss: 0.131437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426941 \n",
      "\n",
      "Epoch 3982\n",
      "-------------------------------\n",
      "loss: 0.118123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425085 \n",
      "\n",
      "Epoch 3983\n",
      "-------------------------------\n",
      "loss: 0.115880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422033 \n",
      "\n",
      "Epoch 3984\n",
      "-------------------------------\n",
      "loss: 0.135253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417887 \n",
      "\n",
      "Epoch 3985\n",
      "-------------------------------\n",
      "loss: 0.125695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413893 \n",
      "\n",
      "Epoch 3986\n",
      "-------------------------------\n",
      "loss: 0.126970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410789 \n",
      "\n",
      "Epoch 3987\n",
      "-------------------------------\n",
      "loss: 0.121419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411734 \n",
      "\n",
      "Epoch 3988\n",
      "-------------------------------\n",
      "loss: 0.130055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410262 \n",
      "\n",
      "Epoch 3989\n",
      "-------------------------------\n",
      "loss: 0.108678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409738 \n",
      "\n",
      "Epoch 3990\n",
      "-------------------------------\n",
      "loss: 0.116351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414369 \n",
      "\n",
      "Epoch 3991\n",
      "-------------------------------\n",
      "loss: 0.106217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419512 \n",
      "\n",
      "Epoch 3992\n",
      "-------------------------------\n",
      "loss: 0.120347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422611 \n",
      "\n",
      "Epoch 3993\n",
      "-------------------------------\n",
      "loss: 0.118515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423934 \n",
      "\n",
      "Epoch 3994\n",
      "-------------------------------\n",
      "loss: 0.110033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423182 \n",
      "\n",
      "Epoch 3995\n",
      "-------------------------------\n",
      "loss: 0.105592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421677 \n",
      "\n",
      "Epoch 3996\n",
      "-------------------------------\n",
      "loss: 0.119078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418350 \n",
      "\n",
      "Epoch 3997\n",
      "-------------------------------\n",
      "loss: 0.111263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416807 \n",
      "\n",
      "Epoch 3998\n",
      "-------------------------------\n",
      "loss: 0.102328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420194 \n",
      "\n",
      "Epoch 3999\n",
      "-------------------------------\n",
      "loss: 0.127356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422298 \n",
      "\n",
      "Epoch 4000\n",
      "-------------------------------\n",
      "loss: 0.094466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424698 \n",
      "\n",
      "Epoch 4001\n",
      "-------------------------------\n",
      "loss: 0.134539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423412 \n",
      "\n",
      "Epoch 4002\n",
      "-------------------------------\n",
      "loss: 0.098189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420783 \n",
      "\n",
      "Epoch 4003\n",
      "-------------------------------\n",
      "loss: 0.127556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415467 \n",
      "\n",
      "Epoch 4004\n",
      "-------------------------------\n",
      "loss: 0.116687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410416 \n",
      "\n",
      "Epoch 4005\n",
      "-------------------------------\n",
      "loss: 0.117348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412026 \n",
      "\n",
      "Epoch 4006\n",
      "-------------------------------\n",
      "loss: 0.112686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413304 \n",
      "\n",
      "Epoch 4007\n",
      "-------------------------------\n",
      "loss: 0.101622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417462 \n",
      "\n",
      "Epoch 4008\n",
      "-------------------------------\n",
      "loss: 0.116139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423517 \n",
      "\n",
      "Epoch 4009\n",
      "-------------------------------\n",
      "loss: 0.114044  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.424444 \n",
      "\n",
      "Epoch 4010\n",
      "-------------------------------\n",
      "loss: 0.110479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421772 \n",
      "\n",
      "Epoch 4011\n",
      "-------------------------------\n",
      "loss: 0.105771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414897 \n",
      "\n",
      "Epoch 4012\n",
      "-------------------------------\n",
      "loss: 0.103365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407958 \n",
      "\n",
      "Epoch 4013\n",
      "-------------------------------\n",
      "loss: 0.110878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408131 \n",
      "\n",
      "Epoch 4014\n",
      "-------------------------------\n",
      "loss: 0.111899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408988 \n",
      "\n",
      "Epoch 4015\n",
      "-------------------------------\n",
      "loss: 0.129627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408064 \n",
      "\n",
      "Epoch 4016\n",
      "-------------------------------\n",
      "loss: 0.110265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416644 \n",
      "\n",
      "Epoch 4017\n",
      "-------------------------------\n",
      "loss: 0.103970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427289 \n",
      "\n",
      "Epoch 4018\n",
      "-------------------------------\n",
      "loss: 0.122003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427697 \n",
      "\n",
      "Epoch 4019\n",
      "-------------------------------\n",
      "loss: 0.106627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423331 \n",
      "\n",
      "Epoch 4020\n",
      "-------------------------------\n",
      "loss: 0.111616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416743 \n",
      "\n",
      "Epoch 4021\n",
      "-------------------------------\n",
      "loss: 0.102271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416208 \n",
      "\n",
      "Epoch 4022\n",
      "-------------------------------\n",
      "loss: 0.110841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416390 \n",
      "\n",
      "Epoch 4023\n",
      "-------------------------------\n",
      "loss: 0.098691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416415 \n",
      "\n",
      "Epoch 4024\n",
      "-------------------------------\n",
      "loss: 0.107574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414517 \n",
      "\n",
      "Epoch 4025\n",
      "-------------------------------\n",
      "loss: 0.100854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414179 \n",
      "\n",
      "Epoch 4026\n",
      "-------------------------------\n",
      "loss: 0.103148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414078 \n",
      "\n",
      "Epoch 4027\n",
      "-------------------------------\n",
      "loss: 0.097699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413886 \n",
      "\n",
      "Epoch 4028\n",
      "-------------------------------\n",
      "loss: 0.104971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413509 \n",
      "\n",
      "Epoch 4029\n",
      "-------------------------------\n",
      "loss: 0.100295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412886 \n",
      "\n",
      "Epoch 4030\n",
      "-------------------------------\n",
      "loss: 0.094327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414050 \n",
      "\n",
      "Epoch 4031\n",
      "-------------------------------\n",
      "loss: 0.091932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420011 \n",
      "\n",
      "Epoch 4032\n",
      "-------------------------------\n",
      "loss: 0.095825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425817 \n",
      "\n",
      "Epoch 4033\n",
      "-------------------------------\n",
      "loss: 0.101298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425013 \n",
      "\n",
      "Epoch 4034\n",
      "-------------------------------\n",
      "loss: 0.100887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418382 \n",
      "\n",
      "Epoch 4035\n",
      "-------------------------------\n",
      "loss: 0.102028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414236 \n",
      "\n",
      "Epoch 4036\n",
      "-------------------------------\n",
      "loss: 0.099926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413048 \n",
      "\n",
      "Epoch 4037\n",
      "-------------------------------\n",
      "loss: 0.104221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409036 \n",
      "\n",
      "Epoch 4038\n",
      "-------------------------------\n",
      "loss: 0.104341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407713 \n",
      "\n",
      "Epoch 4039\n",
      "-------------------------------\n",
      "loss: 0.113099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411690 \n",
      "\n",
      "Epoch 4040\n",
      "-------------------------------\n",
      "loss: 0.116642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415269 \n",
      "\n",
      "Epoch 4041\n",
      "-------------------------------\n",
      "loss: 0.103280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415703 \n",
      "\n",
      "Epoch 4042\n",
      "-------------------------------\n",
      "loss: 0.100095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415518 \n",
      "\n",
      "Epoch 4043\n",
      "-------------------------------\n",
      "loss: 0.111300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417647 \n",
      "\n",
      "Epoch 4044\n",
      "-------------------------------\n",
      "loss: 0.104664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420615 \n",
      "\n",
      "Epoch 4045\n",
      "-------------------------------\n",
      "loss: 0.120870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419887 \n",
      "\n",
      "Epoch 4046\n",
      "-------------------------------\n",
      "loss: 0.108080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417490 \n",
      "\n",
      "Epoch 4047\n",
      "-------------------------------\n",
      "loss: 0.101047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415463 \n",
      "\n",
      "Epoch 4048\n",
      "-------------------------------\n",
      "loss: 0.093490  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416098 \n",
      "\n",
      "Epoch 4049\n",
      "-------------------------------\n",
      "loss: 0.105728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416955 \n",
      "\n",
      "Epoch 4050\n",
      "-------------------------------\n",
      "loss: 0.108327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414789 \n",
      "\n",
      "Epoch 4051\n",
      "-------------------------------\n",
      "loss: 0.114748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412414 \n",
      "\n",
      "Epoch 4052\n",
      "-------------------------------\n",
      "loss: 0.116187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413008 \n",
      "\n",
      "Epoch 4053\n",
      "-------------------------------\n",
      "loss: 0.128188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414563 \n",
      "\n",
      "Epoch 4054\n",
      "-------------------------------\n",
      "loss: 0.109625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416710 \n",
      "\n",
      "Epoch 4055\n",
      "-------------------------------\n",
      "loss: 0.098313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417862 \n",
      "\n",
      "Epoch 4056\n",
      "-------------------------------\n",
      "loss: 0.105228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418939 \n",
      "\n",
      "Epoch 4057\n",
      "-------------------------------\n",
      "loss: 0.103780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420625 \n",
      "\n",
      "Epoch 4058\n",
      "-------------------------------\n",
      "loss: 0.103167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421659 \n",
      "\n",
      "Epoch 4059\n",
      "-------------------------------\n",
      "loss: 0.128021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421000 \n",
      "\n",
      "Epoch 4060\n",
      "-------------------------------\n",
      "loss: 0.121626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419248 \n",
      "\n",
      "Epoch 4061\n",
      "-------------------------------\n",
      "loss: 0.097309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417029 \n",
      "\n",
      "Epoch 4062\n",
      "-------------------------------\n",
      "loss: 0.118462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413973 \n",
      "\n",
      "Epoch 4063\n",
      "-------------------------------\n",
      "loss: 0.102641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416487 \n",
      "\n",
      "Epoch 4064\n",
      "-------------------------------\n",
      "loss: 0.101915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420462 \n",
      "\n",
      "Epoch 4065\n",
      "-------------------------------\n",
      "loss: 0.126309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424404 \n",
      "\n",
      "Epoch 4066\n",
      "-------------------------------\n",
      "loss: 0.102667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425572 \n",
      "\n",
      "Epoch 4067\n",
      "-------------------------------\n",
      "loss: 0.108778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424071 \n",
      "\n",
      "Epoch 4068\n",
      "-------------------------------\n",
      "loss: 0.114459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419985 \n",
      "\n",
      "Epoch 4069\n",
      "-------------------------------\n",
      "loss: 0.109601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416084 \n",
      "\n",
      "Epoch 4070\n",
      "-------------------------------\n",
      "loss: 0.115292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417949 \n",
      "\n",
      "Epoch 4071\n",
      "-------------------------------\n",
      "loss: 0.107639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421023 \n",
      "\n",
      "Epoch 4072\n",
      "-------------------------------\n",
      "loss: 0.112748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426254 \n",
      "\n",
      "Epoch 4073\n",
      "-------------------------------\n",
      "loss: 0.101783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429116 \n",
      "\n",
      "Epoch 4074\n",
      "-------------------------------\n",
      "loss: 0.103964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428652 \n",
      "\n",
      "Epoch 4075\n",
      "-------------------------------\n",
      "loss: 0.114384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423303 \n",
      "\n",
      "Epoch 4076\n",
      "-------------------------------\n",
      "loss: 0.119931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417951 \n",
      "\n",
      "Epoch 4077\n",
      "-------------------------------\n",
      "loss: 0.095194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412867 \n",
      "\n",
      "Epoch 4078\n",
      "-------------------------------\n",
      "loss: 0.120284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410170 \n",
      "\n",
      "Epoch 4079\n",
      "-------------------------------\n",
      "loss: 0.100238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409770 \n",
      "\n",
      "Epoch 4080\n",
      "-------------------------------\n",
      "loss: 0.101359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410407 \n",
      "\n",
      "Epoch 4081\n",
      "-------------------------------\n",
      "loss: 0.103245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413270 \n",
      "\n",
      "Epoch 4082\n",
      "-------------------------------\n",
      "loss: 0.107755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413554 \n",
      "\n",
      "Epoch 4083\n",
      "-------------------------------\n",
      "loss: 0.098306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411128 \n",
      "\n",
      "Epoch 4084\n",
      "-------------------------------\n",
      "loss: 0.101888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409527 \n",
      "\n",
      "Epoch 4085\n",
      "-------------------------------\n",
      "loss: 0.094932  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.408249 \n",
      "\n",
      "Epoch 4086\n",
      "-------------------------------\n",
      "loss: 0.106765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408910 \n",
      "\n",
      "Epoch 4087\n",
      "-------------------------------\n",
      "loss: 0.111032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409667 \n",
      "\n",
      "Epoch 4088\n",
      "-------------------------------\n",
      "loss: 0.112529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415649 \n",
      "\n",
      "Epoch 4089\n",
      "-------------------------------\n",
      "loss: 0.097355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420786 \n",
      "\n",
      "Epoch 4090\n",
      "-------------------------------\n",
      "loss: 0.108937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418025 \n",
      "\n",
      "Epoch 4091\n",
      "-------------------------------\n",
      "loss: 0.090856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414199 \n",
      "\n",
      "Epoch 4092\n",
      "-------------------------------\n",
      "loss: 0.099926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411828 \n",
      "\n",
      "Epoch 4093\n",
      "-------------------------------\n",
      "loss: 0.106614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412230 \n",
      "\n",
      "Epoch 4094\n",
      "-------------------------------\n",
      "loss: 0.102011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410388 \n",
      "\n",
      "Epoch 4095\n",
      "-------------------------------\n",
      "loss: 0.100461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409497 \n",
      "\n",
      "Epoch 4096\n",
      "-------------------------------\n",
      "loss: 0.105926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410693 \n",
      "\n",
      "Epoch 4097\n",
      "-------------------------------\n",
      "loss: 0.106767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413343 \n",
      "\n",
      "Epoch 4098\n",
      "-------------------------------\n",
      "loss: 0.100715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414463 \n",
      "\n",
      "Epoch 4099\n",
      "-------------------------------\n",
      "loss: 0.101745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415263 \n",
      "\n",
      "Epoch 4100\n",
      "-------------------------------\n",
      "loss: 0.104314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418088 \n",
      "\n",
      "Epoch 4101\n",
      "-------------------------------\n",
      "loss: 0.101401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416287 \n",
      "\n",
      "Epoch 4102\n",
      "-------------------------------\n",
      "loss: 0.097063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413329 \n",
      "\n",
      "Epoch 4103\n",
      "-------------------------------\n",
      "loss: 0.104021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411645 \n",
      "\n",
      "Epoch 4104\n",
      "-------------------------------\n",
      "loss: 0.121713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409064 \n",
      "\n",
      "Epoch 4105\n",
      "-------------------------------\n",
      "loss: 0.091024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409055 \n",
      "\n",
      "Epoch 4106\n",
      "-------------------------------\n",
      "loss: 0.101944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409086 \n",
      "\n",
      "Epoch 4107\n",
      "-------------------------------\n",
      "loss: 0.100438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410368 \n",
      "\n",
      "Epoch 4108\n",
      "-------------------------------\n",
      "loss: 0.109146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412214 \n",
      "\n",
      "Epoch 4109\n",
      "-------------------------------\n",
      "loss: 0.098750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412066 \n",
      "\n",
      "Epoch 4110\n",
      "-------------------------------\n",
      "loss: 0.116035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415212 \n",
      "\n",
      "Epoch 4111\n",
      "-------------------------------\n",
      "loss: 0.089009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417820 \n",
      "\n",
      "Epoch 4112\n",
      "-------------------------------\n",
      "loss: 0.096168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420629 \n",
      "\n",
      "Epoch 4113\n",
      "-------------------------------\n",
      "loss: 0.104249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418514 \n",
      "\n",
      "Epoch 4114\n",
      "-------------------------------\n",
      "loss: 0.111620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416783 \n",
      "\n",
      "Epoch 4115\n",
      "-------------------------------\n",
      "loss: 0.096633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416637 \n",
      "\n",
      "Epoch 4116\n",
      "-------------------------------\n",
      "loss: 0.100348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414272 \n",
      "\n",
      "Epoch 4117\n",
      "-------------------------------\n",
      "loss: 0.105659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412318 \n",
      "\n",
      "Epoch 4118\n",
      "-------------------------------\n",
      "loss: 0.119371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409343 \n",
      "\n",
      "Epoch 4119\n",
      "-------------------------------\n",
      "loss: 0.108487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407709 \n",
      "\n",
      "Epoch 4120\n",
      "-------------------------------\n",
      "loss: 0.104066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410255 \n",
      "\n",
      "Epoch 4121\n",
      "-------------------------------\n",
      "loss: 0.102551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416894 \n",
      "\n",
      "Epoch 4122\n",
      "-------------------------------\n",
      "loss: 0.113149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420010 \n",
      "\n",
      "Epoch 4123\n",
      "-------------------------------\n",
      "loss: 0.112020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421201 \n",
      "\n",
      "Epoch 4124\n",
      "-------------------------------\n",
      "loss: 0.103768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418546 \n",
      "\n",
      "Epoch 4125\n",
      "-------------------------------\n",
      "loss: 0.097986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412995 \n",
      "\n",
      "Epoch 4126\n",
      "-------------------------------\n",
      "loss: 0.103213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408032 \n",
      "\n",
      "Epoch 4127\n",
      "-------------------------------\n",
      "loss: 0.104085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407248 \n",
      "\n",
      "Epoch 4128\n",
      "-------------------------------\n",
      "loss: 0.107530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415382 \n",
      "\n",
      "Epoch 4129\n",
      "-------------------------------\n",
      "loss: 0.101985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423156 \n",
      "\n",
      "Epoch 4130\n",
      "-------------------------------\n",
      "loss: 0.100160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426408 \n",
      "\n",
      "Epoch 4131\n",
      "-------------------------------\n",
      "loss: 0.106619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423114 \n",
      "\n",
      "Epoch 4132\n",
      "-------------------------------\n",
      "loss: 0.106308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415481 \n",
      "\n",
      "Epoch 4133\n",
      "-------------------------------\n",
      "loss: 0.101635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411901 \n",
      "\n",
      "Epoch 4134\n",
      "-------------------------------\n",
      "loss: 0.103221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409176 \n",
      "\n",
      "Epoch 4135\n",
      "-------------------------------\n",
      "loss: 0.100535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407332 \n",
      "\n",
      "Epoch 4136\n",
      "-------------------------------\n",
      "loss: 0.108294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405817 \n",
      "\n",
      "Epoch 4137\n",
      "-------------------------------\n",
      "loss: 0.108269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405251 \n",
      "\n",
      "Epoch 4138\n",
      "-------------------------------\n",
      "loss: 0.108234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407657 \n",
      "\n",
      "Epoch 4139\n",
      "-------------------------------\n",
      "loss: 0.098924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412895 \n",
      "\n",
      "Epoch 4140\n",
      "-------------------------------\n",
      "loss: 0.105607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419980 \n",
      "\n",
      "Epoch 4141\n",
      "-------------------------------\n",
      "loss: 0.115252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421283 \n",
      "\n",
      "Epoch 4142\n",
      "-------------------------------\n",
      "loss: 0.116404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416798 \n",
      "\n",
      "Epoch 4143\n",
      "-------------------------------\n",
      "loss: 0.105337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411157 \n",
      "\n",
      "Epoch 4144\n",
      "-------------------------------\n",
      "loss: 0.099530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410430 \n",
      "\n",
      "Epoch 4145\n",
      "-------------------------------\n",
      "loss: 0.102955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411359 \n",
      "\n",
      "Epoch 4146\n",
      "-------------------------------\n",
      "loss: 0.104819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413166 \n",
      "\n",
      "Epoch 4147\n",
      "-------------------------------\n",
      "loss: 0.098292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413043 \n",
      "\n",
      "Epoch 4148\n",
      "-------------------------------\n",
      "loss: 0.110184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413022 \n",
      "\n",
      "Epoch 4149\n",
      "-------------------------------\n",
      "loss: 0.114234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415051 \n",
      "\n",
      "Epoch 4150\n",
      "-------------------------------\n",
      "loss: 0.103383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421342 \n",
      "\n",
      "Epoch 4151\n",
      "-------------------------------\n",
      "loss: 0.095254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429453 \n",
      "\n",
      "Epoch 4152\n",
      "-------------------------------\n",
      "loss: 0.103006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433813 \n",
      "\n",
      "Epoch 4153\n",
      "-------------------------------\n",
      "loss: 0.107762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430268 \n",
      "\n",
      "Epoch 4154\n",
      "-------------------------------\n",
      "loss: 0.103810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421132 \n",
      "\n",
      "Epoch 4155\n",
      "-------------------------------\n",
      "loss: 0.103581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414313 \n",
      "\n",
      "Epoch 4156\n",
      "-------------------------------\n",
      "loss: 0.105331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407927 \n",
      "\n",
      "Epoch 4157\n",
      "-------------------------------\n",
      "loss: 0.115711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404558 \n",
      "\n",
      "Epoch 4158\n",
      "-------------------------------\n",
      "loss: 0.097998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410888 \n",
      "\n",
      "Epoch 4159\n",
      "-------------------------------\n",
      "loss: 0.107453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419447 \n",
      "\n",
      "Epoch 4160\n",
      "-------------------------------\n",
      "loss: 0.101824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422849 \n",
      "\n",
      "Epoch 4161\n",
      "-------------------------------\n",
      "loss: 0.110708  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.426101 \n",
      "\n",
      "Epoch 4162\n",
      "-------------------------------\n",
      "loss: 0.100718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427190 \n",
      "\n",
      "Epoch 4163\n",
      "-------------------------------\n",
      "loss: 0.108332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424662 \n",
      "\n",
      "Epoch 4164\n",
      "-------------------------------\n",
      "loss: 0.123068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421844 \n",
      "\n",
      "Epoch 4165\n",
      "-------------------------------\n",
      "loss: 0.107748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419526 \n",
      "\n",
      "Epoch 4166\n",
      "-------------------------------\n",
      "loss: 0.096928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415604 \n",
      "\n",
      "Epoch 4167\n",
      "-------------------------------\n",
      "loss: 0.108135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411695 \n",
      "\n",
      "Epoch 4168\n",
      "-------------------------------\n",
      "loss: 0.101969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410577 \n",
      "\n",
      "Epoch 4169\n",
      "-------------------------------\n",
      "loss: 0.104671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409467 \n",
      "\n",
      "Epoch 4170\n",
      "-------------------------------\n",
      "loss: 0.094974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409089 \n",
      "\n",
      "Epoch 4171\n",
      "-------------------------------\n",
      "loss: 0.098203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412672 \n",
      "\n",
      "Epoch 4172\n",
      "-------------------------------\n",
      "loss: 0.097561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416468 \n",
      "\n",
      "Epoch 4173\n",
      "-------------------------------\n",
      "loss: 0.102472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416603 \n",
      "\n",
      "Epoch 4174\n",
      "-------------------------------\n",
      "loss: 0.100383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417014 \n",
      "\n",
      "Epoch 4175\n",
      "-------------------------------\n",
      "loss: 0.099216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414461 \n",
      "\n",
      "Epoch 4176\n",
      "-------------------------------\n",
      "loss: 0.102291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410720 \n",
      "\n",
      "Epoch 4177\n",
      "-------------------------------\n",
      "loss: 0.098055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409734 \n",
      "\n",
      "Epoch 4178\n",
      "-------------------------------\n",
      "loss: 0.099163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409933 \n",
      "\n",
      "Epoch 4179\n",
      "-------------------------------\n",
      "loss: 0.106050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410932 \n",
      "\n",
      "Epoch 4180\n",
      "-------------------------------\n",
      "loss: 0.105030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414249 \n",
      "\n",
      "Epoch 4181\n",
      "-------------------------------\n",
      "loss: 0.103916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418908 \n",
      "\n",
      "Epoch 4182\n",
      "-------------------------------\n",
      "loss: 0.101197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417224 \n",
      "\n",
      "Epoch 4183\n",
      "-------------------------------\n",
      "loss: 0.109066  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412322 \n",
      "\n",
      "Epoch 4184\n",
      "-------------------------------\n",
      "loss: 0.093321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407258 \n",
      "\n",
      "Epoch 4185\n",
      "-------------------------------\n",
      "loss: 0.102108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405593 \n",
      "\n",
      "Epoch 4186\n",
      "-------------------------------\n",
      "loss: 0.102641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407141 \n",
      "\n",
      "Epoch 4187\n",
      "-------------------------------\n",
      "loss: 0.111135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410455 \n",
      "\n",
      "Epoch 4188\n",
      "-------------------------------\n",
      "loss: 0.114682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414486 \n",
      "\n",
      "Epoch 4189\n",
      "-------------------------------\n",
      "loss: 0.111349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418756 \n",
      "\n",
      "Epoch 4190\n",
      "-------------------------------\n",
      "loss: 0.090645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419363 \n",
      "\n",
      "Epoch 4191\n",
      "-------------------------------\n",
      "loss: 0.118439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415472 \n",
      "\n",
      "Epoch 4192\n",
      "-------------------------------\n",
      "loss: 0.098916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412899 \n",
      "\n",
      "Epoch 4193\n",
      "-------------------------------\n",
      "loss: 0.102027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412334 \n",
      "\n",
      "Epoch 4194\n",
      "-------------------------------\n",
      "loss: 0.102818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412338 \n",
      "\n",
      "Epoch 4195\n",
      "-------------------------------\n",
      "loss: 0.097382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412909 \n",
      "\n",
      "Epoch 4196\n",
      "-------------------------------\n",
      "loss: 0.095467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415313 \n",
      "\n",
      "Epoch 4197\n",
      "-------------------------------\n",
      "loss: 0.112153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416640 \n",
      "\n",
      "Epoch 4198\n",
      "-------------------------------\n",
      "loss: 0.103573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417815 \n",
      "\n",
      "Epoch 4199\n",
      "-------------------------------\n",
      "loss: 0.098910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417530 \n",
      "\n",
      "Epoch 4200\n",
      "-------------------------------\n",
      "loss: 0.100757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416650 \n",
      "\n",
      "Epoch 4201\n",
      "-------------------------------\n",
      "loss: 0.105116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414948 \n",
      "\n",
      "Epoch 4202\n",
      "-------------------------------\n",
      "loss: 0.105670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411531 \n",
      "\n",
      "Epoch 4203\n",
      "-------------------------------\n",
      "loss: 0.118995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410480 \n",
      "\n",
      "Epoch 4204\n",
      "-------------------------------\n",
      "loss: 0.097455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411025 \n",
      "\n",
      "Epoch 4205\n",
      "-------------------------------\n",
      "loss: 0.096518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412200 \n",
      "\n",
      "Epoch 4206\n",
      "-------------------------------\n",
      "loss: 0.092619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413253 \n",
      "\n",
      "Epoch 4207\n",
      "-------------------------------\n",
      "loss: 0.096338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411390 \n",
      "\n",
      "Epoch 4208\n",
      "-------------------------------\n",
      "loss: 0.091071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409375 \n",
      "\n",
      "Epoch 4209\n",
      "-------------------------------\n",
      "loss: 0.092556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408550 \n",
      "\n",
      "Epoch 4210\n",
      "-------------------------------\n",
      "loss: 0.099665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407558 \n",
      "\n",
      "Epoch 4211\n",
      "-------------------------------\n",
      "loss: 0.095755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407776 \n",
      "\n",
      "Epoch 4212\n",
      "-------------------------------\n",
      "loss: 0.101966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409469 \n",
      "\n",
      "Epoch 4213\n",
      "-------------------------------\n",
      "loss: 0.121519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411651 \n",
      "\n",
      "Epoch 4214\n",
      "-------------------------------\n",
      "loss: 0.101029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414668 \n",
      "\n",
      "Epoch 4215\n",
      "-------------------------------\n",
      "loss: 0.109777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415638 \n",
      "\n",
      "Epoch 4216\n",
      "-------------------------------\n",
      "loss: 0.102522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415908 \n",
      "\n",
      "Epoch 4217\n",
      "-------------------------------\n",
      "loss: 0.107337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417801 \n",
      "\n",
      "Epoch 4218\n",
      "-------------------------------\n",
      "loss: 0.111126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419356 \n",
      "\n",
      "Epoch 4219\n",
      "-------------------------------\n",
      "loss: 0.105190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419453 \n",
      "\n",
      "Epoch 4220\n",
      "-------------------------------\n",
      "loss: 0.099668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415764 \n",
      "\n",
      "Epoch 4221\n",
      "-------------------------------\n",
      "loss: 0.098190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412298 \n",
      "\n",
      "Epoch 4222\n",
      "-------------------------------\n",
      "loss: 0.099075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410907 \n",
      "\n",
      "Epoch 4223\n",
      "-------------------------------\n",
      "loss: 0.096218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410666 \n",
      "\n",
      "Epoch 4224\n",
      "-------------------------------\n",
      "loss: 0.135241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408899 \n",
      "\n",
      "Epoch 4225\n",
      "-------------------------------\n",
      "loss: 0.101030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405674 \n",
      "\n",
      "Epoch 4226\n",
      "-------------------------------\n",
      "loss: 0.091375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404248 \n",
      "\n",
      "Epoch 4227\n",
      "-------------------------------\n",
      "loss: 0.096133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408166 \n",
      "\n",
      "Epoch 4228\n",
      "-------------------------------\n",
      "loss: 0.100991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411888 \n",
      "\n",
      "Epoch 4229\n",
      "-------------------------------\n",
      "loss: 0.100783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414579 \n",
      "\n",
      "Epoch 4230\n",
      "-------------------------------\n",
      "loss: 0.091629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416794 \n",
      "\n",
      "Epoch 4231\n",
      "-------------------------------\n",
      "loss: 0.106837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420137 \n",
      "\n",
      "Epoch 4232\n",
      "-------------------------------\n",
      "loss: 0.098234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418720 \n",
      "\n",
      "Epoch 4233\n",
      "-------------------------------\n",
      "loss: 0.105363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416897 \n",
      "\n",
      "Epoch 4234\n",
      "-------------------------------\n",
      "loss: 0.111934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413541 \n",
      "\n",
      "Epoch 4235\n",
      "-------------------------------\n",
      "loss: 0.107870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411684 \n",
      "\n",
      "Epoch 4236\n",
      "-------------------------------\n",
      "loss: 0.094329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410996 \n",
      "\n",
      "Epoch 4237\n",
      "-------------------------------\n",
      "loss: 0.102102  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.411638 \n",
      "\n",
      "Epoch 4238\n",
      "-------------------------------\n",
      "loss: 0.106757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413351 \n",
      "\n",
      "Epoch 4239\n",
      "-------------------------------\n",
      "loss: 0.101798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414650 \n",
      "\n",
      "Epoch 4240\n",
      "-------------------------------\n",
      "loss: 0.097626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414094 \n",
      "\n",
      "Epoch 4241\n",
      "-------------------------------\n",
      "loss: 0.098767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414460 \n",
      "\n",
      "Epoch 4242\n",
      "-------------------------------\n",
      "loss: 0.106388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411818 \n",
      "\n",
      "Epoch 4243\n",
      "-------------------------------\n",
      "loss: 0.098020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408241 \n",
      "\n",
      "Epoch 4244\n",
      "-------------------------------\n",
      "loss: 0.107782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405868 \n",
      "\n",
      "Epoch 4245\n",
      "-------------------------------\n",
      "loss: 0.101069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405045 \n",
      "\n",
      "Epoch 4246\n",
      "-------------------------------\n",
      "loss: 0.101268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407762 \n",
      "\n",
      "Epoch 4247\n",
      "-------------------------------\n",
      "loss: 0.107687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412258 \n",
      "\n",
      "Epoch 4248\n",
      "-------------------------------\n",
      "loss: 0.113722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418012 \n",
      "\n",
      "Epoch 4249\n",
      "-------------------------------\n",
      "loss: 0.107921  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421364 \n",
      "\n",
      "Epoch 4250\n",
      "-------------------------------\n",
      "loss: 0.116165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418890 \n",
      "\n",
      "Epoch 4251\n",
      "-------------------------------\n",
      "loss: 0.131141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416862 \n",
      "\n",
      "Epoch 4252\n",
      "-------------------------------\n",
      "loss: 0.097839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412643 \n",
      "\n",
      "Epoch 4253\n",
      "-------------------------------\n",
      "loss: 0.110674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410201 \n",
      "\n",
      "Epoch 4254\n",
      "-------------------------------\n",
      "loss: 0.097773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408993 \n",
      "\n",
      "Epoch 4255\n",
      "-------------------------------\n",
      "loss: 0.098797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408206 \n",
      "\n",
      "Epoch 4256\n",
      "-------------------------------\n",
      "loss: 0.114302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407847 \n",
      "\n",
      "Epoch 4257\n",
      "-------------------------------\n",
      "loss: 0.103843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410143 \n",
      "\n",
      "Epoch 4258\n",
      "-------------------------------\n",
      "loss: 0.106724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414958 \n",
      "\n",
      "Epoch 4259\n",
      "-------------------------------\n",
      "loss: 0.110988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419951 \n",
      "\n",
      "Epoch 4260\n",
      "-------------------------------\n",
      "loss: 0.112054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421858 \n",
      "\n",
      "Epoch 4261\n",
      "-------------------------------\n",
      "loss: 0.106189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423071 \n",
      "\n",
      "Epoch 4262\n",
      "-------------------------------\n",
      "loss: 0.101039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425717 \n",
      "\n",
      "Epoch 4263\n",
      "-------------------------------\n",
      "loss: 0.119920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421550 \n",
      "\n",
      "Epoch 4264\n",
      "-------------------------------\n",
      "loss: 0.108772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412784 \n",
      "\n",
      "Epoch 4265\n",
      "-------------------------------\n",
      "loss: 0.106950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408899 \n",
      "\n",
      "Epoch 4266\n",
      "-------------------------------\n",
      "loss: 0.097462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409228 \n",
      "\n",
      "Epoch 4267\n",
      "-------------------------------\n",
      "loss: 0.107596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416601 \n",
      "\n",
      "Epoch 4268\n",
      "-------------------------------\n",
      "loss: 0.107781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420897 \n",
      "\n",
      "Epoch 4269\n",
      "-------------------------------\n",
      "loss: 0.095582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418076 \n",
      "\n",
      "Epoch 4270\n",
      "-------------------------------\n",
      "loss: 0.115302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412302 \n",
      "\n",
      "Epoch 4271\n",
      "-------------------------------\n",
      "loss: 0.098161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409401 \n",
      "\n",
      "Epoch 4272\n",
      "-------------------------------\n",
      "loss: 0.124147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409584 \n",
      "\n",
      "Epoch 4273\n",
      "-------------------------------\n",
      "loss: 0.111848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411427 \n",
      "\n",
      "Epoch 4274\n",
      "-------------------------------\n",
      "loss: 0.111581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415149 \n",
      "\n",
      "Epoch 4275\n",
      "-------------------------------\n",
      "loss: 0.100739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416893 \n",
      "\n",
      "Epoch 4276\n",
      "-------------------------------\n",
      "loss: 0.103883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417826 \n",
      "\n",
      "Epoch 4277\n",
      "-------------------------------\n",
      "loss: 0.107087  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414785 \n",
      "\n",
      "Epoch 4278\n",
      "-------------------------------\n",
      "loss: 0.114864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414128 \n",
      "\n",
      "Epoch 4279\n",
      "-------------------------------\n",
      "loss: 0.108198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414485 \n",
      "\n",
      "Epoch 4280\n",
      "-------------------------------\n",
      "loss: 0.098102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412807 \n",
      "\n",
      "Epoch 4281\n",
      "-------------------------------\n",
      "loss: 0.109226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409297 \n",
      "\n",
      "Epoch 4282\n",
      "-------------------------------\n",
      "loss: 0.110996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408004 \n",
      "\n",
      "Epoch 4283\n",
      "-------------------------------\n",
      "loss: 0.106072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410247 \n",
      "\n",
      "Epoch 4284\n",
      "-------------------------------\n",
      "loss: 0.106641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413994 \n",
      "\n",
      "Epoch 4285\n",
      "-------------------------------\n",
      "loss: 0.114286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415689 \n",
      "\n",
      "Epoch 4286\n",
      "-------------------------------\n",
      "loss: 0.103176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416898 \n",
      "\n",
      "Epoch 4287\n",
      "-------------------------------\n",
      "loss: 0.096483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416118 \n",
      "\n",
      "Epoch 4288\n",
      "-------------------------------\n",
      "loss: 0.106552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415163 \n",
      "\n",
      "Epoch 4289\n",
      "-------------------------------\n",
      "loss: 0.109760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410908 \n",
      "\n",
      "Epoch 4290\n",
      "-------------------------------\n",
      "loss: 0.118258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406838 \n",
      "\n",
      "Epoch 4291\n",
      "-------------------------------\n",
      "loss: 0.100682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404647 \n",
      "\n",
      "Epoch 4292\n",
      "-------------------------------\n",
      "loss: 0.105103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406661 \n",
      "\n",
      "Epoch 4293\n",
      "-------------------------------\n",
      "loss: 0.106431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409199 \n",
      "\n",
      "Epoch 4294\n",
      "-------------------------------\n",
      "loss: 0.113265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411245 \n",
      "\n",
      "Epoch 4295\n",
      "-------------------------------\n",
      "loss: 0.098463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418124 \n",
      "\n",
      "Epoch 4296\n",
      "-------------------------------\n",
      "loss: 0.102487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424042 \n",
      "\n",
      "Epoch 4297\n",
      "-------------------------------\n",
      "loss: 0.114866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425425 \n",
      "\n",
      "Epoch 4298\n",
      "-------------------------------\n",
      "loss: 0.115992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421209 \n",
      "\n",
      "Epoch 4299\n",
      "-------------------------------\n",
      "loss: 0.102832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417725 \n",
      "\n",
      "Epoch 4300\n",
      "-------------------------------\n",
      "loss: 0.117391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413903 \n",
      "\n",
      "Epoch 4301\n",
      "-------------------------------\n",
      "loss: 0.101749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411018 \n",
      "\n",
      "Epoch 4302\n",
      "-------------------------------\n",
      "loss: 0.095164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409461 \n",
      "\n",
      "Epoch 4303\n",
      "-------------------------------\n",
      "loss: 0.103224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409565 \n",
      "\n",
      "Epoch 4304\n",
      "-------------------------------\n",
      "loss: 0.119176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412061 \n",
      "\n",
      "Epoch 4305\n",
      "-------------------------------\n",
      "loss: 0.114891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414986 \n",
      "\n",
      "Epoch 4306\n",
      "-------------------------------\n",
      "loss: 0.108518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416094 \n",
      "\n",
      "Epoch 4307\n",
      "-------------------------------\n",
      "loss: 0.132694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416713 \n",
      "\n",
      "Epoch 4308\n",
      "-------------------------------\n",
      "loss: 0.110562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417468 \n",
      "\n",
      "Epoch 4309\n",
      "-------------------------------\n",
      "loss: 0.101342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418078 \n",
      "\n",
      "Epoch 4310\n",
      "-------------------------------\n",
      "loss: 0.110673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419392 \n",
      "\n",
      "Epoch 4311\n",
      "-------------------------------\n",
      "loss: 0.114322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422109 \n",
      "\n",
      "Epoch 4312\n",
      "-------------------------------\n",
      "loss: 0.109795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419203 \n",
      "\n",
      "Epoch 4313\n",
      "-------------------------------\n",
      "loss: 0.107959  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.418755 \n",
      "\n",
      "Epoch 4314\n",
      "-------------------------------\n",
      "loss: 0.116234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419469 \n",
      "\n",
      "Epoch 4315\n",
      "-------------------------------\n",
      "loss: 0.103203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420806 \n",
      "\n",
      "Epoch 4316\n",
      "-------------------------------\n",
      "loss: 0.103491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420003 \n",
      "\n",
      "Epoch 4317\n",
      "-------------------------------\n",
      "loss: 0.107488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418247 \n",
      "\n",
      "Epoch 4318\n",
      "-------------------------------\n",
      "loss: 0.108287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416617 \n",
      "\n",
      "Epoch 4319\n",
      "-------------------------------\n",
      "loss: 0.109421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413763 \n",
      "\n",
      "Epoch 4320\n",
      "-------------------------------\n",
      "loss: 0.106761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409890 \n",
      "\n",
      "Epoch 4321\n",
      "-------------------------------\n",
      "loss: 0.118258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406948 \n",
      "\n",
      "Epoch 4322\n",
      "-------------------------------\n",
      "loss: 0.105619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406773 \n",
      "\n",
      "Epoch 4323\n",
      "-------------------------------\n",
      "loss: 0.106404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408592 \n",
      "\n",
      "Epoch 4324\n",
      "-------------------------------\n",
      "loss: 0.086637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412219 \n",
      "\n",
      "Epoch 4325\n",
      "-------------------------------\n",
      "loss: 0.094626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417649 \n",
      "\n",
      "Epoch 4326\n",
      "-------------------------------\n",
      "loss: 0.096858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420416 \n",
      "\n",
      "Epoch 4327\n",
      "-------------------------------\n",
      "loss: 0.106022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420653 \n",
      "\n",
      "Epoch 4328\n",
      "-------------------------------\n",
      "loss: 0.104242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417595 \n",
      "\n",
      "Epoch 4329\n",
      "-------------------------------\n",
      "loss: 0.109718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416326 \n",
      "\n",
      "Epoch 4330\n",
      "-------------------------------\n",
      "loss: 0.100783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416514 \n",
      "\n",
      "Epoch 4331\n",
      "-------------------------------\n",
      "loss: 0.106605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413897 \n",
      "\n",
      "Epoch 4332\n",
      "-------------------------------\n",
      "loss: 0.095786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412399 \n",
      "\n",
      "Epoch 4333\n",
      "-------------------------------\n",
      "loss: 0.102967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409055 \n",
      "\n",
      "Epoch 4334\n",
      "-------------------------------\n",
      "loss: 0.096344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407390 \n",
      "\n",
      "Epoch 4335\n",
      "-------------------------------\n",
      "loss: 0.098276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408884 \n",
      "\n",
      "Epoch 4336\n",
      "-------------------------------\n",
      "loss: 0.091198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408549 \n",
      "\n",
      "Epoch 4337\n",
      "-------------------------------\n",
      "loss: 0.096555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408496 \n",
      "\n",
      "Epoch 4338\n",
      "-------------------------------\n",
      "loss: 0.088982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408751 \n",
      "\n",
      "Epoch 4339\n",
      "-------------------------------\n",
      "loss: 0.101031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406168 \n",
      "\n",
      "Epoch 4340\n",
      "-------------------------------\n",
      "loss: 0.121524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406992 \n",
      "\n",
      "Epoch 4341\n",
      "-------------------------------\n",
      "loss: 0.108281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410266 \n",
      "\n",
      "Epoch 4342\n",
      "-------------------------------\n",
      "loss: 0.116240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411325 \n",
      "\n",
      "Epoch 4343\n",
      "-------------------------------\n",
      "loss: 0.094761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410856 \n",
      "\n",
      "Epoch 4344\n",
      "-------------------------------\n",
      "loss: 0.100477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412912 \n",
      "\n",
      "Epoch 4345\n",
      "-------------------------------\n",
      "loss: 0.105300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413043 \n",
      "\n",
      "Epoch 4346\n",
      "-------------------------------\n",
      "loss: 0.114754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410648 \n",
      "\n",
      "Epoch 4347\n",
      "-------------------------------\n",
      "loss: 0.114653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408623 \n",
      "\n",
      "Epoch 4348\n",
      "-------------------------------\n",
      "loss: 0.092052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409189 \n",
      "\n",
      "Epoch 4349\n",
      "-------------------------------\n",
      "loss: 0.109876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410644 \n",
      "\n",
      "Epoch 4350\n",
      "-------------------------------\n",
      "loss: 0.108062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410470 \n",
      "\n",
      "Epoch 4351\n",
      "-------------------------------\n",
      "loss: 0.108863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410784 \n",
      "\n",
      "Epoch 4352\n",
      "-------------------------------\n",
      "loss: 0.092707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410607 \n",
      "\n",
      "Epoch 4353\n",
      "-------------------------------\n",
      "loss: 0.096422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409382 \n",
      "\n",
      "Epoch 4354\n",
      "-------------------------------\n",
      "loss: 0.110781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404593 \n",
      "\n",
      "Epoch 4355\n",
      "-------------------------------\n",
      "loss: 0.098086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402464 \n",
      "\n",
      "Epoch 4356\n",
      "-------------------------------\n",
      "loss: 0.103194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404523 \n",
      "\n",
      "Epoch 4357\n",
      "-------------------------------\n",
      "loss: 0.107334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409121 \n",
      "\n",
      "Epoch 4358\n",
      "-------------------------------\n",
      "loss: 0.102394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413914 \n",
      "\n",
      "Epoch 4359\n",
      "-------------------------------\n",
      "loss: 0.104128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419715 \n",
      "\n",
      "Epoch 4360\n",
      "-------------------------------\n",
      "loss: 0.099305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422954 \n",
      "\n",
      "Epoch 4361\n",
      "-------------------------------\n",
      "loss: 0.109268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427906 \n",
      "\n",
      "Epoch 4362\n",
      "-------------------------------\n",
      "loss: 0.102463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426986 \n",
      "\n",
      "Epoch 4363\n",
      "-------------------------------\n",
      "loss: 0.105792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422278 \n",
      "\n",
      "Epoch 4364\n",
      "-------------------------------\n",
      "loss: 0.112699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416617 \n",
      "\n",
      "Epoch 4365\n",
      "-------------------------------\n",
      "loss: 0.098924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413808 \n",
      "\n",
      "Epoch 4366\n",
      "-------------------------------\n",
      "loss: 0.102833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412855 \n",
      "\n",
      "Epoch 4367\n",
      "-------------------------------\n",
      "loss: 0.103077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411373 \n",
      "\n",
      "Epoch 4368\n",
      "-------------------------------\n",
      "loss: 0.095074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412947 \n",
      "\n",
      "Epoch 4369\n",
      "-------------------------------\n",
      "loss: 0.094326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417189 \n",
      "\n",
      "Epoch 4370\n",
      "-------------------------------\n",
      "loss: 0.128641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418771 \n",
      "\n",
      "Epoch 4371\n",
      "-------------------------------\n",
      "loss: 0.100850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419300 \n",
      "\n",
      "Epoch 4372\n",
      "-------------------------------\n",
      "loss: 0.104370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419032 \n",
      "\n",
      "Epoch 4373\n",
      "-------------------------------\n",
      "loss: 0.100840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416997 \n",
      "\n",
      "Epoch 4374\n",
      "-------------------------------\n",
      "loss: 0.117211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416312 \n",
      "\n",
      "Epoch 4375\n",
      "-------------------------------\n",
      "loss: 0.102475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415898 \n",
      "\n",
      "Epoch 4376\n",
      "-------------------------------\n",
      "loss: 0.093491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415677 \n",
      "\n",
      "Epoch 4377\n",
      "-------------------------------\n",
      "loss: 0.111623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415021 \n",
      "\n",
      "Epoch 4378\n",
      "-------------------------------\n",
      "loss: 0.097141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412175 \n",
      "\n",
      "Epoch 4379\n",
      "-------------------------------\n",
      "loss: 0.103655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411197 \n",
      "\n",
      "Epoch 4380\n",
      "-------------------------------\n",
      "loss: 0.102035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411863 \n",
      "\n",
      "Epoch 4381\n",
      "-------------------------------\n",
      "loss: 0.092988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414271 \n",
      "\n",
      "Epoch 4382\n",
      "-------------------------------\n",
      "loss: 0.108573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418204 \n",
      "\n",
      "Epoch 4383\n",
      "-------------------------------\n",
      "loss: 0.103674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421257 \n",
      "\n",
      "Epoch 4384\n",
      "-------------------------------\n",
      "loss: 0.108446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420628 \n",
      "\n",
      "Epoch 4385\n",
      "-------------------------------\n",
      "loss: 0.101975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419202 \n",
      "\n",
      "Epoch 4386\n",
      "-------------------------------\n",
      "loss: 0.106181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416191 \n",
      "\n",
      "Epoch 4387\n",
      "-------------------------------\n",
      "loss: 0.119050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415057 \n",
      "\n",
      "Epoch 4388\n",
      "-------------------------------\n",
      "loss: 0.098017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412918 \n",
      "\n",
      "Epoch 4389\n",
      "-------------------------------\n",
      "loss: 0.104265  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.410967 \n",
      "\n",
      "Epoch 4390\n",
      "-------------------------------\n",
      "loss: 0.105690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413597 \n",
      "\n",
      "Epoch 4391\n",
      "-------------------------------\n",
      "loss: 0.109446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413846 \n",
      "\n",
      "Epoch 4392\n",
      "-------------------------------\n",
      "loss: 0.099826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412834 \n",
      "\n",
      "Epoch 4393\n",
      "-------------------------------\n",
      "loss: 0.108480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412746 \n",
      "\n",
      "Epoch 4394\n",
      "-------------------------------\n",
      "loss: 0.101663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412389 \n",
      "\n",
      "Epoch 4395\n",
      "-------------------------------\n",
      "loss: 0.102357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412134 \n",
      "\n",
      "Epoch 4396\n",
      "-------------------------------\n",
      "loss: 0.107720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412739 \n",
      "\n",
      "Epoch 4397\n",
      "-------------------------------\n",
      "loss: 0.099867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413536 \n",
      "\n",
      "Epoch 4398\n",
      "-------------------------------\n",
      "loss: 0.092315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414307 \n",
      "\n",
      "Epoch 4399\n",
      "-------------------------------\n",
      "loss: 0.106387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413877 \n",
      "\n",
      "Epoch 4400\n",
      "-------------------------------\n",
      "loss: 0.099482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415528 \n",
      "\n",
      "Epoch 4401\n",
      "-------------------------------\n",
      "loss: 0.099779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413211 \n",
      "\n",
      "Epoch 4402\n",
      "-------------------------------\n",
      "loss: 0.102882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409363 \n",
      "\n",
      "Epoch 4403\n",
      "-------------------------------\n",
      "loss: 0.094933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405320 \n",
      "\n",
      "Epoch 4404\n",
      "-------------------------------\n",
      "loss: 0.099894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403289 \n",
      "\n",
      "Epoch 4405\n",
      "-------------------------------\n",
      "loss: 0.103424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401483 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 4406\n",
      "-------------------------------\n",
      "loss: 0.107722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401959 \n",
      "\n",
      "Epoch 4407\n",
      "-------------------------------\n",
      "loss: 0.095869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405194 \n",
      "\n",
      "Epoch 4408\n",
      "-------------------------------\n",
      "loss: 0.090489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411639 \n",
      "\n",
      "Epoch 4409\n",
      "-------------------------------\n",
      "loss: 0.094245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418093 \n",
      "\n",
      "Epoch 4410\n",
      "-------------------------------\n",
      "loss: 0.093106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422856 \n",
      "\n",
      "Epoch 4411\n",
      "-------------------------------\n",
      "loss: 0.101393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424648 \n",
      "\n",
      "Epoch 4412\n",
      "-------------------------------\n",
      "loss: 0.112791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422926 \n",
      "\n",
      "Epoch 4413\n",
      "-------------------------------\n",
      "loss: 0.111062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418038 \n",
      "\n",
      "Epoch 4414\n",
      "-------------------------------\n",
      "loss: 0.111771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410283 \n",
      "\n",
      "Epoch 4415\n",
      "-------------------------------\n",
      "loss: 0.095357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406429 \n",
      "\n",
      "Epoch 4416\n",
      "-------------------------------\n",
      "loss: 0.103929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407377 \n",
      "\n",
      "Epoch 4417\n",
      "-------------------------------\n",
      "loss: 0.099950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408039 \n",
      "\n",
      "Epoch 4418\n",
      "-------------------------------\n",
      "loss: 0.106780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409635 \n",
      "\n",
      "Epoch 4419\n",
      "-------------------------------\n",
      "loss: 0.110795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412258 \n",
      "\n",
      "Epoch 4420\n",
      "-------------------------------\n",
      "loss: 0.095845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414161 \n",
      "\n",
      "Epoch 4421\n",
      "-------------------------------\n",
      "loss: 0.097089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415461 \n",
      "\n",
      "Epoch 4422\n",
      "-------------------------------\n",
      "loss: 0.109620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417705 \n",
      "\n",
      "Epoch 4423\n",
      "-------------------------------\n",
      "loss: 0.096583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417273 \n",
      "\n",
      "Epoch 4424\n",
      "-------------------------------\n",
      "loss: 0.109017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412601 \n",
      "\n",
      "Epoch 4425\n",
      "-------------------------------\n",
      "loss: 0.103757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406009 \n",
      "\n",
      "Epoch 4426\n",
      "-------------------------------\n",
      "loss: 0.095572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404144 \n",
      "\n",
      "Epoch 4427\n",
      "-------------------------------\n",
      "loss: 0.093797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402190 \n",
      "\n",
      "Epoch 4428\n",
      "-------------------------------\n",
      "loss: 0.095955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401504 \n",
      "\n",
      "Epoch 4429\n",
      "-------------------------------\n",
      "loss: 0.096802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402574 \n",
      "\n",
      "Epoch 4430\n",
      "-------------------------------\n",
      "loss: 0.097122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407078 \n",
      "\n",
      "Epoch 4431\n",
      "-------------------------------\n",
      "loss: 0.096194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412156 \n",
      "\n",
      "Epoch 4432\n",
      "-------------------------------\n",
      "loss: 0.093314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415035 \n",
      "\n",
      "Epoch 4433\n",
      "-------------------------------\n",
      "loss: 0.093504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415829 \n",
      "\n",
      "Epoch 4434\n",
      "-------------------------------\n",
      "loss: 0.100082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416002 \n",
      "\n",
      "Epoch 4435\n",
      "-------------------------------\n",
      "loss: 0.100887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417441 \n",
      "\n",
      "Epoch 4436\n",
      "-------------------------------\n",
      "loss: 0.108044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416092 \n",
      "\n",
      "Epoch 4437\n",
      "-------------------------------\n",
      "loss: 0.084950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414120 \n",
      "\n",
      "Epoch 4438\n",
      "-------------------------------\n",
      "loss: 0.091826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413492 \n",
      "\n",
      "Epoch 4439\n",
      "-------------------------------\n",
      "loss: 0.089689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415597 \n",
      "\n",
      "Epoch 4440\n",
      "-------------------------------\n",
      "loss: 0.088608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419158 \n",
      "\n",
      "Epoch 4441\n",
      "-------------------------------\n",
      "loss: 0.103501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418217 \n",
      "\n",
      "Epoch 4442\n",
      "-------------------------------\n",
      "loss: 0.121044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416914 \n",
      "\n",
      "Epoch 4443\n",
      "-------------------------------\n",
      "loss: 0.089661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417597 \n",
      "\n",
      "Epoch 4444\n",
      "-------------------------------\n",
      "loss: 0.105962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417904 \n",
      "\n",
      "Epoch 4445\n",
      "-------------------------------\n",
      "loss: 0.126014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418189 \n",
      "\n",
      "Epoch 4446\n",
      "-------------------------------\n",
      "loss: 0.110095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414503 \n",
      "\n",
      "Epoch 4447\n",
      "-------------------------------\n",
      "loss: 0.102717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411536 \n",
      "\n",
      "Epoch 4448\n",
      "-------------------------------\n",
      "loss: 0.097287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409742 \n",
      "\n",
      "Epoch 4449\n",
      "-------------------------------\n",
      "loss: 0.104389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406708 \n",
      "\n",
      "Epoch 4450\n",
      "-------------------------------\n",
      "loss: 0.093732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403918 \n",
      "\n",
      "Epoch 4451\n",
      "-------------------------------\n",
      "loss: 0.101455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404457 \n",
      "\n",
      "Epoch 4452\n",
      "-------------------------------\n",
      "loss: 0.096481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409399 \n",
      "\n",
      "Epoch 4453\n",
      "-------------------------------\n",
      "loss: 0.100198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415553 \n",
      "\n",
      "Epoch 4454\n",
      "-------------------------------\n",
      "loss: 0.102334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421417 \n",
      "\n",
      "Epoch 4455\n",
      "-------------------------------\n",
      "loss: 0.112855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423058 \n",
      "\n",
      "Epoch 4456\n",
      "-------------------------------\n",
      "loss: 0.106577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423432 \n",
      "\n",
      "Epoch 4457\n",
      "-------------------------------\n",
      "loss: 0.110946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419175 \n",
      "\n",
      "Epoch 4458\n",
      "-------------------------------\n",
      "loss: 0.106848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416630 \n",
      "\n",
      "Epoch 4459\n",
      "-------------------------------\n",
      "loss: 0.104861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416035 \n",
      "\n",
      "Epoch 4460\n",
      "-------------------------------\n",
      "loss: 0.115283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415223 \n",
      "\n",
      "Epoch 4461\n",
      "-------------------------------\n",
      "loss: 0.110489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416183 \n",
      "\n",
      "Epoch 4462\n",
      "-------------------------------\n",
      "loss: 0.099401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418833 \n",
      "\n",
      "Epoch 4463\n",
      "-------------------------------\n",
      "loss: 0.107807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418046 \n",
      "\n",
      "Epoch 4464\n",
      "-------------------------------\n",
      "loss: 0.105509  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.414073 \n",
      "\n",
      "Epoch 4465\n",
      "-------------------------------\n",
      "loss: 0.105526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409655 \n",
      "\n",
      "Epoch 4466\n",
      "-------------------------------\n",
      "loss: 0.097095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406379 \n",
      "\n",
      "Epoch 4467\n",
      "-------------------------------\n",
      "loss: 0.094446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406393 \n",
      "\n",
      "Epoch 4468\n",
      "-------------------------------\n",
      "loss: 0.090683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409250 \n",
      "\n",
      "Epoch 4469\n",
      "-------------------------------\n",
      "loss: 0.089106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415876 \n",
      "\n",
      "Epoch 4470\n",
      "-------------------------------\n",
      "loss: 0.096231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422878 \n",
      "\n",
      "Epoch 4471\n",
      "-------------------------------\n",
      "loss: 0.108919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425864 \n",
      "\n",
      "Epoch 4472\n",
      "-------------------------------\n",
      "loss: 0.099315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424615 \n",
      "\n",
      "Epoch 4473\n",
      "-------------------------------\n",
      "loss: 0.099986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420681 \n",
      "\n",
      "Epoch 4474\n",
      "-------------------------------\n",
      "loss: 0.098175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415308 \n",
      "\n",
      "Epoch 4475\n",
      "-------------------------------\n",
      "loss: 0.092587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411055 \n",
      "\n",
      "Epoch 4476\n",
      "-------------------------------\n",
      "loss: 0.105251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411492 \n",
      "\n",
      "Epoch 4477\n",
      "-------------------------------\n",
      "loss: 0.099123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414527 \n",
      "\n",
      "Epoch 4478\n",
      "-------------------------------\n",
      "loss: 0.102717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417253 \n",
      "\n",
      "Epoch 4479\n",
      "-------------------------------\n",
      "loss: 0.101923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417381 \n",
      "\n",
      "Epoch 4480\n",
      "-------------------------------\n",
      "loss: 0.113530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416514 \n",
      "\n",
      "Epoch 4481\n",
      "-------------------------------\n",
      "loss: 0.103792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414438 \n",
      "\n",
      "Epoch 4482\n",
      "-------------------------------\n",
      "loss: 0.093676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418841 \n",
      "\n",
      "Epoch 4483\n",
      "-------------------------------\n",
      "loss: 0.110569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425910 \n",
      "\n",
      "Epoch 4484\n",
      "-------------------------------\n",
      "loss: 0.097598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431121 \n",
      "\n",
      "Epoch 4485\n",
      "-------------------------------\n",
      "loss: 0.101171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433008 \n",
      "\n",
      "Epoch 4486\n",
      "-------------------------------\n",
      "loss: 0.098987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430175 \n",
      "\n",
      "Epoch 4487\n",
      "-------------------------------\n",
      "loss: 0.097319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424466 \n",
      "\n",
      "Epoch 4488\n",
      "-------------------------------\n",
      "loss: 0.099199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420118 \n",
      "\n",
      "Epoch 4489\n",
      "-------------------------------\n",
      "loss: 0.107651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415808 \n",
      "\n",
      "Epoch 4490\n",
      "-------------------------------\n",
      "loss: 0.109605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413835 \n",
      "\n",
      "Epoch 4491\n",
      "-------------------------------\n",
      "loss: 0.101803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412827 \n",
      "\n",
      "Epoch 4492\n",
      "-------------------------------\n",
      "loss: 0.106918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414259 \n",
      "\n",
      "Epoch 4493\n",
      "-------------------------------\n",
      "loss: 0.094415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418894 \n",
      "\n",
      "Epoch 4494\n",
      "-------------------------------\n",
      "loss: 0.127654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420653 \n",
      "\n",
      "Epoch 4495\n",
      "-------------------------------\n",
      "loss: 0.111783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416888 \n",
      "\n",
      "Epoch 4496\n",
      "-------------------------------\n",
      "loss: 0.104207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413657 \n",
      "\n",
      "Epoch 4497\n",
      "-------------------------------\n",
      "loss: 0.106075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413231 \n",
      "\n",
      "Epoch 4498\n",
      "-------------------------------\n",
      "loss: 0.112589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417889 \n",
      "\n",
      "Epoch 4499\n",
      "-------------------------------\n",
      "loss: 0.101900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421058 \n",
      "\n",
      "Epoch 4500\n",
      "-------------------------------\n",
      "loss: 0.098015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420369 \n",
      "\n",
      "Epoch 4501\n",
      "-------------------------------\n",
      "loss: 0.103716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422227 \n",
      "\n",
      "Epoch 4502\n",
      "-------------------------------\n",
      "loss: 0.122141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419487 \n",
      "\n",
      "Epoch 4503\n",
      "-------------------------------\n",
      "loss: 0.108142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417771 \n",
      "\n",
      "Epoch 4504\n",
      "-------------------------------\n",
      "loss: 0.113582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417040 \n",
      "\n",
      "Epoch 4505\n",
      "-------------------------------\n",
      "loss: 0.094260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418900 \n",
      "\n",
      "Epoch 4506\n",
      "-------------------------------\n",
      "loss: 0.105054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418281 \n",
      "\n",
      "Epoch 4507\n",
      "-------------------------------\n",
      "loss: 0.110021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413352 \n",
      "\n",
      "Epoch 4508\n",
      "-------------------------------\n",
      "loss: 0.109625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407942 \n",
      "\n",
      "Epoch 4509\n",
      "-------------------------------\n",
      "loss: 0.106061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404464 \n",
      "\n",
      "Epoch 4510\n",
      "-------------------------------\n",
      "loss: 0.096567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402960 \n",
      "\n",
      "Epoch 4511\n",
      "-------------------------------\n",
      "loss: 0.095358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405786 \n",
      "\n",
      "Epoch 4512\n",
      "-------------------------------\n",
      "loss: 0.102083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408347 \n",
      "\n",
      "Epoch 4513\n",
      "-------------------------------\n",
      "loss: 0.116395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409507 \n",
      "\n",
      "Epoch 4514\n",
      "-------------------------------\n",
      "loss: 0.111602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409342 \n",
      "\n",
      "Epoch 4515\n",
      "-------------------------------\n",
      "loss: 0.113629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412193 \n",
      "\n",
      "Epoch 4516\n",
      "-------------------------------\n",
      "loss: 0.098485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415222 \n",
      "\n",
      "Epoch 4517\n",
      "-------------------------------\n",
      "loss: 0.096145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418419 \n",
      "\n",
      "Epoch 4518\n",
      "-------------------------------\n",
      "loss: 0.102347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421248 \n",
      "\n",
      "Epoch 4519\n",
      "-------------------------------\n",
      "loss: 0.108401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421713 \n",
      "\n",
      "Epoch 4520\n",
      "-------------------------------\n",
      "loss: 0.100804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415709 \n",
      "\n",
      "Epoch 4521\n",
      "-------------------------------\n",
      "loss: 0.102585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410776 \n",
      "\n",
      "Epoch 4522\n",
      "-------------------------------\n",
      "loss: 0.105741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408673 \n",
      "\n",
      "Epoch 4523\n",
      "-------------------------------\n",
      "loss: 0.092939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410397 \n",
      "\n",
      "Epoch 4524\n",
      "-------------------------------\n",
      "loss: 0.109280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414238 \n",
      "\n",
      "Epoch 4525\n",
      "-------------------------------\n",
      "loss: 0.102393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419943 \n",
      "\n",
      "Epoch 4526\n",
      "-------------------------------\n",
      "loss: 0.107825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425691 \n",
      "\n",
      "Epoch 4527\n",
      "-------------------------------\n",
      "loss: 0.095530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430106 \n",
      "\n",
      "Epoch 4528\n",
      "-------------------------------\n",
      "loss: 0.110712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431382 \n",
      "\n",
      "Epoch 4529\n",
      "-------------------------------\n",
      "loss: 0.109954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431656 \n",
      "\n",
      "Epoch 4530\n",
      "-------------------------------\n",
      "loss: 0.107268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427510 \n",
      "\n",
      "Epoch 4531\n",
      "-------------------------------\n",
      "loss: 0.100680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418444 \n",
      "\n",
      "Epoch 4532\n",
      "-------------------------------\n",
      "loss: 0.100083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412113 \n",
      "\n",
      "Epoch 4533\n",
      "-------------------------------\n",
      "loss: 0.100951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408906 \n",
      "\n",
      "Epoch 4534\n",
      "-------------------------------\n",
      "loss: 0.101400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406982 \n",
      "\n",
      "Epoch 4535\n",
      "-------------------------------\n",
      "loss: 0.093731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407470 \n",
      "\n",
      "Epoch 4536\n",
      "-------------------------------\n",
      "loss: 0.119940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409961 \n",
      "\n",
      "Epoch 4537\n",
      "-------------------------------\n",
      "loss: 0.087615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411226 \n",
      "\n",
      "Epoch 4538\n",
      "-------------------------------\n",
      "loss: 0.099663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410421 \n",
      "\n",
      "Epoch 4539\n",
      "-------------------------------\n",
      "loss: 0.093875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412411 \n",
      "\n",
      "Epoch 4540\n",
      "-------------------------------\n",
      "loss: 0.093373  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.415243 \n",
      "\n",
      "Epoch 4541\n",
      "-------------------------------\n",
      "loss: 0.102244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417333 \n",
      "\n",
      "Epoch 4542\n",
      "-------------------------------\n",
      "loss: 0.103032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417638 \n",
      "\n",
      "Epoch 4543\n",
      "-------------------------------\n",
      "loss: 0.090553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417948 \n",
      "\n",
      "Epoch 4544\n",
      "-------------------------------\n",
      "loss: 0.129022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417816 \n",
      "\n",
      "Epoch 4545\n",
      "-------------------------------\n",
      "loss: 0.089069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419870 \n",
      "\n",
      "Epoch 4546\n",
      "-------------------------------\n",
      "loss: 0.086802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419741 \n",
      "\n",
      "Epoch 4547\n",
      "-------------------------------\n",
      "loss: 0.107321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416034 \n",
      "\n",
      "Epoch 4548\n",
      "-------------------------------\n",
      "loss: 0.102057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412087 \n",
      "\n",
      "Epoch 4549\n",
      "-------------------------------\n",
      "loss: 0.126259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408853 \n",
      "\n",
      "Epoch 4550\n",
      "-------------------------------\n",
      "loss: 0.110664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411097 \n",
      "\n",
      "Epoch 4551\n",
      "-------------------------------\n",
      "loss: 0.103232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416421 \n",
      "\n",
      "Epoch 4552\n",
      "-------------------------------\n",
      "loss: 0.100588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426601 \n",
      "\n",
      "Epoch 4553\n",
      "-------------------------------\n",
      "loss: 0.104109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431924 \n",
      "\n",
      "Epoch 4554\n",
      "-------------------------------\n",
      "loss: 0.115473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428362 \n",
      "\n",
      "Epoch 4555\n",
      "-------------------------------\n",
      "loss: 0.100569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418722 \n",
      "\n",
      "Epoch 4556\n",
      "-------------------------------\n",
      "loss: 0.102429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413852 \n",
      "\n",
      "Epoch 4557\n",
      "-------------------------------\n",
      "loss: 0.097484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409727 \n",
      "\n",
      "Epoch 4558\n",
      "-------------------------------\n",
      "loss: 0.103397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406159 \n",
      "\n",
      "Epoch 4559\n",
      "-------------------------------\n",
      "loss: 0.097620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406727 \n",
      "\n",
      "Epoch 4560\n",
      "-------------------------------\n",
      "loss: 0.104421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410827 \n",
      "\n",
      "Epoch 4561\n",
      "-------------------------------\n",
      "loss: 0.115065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413338 \n",
      "\n",
      "Epoch 4562\n",
      "-------------------------------\n",
      "loss: 0.107933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410404 \n",
      "\n",
      "Epoch 4563\n",
      "-------------------------------\n",
      "loss: 0.100542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409576 \n",
      "\n",
      "Epoch 4564\n",
      "-------------------------------\n",
      "loss: 0.092498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413106 \n",
      "\n",
      "Epoch 4565\n",
      "-------------------------------\n",
      "loss: 0.115290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416529 \n",
      "\n",
      "Epoch 4566\n",
      "-------------------------------\n",
      "loss: 0.104031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416209 \n",
      "\n",
      "Epoch 4567\n",
      "-------------------------------\n",
      "loss: 0.118356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415352 \n",
      "\n",
      "Epoch 4568\n",
      "-------------------------------\n",
      "loss: 0.123929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413774 \n",
      "\n",
      "Epoch 4569\n",
      "-------------------------------\n",
      "loss: 0.115469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413290 \n",
      "\n",
      "Epoch 4570\n",
      "-------------------------------\n",
      "loss: 0.091650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411910 \n",
      "\n",
      "Epoch 4571\n",
      "-------------------------------\n",
      "loss: 0.096273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410912 \n",
      "\n",
      "Epoch 4572\n",
      "-------------------------------\n",
      "loss: 0.099831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411705 \n",
      "\n",
      "Epoch 4573\n",
      "-------------------------------\n",
      "loss: 0.089110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412879 \n",
      "\n",
      "Epoch 4574\n",
      "-------------------------------\n",
      "loss: 0.093513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414466 \n",
      "\n",
      "Epoch 4575\n",
      "-------------------------------\n",
      "loss: 0.090368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416775 \n",
      "\n",
      "Epoch 4576\n",
      "-------------------------------\n",
      "loss: 0.106481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418476 \n",
      "\n",
      "Epoch 4577\n",
      "-------------------------------\n",
      "loss: 0.091387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418489 \n",
      "\n",
      "Epoch 4578\n",
      "-------------------------------\n",
      "loss: 0.095420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413858 \n",
      "\n",
      "Epoch 4579\n",
      "-------------------------------\n",
      "loss: 0.114288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408056 \n",
      "\n",
      "Epoch 4580\n",
      "-------------------------------\n",
      "loss: 0.108678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410096 \n",
      "\n",
      "Epoch 4581\n",
      "-------------------------------\n",
      "loss: 0.105114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418780 \n",
      "\n",
      "Epoch 4582\n",
      "-------------------------------\n",
      "loss: 0.099459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427542 \n",
      "\n",
      "Epoch 4583\n",
      "-------------------------------\n",
      "loss: 0.110485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429624 \n",
      "\n",
      "Epoch 4584\n",
      "-------------------------------\n",
      "loss: 0.123323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423999 \n",
      "\n",
      "Epoch 4585\n",
      "-------------------------------\n",
      "loss: 0.098946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416711 \n",
      "\n",
      "Epoch 4586\n",
      "-------------------------------\n",
      "loss: 0.114583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412201 \n",
      "\n",
      "Epoch 4587\n",
      "-------------------------------\n",
      "loss: 0.101560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412147 \n",
      "\n",
      "Epoch 4588\n",
      "-------------------------------\n",
      "loss: 0.094697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415184 \n",
      "\n",
      "Epoch 4589\n",
      "-------------------------------\n",
      "loss: 0.105342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417492 \n",
      "\n",
      "Epoch 4590\n",
      "-------------------------------\n",
      "loss: 0.114080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416294 \n",
      "\n",
      "Epoch 4591\n",
      "-------------------------------\n",
      "loss: 0.098430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414080 \n",
      "\n",
      "Epoch 4592\n",
      "-------------------------------\n",
      "loss: 0.111337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410747 \n",
      "\n",
      "Epoch 4593\n",
      "-------------------------------\n",
      "loss: 0.097199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409044 \n",
      "\n",
      "Epoch 4594\n",
      "-------------------------------\n",
      "loss: 0.103714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410910 \n",
      "\n",
      "Epoch 4595\n",
      "-------------------------------\n",
      "loss: 0.109981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411027 \n",
      "\n",
      "Epoch 4596\n",
      "-------------------------------\n",
      "loss: 0.112555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411314 \n",
      "\n",
      "Epoch 4597\n",
      "-------------------------------\n",
      "loss: 0.114069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411438 \n",
      "\n",
      "Epoch 4598\n",
      "-------------------------------\n",
      "loss: 0.092699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411168 \n",
      "\n",
      "Epoch 4599\n",
      "-------------------------------\n",
      "loss: 0.101701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410919 \n",
      "\n",
      "Epoch 4600\n",
      "-------------------------------\n",
      "loss: 0.101739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410085 \n",
      "\n",
      "Epoch 4601\n",
      "-------------------------------\n",
      "loss: 0.107916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410418 \n",
      "\n",
      "Epoch 4602\n",
      "-------------------------------\n",
      "loss: 0.101209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408346 \n",
      "\n",
      "Epoch 4603\n",
      "-------------------------------\n",
      "loss: 0.094165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407133 \n",
      "\n",
      "Epoch 4604\n",
      "-------------------------------\n",
      "loss: 0.103014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410564 \n",
      "\n",
      "Epoch 4605\n",
      "-------------------------------\n",
      "loss: 0.098616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415351 \n",
      "\n",
      "Epoch 4606\n",
      "-------------------------------\n",
      "loss: 0.098968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414196 \n",
      "\n",
      "Epoch 4607\n",
      "-------------------------------\n",
      "loss: 0.106927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414364 \n",
      "\n",
      "Epoch 4608\n",
      "-------------------------------\n",
      "loss: 0.089711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415408 \n",
      "\n",
      "Epoch 4609\n",
      "-------------------------------\n",
      "loss: 0.111213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418025 \n",
      "\n",
      "Epoch 4610\n",
      "-------------------------------\n",
      "loss: 0.094916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418951 \n",
      "\n",
      "Epoch 4611\n",
      "-------------------------------\n",
      "loss: 0.098773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416498 \n",
      "\n",
      "Epoch 4612\n",
      "-------------------------------\n",
      "loss: 0.109780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414474 \n",
      "\n",
      "Epoch 4613\n",
      "-------------------------------\n",
      "loss: 0.100835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413657 \n",
      "\n",
      "Epoch 4614\n",
      "-------------------------------\n",
      "loss: 0.095830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413882 \n",
      "\n",
      "Epoch 4615\n",
      "-------------------------------\n",
      "loss: 0.115894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413733 \n",
      "\n",
      "Epoch 4616\n",
      "-------------------------------\n",
      "loss: 0.095419  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.413894 \n",
      "\n",
      "Epoch 4617\n",
      "-------------------------------\n",
      "loss: 0.110428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412539 \n",
      "\n",
      "Epoch 4618\n",
      "-------------------------------\n",
      "loss: 0.091583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408907 \n",
      "\n",
      "Epoch 4619\n",
      "-------------------------------\n",
      "loss: 0.105943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404428 \n",
      "\n",
      "Epoch 4620\n",
      "-------------------------------\n",
      "loss: 0.094916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404714 \n",
      "\n",
      "Epoch 4621\n",
      "-------------------------------\n",
      "loss: 0.103948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406036 \n",
      "\n",
      "Epoch 4622\n",
      "-------------------------------\n",
      "loss: 0.099917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407906 \n",
      "\n",
      "Epoch 4623\n",
      "-------------------------------\n",
      "loss: 0.118722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410319 \n",
      "\n",
      "Epoch 4624\n",
      "-------------------------------\n",
      "loss: 0.096906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412845 \n",
      "\n",
      "Epoch 4625\n",
      "-------------------------------\n",
      "loss: 0.109088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412462 \n",
      "\n",
      "Epoch 4626\n",
      "-------------------------------\n",
      "loss: 0.103134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411775 \n",
      "\n",
      "Epoch 4627\n",
      "-------------------------------\n",
      "loss: 0.092181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413187 \n",
      "\n",
      "Epoch 4628\n",
      "-------------------------------\n",
      "loss: 0.108642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413412 \n",
      "\n",
      "Epoch 4629\n",
      "-------------------------------\n",
      "loss: 0.099423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416830 \n",
      "\n",
      "Epoch 4630\n",
      "-------------------------------\n",
      "loss: 0.113799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422309 \n",
      "\n",
      "Epoch 4631\n",
      "-------------------------------\n",
      "loss: 0.103366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429086 \n",
      "\n",
      "Epoch 4632\n",
      "-------------------------------\n",
      "loss: 0.095203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429807 \n",
      "\n",
      "Epoch 4633\n",
      "-------------------------------\n",
      "loss: 0.098693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429221 \n",
      "\n",
      "Epoch 4634\n",
      "-------------------------------\n",
      "loss: 0.117244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419141 \n",
      "\n",
      "Epoch 4635\n",
      "-------------------------------\n",
      "loss: 0.094279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412052 \n",
      "\n",
      "Epoch 4636\n",
      "-------------------------------\n",
      "loss: 0.105371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408443 \n",
      "\n",
      "Epoch 4637\n",
      "-------------------------------\n",
      "loss: 0.102819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408883 \n",
      "\n",
      "Epoch 4638\n",
      "-------------------------------\n",
      "loss: 0.102667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410185 \n",
      "\n",
      "Epoch 4639\n",
      "-------------------------------\n",
      "loss: 0.109138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414682 \n",
      "\n",
      "Epoch 4640\n",
      "-------------------------------\n",
      "loss: 0.097322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421397 \n",
      "\n",
      "Epoch 4641\n",
      "-------------------------------\n",
      "loss: 0.099329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425612 \n",
      "\n",
      "Epoch 4642\n",
      "-------------------------------\n",
      "loss: 0.111038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424451 \n",
      "\n",
      "Epoch 4643\n",
      "-------------------------------\n",
      "loss: 0.104222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419439 \n",
      "\n",
      "Epoch 4644\n",
      "-------------------------------\n",
      "loss: 0.112246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412034 \n",
      "\n",
      "Epoch 4645\n",
      "-------------------------------\n",
      "loss: 0.091629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408560 \n",
      "\n",
      "Epoch 4646\n",
      "-------------------------------\n",
      "loss: 0.099446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407302 \n",
      "\n",
      "Epoch 4647\n",
      "-------------------------------\n",
      "loss: 0.112863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406343 \n",
      "\n",
      "Epoch 4648\n",
      "-------------------------------\n",
      "loss: 0.114089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405503 \n",
      "\n",
      "Epoch 4649\n",
      "-------------------------------\n",
      "loss: 0.108391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406549 \n",
      "\n",
      "Epoch 4650\n",
      "-------------------------------\n",
      "loss: 0.113364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410925 \n",
      "\n",
      "Epoch 4651\n",
      "-------------------------------\n",
      "loss: 0.106383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417007 \n",
      "\n",
      "Epoch 4652\n",
      "-------------------------------\n",
      "loss: 0.102823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421706 \n",
      "\n",
      "Epoch 4653\n",
      "-------------------------------\n",
      "loss: 0.102456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422268 \n",
      "\n",
      "Epoch 4654\n",
      "-------------------------------\n",
      "loss: 0.104575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421225 \n",
      "\n",
      "Epoch 4655\n",
      "-------------------------------\n",
      "loss: 0.128321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418035 \n",
      "\n",
      "Epoch 4656\n",
      "-------------------------------\n",
      "loss: 0.103018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413582 \n",
      "\n",
      "Epoch 4657\n",
      "-------------------------------\n",
      "loss: 0.105725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407013 \n",
      "\n",
      "Epoch 4658\n",
      "-------------------------------\n",
      "loss: 0.094882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406829 \n",
      "\n",
      "Epoch 4659\n",
      "-------------------------------\n",
      "loss: 0.108798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419914 \n",
      "\n",
      "Epoch 4660\n",
      "-------------------------------\n",
      "loss: 0.121598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433061 \n",
      "\n",
      "Epoch 4661\n",
      "-------------------------------\n",
      "loss: 0.111278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435024 \n",
      "\n",
      "Epoch 4662\n",
      "-------------------------------\n",
      "loss: 0.101162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428770 \n",
      "\n",
      "Epoch 4663\n",
      "-------------------------------\n",
      "loss: 0.109408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420898 \n",
      "\n",
      "Epoch 4664\n",
      "-------------------------------\n",
      "loss: 0.091497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414747 \n",
      "\n",
      "Epoch 4665\n",
      "-------------------------------\n",
      "loss: 0.089420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411040 \n",
      "\n",
      "Epoch 4666\n",
      "-------------------------------\n",
      "loss: 0.106914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409403 \n",
      "\n",
      "Epoch 4667\n",
      "-------------------------------\n",
      "loss: 0.094666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409565 \n",
      "\n",
      "Epoch 4668\n",
      "-------------------------------\n",
      "loss: 0.102754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410513 \n",
      "\n",
      "Epoch 4669\n",
      "-------------------------------\n",
      "loss: 0.097302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412292 \n",
      "\n",
      "Epoch 4670\n",
      "-------------------------------\n",
      "loss: 0.108371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414751 \n",
      "\n",
      "Epoch 4671\n",
      "-------------------------------\n",
      "loss: 0.090261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416360 \n",
      "\n",
      "Epoch 4672\n",
      "-------------------------------\n",
      "loss: 0.107286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415055 \n",
      "\n",
      "Epoch 4673\n",
      "-------------------------------\n",
      "loss: 0.090277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412129 \n",
      "\n",
      "Epoch 4674\n",
      "-------------------------------\n",
      "loss: 0.106883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406575 \n",
      "\n",
      "Epoch 4675\n",
      "-------------------------------\n",
      "loss: 0.102352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403121 \n",
      "\n",
      "Epoch 4676\n",
      "-------------------------------\n",
      "loss: 0.097297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403396 \n",
      "\n",
      "Epoch 4677\n",
      "-------------------------------\n",
      "loss: 0.088543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405445 \n",
      "\n",
      "Epoch 4678\n",
      "-------------------------------\n",
      "loss: 0.092755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405967 \n",
      "\n",
      "Epoch 4679\n",
      "-------------------------------\n",
      "loss: 0.086602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408805 \n",
      "\n",
      "Epoch 4680\n",
      "-------------------------------\n",
      "loss: 0.092664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412131 \n",
      "\n",
      "Epoch 4681\n",
      "-------------------------------\n",
      "loss: 0.105442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411718 \n",
      "\n",
      "Epoch 4682\n",
      "-------------------------------\n",
      "loss: 0.099554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409453 \n",
      "\n",
      "Epoch 4683\n",
      "-------------------------------\n",
      "loss: 0.092632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407016 \n",
      "\n",
      "Epoch 4684\n",
      "-------------------------------\n",
      "loss: 0.104409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404755 \n",
      "\n",
      "Epoch 4685\n",
      "-------------------------------\n",
      "loss: 0.098291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405369 \n",
      "\n",
      "Epoch 4686\n",
      "-------------------------------\n",
      "loss: 0.090406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406727 \n",
      "\n",
      "Epoch 4687\n",
      "-------------------------------\n",
      "loss: 0.091114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408364 \n",
      "\n",
      "Epoch 4688\n",
      "-------------------------------\n",
      "loss: 0.089836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410092 \n",
      "\n",
      "Epoch 4689\n",
      "-------------------------------\n",
      "loss: 0.089191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412375 \n",
      "\n",
      "Epoch 4690\n",
      "-------------------------------\n",
      "loss: 0.101939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416077 \n",
      "\n",
      "Epoch 4691\n",
      "-------------------------------\n",
      "loss: 0.093643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417870 \n",
      "\n",
      "Epoch 4692\n",
      "-------------------------------\n",
      "loss: 0.092939  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.416908 \n",
      "\n",
      "Epoch 4693\n",
      "-------------------------------\n",
      "loss: 0.096846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416124 \n",
      "\n",
      "Epoch 4694\n",
      "-------------------------------\n",
      "loss: 0.101860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414542 \n",
      "\n",
      "Epoch 4695\n",
      "-------------------------------\n",
      "loss: 0.097245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413941 \n",
      "\n",
      "Epoch 4696\n",
      "-------------------------------\n",
      "loss: 0.097762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415964 \n",
      "\n",
      "Epoch 4697\n",
      "-------------------------------\n",
      "loss: 0.091698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415884 \n",
      "\n",
      "Epoch 4698\n",
      "-------------------------------\n",
      "loss: 0.089428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414430 \n",
      "\n",
      "Epoch 4699\n",
      "-------------------------------\n",
      "loss: 0.096609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410320 \n",
      "\n",
      "Epoch 4700\n",
      "-------------------------------\n",
      "loss: 0.108355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406234 \n",
      "\n",
      "Epoch 4701\n",
      "-------------------------------\n",
      "loss: 0.100841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403399 \n",
      "\n",
      "Epoch 4702\n",
      "-------------------------------\n",
      "loss: 0.112009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401948 \n",
      "\n",
      "Epoch 4703\n",
      "-------------------------------\n",
      "loss: 0.099668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403907 \n",
      "\n",
      "Epoch 4704\n",
      "-------------------------------\n",
      "loss: 0.112206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407417 \n",
      "\n",
      "Epoch 4705\n",
      "-------------------------------\n",
      "loss: 0.100830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406381 \n",
      "\n",
      "Epoch 4706\n",
      "-------------------------------\n",
      "loss: 0.103038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405102 \n",
      "\n",
      "Epoch 4707\n",
      "-------------------------------\n",
      "loss: 0.101165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405856 \n",
      "\n",
      "Epoch 4708\n",
      "-------------------------------\n",
      "loss: 0.112553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408958 \n",
      "\n",
      "Epoch 4709\n",
      "-------------------------------\n",
      "loss: 0.104151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411173 \n",
      "\n",
      "Epoch 4710\n",
      "-------------------------------\n",
      "loss: 0.126197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411997 \n",
      "\n",
      "Epoch 4711\n",
      "-------------------------------\n",
      "loss: 0.110560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412230 \n",
      "\n",
      "Epoch 4712\n",
      "-------------------------------\n",
      "loss: 0.099185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414452 \n",
      "\n",
      "Epoch 4713\n",
      "-------------------------------\n",
      "loss: 0.101907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417661 \n",
      "\n",
      "Epoch 4714\n",
      "-------------------------------\n",
      "loss: 0.099210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418708 \n",
      "\n",
      "Epoch 4715\n",
      "-------------------------------\n",
      "loss: 0.098525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418544 \n",
      "\n",
      "Epoch 4716\n",
      "-------------------------------\n",
      "loss: 0.102816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417929 \n",
      "\n",
      "Epoch 4717\n",
      "-------------------------------\n",
      "loss: 0.104193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412181 \n",
      "\n",
      "Epoch 4718\n",
      "-------------------------------\n",
      "loss: 0.103572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409690 \n",
      "\n",
      "Epoch 4719\n",
      "-------------------------------\n",
      "loss: 0.102237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407871 \n",
      "\n",
      "Epoch 4720\n",
      "-------------------------------\n",
      "loss: 0.104558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408980 \n",
      "\n",
      "Epoch 4721\n",
      "-------------------------------\n",
      "loss: 0.098042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413178 \n",
      "\n",
      "Epoch 4722\n",
      "-------------------------------\n",
      "loss: 0.098729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414799 \n",
      "\n",
      "Epoch 4723\n",
      "-------------------------------\n",
      "loss: 0.099379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415921 \n",
      "\n",
      "Epoch 4724\n",
      "-------------------------------\n",
      "loss: 0.105621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415032 \n",
      "\n",
      "Epoch 4725\n",
      "-------------------------------\n",
      "loss: 0.095315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414543 \n",
      "\n",
      "Epoch 4726\n",
      "-------------------------------\n",
      "loss: 0.093120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413395 \n",
      "\n",
      "Epoch 4727\n",
      "-------------------------------\n",
      "loss: 0.135214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414721 \n",
      "\n",
      "Epoch 4728\n",
      "-------------------------------\n",
      "loss: 0.100503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415211 \n",
      "\n",
      "Epoch 4729\n",
      "-------------------------------\n",
      "loss: 0.096927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415686 \n",
      "\n",
      "Epoch 4730\n",
      "-------------------------------\n",
      "loss: 0.102079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415338 \n",
      "\n",
      "Epoch 4731\n",
      "-------------------------------\n",
      "loss: 0.098872  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413494 \n",
      "\n",
      "Epoch 4732\n",
      "-------------------------------\n",
      "loss: 0.099840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409858 \n",
      "\n",
      "Epoch 4733\n",
      "-------------------------------\n",
      "loss: 0.114558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409339 \n",
      "\n",
      "Epoch 4734\n",
      "-------------------------------\n",
      "loss: 0.122264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410611 \n",
      "\n",
      "Epoch 4735\n",
      "-------------------------------\n",
      "loss: 0.103473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411647 \n",
      "\n",
      "Epoch 4736\n",
      "-------------------------------\n",
      "loss: 0.090997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411145 \n",
      "\n",
      "Epoch 4737\n",
      "-------------------------------\n",
      "loss: 0.111775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414419 \n",
      "\n",
      "Epoch 4738\n",
      "-------------------------------\n",
      "loss: 0.112778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417022 \n",
      "\n",
      "Epoch 4739\n",
      "-------------------------------\n",
      "loss: 0.104097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419082 \n",
      "\n",
      "Epoch 4740\n",
      "-------------------------------\n",
      "loss: 0.126116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419690 \n",
      "\n",
      "Epoch 4741\n",
      "-------------------------------\n",
      "loss: 0.093697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415045 \n",
      "\n",
      "Epoch 4742\n",
      "-------------------------------\n",
      "loss: 0.103078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411540 \n",
      "\n",
      "Epoch 4743\n",
      "-------------------------------\n",
      "loss: 0.095948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410500 \n",
      "\n",
      "Epoch 4744\n",
      "-------------------------------\n",
      "loss: 0.102783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411227 \n",
      "\n",
      "Epoch 4745\n",
      "-------------------------------\n",
      "loss: 0.097639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415020 \n",
      "\n",
      "Epoch 4746\n",
      "-------------------------------\n",
      "loss: 0.098323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417477 \n",
      "\n",
      "Epoch 4747\n",
      "-------------------------------\n",
      "loss: 0.097141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417417 \n",
      "\n",
      "Epoch 4748\n",
      "-------------------------------\n",
      "loss: 0.109546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413890 \n",
      "\n",
      "Epoch 4749\n",
      "-------------------------------\n",
      "loss: 0.105028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410305 \n",
      "\n",
      "Epoch 4750\n",
      "-------------------------------\n",
      "loss: 0.108782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409387 \n",
      "\n",
      "Epoch 4751\n",
      "-------------------------------\n",
      "loss: 0.091980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409837 \n",
      "\n",
      "Epoch 4752\n",
      "-------------------------------\n",
      "loss: 0.100047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410737 \n",
      "\n",
      "Epoch 4753\n",
      "-------------------------------\n",
      "loss: 0.106354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410405 \n",
      "\n",
      "Epoch 4754\n",
      "-------------------------------\n",
      "loss: 0.100290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411322 \n",
      "\n",
      "Epoch 4755\n",
      "-------------------------------\n",
      "loss: 0.098366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412934 \n",
      "\n",
      "Epoch 4756\n",
      "-------------------------------\n",
      "loss: 0.103659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414738 \n",
      "\n",
      "Epoch 4757\n",
      "-------------------------------\n",
      "loss: 0.094929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415260 \n",
      "\n",
      "Epoch 4758\n",
      "-------------------------------\n",
      "loss: 0.108912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415478 \n",
      "\n",
      "Epoch 4759\n",
      "-------------------------------\n",
      "loss: 0.098964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414610 \n",
      "\n",
      "Epoch 4760\n",
      "-------------------------------\n",
      "loss: 0.096136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414487 \n",
      "\n",
      "Epoch 4761\n",
      "-------------------------------\n",
      "loss: 0.091989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412234 \n",
      "\n",
      "Epoch 4762\n",
      "-------------------------------\n",
      "loss: 0.091237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412273 \n",
      "\n",
      "Epoch 4763\n",
      "-------------------------------\n",
      "loss: 0.101244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416898 \n",
      "\n",
      "Epoch 4764\n",
      "-------------------------------\n",
      "loss: 0.109221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425949 \n",
      "\n",
      "Epoch 4765\n",
      "-------------------------------\n",
      "loss: 0.096221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429616 \n",
      "\n",
      "Epoch 4766\n",
      "-------------------------------\n",
      "loss: 0.109149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425971 \n",
      "\n",
      "Epoch 4767\n",
      "-------------------------------\n",
      "loss: 0.093466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416944 \n",
      "\n",
      "Epoch 4768\n",
      "-------------------------------\n",
      "loss: 0.104448  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.408813 \n",
      "\n",
      "Epoch 4769\n",
      "-------------------------------\n",
      "loss: 0.108414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406299 \n",
      "\n",
      "Epoch 4770\n",
      "-------------------------------\n",
      "loss: 0.093892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407227 \n",
      "\n",
      "Epoch 4771\n",
      "-------------------------------\n",
      "loss: 0.103774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408708 \n",
      "\n",
      "Epoch 4772\n",
      "-------------------------------\n",
      "loss: 0.095875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410116 \n",
      "\n",
      "Epoch 4773\n",
      "-------------------------------\n",
      "loss: 0.092580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410686 \n",
      "\n",
      "Epoch 4774\n",
      "-------------------------------\n",
      "loss: 0.088530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409830 \n",
      "\n",
      "Epoch 4775\n",
      "-------------------------------\n",
      "loss: 0.103143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408198 \n",
      "\n",
      "Epoch 4776\n",
      "-------------------------------\n",
      "loss: 0.101327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406283 \n",
      "\n",
      "Epoch 4777\n",
      "-------------------------------\n",
      "loss: 0.129426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405421 \n",
      "\n",
      "Epoch 4778\n",
      "-------------------------------\n",
      "loss: 0.097167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407180 \n",
      "\n",
      "Epoch 4779\n",
      "-------------------------------\n",
      "loss: 0.104676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413023 \n",
      "\n",
      "Epoch 4780\n",
      "-------------------------------\n",
      "loss: 0.097355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417198 \n",
      "\n",
      "Epoch 4781\n",
      "-------------------------------\n",
      "loss: 0.098430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412585 \n",
      "\n",
      "Epoch 4782\n",
      "-------------------------------\n",
      "loss: 0.088813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410480 \n",
      "\n",
      "Epoch 4783\n",
      "-------------------------------\n",
      "loss: 0.086048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411349 \n",
      "\n",
      "Epoch 4784\n",
      "-------------------------------\n",
      "loss: 0.094472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411572 \n",
      "\n",
      "Epoch 4785\n",
      "-------------------------------\n",
      "loss: 0.120125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412511 \n",
      "\n",
      "Epoch 4786\n",
      "-------------------------------\n",
      "loss: 0.092698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411312 \n",
      "\n",
      "Epoch 4787\n",
      "-------------------------------\n",
      "loss: 0.107091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410531 \n",
      "\n",
      "Epoch 4788\n",
      "-------------------------------\n",
      "loss: 0.088473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410063 \n",
      "\n",
      "Epoch 4789\n",
      "-------------------------------\n",
      "loss: 0.105183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409955 \n",
      "\n",
      "Epoch 4790\n",
      "-------------------------------\n",
      "loss: 0.097426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413149 \n",
      "\n",
      "Epoch 4791\n",
      "-------------------------------\n",
      "loss: 0.094542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416481 \n",
      "\n",
      "Epoch 4792\n",
      "-------------------------------\n",
      "loss: 0.102623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420808 \n",
      "\n",
      "Epoch 4793\n",
      "-------------------------------\n",
      "loss: 0.101854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423255 \n",
      "\n",
      "Epoch 4794\n",
      "-------------------------------\n",
      "loss: 0.111253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424292 \n",
      "\n",
      "Epoch 4795\n",
      "-------------------------------\n",
      "loss: 0.107013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421058 \n",
      "\n",
      "Epoch 4796\n",
      "-------------------------------\n",
      "loss: 0.105054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414368 \n",
      "\n",
      "Epoch 4797\n",
      "-------------------------------\n",
      "loss: 0.097010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408688 \n",
      "\n",
      "Epoch 4798\n",
      "-------------------------------\n",
      "loss: 0.094627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406332 \n",
      "\n",
      "Epoch 4799\n",
      "-------------------------------\n",
      "loss: 0.105107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407084 \n",
      "\n",
      "Epoch 4800\n",
      "-------------------------------\n",
      "loss: 0.098154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408412 \n",
      "\n",
      "Epoch 4801\n",
      "-------------------------------\n",
      "loss: 0.099430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411647 \n",
      "\n",
      "Epoch 4802\n",
      "-------------------------------\n",
      "loss: 0.103870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415426 \n",
      "\n",
      "Epoch 4803\n",
      "-------------------------------\n",
      "loss: 0.091149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418332 \n",
      "\n",
      "Epoch 4804\n",
      "-------------------------------\n",
      "loss: 0.103835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422214 \n",
      "\n",
      "Epoch 4805\n",
      "-------------------------------\n",
      "loss: 0.103439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419770 \n",
      "\n",
      "Epoch 4806\n",
      "-------------------------------\n",
      "loss: 0.102944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415375 \n",
      "\n",
      "Epoch 4807\n",
      "-------------------------------\n",
      "loss: 0.105527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412428 \n",
      "\n",
      "Epoch 4808\n",
      "-------------------------------\n",
      "loss: 0.104979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410478 \n",
      "\n",
      "Epoch 4809\n",
      "-------------------------------\n",
      "loss: 0.093581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410792 \n",
      "\n",
      "Epoch 4810\n",
      "-------------------------------\n",
      "loss: 0.097160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411903 \n",
      "\n",
      "Epoch 4811\n",
      "-------------------------------\n",
      "loss: 0.090988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412393 \n",
      "\n",
      "Epoch 4812\n",
      "-------------------------------\n",
      "loss: 0.114731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414564 \n",
      "\n",
      "Epoch 4813\n",
      "-------------------------------\n",
      "loss: 0.093106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417087 \n",
      "\n",
      "Epoch 4814\n",
      "-------------------------------\n",
      "loss: 0.091772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417003 \n",
      "\n",
      "Epoch 4815\n",
      "-------------------------------\n",
      "loss: 0.095839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414110 \n",
      "\n",
      "Epoch 4816\n",
      "-------------------------------\n",
      "loss: 0.094379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412677 \n",
      "\n",
      "Epoch 4817\n",
      "-------------------------------\n",
      "loss: 0.093489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414202 \n",
      "\n",
      "Epoch 4818\n",
      "-------------------------------\n",
      "loss: 0.096724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417988 \n",
      "\n",
      "Epoch 4819\n",
      "-------------------------------\n",
      "loss: 0.099457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419998 \n",
      "\n",
      "Epoch 4820\n",
      "-------------------------------\n",
      "loss: 0.106443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417209 \n",
      "\n",
      "Epoch 4821\n",
      "-------------------------------\n",
      "loss: 0.099114  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412780 \n",
      "\n",
      "Epoch 4822\n",
      "-------------------------------\n",
      "loss: 0.104895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410510 \n",
      "\n",
      "Epoch 4823\n",
      "-------------------------------\n",
      "loss: 0.098268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408400 \n",
      "\n",
      "Epoch 4824\n",
      "-------------------------------\n",
      "loss: 0.097960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409336 \n",
      "\n",
      "Epoch 4825\n",
      "-------------------------------\n",
      "loss: 0.096629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408821 \n",
      "\n",
      "Epoch 4826\n",
      "-------------------------------\n",
      "loss: 0.099503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403371 \n",
      "\n",
      "Epoch 4827\n",
      "-------------------------------\n",
      "loss: 0.098839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399210 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 4828\n",
      "-------------------------------\n",
      "loss: 0.097025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398955 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 4829\n",
      "-------------------------------\n",
      "loss: 0.083156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401994 \n",
      "\n",
      "Epoch 4830\n",
      "-------------------------------\n",
      "loss: 0.097128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405987 \n",
      "\n",
      "Epoch 4831\n",
      "-------------------------------\n",
      "loss: 0.102771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408919 \n",
      "\n",
      "Epoch 4832\n",
      "-------------------------------\n",
      "loss: 0.091633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412141 \n",
      "\n",
      "Epoch 4833\n",
      "-------------------------------\n",
      "loss: 0.099932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415825 \n",
      "\n",
      "Epoch 4834\n",
      "-------------------------------\n",
      "loss: 0.096018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414525 \n",
      "\n",
      "Epoch 4835\n",
      "-------------------------------\n",
      "loss: 0.094617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410003 \n",
      "\n",
      "Epoch 4836\n",
      "-------------------------------\n",
      "loss: 0.096314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403999 \n",
      "\n",
      "Epoch 4837\n",
      "-------------------------------\n",
      "loss: 0.089555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403328 \n",
      "\n",
      "Epoch 4838\n",
      "-------------------------------\n",
      "loss: 0.105381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404737 \n",
      "\n",
      "Epoch 4839\n",
      "-------------------------------\n",
      "loss: 0.086922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407633 \n",
      "\n",
      "Epoch 4840\n",
      "-------------------------------\n",
      "loss: 0.092028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411877 \n",
      "\n",
      "Epoch 4841\n",
      "-------------------------------\n",
      "loss: 0.098799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414535 \n",
      "\n",
      "Epoch 4842\n",
      "-------------------------------\n",
      "loss: 0.101542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417082 \n",
      "\n",
      "Epoch 4843\n",
      "-------------------------------\n",
      "loss: 0.093408  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.417853 \n",
      "\n",
      "Epoch 4844\n",
      "-------------------------------\n",
      "loss: 0.098839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416789 \n",
      "\n",
      "Epoch 4845\n",
      "-------------------------------\n",
      "loss: 0.100488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415955 \n",
      "\n",
      "Epoch 4846\n",
      "-------------------------------\n",
      "loss: 0.095550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413849 \n",
      "\n",
      "Epoch 4847\n",
      "-------------------------------\n",
      "loss: 0.103984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413047 \n",
      "\n",
      "Epoch 4848\n",
      "-------------------------------\n",
      "loss: 0.108615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412661 \n",
      "\n",
      "Epoch 4849\n",
      "-------------------------------\n",
      "loss: 0.110189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411637 \n",
      "\n",
      "Epoch 4850\n",
      "-------------------------------\n",
      "loss: 0.099608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409423 \n",
      "\n",
      "Epoch 4851\n",
      "-------------------------------\n",
      "loss: 0.103088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406978 \n",
      "\n",
      "Epoch 4852\n",
      "-------------------------------\n",
      "loss: 0.101891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405959 \n",
      "\n",
      "Epoch 4853\n",
      "-------------------------------\n",
      "loss: 0.099801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407788 \n",
      "\n",
      "Epoch 4854\n",
      "-------------------------------\n",
      "loss: 0.098298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410013 \n",
      "\n",
      "Epoch 4855\n",
      "-------------------------------\n",
      "loss: 0.099655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411675 \n",
      "\n",
      "Epoch 4856\n",
      "-------------------------------\n",
      "loss: 0.106078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415621 \n",
      "\n",
      "Epoch 4857\n",
      "-------------------------------\n",
      "loss: 0.103058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417456 \n",
      "\n",
      "Epoch 4858\n",
      "-------------------------------\n",
      "loss: 0.116922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417982 \n",
      "\n",
      "Epoch 4859\n",
      "-------------------------------\n",
      "loss: 0.104214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414651 \n",
      "\n",
      "Epoch 4860\n",
      "-------------------------------\n",
      "loss: 0.113679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411405 \n",
      "\n",
      "Epoch 4861\n",
      "-------------------------------\n",
      "loss: 0.114595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409357 \n",
      "\n",
      "Epoch 4862\n",
      "-------------------------------\n",
      "loss: 0.100620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408394 \n",
      "\n",
      "Epoch 4863\n",
      "-------------------------------\n",
      "loss: 0.100929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410016 \n",
      "\n",
      "Epoch 4864\n",
      "-------------------------------\n",
      "loss: 0.104299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415483 \n",
      "\n",
      "Epoch 4865\n",
      "-------------------------------\n",
      "loss: 0.098280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423815 \n",
      "\n",
      "Epoch 4866\n",
      "-------------------------------\n",
      "loss: 0.094793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430682 \n",
      "\n",
      "Epoch 4867\n",
      "-------------------------------\n",
      "loss: 0.095105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432797 \n",
      "\n",
      "Epoch 4868\n",
      "-------------------------------\n",
      "loss: 0.113064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431732 \n",
      "\n",
      "Epoch 4869\n",
      "-------------------------------\n",
      "loss: 0.109214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429214 \n",
      "\n",
      "Epoch 4870\n",
      "-------------------------------\n",
      "loss: 0.087180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424277 \n",
      "\n",
      "Epoch 4871\n",
      "-------------------------------\n",
      "loss: 0.098168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420318 \n",
      "\n",
      "Epoch 4872\n",
      "-------------------------------\n",
      "loss: 0.089912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419083 \n",
      "\n",
      "Epoch 4873\n",
      "-------------------------------\n",
      "loss: 0.093675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415871 \n",
      "\n",
      "Epoch 4874\n",
      "-------------------------------\n",
      "loss: 0.127812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412108 \n",
      "\n",
      "Epoch 4875\n",
      "-------------------------------\n",
      "loss: 0.096689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411926 \n",
      "\n",
      "Epoch 4876\n",
      "-------------------------------\n",
      "loss: 0.101334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413561 \n",
      "\n",
      "Epoch 4877\n",
      "-------------------------------\n",
      "loss: 0.098137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412670 \n",
      "\n",
      "Epoch 4878\n",
      "-------------------------------\n",
      "loss: 0.099964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410620 \n",
      "\n",
      "Epoch 4879\n",
      "-------------------------------\n",
      "loss: 0.095643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409102 \n",
      "\n",
      "Epoch 4880\n",
      "-------------------------------\n",
      "loss: 0.089688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409631 \n",
      "\n",
      "Epoch 4881\n",
      "-------------------------------\n",
      "loss: 0.089148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409601 \n",
      "\n",
      "Epoch 4882\n",
      "-------------------------------\n",
      "loss: 0.098067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409064 \n",
      "\n",
      "Epoch 4883\n",
      "-------------------------------\n",
      "loss: 0.116418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407969 \n",
      "\n",
      "Epoch 4884\n",
      "-------------------------------\n",
      "loss: 0.119144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410181 \n",
      "\n",
      "Epoch 4885\n",
      "-------------------------------\n",
      "loss: 0.090245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413522 \n",
      "\n",
      "Epoch 4886\n",
      "-------------------------------\n",
      "loss: 0.086434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416867 \n",
      "\n",
      "Epoch 4887\n",
      "-------------------------------\n",
      "loss: 0.094172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417529 \n",
      "\n",
      "Epoch 4888\n",
      "-------------------------------\n",
      "loss: 0.096857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417949 \n",
      "\n",
      "Epoch 4889\n",
      "-------------------------------\n",
      "loss: 0.113209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418489 \n",
      "\n",
      "Epoch 4890\n",
      "-------------------------------\n",
      "loss: 0.091148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420042 \n",
      "\n",
      "Epoch 4891\n",
      "-------------------------------\n",
      "loss: 0.094965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421665 \n",
      "\n",
      "Epoch 4892\n",
      "-------------------------------\n",
      "loss: 0.088699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421663 \n",
      "\n",
      "Epoch 4893\n",
      "-------------------------------\n",
      "loss: 0.091055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416627 \n",
      "\n",
      "Epoch 4894\n",
      "-------------------------------\n",
      "loss: 0.100660  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410565 \n",
      "\n",
      "Epoch 4895\n",
      "-------------------------------\n",
      "loss: 0.103157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404595 \n",
      "\n",
      "Epoch 4896\n",
      "-------------------------------\n",
      "loss: 0.098008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404878 \n",
      "\n",
      "Epoch 4897\n",
      "-------------------------------\n",
      "loss: 0.099921  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407409 \n",
      "\n",
      "Epoch 4898\n",
      "-------------------------------\n",
      "loss: 0.106719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412616 \n",
      "\n",
      "Epoch 4899\n",
      "-------------------------------\n",
      "loss: 0.096926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415050 \n",
      "\n",
      "Epoch 4900\n",
      "-------------------------------\n",
      "loss: 0.102825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416921 \n",
      "\n",
      "Epoch 4901\n",
      "-------------------------------\n",
      "loss: 0.109523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418640 \n",
      "\n",
      "Epoch 4902\n",
      "-------------------------------\n",
      "loss: 0.128653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419228 \n",
      "\n",
      "Epoch 4903\n",
      "-------------------------------\n",
      "loss: 0.101017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418596 \n",
      "\n",
      "Epoch 4904\n",
      "-------------------------------\n",
      "loss: 0.112381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415351 \n",
      "\n",
      "Epoch 4905\n",
      "-------------------------------\n",
      "loss: 0.104255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411533 \n",
      "\n",
      "Epoch 4906\n",
      "-------------------------------\n",
      "loss: 0.094206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409426 \n",
      "\n",
      "Epoch 4907\n",
      "-------------------------------\n",
      "loss: 0.090457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414254 \n",
      "\n",
      "Epoch 4908\n",
      "-------------------------------\n",
      "loss: 0.098110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417300 \n",
      "\n",
      "Epoch 4909\n",
      "-------------------------------\n",
      "loss: 0.097770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417202 \n",
      "\n",
      "Epoch 4910\n",
      "-------------------------------\n",
      "loss: 0.123253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415624 \n",
      "\n",
      "Epoch 4911\n",
      "-------------------------------\n",
      "loss: 0.092142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417940 \n",
      "\n",
      "Epoch 4912\n",
      "-------------------------------\n",
      "loss: 0.114822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418559 \n",
      "\n",
      "Epoch 4913\n",
      "-------------------------------\n",
      "loss: 0.096975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416604 \n",
      "\n",
      "Epoch 4914\n",
      "-------------------------------\n",
      "loss: 0.096505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412955 \n",
      "\n",
      "Epoch 4915\n",
      "-------------------------------\n",
      "loss: 0.103426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411561 \n",
      "\n",
      "Epoch 4916\n",
      "-------------------------------\n",
      "loss: 0.104088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414388 \n",
      "\n",
      "Epoch 4917\n",
      "-------------------------------\n",
      "loss: 0.096164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415682 \n",
      "\n",
      "Epoch 4918\n",
      "-------------------------------\n",
      "loss: 0.104254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417325 \n",
      "\n",
      "Epoch 4919\n",
      "-------------------------------\n",
      "loss: 0.097520  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.416238 \n",
      "\n",
      "Epoch 4920\n",
      "-------------------------------\n",
      "loss: 0.090999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415649 \n",
      "\n",
      "Epoch 4921\n",
      "-------------------------------\n",
      "loss: 0.099799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415118 \n",
      "\n",
      "Epoch 4922\n",
      "-------------------------------\n",
      "loss: 0.094965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412923 \n",
      "\n",
      "Epoch 4923\n",
      "-------------------------------\n",
      "loss: 0.108881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407791 \n",
      "\n",
      "Epoch 4924\n",
      "-------------------------------\n",
      "loss: 0.107160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405230 \n",
      "\n",
      "Epoch 4925\n",
      "-------------------------------\n",
      "loss: 0.096727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403123 \n",
      "\n",
      "Epoch 4926\n",
      "-------------------------------\n",
      "loss: 0.112485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402282 \n",
      "\n",
      "Epoch 4927\n",
      "-------------------------------\n",
      "loss: 0.104222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403142 \n",
      "\n",
      "Epoch 4928\n",
      "-------------------------------\n",
      "loss: 0.098389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407346 \n",
      "\n",
      "Epoch 4929\n",
      "-------------------------------\n",
      "loss: 0.097513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411769 \n",
      "\n",
      "Epoch 4930\n",
      "-------------------------------\n",
      "loss: 0.097337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415286 \n",
      "\n",
      "Epoch 4931\n",
      "-------------------------------\n",
      "loss: 0.104930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416986 \n",
      "\n",
      "Epoch 4932\n",
      "-------------------------------\n",
      "loss: 0.089108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419240 \n",
      "\n",
      "Epoch 4933\n",
      "-------------------------------\n",
      "loss: 0.085680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420490 \n",
      "\n",
      "Epoch 4934\n",
      "-------------------------------\n",
      "loss: 0.102337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417416 \n",
      "\n",
      "Epoch 4935\n",
      "-------------------------------\n",
      "loss: 0.117666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411003 \n",
      "\n",
      "Epoch 4936\n",
      "-------------------------------\n",
      "loss: 0.100924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407389 \n",
      "\n",
      "Epoch 4937\n",
      "-------------------------------\n",
      "loss: 0.106269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408096 \n",
      "\n",
      "Epoch 4938\n",
      "-------------------------------\n",
      "loss: 0.095208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411264 \n",
      "\n",
      "Epoch 4939\n",
      "-------------------------------\n",
      "loss: 0.103138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411037 \n",
      "\n",
      "Epoch 4940\n",
      "-------------------------------\n",
      "loss: 0.095819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410875 \n",
      "\n",
      "Epoch 4941\n",
      "-------------------------------\n",
      "loss: 0.090708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411768 \n",
      "\n",
      "Epoch 4942\n",
      "-------------------------------\n",
      "loss: 0.113063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412123 \n",
      "\n",
      "Epoch 4943\n",
      "-------------------------------\n",
      "loss: 0.097478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411454 \n",
      "\n",
      "Epoch 4944\n",
      "-------------------------------\n",
      "loss: 0.102864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410107 \n",
      "\n",
      "Epoch 4945\n",
      "-------------------------------\n",
      "loss: 0.097909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410939 \n",
      "\n",
      "Epoch 4946\n",
      "-------------------------------\n",
      "loss: 0.085920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415064 \n",
      "\n",
      "Epoch 4947\n",
      "-------------------------------\n",
      "loss: 0.107486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419697 \n",
      "\n",
      "Epoch 4948\n",
      "-------------------------------\n",
      "loss: 0.098104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415937 \n",
      "\n",
      "Epoch 4949\n",
      "-------------------------------\n",
      "loss: 0.105197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408216 \n",
      "\n",
      "Epoch 4950\n",
      "-------------------------------\n",
      "loss: 0.097232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408525 \n",
      "\n",
      "Epoch 4951\n",
      "-------------------------------\n",
      "loss: 0.089102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413906 \n",
      "\n",
      "Epoch 4952\n",
      "-------------------------------\n",
      "loss: 0.099692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415716 \n",
      "\n",
      "Epoch 4953\n",
      "-------------------------------\n",
      "loss: 0.094610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412107 \n",
      "\n",
      "Epoch 4954\n",
      "-------------------------------\n",
      "loss: 0.108023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410845 \n",
      "\n",
      "Epoch 4955\n",
      "-------------------------------\n",
      "loss: 0.096591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415339 \n",
      "\n",
      "Epoch 4956\n",
      "-------------------------------\n",
      "loss: 0.112973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423543 \n",
      "\n",
      "Epoch 4957\n",
      "-------------------------------\n",
      "loss: 0.102455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427650 \n",
      "\n",
      "Epoch 4958\n",
      "-------------------------------\n",
      "loss: 0.094926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425742 \n",
      "\n",
      "Epoch 4959\n",
      "-------------------------------\n",
      "loss: 0.097755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420319 \n",
      "\n",
      "Epoch 4960\n",
      "-------------------------------\n",
      "loss: 0.114811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416160 \n",
      "\n",
      "Epoch 4961\n",
      "-------------------------------\n",
      "loss: 0.105861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413942 \n",
      "\n",
      "Epoch 4962\n",
      "-------------------------------\n",
      "loss: 0.104079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412982 \n",
      "\n",
      "Epoch 4963\n",
      "-------------------------------\n",
      "loss: 0.092591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411421 \n",
      "\n",
      "Epoch 4964\n",
      "-------------------------------\n",
      "loss: 0.094538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412871 \n",
      "\n",
      "Epoch 4965\n",
      "-------------------------------\n",
      "loss: 0.096516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415270 \n",
      "\n",
      "Epoch 4966\n",
      "-------------------------------\n",
      "loss: 0.108299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415647 \n",
      "\n",
      "Epoch 4967\n",
      "-------------------------------\n",
      "loss: 0.100149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413457 \n",
      "\n",
      "Epoch 4968\n",
      "-------------------------------\n",
      "loss: 0.109126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411763 \n",
      "\n",
      "Epoch 4969\n",
      "-------------------------------\n",
      "loss: 0.093093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414152 \n",
      "\n",
      "Epoch 4970\n",
      "-------------------------------\n",
      "loss: 0.103992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422799 \n",
      "\n",
      "Epoch 4971\n",
      "-------------------------------\n",
      "loss: 0.099820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427653 \n",
      "\n",
      "Epoch 4972\n",
      "-------------------------------\n",
      "loss: 0.109232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428219 \n",
      "\n",
      "Epoch 4973\n",
      "-------------------------------\n",
      "loss: 0.098858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424654 \n",
      "\n",
      "Epoch 4974\n",
      "-------------------------------\n",
      "loss: 0.110166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418421 \n",
      "\n",
      "Epoch 4975\n",
      "-------------------------------\n",
      "loss: 0.090875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411885 \n",
      "\n",
      "Epoch 4976\n",
      "-------------------------------\n",
      "loss: 0.097399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409528 \n",
      "\n",
      "Epoch 4977\n",
      "-------------------------------\n",
      "loss: 0.087366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412181 \n",
      "\n",
      "Epoch 4978\n",
      "-------------------------------\n",
      "loss: 0.113139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414576 \n",
      "\n",
      "Epoch 4979\n",
      "-------------------------------\n",
      "loss: 0.095088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416657 \n",
      "\n",
      "Epoch 4980\n",
      "-------------------------------\n",
      "loss: 0.095106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416626 \n",
      "\n",
      "Epoch 4981\n",
      "-------------------------------\n",
      "loss: 0.115377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411973 \n",
      "\n",
      "Epoch 4982\n",
      "-------------------------------\n",
      "loss: 0.098278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408984 \n",
      "\n",
      "Epoch 4983\n",
      "-------------------------------\n",
      "loss: 0.093573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410187 \n",
      "\n",
      "Epoch 4984\n",
      "-------------------------------\n",
      "loss: 0.095585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412364 \n",
      "\n",
      "Epoch 4985\n",
      "-------------------------------\n",
      "loss: 0.098816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414209 \n",
      "\n",
      "Epoch 4986\n",
      "-------------------------------\n",
      "loss: 0.113827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416105 \n",
      "\n",
      "Epoch 4987\n",
      "-------------------------------\n",
      "loss: 0.104568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417157 \n",
      "\n",
      "Epoch 4988\n",
      "-------------------------------\n",
      "loss: 0.097210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418357 \n",
      "\n",
      "Epoch 4989\n",
      "-------------------------------\n",
      "loss: 0.096751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418895 \n",
      "\n",
      "Epoch 4990\n",
      "-------------------------------\n",
      "loss: 0.102049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414755 \n",
      "\n",
      "Epoch 4991\n",
      "-------------------------------\n",
      "loss: 0.101734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409434 \n",
      "\n",
      "Epoch 4992\n",
      "-------------------------------\n",
      "loss: 0.104095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408414 \n",
      "\n",
      "Epoch 4993\n",
      "-------------------------------\n",
      "loss: 0.095293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410428 \n",
      "\n",
      "Epoch 4994\n",
      "-------------------------------\n",
      "loss: 0.109426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414501 \n",
      "\n",
      "Epoch 4995\n",
      "-------------------------------\n",
      "loss: 0.092772  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.418186 \n",
      "\n",
      "Epoch 4996\n",
      "-------------------------------\n",
      "loss: 0.112520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420890 \n",
      "\n",
      "Epoch 4997\n",
      "-------------------------------\n",
      "loss: 0.094859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.424246 \n",
      "\n",
      "Epoch 4998\n",
      "-------------------------------\n",
      "loss: 0.104515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426692 \n",
      "\n",
      "Epoch 4999\n",
      "-------------------------------\n",
      "loss: 0.110017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423361 \n",
      "\n",
      "Epoch 5000\n",
      "-------------------------------\n",
      "loss: 0.090034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418558 \n",
      "\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 49 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 49 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-38/metadata\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if optChoice == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "elif optChoice == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "else:\n",
    "    optimizer = None\n",
    "    print('no optimizer chosen...')\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=neptuneProject,\n",
    "    api_token=api_token,  \n",
    "    capture_hardware_metrics=True,\n",
    "    capture_stderr=True,\n",
    "    capture_stdout=True,\n",
    ")\n",
    "\n",
    "PARAMS = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": learningRate,\n",
    "    \"optimizer\": optChoice,\n",
    "    \"patience\": patience,\n",
    "    \"subsampleFreq\": subsampleFreq,\n",
    "    \"secondsInWindow\": secondsInWindow,\n",
    "    \"nperseg\": nperseg,\n",
    "    \"noverlap\": noverlap,\n",
    "    \"window\": stringify_unsupported(window),\n",
    "    \"loss_fn\": stringify_unsupported(loss_fn),\n",
    "    \"architectureString\": str(model),\n",
    "    \"numParameters\": count_parameters(model)\n",
    "}\n",
    "run[\"parameters\"] = PARAMS\n",
    "\n",
    "noImprovementCount = 0\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(trainDataLoader, model, loss_fn, optimizer)\n",
    "    test_loss = test(validDataLoader, model, loss_fn)\n",
    "    \n",
    "    if test_loss < bestTestLoss:\n",
    "        noImprovementCount = 0\n",
    "        bestTestLoss = test_loss\n",
    "        torch.save(model, modelPath)\n",
    "        run[\"model_best\"].upload(modelPath)\n",
    "        run[\"best_test_loss\"] =  bestTestLoss\n",
    "        run[\"best_test_epoch\"] = t\n",
    "        print(\"\\nSaved a new best model!\\n\")\n",
    "    else:\n",
    "        noImprovementCount = noImprovementCount + 1\n",
    "        \n",
    "    run[\"train/loss\"].append(train_loss)\n",
    "    run[\"test/loss\"].append(test_loss)\n",
    "    \n",
    "    if noImprovementCount >= patience:   \n",
    "        print(\"Early stopping invoked....\")\n",
    "        break\n",
    "        \n",
    "run.stop()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3474b",
   "metadata": {},
   "source": [
    "# PLOT RESULTS OF FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a858773f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT PREDICTION VERSUS TRUTH\n",
    "\n",
    "trainPlotFlag = True\n",
    "    \n",
    "if trainPlotFlag:\n",
    "    x = trainXTensor\n",
    "    trainTitle = 'train'\n",
    "else:\n",
    "    x = validXTensor\n",
    "    trainTitle = 'valididation'\n",
    "\n",
    "model.to('cpu')\n",
    "predict = model(x).cpu().detach().numpy()\n",
    "model.to(device)\n",
    "\n",
    "if predict.shape[1] == 1:\n",
    "    yPred = predict[:,0]\n",
    "    if trainPlotFlag:\n",
    "        yTrue = yTrainTimeDomain[:,0]\n",
    "    else:\n",
    "        yTrue = yValidTimeDomain[:,0]\n",
    "else:\n",
    "    _, yPred = realSTFTtoTimeSeries(predict)\n",
    "    if trainPlotFlag:\n",
    "        y = y_trainRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "    else:\n",
    "        y = y_validRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "        \n",
    "\n",
    "lossTemp = loss_fn(torch.tensor(yPred), torch.tensor(yTrue)).item()\n",
    "title = 'Data: ' + trainTitle + ' (loss: %s)' % str(lossTemp)\n",
    "plt.figure()\n",
    "plt.plot(yPred, label='predict')\n",
    "plt.plot(yTrue, label='true')\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671c8d3",
   "metadata": {},
   "source": [
    "# SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c14b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "fs = 1\n",
    "nperseg = 32\n",
    "noverlap = 31\n",
    "#windowType = ('tukey', .25)\n",
    "windowType = np.ones(nperseg)\n",
    "\n",
    "\n",
    "a = np.random.rand(100)\n",
    "f, t, S = stft(a, fs=fs, window=windowType, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "b = torch.stft(torch.tensor(a), \n",
    "               n_fft = nperseg, \n",
    "               hop_length = 1, \n",
    "               return_complex=True, \n",
    "               normalized=False, \n",
    "               onesided=True, \n",
    "               pad_mode='constant').numpy()\n",
    "\n",
    "np.abs(np.divide(b,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO GRAB DATA FROM NEPTUNE\n",
    "\n",
    "project = neptune.init_project(project=\"jettinger35/predictScalp\")\n",
    "df = project.fetch_runs_table().to_pandas()\n",
    "df[['sys/id','best_test_loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d95ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00960736, 0.03806023, 0.08426519, 0.14644661,\n",
       "       0.22221488, 0.30865828, 0.40245484, 0.5       , 0.59754516,\n",
       "       0.69134172, 0.77778512, 0.85355339, 0.91573481, 0.96193977,\n",
       "       0.99039264, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.99039264, 0.96193977,\n",
       "       0.91573481, 0.85355339, 0.77778512, 0.69134172, 0.59754516,\n",
       "       0.5       , 0.40245484, 0.30865828, 0.22221488, 0.14644661,\n",
       "       0.08426519, 0.03806023, 0.00960736])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import get_window\n",
    "a = get_window(('tukey', .25), nperseg)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0c6db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.13",
   "language": "python",
   "name": "pytorch-1.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
