{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d3475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "import scalpDeepModels as sdm\n",
    "\n",
    "import importlib\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef38d8",
   "metadata": {},
   "source": [
    "# PARAMETERS - GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f63db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "stftSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/freqRTheta.npz'\n",
    "timeDomainSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeDomain.npz'\n",
    "timeFreqSavePath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/timeFreqRTheta.npz'\n",
    "\n",
    "modelPath = '/blue/gkalamangalam/jmark.ettinger/predictScalp/pytorchModels/'\n",
    "\n",
    "neptuneProject = 'jettinger35/predictScalp'\n",
    "api_token = os.environ.get('NEPTUNE_API_TOKEN')\n",
    "\n",
    "subsampleFreq = 128   # FINAL FREQUENCY IN HERTZ AFTER SUBSAMPLING\n",
    "secondsInWindow = 1\n",
    "nperseg = subsampleFreq * secondsInWindow\n",
    "noverlap = nperseg - 1\n",
    "window = ('tukey', .25)\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7fce9",
   "metadata": {},
   "source": [
    "# PARAMETERS - TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224077ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 1024\n",
    "learningRate = 1e-3\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "optChoice = 'adam'\n",
    "\n",
    "patience = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6db8c0",
   "metadata": {},
   "source": [
    "# UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7e2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT STFT FROM R,THETA TO COMPLEX\n",
    "# dim(z) = (# timesteps, # freq bins x 2 (2 reals = 1 complex))\n",
    "\n",
    "def rThetaToComplex(z):\n",
    "    rows, cols = z.shape\n",
    "    shortTermFourier = np.zeros((rows, cols // 2), dtype=np.csingle)\n",
    "    for i in range(rows):\n",
    "        for k in range(cols // 2):\n",
    "            r = z[i,k]\n",
    "            theta = z[i, (k + cols // 2)]\n",
    "            shortTermFourier[i,k] =  r * np.exp(complex(0, theta))\n",
    "    return shortTermFourier.transpose() # dim = (# freq bins, # timepoints)\n",
    "\n",
    "# CONVERT REAL STFT TO COMPLEX STFT, INVERT TO GET THE ISTFT (I.E. TIME SERIES), THEN PLOT\n",
    "\n",
    "def realSTFTtoTimeSeries(realSTFT):\n",
    "    shortTermFourierComplex = rThetaToComplex(realSTFT)\n",
    "    times, inverseShortFourier = istft(shortTermFourierComplex, \n",
    "                                       fs=subsampleFreq, \n",
    "                                       window=window, \n",
    "                                       nperseg=nperseg, \n",
    "                                       noverlap=noverlap)\n",
    "    return times, inverseShortFourier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbd749",
   "metadata": {},
   "source": [
    "# LOAD NUMPY DATA ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba4b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSwitch = 'time'\n",
    "\n",
    "if dataSwitch == 'freq':\n",
    "    # STFT DATA\n",
    "\n",
    "    npzfile = np.load(stftSavePath)\n",
    "    x_trainRTheta = npzfile['x_trainRTheta']\n",
    "    x_validRTheta = npzfile['x_validRTheta'] \n",
    "    y_trainRTheta = npzfile['y_trainRTheta'] \n",
    "    y_validRTheta = npzfile['y_validRTheta']\n",
    "\n",
    "    trainXTensor = torch.Tensor(x_trainRTheta)\n",
    "    trainYTensor = torch.Tensor(y_trainRTheta)\n",
    "    validXTensor = torch.Tensor(x_validRTheta)\n",
    "    validYTensor = torch.Tensor(y_validRTheta)\n",
    "\n",
    "elif dataSwitch == 'time':\n",
    "    # TIME DOMAIN DATA\n",
    "\n",
    "    npzfile = np.load(timeDomainSavePath)\n",
    "    xTrainTimeDomain = npzfile['xTrainTimeDomain']\n",
    "    xValidTimeDomain = npzfile['xValidTimeDomain'] \n",
    "    yTrainTimeDomain = npzfile['yTrainTimeDomain'] \n",
    "    yValidTimeDomain = npzfile['yValidTimeDomain']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrainTimeDomain)\n",
    "    trainYTensor = torch.Tensor(yTrainTimeDomain)\n",
    "    validXTensor = torch.Tensor(xValidTimeDomain)\n",
    "    validYTensor = torch.Tensor(yValidTimeDomain)\n",
    "    \n",
    "elif dataSwitch == 'timeFreq':\n",
    "    \n",
    "    npzfile = np.load(timeFreqSavePath)\n",
    "    xTrain = npzfile['x_trainTimeFreq']\n",
    "    xValid = npzfile['x_validTimeFreq'] \n",
    "    yTrain = npzfile['y_trainTimeFreq'] \n",
    "    yValid = npzfile['y_validTimeFreq']\n",
    "\n",
    "    trainXTensor = torch.Tensor(xTrain)\n",
    "    trainYTensor = torch.Tensor(yTrain)\n",
    "    validXTensor = torch.Tensor(xValid)\n",
    "    validYTensor = torch.Tensor(yValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedd53c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 1]) torch.float32\n",
      "\n",
      "test: \n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 5655])\n",
      "Shape of y: torch.Size([1024, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# CREATE PYTORCH DATALOADERS\n",
    "\n",
    "trainDataset = TensorDataset(trainXTensor,trainYTensor)\n",
    "trainDataLoader = DataLoader(trainDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validDataset = TensorDataset(validXTensor,validYTensor)\n",
    "validDataLoader = DataLoader(validDataset,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"train: \")\n",
    "for X, y in trainDataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "print(\"\\ntest: \")\n",
    "for X, y in validDataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243c05c",
   "metadata": {},
   "source": [
    "# DEFINE OR LOAD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeaad9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: 982815\n",
      "Number of parameters:  3963439\n",
      "Sequential(\n",
      "  (bn0): BatchNorm1d(5655, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l0): Linear(in_features=5655, out_features=512, bias=True)\n",
      "  (r0): ReLU()\n",
      "  (d0): Dropout(p=0.5, inplace=False)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r1): ReLU()\n",
      "  (d1): Dropout(p=0.5, inplace=False)\n",
      "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r2): ReLU()\n",
      "  (d2): Dropout(p=0.5, inplace=False)\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r3): ReLU()\n",
      "  (d3): Dropout(p=0.5, inplace=False)\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r4): ReLU()\n",
      "  (d4): Dropout(p=0.5, inplace=False)\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "modelID = None\n",
    "\n",
    "if modelID != None:\n",
    "    model = torch.jit.load(modelPath + 'model_%s.pt' % str(modelID))\n",
    "    bestTestLoss = sdm.test(validDataLoader, model, loss_fn, device)\n",
    "else:\n",
    "    importlib.reload(sdm) # reload in case we've made any architecture changes\n",
    "    \n",
    "    modelID = np.random.randint(0, 10**6)\n",
    "    \n",
    "    # DEFINE ARCHITECTURE HERE\n",
    "    inputSize = trainXTensor.shape[1]\n",
    "    hiddenLayerSizes = [512,512,512,512,512,512]\n",
    "    \n",
    "    layerDict = sdm.listToOrderedDict_1([inputSize] + hiddenLayerSizes)\n",
    "    #layerDict = sdm.residualAddDict(inputSize, 512, 5)\n",
    "    #layerDict = sdm.residualConcatDict(inputSize, hiddenLayerSizes)\n",
    "    \n",
    "    model = nn.Sequential(layerDict)\n",
    "    bestTestLoss = float('inf')\n",
    "    \n",
    "print(\"Model ID: \" + str(modelID))\n",
    "print(\"Number of parameters: \", sdm.count_parameters(model))\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68e5ed",
   "metadata": {},
   "source": [
    "# TRAIN (LOG DATA TO NEPTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c6012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-66\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.829233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.679717 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.757629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.675505 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.798541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.669964 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.777038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.663156 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.698888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.656167 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.746138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.648799 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.739126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.641775 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.677994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.637637 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.718581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.638230 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.692159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.634185 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.686396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.631450 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.684408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.631075 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.689453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.625338 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.646151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.621583 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.631158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.618137 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.665125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.615213 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.653768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.613483 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.640502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.612933 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.638480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.613576 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.645236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.605314 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.621704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.595437 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.634750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.582952 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.592622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.575960 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.594341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.565944 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.618985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.554301 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.588213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.543652 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.597751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.535405 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.587108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.531927 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.566434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.525821 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.589449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.520669 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.604607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.517501 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.560996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.513827 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.530087  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.511120 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.535027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.509348 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.542265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.506184 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.574717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.500585 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.532931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.497076 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.547938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.493331 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.555251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.492168 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.530863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.492733 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.509203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.490837 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.519150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.486567 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.560927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.484449 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.533001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.486884 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.540838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487855 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.510140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487153 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.526427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487195 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.550625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487053 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.507902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.485662 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.488638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.486823 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.501453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.488295 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.510948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.487518 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.514923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.485013 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.493525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.480865 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.492582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.478007 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.527518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.473277 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.505698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.469598 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.493005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.466852 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.502857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.464033 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.478453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.463110 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.493571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.461931 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.448940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.463268 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.479353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.465395 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.464507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.465550 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.483207  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.465547 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.464357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.463298 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.477719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.461513 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.485830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.460736 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.458687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.462277 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.464907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.462778 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.460154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.459822 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.461097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.454711 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.492307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.451280 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.477425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447671 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.467293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.447747 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.458881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.446318 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.462314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445666 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.454846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445667 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.474434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445515 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.455290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444513 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.443264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442174 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.440239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442666 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.438727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444267 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.462324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445141 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.474124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.445289 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.447501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.444547 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.458916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.442982 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.449070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441257 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.453884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.441245 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.434602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.440991 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.436645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439062 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.424196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437964 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.430298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436247 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.434483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435407 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.435115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.436608 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.401457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437705 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.424353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.439185 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.436875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.437099 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.421766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.435116 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.420605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.433393 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.443041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429349 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.447454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427450 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.424714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427483 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.417027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428551 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.427003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428851 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.423848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428574 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.448007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428660 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.424907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429093 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.421124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427578 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.465652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426911 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.423828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426810 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.429750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427656 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.426906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427856 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.435391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427053 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.434502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426605 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.431928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428579 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.423191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432244 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.435864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432060 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.470842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430124 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.426825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427357 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.451083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426160 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.435115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428832 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.429988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431938 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.436286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.432935 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.429190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428893 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.436071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423590 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.414821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420663 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.413176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422743 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.413862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426034 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.411402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.426702 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.438672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422410 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.429274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418869 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.390766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421107 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.428084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.429491 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.430783  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.433386 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.435549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.431005 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.453028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422959 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.442638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413788 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.393823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415867 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.421842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425170 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.414223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.428151 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.442633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423561 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.409549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418465 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.440031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418245 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.421166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423392 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.410377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.427972 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.408565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.430341 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.396065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.425981 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.410724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420051 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.407757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417112 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.409433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415923 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.404343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417862 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.416279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419283 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.412882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419014 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.413624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417288 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.412017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415201 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.443233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415622 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.411867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418229 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.413347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420835 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.402067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.422263 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.424143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421848 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.423987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418812 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.435182  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416736 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.413065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413957 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.418743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412638 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.407356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412136 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.426064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411806 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.391282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411656 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.403640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410531 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.401424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410894 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.403612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411144 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.402783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411065 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.398172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411327 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.404805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411223 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.404519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412082 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.407729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412628 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.416458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411330 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.412392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409926 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.376147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409888 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.413788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410740 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.431203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411059 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.418239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409660 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.423720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406801 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.383075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406128 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.408688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409959 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.438628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412933 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.411999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411908 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.407705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410944 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.408108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415728 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.408588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421485 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.402861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.423383 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.408264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420562 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.391970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416006 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.383619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412187 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.420701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409763 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.407526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409234 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.411545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408737 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.404347  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407472 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.437440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407301 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.395233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409717 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.401836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410654 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.415336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409017 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.403270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407646 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.400258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406140 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.388546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405343 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.378420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404931 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.390330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404898 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.409594  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.405446 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.381952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405767 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.426137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403918 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.388333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403287 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.414971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403797 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.384628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404866 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.392816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405908 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.400754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406275 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.385122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404419 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.377778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403981 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.404784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405517 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.375736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407703 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.395417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408008 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.405307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406245 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.395472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406042 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.413943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413285 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.396912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.420084 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.400878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.419404 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.413329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413627 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.400753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405770 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.379701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408181 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.404413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418941 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.421418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.421880 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.420778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413769 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.386307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408200 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.374785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410562 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.399317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414606 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.406012  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415881 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.413400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414544 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.407958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411547 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.381397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408483 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.400551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405977 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.406262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405318 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.382881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408003 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.396544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410758 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.395781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408965 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.402237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405835 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.356926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406206 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.391436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410555 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.399652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417363 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.402686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418390 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.387021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411085 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.374229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404377 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.383477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404386 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.394993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407080 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.379053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408285 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.400912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407029 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.384700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405889 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.384948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409319 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.392332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414521 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.399072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414621 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.394210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408459 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.411893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404158 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.384416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404681 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.387943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405962 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.400988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405820 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.387170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405598 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.413797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406353 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.378650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407386 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.379657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406219 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.389153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404074 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.395091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403428 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.372906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403731 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.391661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404810 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.404132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405847 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.389375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406425 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.399497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408213 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.389508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409066 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.419641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405419 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.365803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404332 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.375445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403803 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.399701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407017 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.377946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409650 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.382374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409635 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.390661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406713 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.384676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405101 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.381008  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.407723 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.386351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410841 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.366865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410830 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.373037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407158 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.395135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401667 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.412316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398634 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.351128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399135 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.391482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399760 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.388072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399597 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.389166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398239 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.376221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398435 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.367793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399890 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.387201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401049 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.374048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401960 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.384677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402668 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.376620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403455 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.375973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403427 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.392556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402182 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.403324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399573 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.368461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397909 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.392277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398034 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.370736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397795 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.374146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396471 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.357873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396833 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.410720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397723 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.359060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395721 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.377965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394303 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.381294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395150 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.394199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398001 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.382310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400135 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.387605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400190 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.396007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401241 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.365829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404206 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.380888  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404493 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.405764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400506 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.382727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398421 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.374097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402604 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.379199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407527 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.395957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406360 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.387209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399583 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.380898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401221 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.385562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406336 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.359006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409645 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.359267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409271 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.389334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404022 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.369200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399830 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.394087  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400262 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.370737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402523 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.389414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403723 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.379329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400078 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.372020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398639 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.371965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399512 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.372391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401765 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.359080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405711 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.385607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408342 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.377585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407370 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.378103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403810 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.360670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399734 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.374240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396959 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.390108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396542 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.377485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397069 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.370191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396539 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.384303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396839 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.391688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397510 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.345570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395945 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.375733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396372 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.380152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397370 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.372311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397333 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.355477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396124 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.360824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395985 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.370820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395910 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.370296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395376 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.373243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396060 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.381846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397713 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.386191  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397830 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.361890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397619 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.373946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397398 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.400412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397120 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.367069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397861 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.371758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399688 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.393206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402384 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.351129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405739 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.360768  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408577 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.386500  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407172 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.381075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402616 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.366185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402410 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.366752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403960 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.364556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406075 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.369880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405014 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.369063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401466 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.365426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399234 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.368870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398219 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.371124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399266 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.362767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401460 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.348954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400930 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.370343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397904 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.359624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396316 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.372202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396978 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.382568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396376 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.359362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395135 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.366910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395860 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.389170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399394 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.364975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400693 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.365266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398949 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.366926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396089 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.375312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394451 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.363255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394306 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.371818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394811 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.373179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396961 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.358485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398795 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.339384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399904 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.368874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401925 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.372229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401753 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.380496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400877 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.388499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400462 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.356968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400090 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.355938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398261 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.363464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397625 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.348379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399275 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.364499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400554 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.362059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401202 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.355756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399830 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.393036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399636 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.375216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402627 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.362079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410423 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.379665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415290 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.378124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413202 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.369341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403456 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.373817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402060 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.348980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410241 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.373855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415383 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.384716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414573 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.380495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406706 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.380664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402351 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.350503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403937 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.375014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408595 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.364481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409851 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.373403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405513 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.397751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401543 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.361980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402395 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.348740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407216 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.381295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408449 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.388526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405216 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.367534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399870 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.374181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396909 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.359789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399340 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.376851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403570 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.377039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403563 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.363587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401761 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.351812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399832 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.367280  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400148 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.353776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400878 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.372344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401404 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.381031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400412 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.355015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400447 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.357157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401718 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.361782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401677 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.368694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400080 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.372610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398756 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.370607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398345 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.342887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399434 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.371854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400405 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.365583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400667 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.359436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400682 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.358197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400493 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.354856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399163 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.368062  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398313 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.356402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396866 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.373854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395897 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.343101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396746 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.361537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397420 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.368969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396224 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.361443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397123 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.366605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397352 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.376885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397998 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.354985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397410 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.345654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395623 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.356454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393649 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.362880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394216 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.360448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395028 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.369599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397322 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.347575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397121 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.356393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396402 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.365909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400770 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.332970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406478 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.379372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406684 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.352414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404468 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.362572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400462 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.374023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399140 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.342736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400500 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.359008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402773 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.368023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402803 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.358199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400015 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.355618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396640 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.339706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397259 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.353133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402885 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.336856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406264 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.351106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403726 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.343297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399127 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.355407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395864 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.358223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396127 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.358072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397942 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.360379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398183 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.345694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400514 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.357410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402833 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.366380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404762 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.385538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406811 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.350951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404135 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.379742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400523 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.350222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397937 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.360927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397227 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.350612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398378 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.369328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398610 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.363577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396245 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.351491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393947 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.375204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394657 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.361842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397620 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.359563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399433 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.384886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398084 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.353588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396388 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.358470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397150 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.357777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398613 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.341967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399152 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.369537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398011 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.348084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396635 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.341935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395384 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.349295  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.394064 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.359295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394841 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.354126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396777 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.378165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397939 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.367201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396498 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.346504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396443 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.362808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396056 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.352599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395165 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.359943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395136 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.358221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395006 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.361664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395337 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.368364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396687 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.342974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395730 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.365160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394023 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.334300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394441 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.368015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397247 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.354137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399723 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.339930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400330 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.365067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396112 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.348478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393724 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.353796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394799 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.348278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397524 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.364812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398924 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.350913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399395 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.387610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399593 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.347259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404420 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.349067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411149 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.373205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411188 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.336172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405571 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.346263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398281 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.338203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395924 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.363157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398847 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.354780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400142 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.371918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398055 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.346959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396710 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.340163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398977 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.334545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399474 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.343919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399662 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.350757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396476 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.356321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394971 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.359101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395900 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.356040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397645 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.353556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398443 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.344574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394762 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.332333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393214 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.355068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396266 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.350770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401741 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.359761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402075 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.333255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399140 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.344996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395799 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.353120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392637 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.359047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394524 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.345339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397122 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.357314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397441 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.348563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396084 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.360298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397254 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.330536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401381 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.348550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404521 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.350863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404183 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.351796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401591 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.353681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398674 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.383225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396166 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.332439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396267 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.352261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396745 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.344706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397115 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.356904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396090 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.353220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397169 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.344115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401030 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.352555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405338 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.340793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403524 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.350196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398286 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.341754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394842 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.349472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394646 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.329324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395745 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.331294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395853 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.346336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395191 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.346557  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.396760 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.349175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398300 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.358883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398541 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.360936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398076 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.352247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396731 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.342657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395820 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.366579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395937 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.376844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395863 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.349727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396197 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.356555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396208 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.335523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396508 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.352316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397611 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.387802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395749 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.336999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394178 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.360112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393176 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.339184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394767 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.350013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399827 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.347187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403458 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.333456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403076 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.331194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400204 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.342437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396861 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.347906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392041 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.344245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.389841 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.372044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391170 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.319176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394038 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.338059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393919 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.337898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392592 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.341220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391379 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.321092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391814 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.363006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395147 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.340225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398201 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.342811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401182 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.347507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400682 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.358356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398794 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.355232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397243 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.349045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397649 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.349022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400352 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.361991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402067 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.351463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401636 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.337741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399562 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.350339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397153 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.337655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396838 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.347823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397183 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.348583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398307 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.342249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398017 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.323221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397535 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.336972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397209 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.323308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397452 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.328984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397749 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.354233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398169 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.337084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398376 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.351509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398403 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.323314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398512 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.337658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398116 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.346362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398446 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.338471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398349 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.342557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398970 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.339621  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399087 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.338540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398023 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.328601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397307 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.328378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398006 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.339291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399131 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.332991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399608 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.345267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399353 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.354801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396853 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.322386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396596 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.367148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397458 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.326411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397846 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.321771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396984 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.344425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397859 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.324172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401360 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.356122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399709 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.348717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393650 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.345869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392641 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.339016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393891 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.352531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394862 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.336647  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.393927 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.342674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393299 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.348933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396377 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.347349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398484 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.344966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399020 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.349816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394265 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.313084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392480 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.327477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393710 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.352831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395634 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.340656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398114 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.355552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398367 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.353455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396502 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.332142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395920 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.355156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395430 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.341658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394740 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.328625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396599 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.329676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400849 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.332610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401302 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.330591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398018 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.361644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394423 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.330540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396323 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.329088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399966 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.340318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401530 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.348811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398637 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.346840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397003 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.337518  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399283 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.333457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401180 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.352386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399151 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.350103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397685 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.331188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397616 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.334475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396741 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.335263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396193 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.336211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396367 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.331239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395255 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.325562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396583 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.339247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397142 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.350297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398793 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.351441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397870 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.327140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397024 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.342581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398901 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.310375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401465 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.346064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401708 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.333811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400180 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.339269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399020 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.339746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396748 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.339023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394321 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.336226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393987 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.333769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395472 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.336057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397276 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.329019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396807 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.337207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395237 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.342943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396084 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.323597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401618 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.317975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405120 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.332115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404178 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.328313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401403 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.339991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399597 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.344755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395645 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.318085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393444 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.329482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395418 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.342596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398841 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.361945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401948 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.345014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402609 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.335461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400074 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.334687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398093 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.339202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398634 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.348009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401227 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.344819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402291 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.303397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402612 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.347932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401161 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.346945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397848 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.339419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394688 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.309018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394331 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.329537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396331 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.357276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398151 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.329020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398737 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.348211  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.396885 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.307733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395857 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.312056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395653 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.335818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395383 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.343983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395919 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.349392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395805 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.339474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395998 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.326417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394439 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.330355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394373 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.325626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397242 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.335371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400655 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.323397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401804 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.336361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399544 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.311297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395966 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.340387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395318 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.321823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397001 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.327651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399709 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.328584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401362 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.337123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397181 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.332187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395412 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.310954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399082 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.330700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402407 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.332181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401712 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.342643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397296 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.334144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393219 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.321811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393540 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.334570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394444 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.321540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395561 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.321689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395898 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.318957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396256 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.348680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396530 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.326306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398082 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.325341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400086 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.347052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400013 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.357629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398003 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.334383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396047 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.328958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395811 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.309687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396264 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.323310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397792 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.337902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399013 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.328785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400224 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.342883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401632 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.353206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400406 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.332603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398653 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.353228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397014 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.316769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395283 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.348009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394764 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.321631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395546 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.326266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396337 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.335150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398539 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.304497  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398544 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.337870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397118 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.332857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395521 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.343096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396444 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.334870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398835 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.333672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398089 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.348602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397102 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.337629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397213 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.347568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399236 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.338235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399662 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.348688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399194 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.346929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398202 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.326598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396720 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.341204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395702 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.350273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395855 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.332128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397603 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.306461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398984 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.336299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398262 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.325194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398462 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.343928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400274 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.322799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401553 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.342165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402017 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.341205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401137 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.332007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402514 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.324011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404369 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.324698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404491 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.317097  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403979 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.331001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400670 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.314259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396552 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.345943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395313 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.326063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395386 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.326341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394911 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.327994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395272 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.313428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399425 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.345818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405391 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.324392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407053 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.323733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404005 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.326566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396251 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.341492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391168 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.328502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392383 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.337259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393521 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.343939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392956 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.303699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393560 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.330054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394922 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.318580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396141 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.335543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395732 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.332338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395312 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.306790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395443 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.337517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393121 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.316346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392646 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.327899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392480 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.317392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392097 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.316879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394037 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.313043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400686 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.336829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402861 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.310094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399532 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.331247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396077 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.322807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395385 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.333688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396479 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.340654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396358 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.333541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395562 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.320202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398140 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.319489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402074 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.318072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403150 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.315125  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400807 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.332117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397404 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.320638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398762 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.330543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402511 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.321427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402389 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.340312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398110 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.312209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400477 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.327261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406480 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.338152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407760 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.336181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402748 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.329875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396840 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.307159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396039 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.324464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398057 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.320720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397543 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.323492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397001 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.331256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396369 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.312611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398154 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.311770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398728 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.318268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398068 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.315725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396511 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.291142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395487 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.330093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394084 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.299349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394639 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.309543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394932 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.319383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394295 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.321404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395169 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.318922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397331 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.339166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400170 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.312915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400358 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.338300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395877 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.306541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394270 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.326427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396414 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.314721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399526 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.327126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400325 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.314024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400920 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.314965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401146 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.323247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401385 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.324459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400895 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.315347  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399724 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.326286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397868 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.322751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396737 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.307778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396443 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.309435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397019 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.311040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397032 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.330194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396901 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.324192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396512 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.338175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395928 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.329158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394696 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.314176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394637 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.319959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394376 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.321654  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393695 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.316906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394442 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.319834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397112 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.304141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398546 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.322071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399343 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.326149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398594 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.316344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397906 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.296243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396018 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.332928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394728 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.302179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393630 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.309055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.391863 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.333726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392566 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.316975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397777 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.336077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401983 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.335884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402633 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.337414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399537 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.314874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397628 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.313948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400054 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.315346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401192 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.346682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398538 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.323656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396287 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.309723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396168 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.321628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398728 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.319753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400233 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.318958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399714 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.308776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398838 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.315813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398022 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.311554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397932 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.312123  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398179 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.324893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397444 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.336509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397525 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.330129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399896 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.309809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402555 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.312752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402489 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.314433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401790 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.324202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399841 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.324778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398928 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.324679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398708 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.323756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399390 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.331978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400884 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.308951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403792 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.333434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408789 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.316643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412972 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.306136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412064 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.347157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405444 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.318144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399391 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.320271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398171 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.316988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398092 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.326646  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397424 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.312404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397203 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.321016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397603 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.324622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398728 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.309097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400375 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.328798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400899 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.325897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400565 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.317265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400636 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.310726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400650 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.329854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400583 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.298351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401031 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.318724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403904 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.308311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407810 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.320996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409738 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.313612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406357 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.313587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401077 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.305670  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.398603 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.334078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398389 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.328870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398728 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.311814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397855 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.321183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397232 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.321300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398087 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.308409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399793 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.310262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400350 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.306672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400355 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.313571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401748 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.298524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401635 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.299369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399819 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.319371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398733 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.308516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397665 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.338628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395984 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.321428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393858 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.303927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395593 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.342217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397990 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.337567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398639 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.320887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397659 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.301868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395990 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.320781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396302 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.309156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399004 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.323606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399083 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.314240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397579 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.302762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397557 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.323375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398634 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.323127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398128 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.319791  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396099 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.298767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395438 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.293249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396785 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.315343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398233 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.293155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400715 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.317746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401212 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.308333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399840 \n",
      "\n",
      "Epoch 1001\n",
      "-------------------------------\n",
      "loss: 0.317856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397952 \n",
      "\n",
      "Epoch 1002\n",
      "-------------------------------\n",
      "loss: 0.322397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397521 \n",
      "\n",
      "Epoch 1003\n",
      "-------------------------------\n",
      "loss: 0.302782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397718 \n",
      "\n",
      "Epoch 1004\n",
      "-------------------------------\n",
      "loss: 0.323842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397181 \n",
      "\n",
      "Epoch 1005\n",
      "-------------------------------\n",
      "loss: 0.334721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397377 \n",
      "\n",
      "Epoch 1006\n",
      "-------------------------------\n",
      "loss: 0.300503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398841 \n",
      "\n",
      "Epoch 1007\n",
      "-------------------------------\n",
      "loss: 0.291744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401268 \n",
      "\n",
      "Epoch 1008\n",
      "-------------------------------\n",
      "loss: 0.314410  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399942 \n",
      "\n",
      "Epoch 1009\n",
      "-------------------------------\n",
      "loss: 0.304719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398446 \n",
      "\n",
      "Epoch 1010\n",
      "-------------------------------\n",
      "loss: 0.327674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396792 \n",
      "\n",
      "Epoch 1011\n",
      "-------------------------------\n",
      "loss: 0.333243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396246 \n",
      "\n",
      "Epoch 1012\n",
      "-------------------------------\n",
      "loss: 0.305202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396873 \n",
      "\n",
      "Epoch 1013\n",
      "-------------------------------\n",
      "loss: 0.302215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397656 \n",
      "\n",
      "Epoch 1014\n",
      "-------------------------------\n",
      "loss: 0.295728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399254 \n",
      "\n",
      "Epoch 1015\n",
      "-------------------------------\n",
      "loss: 0.297919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402171 \n",
      "\n",
      "Epoch 1016\n",
      "-------------------------------\n",
      "loss: 0.319466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404364 \n",
      "\n",
      "Epoch 1017\n",
      "-------------------------------\n",
      "loss: 0.332220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404529 \n",
      "\n",
      "Epoch 1018\n",
      "-------------------------------\n",
      "loss: 0.326599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400785 \n",
      "\n",
      "Epoch 1019\n",
      "-------------------------------\n",
      "loss: 0.302168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397280 \n",
      "\n",
      "Epoch 1020\n",
      "-------------------------------\n",
      "loss: 0.302348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395741 \n",
      "\n",
      "Epoch 1021\n",
      "-------------------------------\n",
      "loss: 0.310899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396151 \n",
      "\n",
      "Epoch 1022\n",
      "-------------------------------\n",
      "loss: 0.310680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396338 \n",
      "\n",
      "Epoch 1023\n",
      "-------------------------------\n",
      "loss: 0.324711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396881 \n",
      "\n",
      "Epoch 1024\n",
      "-------------------------------\n",
      "loss: 0.313393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396781 \n",
      "\n",
      "Epoch 1025\n",
      "-------------------------------\n",
      "loss: 0.324029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396605 \n",
      "\n",
      "Epoch 1026\n",
      "-------------------------------\n",
      "loss: 0.317854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396377 \n",
      "\n",
      "Epoch 1027\n",
      "-------------------------------\n",
      "loss: 0.300661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395854 \n",
      "\n",
      "Epoch 1028\n",
      "-------------------------------\n",
      "loss: 0.319998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395095 \n",
      "\n",
      "Epoch 1029\n",
      "-------------------------------\n",
      "loss: 0.316606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394599 \n",
      "\n",
      "Epoch 1030\n",
      "-------------------------------\n",
      "loss: 0.317811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394725 \n",
      "\n",
      "Epoch 1031\n",
      "-------------------------------\n",
      "loss: 0.319296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395284 \n",
      "\n",
      "Epoch 1032\n",
      "-------------------------------\n",
      "loss: 0.331290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396629 \n",
      "\n",
      "Epoch 1033\n",
      "-------------------------------\n",
      "loss: 0.300998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399145 \n",
      "\n",
      "Epoch 1034\n",
      "-------------------------------\n",
      "loss: 0.295669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401094 \n",
      "\n",
      "Epoch 1035\n",
      "-------------------------------\n",
      "loss: 0.302730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402724 \n",
      "\n",
      "Epoch 1036\n",
      "-------------------------------\n",
      "loss: 0.305083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402338 \n",
      "\n",
      "Epoch 1037\n",
      "-------------------------------\n",
      "loss: 0.285547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401705 \n",
      "\n",
      "Epoch 1038\n",
      "-------------------------------\n",
      "loss: 0.305772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400578 \n",
      "\n",
      "Epoch 1039\n",
      "-------------------------------\n",
      "loss: 0.324894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401398 \n",
      "\n",
      "Epoch 1040\n",
      "-------------------------------\n",
      "loss: 0.308974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400925 \n",
      "\n",
      "Epoch 1041\n",
      "-------------------------------\n",
      "loss: 0.302273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400408 \n",
      "\n",
      "Epoch 1042\n",
      "-------------------------------\n",
      "loss: 0.310806  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.398556 \n",
      "\n",
      "Epoch 1043\n",
      "-------------------------------\n",
      "loss: 0.308288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396911 \n",
      "\n",
      "Epoch 1044\n",
      "-------------------------------\n",
      "loss: 0.299866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395000 \n",
      "\n",
      "Epoch 1045\n",
      "-------------------------------\n",
      "loss: 0.316980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394729 \n",
      "\n",
      "Epoch 1046\n",
      "-------------------------------\n",
      "loss: 0.295892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394878 \n",
      "\n",
      "Epoch 1047\n",
      "-------------------------------\n",
      "loss: 0.325225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395965 \n",
      "\n",
      "Epoch 1048\n",
      "-------------------------------\n",
      "loss: 0.310552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395237 \n",
      "\n",
      "Epoch 1049\n",
      "-------------------------------\n",
      "loss: 0.328959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394168 \n",
      "\n",
      "Epoch 1050\n",
      "-------------------------------\n",
      "loss: 0.309224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394708 \n",
      "\n",
      "Epoch 1051\n",
      "-------------------------------\n",
      "loss: 0.299633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395733 \n",
      "\n",
      "Epoch 1052\n",
      "-------------------------------\n",
      "loss: 0.311556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396251 \n",
      "\n",
      "Epoch 1053\n",
      "-------------------------------\n",
      "loss: 0.310949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394839 \n",
      "\n",
      "Epoch 1054\n",
      "-------------------------------\n",
      "loss: 0.298179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397134 \n",
      "\n",
      "Epoch 1055\n",
      "-------------------------------\n",
      "loss: 0.301823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404569 \n",
      "\n",
      "Epoch 1056\n",
      "-------------------------------\n",
      "loss: 0.295286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409947 \n",
      "\n",
      "Epoch 1057\n",
      "-------------------------------\n",
      "loss: 0.326723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407390 \n",
      "\n",
      "Epoch 1058\n",
      "-------------------------------\n",
      "loss: 0.299883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400987 \n",
      "\n",
      "Epoch 1059\n",
      "-------------------------------\n",
      "loss: 0.315041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396943 \n",
      "\n",
      "Epoch 1060\n",
      "-------------------------------\n",
      "loss: 0.295541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396661 \n",
      "\n",
      "Epoch 1061\n",
      "-------------------------------\n",
      "loss: 0.314874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400988 \n",
      "\n",
      "Epoch 1062\n",
      "-------------------------------\n",
      "loss: 0.327980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400888 \n",
      "\n",
      "Epoch 1063\n",
      "-------------------------------\n",
      "loss: 0.324339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397452 \n",
      "\n",
      "Epoch 1064\n",
      "-------------------------------\n",
      "loss: 0.311180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398545 \n",
      "\n",
      "Epoch 1065\n",
      "-------------------------------\n",
      "loss: 0.300910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403287 \n",
      "\n",
      "Epoch 1066\n",
      "-------------------------------\n",
      "loss: 0.301798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404528 \n",
      "\n",
      "Epoch 1067\n",
      "-------------------------------\n",
      "loss: 0.303624  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402668 \n",
      "\n",
      "Epoch 1068\n",
      "-------------------------------\n",
      "loss: 0.292237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401169 \n",
      "\n",
      "Epoch 1069\n",
      "-------------------------------\n",
      "loss: 0.293662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401881 \n",
      "\n",
      "Epoch 1070\n",
      "-------------------------------\n",
      "loss: 0.319341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403197 \n",
      "\n",
      "Epoch 1071\n",
      "-------------------------------\n",
      "loss: 0.316838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402675 \n",
      "\n",
      "Epoch 1072\n",
      "-------------------------------\n",
      "loss: 0.300339  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402350 \n",
      "\n",
      "Epoch 1073\n",
      "-------------------------------\n",
      "loss: 0.314933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402273 \n",
      "\n",
      "Epoch 1074\n",
      "-------------------------------\n",
      "loss: 0.301135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402378 \n",
      "\n",
      "Epoch 1075\n",
      "-------------------------------\n",
      "loss: 0.310504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401633 \n",
      "\n",
      "Epoch 1076\n",
      "-------------------------------\n",
      "loss: 0.315345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399519 \n",
      "\n",
      "Epoch 1077\n",
      "-------------------------------\n",
      "loss: 0.305855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398990 \n",
      "\n",
      "Epoch 1078\n",
      "-------------------------------\n",
      "loss: 0.327283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397426 \n",
      "\n",
      "Epoch 1079\n",
      "-------------------------------\n",
      "loss: 0.321850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394116 \n",
      "\n",
      "Epoch 1080\n",
      "-------------------------------\n",
      "loss: 0.306663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392999 \n",
      "\n",
      "Epoch 1081\n",
      "-------------------------------\n",
      "loss: 0.300158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395896 \n",
      "\n",
      "Epoch 1082\n",
      "-------------------------------\n",
      "loss: 0.314685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399458 \n",
      "\n",
      "Epoch 1083\n",
      "-------------------------------\n",
      "loss: 0.310094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400187 \n",
      "\n",
      "Epoch 1084\n",
      "-------------------------------\n",
      "loss: 0.310948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396315 \n",
      "\n",
      "Epoch 1085\n",
      "-------------------------------\n",
      "loss: 0.320954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392354 \n",
      "\n",
      "Epoch 1086\n",
      "-------------------------------\n",
      "loss: 0.314474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.390173 \n",
      "\n",
      "Epoch 1087\n",
      "-------------------------------\n",
      "loss: 0.292119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.389803 \n",
      "\n",
      "\n",
      "Saved a new best model!\n",
      "\n",
      "Epoch 1088\n",
      "-------------------------------\n",
      "loss: 0.299423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.390882 \n",
      "\n",
      "Epoch 1089\n",
      "-------------------------------\n",
      "loss: 0.303494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393389 \n",
      "\n",
      "Epoch 1090\n",
      "-------------------------------\n",
      "loss: 0.297575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396085 \n",
      "\n",
      "Epoch 1091\n",
      "-------------------------------\n",
      "loss: 0.334006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398674 \n",
      "\n",
      "Epoch 1092\n",
      "-------------------------------\n",
      "loss: 0.305205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399420 \n",
      "\n",
      "Epoch 1093\n",
      "-------------------------------\n",
      "loss: 0.300994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401313 \n",
      "\n",
      "Epoch 1094\n",
      "-------------------------------\n",
      "loss: 0.301178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403861 \n",
      "\n",
      "Epoch 1095\n",
      "-------------------------------\n",
      "loss: 0.296419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404016 \n",
      "\n",
      "Epoch 1096\n",
      "-------------------------------\n",
      "loss: 0.302903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402324 \n",
      "\n",
      "Epoch 1097\n",
      "-------------------------------\n",
      "loss: 0.304902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400605 \n",
      "\n",
      "Epoch 1098\n",
      "-------------------------------\n",
      "loss: 0.299456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398141 \n",
      "\n",
      "Epoch 1099\n",
      "-------------------------------\n",
      "loss: 0.309312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397380 \n",
      "\n",
      "Epoch 1100\n",
      "-------------------------------\n",
      "loss: 0.311088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397892 \n",
      "\n",
      "Epoch 1101\n",
      "-------------------------------\n",
      "loss: 0.305527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398452 \n",
      "\n",
      "Epoch 1102\n",
      "-------------------------------\n",
      "loss: 0.313162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399037 \n",
      "\n",
      "Epoch 1103\n",
      "-------------------------------\n",
      "loss: 0.315007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400245 \n",
      "\n",
      "Epoch 1104\n",
      "-------------------------------\n",
      "loss: 0.330568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399939 \n",
      "\n",
      "Epoch 1105\n",
      "-------------------------------\n",
      "loss: 0.317779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398312 \n",
      "\n",
      "Epoch 1106\n",
      "-------------------------------\n",
      "loss: 0.288239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397724 \n",
      "\n",
      "Epoch 1107\n",
      "-------------------------------\n",
      "loss: 0.307704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398703 \n",
      "\n",
      "Epoch 1108\n",
      "-------------------------------\n",
      "loss: 0.292787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400281 \n",
      "\n",
      "Epoch 1109\n",
      "-------------------------------\n",
      "loss: 0.310069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401129 \n",
      "\n",
      "Epoch 1110\n",
      "-------------------------------\n",
      "loss: 0.286752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401495 \n",
      "\n",
      "Epoch 1111\n",
      "-------------------------------\n",
      "loss: 0.285281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400828 \n",
      "\n",
      "Epoch 1112\n",
      "-------------------------------\n",
      "loss: 0.315951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398900 \n",
      "\n",
      "Epoch 1113\n",
      "-------------------------------\n",
      "loss: 0.306830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396773 \n",
      "\n",
      "Epoch 1114\n",
      "-------------------------------\n",
      "loss: 0.298801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396488 \n",
      "\n",
      "Epoch 1115\n",
      "-------------------------------\n",
      "loss: 0.308320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397215 \n",
      "\n",
      "Epoch 1116\n",
      "-------------------------------\n",
      "loss: 0.291998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397393 \n",
      "\n",
      "Epoch 1117\n",
      "-------------------------------\n",
      "loss: 0.325611  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397101 \n",
      "\n",
      "Epoch 1118\n",
      "-------------------------------\n",
      "loss: 0.317491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397478 \n",
      "\n",
      "Epoch 1119\n",
      "-------------------------------\n",
      "loss: 0.290903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399797 \n",
      "\n",
      "Epoch 1120\n",
      "-------------------------------\n",
      "loss: 0.333008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398603 \n",
      "\n",
      "Epoch 1121\n",
      "-------------------------------\n",
      "loss: 0.295445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396455 \n",
      "\n",
      "Epoch 1122\n",
      "-------------------------------\n",
      "loss: 0.313927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395720 \n",
      "\n",
      "Epoch 1123\n",
      "-------------------------------\n",
      "loss: 0.317891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396304 \n",
      "\n",
      "Epoch 1124\n",
      "-------------------------------\n",
      "loss: 0.295488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396239 \n",
      "\n",
      "Epoch 1125\n",
      "-------------------------------\n",
      "loss: 0.326617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396780 \n",
      "\n",
      "Epoch 1126\n",
      "-------------------------------\n",
      "loss: 0.304679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397294 \n",
      "\n",
      "Epoch 1127\n",
      "-------------------------------\n",
      "loss: 0.314519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399471 \n",
      "\n",
      "Epoch 1128\n",
      "-------------------------------\n",
      "loss: 0.301680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401130 \n",
      "\n",
      "Epoch 1129\n",
      "-------------------------------\n",
      "loss: 0.300327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400808 \n",
      "\n",
      "Epoch 1130\n",
      "-------------------------------\n",
      "loss: 0.301758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399287 \n",
      "\n",
      "Epoch 1131\n",
      "-------------------------------\n",
      "loss: 0.304956  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397295 \n",
      "\n",
      "Epoch 1132\n",
      "-------------------------------\n",
      "loss: 0.302448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395422 \n",
      "\n",
      "Epoch 1133\n",
      "-------------------------------\n",
      "loss: 0.315352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395819 \n",
      "\n",
      "Epoch 1134\n",
      "-------------------------------\n",
      "loss: 0.310664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397420 \n",
      "\n",
      "Epoch 1135\n",
      "-------------------------------\n",
      "loss: 0.295074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399886 \n",
      "\n",
      "Epoch 1136\n",
      "-------------------------------\n",
      "loss: 0.323816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404410 \n",
      "\n",
      "Epoch 1137\n",
      "-------------------------------\n",
      "loss: 0.287030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408793 \n",
      "\n",
      "Epoch 1138\n",
      "-------------------------------\n",
      "loss: 0.309145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409732 \n",
      "\n",
      "Epoch 1139\n",
      "-------------------------------\n",
      "loss: 0.297168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408049 \n",
      "\n",
      "Epoch 1140\n",
      "-------------------------------\n",
      "loss: 0.300807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405190 \n",
      "\n",
      "Epoch 1141\n",
      "-------------------------------\n",
      "loss: 0.304926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403304 \n",
      "\n",
      "Epoch 1142\n",
      "-------------------------------\n",
      "loss: 0.290788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401193 \n",
      "\n",
      "Epoch 1143\n",
      "-------------------------------\n",
      "loss: 0.300760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399550 \n",
      "\n",
      "Epoch 1144\n",
      "-------------------------------\n",
      "loss: 0.291735  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399737 \n",
      "\n",
      "Epoch 1145\n",
      "-------------------------------\n",
      "loss: 0.305695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401419 \n",
      "\n",
      "Epoch 1146\n",
      "-------------------------------\n",
      "loss: 0.292613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403704 \n",
      "\n",
      "Epoch 1147\n",
      "-------------------------------\n",
      "loss: 0.293388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403651 \n",
      "\n",
      "Epoch 1148\n",
      "-------------------------------\n",
      "loss: 0.305873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403225 \n",
      "\n",
      "Epoch 1149\n",
      "-------------------------------\n",
      "loss: 0.304305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403449 \n",
      "\n",
      "Epoch 1150\n",
      "-------------------------------\n",
      "loss: 0.311036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403912 \n",
      "\n",
      "Epoch 1151\n",
      "-------------------------------\n",
      "loss: 0.307243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402423 \n",
      "\n",
      "Epoch 1152\n",
      "-------------------------------\n",
      "loss: 0.302251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402630 \n",
      "\n",
      "Epoch 1153\n",
      "-------------------------------\n",
      "loss: 0.304304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403805 \n",
      "\n",
      "Epoch 1154\n",
      "-------------------------------\n",
      "loss: 0.307471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407082 \n",
      "\n",
      "Epoch 1155\n",
      "-------------------------------\n",
      "loss: 0.318883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405807 \n",
      "\n",
      "Epoch 1156\n",
      "-------------------------------\n",
      "loss: 0.314056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402559 \n",
      "\n",
      "Epoch 1157\n",
      "-------------------------------\n",
      "loss: 0.296820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400705 \n",
      "\n",
      "Epoch 1158\n",
      "-------------------------------\n",
      "loss: 0.308954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399428 \n",
      "\n",
      "Epoch 1159\n",
      "-------------------------------\n",
      "loss: 0.304707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399874 \n",
      "\n",
      "Epoch 1160\n",
      "-------------------------------\n",
      "loss: 0.310889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402180 \n",
      "\n",
      "Epoch 1161\n",
      "-------------------------------\n",
      "loss: 0.312896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402819 \n",
      "\n",
      "Epoch 1162\n",
      "-------------------------------\n",
      "loss: 0.296092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402895 \n",
      "\n",
      "Epoch 1163\n",
      "-------------------------------\n",
      "loss: 0.296914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403531 \n",
      "\n",
      "Epoch 1164\n",
      "-------------------------------\n",
      "loss: 0.287701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407087 \n",
      "\n",
      "Epoch 1165\n",
      "-------------------------------\n",
      "loss: 0.297779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412288 \n",
      "\n",
      "Epoch 1166\n",
      "-------------------------------\n",
      "loss: 0.319599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412749 \n",
      "\n",
      "Epoch 1167\n",
      "-------------------------------\n",
      "loss: 0.294800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408805 \n",
      "\n",
      "Epoch 1168\n",
      "-------------------------------\n",
      "loss: 0.281428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403147 \n",
      "\n",
      "Epoch 1169\n",
      "-------------------------------\n",
      "loss: 0.307230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400835 \n",
      "\n",
      "Epoch 1170\n",
      "-------------------------------\n",
      "loss: 0.311766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400315 \n",
      "\n",
      "Epoch 1171\n",
      "-------------------------------\n",
      "loss: 0.303068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399851 \n",
      "\n",
      "Epoch 1172\n",
      "-------------------------------\n",
      "loss: 0.300306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399261 \n",
      "\n",
      "Epoch 1173\n",
      "-------------------------------\n",
      "loss: 0.301984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399853 \n",
      "\n",
      "Epoch 1174\n",
      "-------------------------------\n",
      "loss: 0.303296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401456 \n",
      "\n",
      "Epoch 1175\n",
      "-------------------------------\n",
      "loss: 0.307391  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403621 \n",
      "\n",
      "Epoch 1176\n",
      "-------------------------------\n",
      "loss: 0.307683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403967 \n",
      "\n",
      "Epoch 1177\n",
      "-------------------------------\n",
      "loss: 0.315199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403026 \n",
      "\n",
      "Epoch 1178\n",
      "-------------------------------\n",
      "loss: 0.304185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400314 \n",
      "\n",
      "Epoch 1179\n",
      "-------------------------------\n",
      "loss: 0.297380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400047 \n",
      "\n",
      "Epoch 1180\n",
      "-------------------------------\n",
      "loss: 0.294070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398719 \n",
      "\n",
      "Epoch 1181\n",
      "-------------------------------\n",
      "loss: 0.287713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398042 \n",
      "\n",
      "Epoch 1182\n",
      "-------------------------------\n",
      "loss: 0.294787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397070 \n",
      "\n",
      "Epoch 1183\n",
      "-------------------------------\n",
      "loss: 0.298439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397311 \n",
      "\n",
      "Epoch 1184\n",
      "-------------------------------\n",
      "loss: 0.297185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398630 \n",
      "\n",
      "Epoch 1185\n",
      "-------------------------------\n",
      "loss: 0.311142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398564 \n",
      "\n",
      "Epoch 1186\n",
      "-------------------------------\n",
      "loss: 0.299129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399009 \n",
      "\n",
      "Epoch 1187\n",
      "-------------------------------\n",
      "loss: 0.300598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400139 \n",
      "\n",
      "Epoch 1188\n",
      "-------------------------------\n",
      "loss: 0.300201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400711 \n",
      "\n",
      "Epoch 1189\n",
      "-------------------------------\n",
      "loss: 0.292011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400873 \n",
      "\n",
      "Epoch 1190\n",
      "-------------------------------\n",
      "loss: 0.308427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401148 \n",
      "\n",
      "Epoch 1191\n",
      "-------------------------------\n",
      "loss: 0.294358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401204 \n",
      "\n",
      "Epoch 1192\n",
      "-------------------------------\n",
      "loss: 0.283669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402087 \n",
      "\n",
      "Epoch 1193\n",
      "-------------------------------\n",
      "loss: 0.308044  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.402939 \n",
      "\n",
      "Epoch 1194\n",
      "-------------------------------\n",
      "loss: 0.313576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403802 \n",
      "\n",
      "Epoch 1195\n",
      "-------------------------------\n",
      "loss: 0.287374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404185 \n",
      "\n",
      "Epoch 1196\n",
      "-------------------------------\n",
      "loss: 0.289853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404376 \n",
      "\n",
      "Epoch 1197\n",
      "-------------------------------\n",
      "loss: 0.289074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404731 \n",
      "\n",
      "Epoch 1198\n",
      "-------------------------------\n",
      "loss: 0.297691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405601 \n",
      "\n",
      "Epoch 1199\n",
      "-------------------------------\n",
      "loss: 0.294601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406387 \n",
      "\n",
      "Epoch 1200\n",
      "-------------------------------\n",
      "loss: 0.320061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406713 \n",
      "\n",
      "Epoch 1201\n",
      "-------------------------------\n",
      "loss: 0.292226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406945 \n",
      "\n",
      "Epoch 1202\n",
      "-------------------------------\n",
      "loss: 0.290666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406129 \n",
      "\n",
      "Epoch 1203\n",
      "-------------------------------\n",
      "loss: 0.279007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405585 \n",
      "\n",
      "Epoch 1204\n",
      "-------------------------------\n",
      "loss: 0.289037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405093 \n",
      "\n",
      "Epoch 1205\n",
      "-------------------------------\n",
      "loss: 0.287904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405885 \n",
      "\n",
      "Epoch 1206\n",
      "-------------------------------\n",
      "loss: 0.279433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405762 \n",
      "\n",
      "Epoch 1207\n",
      "-------------------------------\n",
      "loss: 0.283978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407364 \n",
      "\n",
      "Epoch 1208\n",
      "-------------------------------\n",
      "loss: 0.286523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410537 \n",
      "\n",
      "Epoch 1209\n",
      "-------------------------------\n",
      "loss: 0.281059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411410 \n",
      "\n",
      "Epoch 1210\n",
      "-------------------------------\n",
      "loss: 0.310650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409880 \n",
      "\n",
      "Epoch 1211\n",
      "-------------------------------\n",
      "loss: 0.307320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406653 \n",
      "\n",
      "Epoch 1212\n",
      "-------------------------------\n",
      "loss: 0.303569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403913 \n",
      "\n",
      "Epoch 1213\n",
      "-------------------------------\n",
      "loss: 0.294603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403214 \n",
      "\n",
      "Epoch 1214\n",
      "-------------------------------\n",
      "loss: 0.304950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403035 \n",
      "\n",
      "Epoch 1215\n",
      "-------------------------------\n",
      "loss: 0.320224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402538 \n",
      "\n",
      "Epoch 1216\n",
      "-------------------------------\n",
      "loss: 0.319195  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401569 \n",
      "\n",
      "Epoch 1217\n",
      "-------------------------------\n",
      "loss: 0.300683  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401837 \n",
      "\n",
      "Epoch 1218\n",
      "-------------------------------\n",
      "loss: 0.299115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403264 \n",
      "\n",
      "Epoch 1219\n",
      "-------------------------------\n",
      "loss: 0.289844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405030 \n",
      "\n",
      "Epoch 1220\n",
      "-------------------------------\n",
      "loss: 0.296083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404125 \n",
      "\n",
      "Epoch 1221\n",
      "-------------------------------\n",
      "loss: 0.301169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401812 \n",
      "\n",
      "Epoch 1222\n",
      "-------------------------------\n",
      "loss: 0.314007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399879 \n",
      "\n",
      "Epoch 1223\n",
      "-------------------------------\n",
      "loss: 0.280940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399005 \n",
      "\n",
      "Epoch 1224\n",
      "-------------------------------\n",
      "loss: 0.279578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399792 \n",
      "\n",
      "Epoch 1225\n",
      "-------------------------------\n",
      "loss: 0.303384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400692 \n",
      "\n",
      "Epoch 1226\n",
      "-------------------------------\n",
      "loss: 0.294632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402105 \n",
      "\n",
      "Epoch 1227\n",
      "-------------------------------\n",
      "loss: 0.293837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404533 \n",
      "\n",
      "Epoch 1228\n",
      "-------------------------------\n",
      "loss: 0.284853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407230 \n",
      "\n",
      "Epoch 1229\n",
      "-------------------------------\n",
      "loss: 0.287620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408687 \n",
      "\n",
      "Epoch 1230\n",
      "-------------------------------\n",
      "loss: 0.277197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409111 \n",
      "\n",
      "Epoch 1231\n",
      "-------------------------------\n",
      "loss: 0.289932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407107 \n",
      "\n",
      "Epoch 1232\n",
      "-------------------------------\n",
      "loss: 0.283983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404082 \n",
      "\n",
      "Epoch 1233\n",
      "-------------------------------\n",
      "loss: 0.296356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402575 \n",
      "\n",
      "Epoch 1234\n",
      "-------------------------------\n",
      "loss: 0.291565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401774 \n",
      "\n",
      "Epoch 1235\n",
      "-------------------------------\n",
      "loss: 0.299831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401350 \n",
      "\n",
      "Epoch 1236\n",
      "-------------------------------\n",
      "loss: 0.309304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400835 \n",
      "\n",
      "Epoch 1237\n",
      "-------------------------------\n",
      "loss: 0.294655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 1238\n",
      "-------------------------------\n",
      "loss: 0.305555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401871 \n",
      "\n",
      "Epoch 1239\n",
      "-------------------------------\n",
      "loss: 0.297441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402049 \n",
      "\n",
      "Epoch 1240\n",
      "-------------------------------\n",
      "loss: 0.284268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400537 \n",
      "\n",
      "Epoch 1241\n",
      "-------------------------------\n",
      "loss: 0.282059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399170 \n",
      "\n",
      "Epoch 1242\n",
      "-------------------------------\n",
      "loss: 0.295542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396907 \n",
      "\n",
      "Epoch 1243\n",
      "-------------------------------\n",
      "loss: 0.301856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395116 \n",
      "\n",
      "Epoch 1244\n",
      "-------------------------------\n",
      "loss: 0.303378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393819 \n",
      "\n",
      "Epoch 1245\n",
      "-------------------------------\n",
      "loss: 0.286313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393059 \n",
      "\n",
      "Epoch 1246\n",
      "-------------------------------\n",
      "loss: 0.302251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393758 \n",
      "\n",
      "Epoch 1247\n",
      "-------------------------------\n",
      "loss: 0.295689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394525 \n",
      "\n",
      "Epoch 1248\n",
      "-------------------------------\n",
      "loss: 0.292974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394735 \n",
      "\n",
      "Epoch 1249\n",
      "-------------------------------\n",
      "loss: 0.286355  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395828 \n",
      "\n",
      "Epoch 1250\n",
      "-------------------------------\n",
      "loss: 0.295720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397935 \n",
      "\n",
      "Epoch 1251\n",
      "-------------------------------\n",
      "loss: 0.286264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399243 \n",
      "\n",
      "Epoch 1252\n",
      "-------------------------------\n",
      "loss: 0.288323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400014 \n",
      "\n",
      "Epoch 1253\n",
      "-------------------------------\n",
      "loss: 0.307676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399000 \n",
      "\n",
      "Epoch 1254\n",
      "-------------------------------\n",
      "loss: 0.268415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398381 \n",
      "\n",
      "Epoch 1255\n",
      "-------------------------------\n",
      "loss: 0.290953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398072 \n",
      "\n",
      "Epoch 1256\n",
      "-------------------------------\n",
      "loss: 0.271623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398630 \n",
      "\n",
      "Epoch 1257\n",
      "-------------------------------\n",
      "loss: 0.298175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397969 \n",
      "\n",
      "Epoch 1258\n",
      "-------------------------------\n",
      "loss: 0.290625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397067 \n",
      "\n",
      "Epoch 1259\n",
      "-------------------------------\n",
      "loss: 0.293965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395708 \n",
      "\n",
      "Epoch 1260\n",
      "-------------------------------\n",
      "loss: 0.304745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394105 \n",
      "\n",
      "Epoch 1261\n",
      "-------------------------------\n",
      "loss: 0.304177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393784 \n",
      "\n",
      "Epoch 1262\n",
      "-------------------------------\n",
      "loss: 0.298854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393723 \n",
      "\n",
      "Epoch 1263\n",
      "-------------------------------\n",
      "loss: 0.324782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394176 \n",
      "\n",
      "Epoch 1264\n",
      "-------------------------------\n",
      "loss: 0.294219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396310 \n",
      "\n",
      "Epoch 1265\n",
      "-------------------------------\n",
      "loss: 0.296623  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402221 \n",
      "\n",
      "Epoch 1266\n",
      "-------------------------------\n",
      "loss: 0.282569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409204 \n",
      "\n",
      "Epoch 1267\n",
      "-------------------------------\n",
      "loss: 0.305541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410181 \n",
      "\n",
      "Epoch 1268\n",
      "-------------------------------\n",
      "loss: 0.315104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403958 \n",
      "\n",
      "Epoch 1269\n",
      "-------------------------------\n",
      "loss: 0.301255  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397019 \n",
      "\n",
      "Epoch 1270\n",
      "-------------------------------\n",
      "loss: 0.287580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394194 \n",
      "\n",
      "Epoch 1271\n",
      "-------------------------------\n",
      "loss: 0.304047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394801 \n",
      "\n",
      "Epoch 1272\n",
      "-------------------------------\n",
      "loss: 0.300194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395960 \n",
      "\n",
      "Epoch 1273\n",
      "-------------------------------\n",
      "loss: 0.283871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397156 \n",
      "\n",
      "Epoch 1274\n",
      "-------------------------------\n",
      "loss: 0.290903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398649 \n",
      "\n",
      "Epoch 1275\n",
      "-------------------------------\n",
      "loss: 0.312232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399019 \n",
      "\n",
      "Epoch 1276\n",
      "-------------------------------\n",
      "loss: 0.297843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399298 \n",
      "\n",
      "Epoch 1277\n",
      "-------------------------------\n",
      "loss: 0.284127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398810 \n",
      "\n",
      "Epoch 1278\n",
      "-------------------------------\n",
      "loss: 0.290419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398752 \n",
      "\n",
      "Epoch 1279\n",
      "-------------------------------\n",
      "loss: 0.315416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399155 \n",
      "\n",
      "Epoch 1280\n",
      "-------------------------------\n",
      "loss: 0.305225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399831 \n",
      "\n",
      "Epoch 1281\n",
      "-------------------------------\n",
      "loss: 0.303341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400066 \n",
      "\n",
      "Epoch 1282\n",
      "-------------------------------\n",
      "loss: 0.277025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400033 \n",
      "\n",
      "Epoch 1283\n",
      "-------------------------------\n",
      "loss: 0.320133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399268 \n",
      "\n",
      "Epoch 1284\n",
      "-------------------------------\n",
      "loss: 0.298366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398301 \n",
      "\n",
      "Epoch 1285\n",
      "-------------------------------\n",
      "loss: 0.300582  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396873 \n",
      "\n",
      "Epoch 1286\n",
      "-------------------------------\n",
      "loss: 0.290405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396936 \n",
      "\n",
      "Epoch 1287\n",
      "-------------------------------\n",
      "loss: 0.287331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397686 \n",
      "\n",
      "Epoch 1288\n",
      "-------------------------------\n",
      "loss: 0.293449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399580 \n",
      "\n",
      "Epoch 1289\n",
      "-------------------------------\n",
      "loss: 0.285371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399560 \n",
      "\n",
      "Epoch 1290\n",
      "-------------------------------\n",
      "loss: 0.283808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399402 \n",
      "\n",
      "Epoch 1291\n",
      "-------------------------------\n",
      "loss: 0.300631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399977 \n",
      "\n",
      "Epoch 1292\n",
      "-------------------------------\n",
      "loss: 0.296135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399472 \n",
      "\n",
      "Epoch 1293\n",
      "-------------------------------\n",
      "loss: 0.314265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399117 \n",
      "\n",
      "Epoch 1294\n",
      "-------------------------------\n",
      "loss: 0.304918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399666 \n",
      "\n",
      "Epoch 1295\n",
      "-------------------------------\n",
      "loss: 0.300059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400673 \n",
      "\n",
      "Epoch 1296\n",
      "-------------------------------\n",
      "loss: 0.292322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402914 \n",
      "\n",
      "Epoch 1297\n",
      "-------------------------------\n",
      "loss: 0.287180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404707 \n",
      "\n",
      "Epoch 1298\n",
      "-------------------------------\n",
      "loss: 0.303431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403874 \n",
      "\n",
      "Epoch 1299\n",
      "-------------------------------\n",
      "loss: 0.293033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402043 \n",
      "\n",
      "Epoch 1300\n",
      "-------------------------------\n",
      "loss: 0.303435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400178 \n",
      "\n",
      "Epoch 1301\n",
      "-------------------------------\n",
      "loss: 0.281640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398787 \n",
      "\n",
      "Epoch 1302\n",
      "-------------------------------\n",
      "loss: 0.300211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397621 \n",
      "\n",
      "Epoch 1303\n",
      "-------------------------------\n",
      "loss: 0.295091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395854 \n",
      "\n",
      "Epoch 1304\n",
      "-------------------------------\n",
      "loss: 0.280454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396001 \n",
      "\n",
      "Epoch 1305\n",
      "-------------------------------\n",
      "loss: 0.279578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396682 \n",
      "\n",
      "Epoch 1306\n",
      "-------------------------------\n",
      "loss: 0.293949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397312 \n",
      "\n",
      "Epoch 1307\n",
      "-------------------------------\n",
      "loss: 0.294574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396615 \n",
      "\n",
      "Epoch 1308\n",
      "-------------------------------\n",
      "loss: 0.278217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396610 \n",
      "\n",
      "Epoch 1309\n",
      "-------------------------------\n",
      "loss: 0.300282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396743 \n",
      "\n",
      "Epoch 1310\n",
      "-------------------------------\n",
      "loss: 0.289970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397495 \n",
      "\n",
      "Epoch 1311\n",
      "-------------------------------\n",
      "loss: 0.279446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397790 \n",
      "\n",
      "Epoch 1312\n",
      "-------------------------------\n",
      "loss: 0.303271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396837 \n",
      "\n",
      "Epoch 1313\n",
      "-------------------------------\n",
      "loss: 0.292464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397232 \n",
      "\n",
      "Epoch 1314\n",
      "-------------------------------\n",
      "loss: 0.287962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398133 \n",
      "\n",
      "Epoch 1315\n",
      "-------------------------------\n",
      "loss: 0.289036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398901 \n",
      "\n",
      "Epoch 1316\n",
      "-------------------------------\n",
      "loss: 0.306500  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399459 \n",
      "\n",
      "Epoch 1317\n",
      "-------------------------------\n",
      "loss: 0.274401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399629 \n",
      "\n",
      "Epoch 1318\n",
      "-------------------------------\n",
      "loss: 0.298519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398548 \n",
      "\n",
      "Epoch 1319\n",
      "-------------------------------\n",
      "loss: 0.302190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398167 \n",
      "\n",
      "Epoch 1320\n",
      "-------------------------------\n",
      "loss: 0.274878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398494 \n",
      "\n",
      "Epoch 1321\n",
      "-------------------------------\n",
      "loss: 0.292364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398408 \n",
      "\n",
      "Epoch 1322\n",
      "-------------------------------\n",
      "loss: 0.306396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398231 \n",
      "\n",
      "Epoch 1323\n",
      "-------------------------------\n",
      "loss: 0.294900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398466 \n",
      "\n",
      "Epoch 1324\n",
      "-------------------------------\n",
      "loss: 0.293173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400039 \n",
      "\n",
      "Epoch 1325\n",
      "-------------------------------\n",
      "loss: 0.297990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402015 \n",
      "\n",
      "Epoch 1326\n",
      "-------------------------------\n",
      "loss: 0.300276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403281 \n",
      "\n",
      "Epoch 1327\n",
      "-------------------------------\n",
      "loss: 0.292044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403624 \n",
      "\n",
      "Epoch 1328\n",
      "-------------------------------\n",
      "loss: 0.294159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403073 \n",
      "\n",
      "Epoch 1329\n",
      "-------------------------------\n",
      "loss: 0.288813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402404 \n",
      "\n",
      "Epoch 1330\n",
      "-------------------------------\n",
      "loss: 0.283470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402780 \n",
      "\n",
      "Epoch 1331\n",
      "-------------------------------\n",
      "loss: 0.279779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402701 \n",
      "\n",
      "Epoch 1332\n",
      "-------------------------------\n",
      "loss: 0.316185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400766 \n",
      "\n",
      "Epoch 1333\n",
      "-------------------------------\n",
      "loss: 0.287439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401066 \n",
      "\n",
      "Epoch 1334\n",
      "-------------------------------\n",
      "loss: 0.295405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404117 \n",
      "\n",
      "Epoch 1335\n",
      "-------------------------------\n",
      "loss: 0.287720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406140 \n",
      "\n",
      "Epoch 1336\n",
      "-------------------------------\n",
      "loss: 0.294442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407133 \n",
      "\n",
      "Epoch 1337\n",
      "-------------------------------\n",
      "loss: 0.289764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406474 \n",
      "\n",
      "Epoch 1338\n",
      "-------------------------------\n",
      "loss: 0.320944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405098 \n",
      "\n",
      "Epoch 1339\n",
      "-------------------------------\n",
      "loss: 0.315396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403091 \n",
      "\n",
      "Epoch 1340\n",
      "-------------------------------\n",
      "loss: 0.303399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403523 \n",
      "\n",
      "Epoch 1341\n",
      "-------------------------------\n",
      "loss: 0.313566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405324 \n",
      "\n",
      "Epoch 1342\n",
      "-------------------------------\n",
      "loss: 0.293046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405880 \n",
      "\n",
      "Epoch 1343\n",
      "-------------------------------\n",
      "loss: 0.307756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405114 \n",
      "\n",
      "Epoch 1344\n",
      "-------------------------------\n",
      "loss: 0.312191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402144 \n",
      "\n",
      "Epoch 1345\n",
      "-------------------------------\n",
      "loss: 0.293659  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400673 \n",
      "\n",
      "Epoch 1346\n",
      "-------------------------------\n",
      "loss: 0.290679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399934 \n",
      "\n",
      "Epoch 1347\n",
      "-------------------------------\n",
      "loss: 0.286425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399655 \n",
      "\n",
      "Epoch 1348\n",
      "-------------------------------\n",
      "loss: 0.297222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401447 \n",
      "\n",
      "Epoch 1349\n",
      "-------------------------------\n",
      "loss: 0.315863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401681 \n",
      "\n",
      "Epoch 1350\n",
      "-------------------------------\n",
      "loss: 0.312536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400112 \n",
      "\n",
      "Epoch 1351\n",
      "-------------------------------\n",
      "loss: 0.294984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400094 \n",
      "\n",
      "Epoch 1352\n",
      "-------------------------------\n",
      "loss: 0.287538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400171 \n",
      "\n",
      "Epoch 1353\n",
      "-------------------------------\n",
      "loss: 0.317969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399915 \n",
      "\n",
      "Epoch 1354\n",
      "-------------------------------\n",
      "loss: 0.291817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399604 \n",
      "\n",
      "Epoch 1355\n",
      "-------------------------------\n",
      "loss: 0.302736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400457 \n",
      "\n",
      "Epoch 1356\n",
      "-------------------------------\n",
      "loss: 0.296688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401953 \n",
      "\n",
      "Epoch 1357\n",
      "-------------------------------\n",
      "loss: 0.279565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401368 \n",
      "\n",
      "Epoch 1358\n",
      "-------------------------------\n",
      "loss: 0.294994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400981 \n",
      "\n",
      "Epoch 1359\n",
      "-------------------------------\n",
      "loss: 0.290736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400328 \n",
      "\n",
      "Epoch 1360\n",
      "-------------------------------\n",
      "loss: 0.285292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400002 \n",
      "\n",
      "Epoch 1361\n",
      "-------------------------------\n",
      "loss: 0.299001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400385 \n",
      "\n",
      "Epoch 1362\n",
      "-------------------------------\n",
      "loss: 0.293375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400003 \n",
      "\n",
      "Epoch 1363\n",
      "-------------------------------\n",
      "loss: 0.298593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399685 \n",
      "\n",
      "Epoch 1364\n",
      "-------------------------------\n",
      "loss: 0.274760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401262 \n",
      "\n",
      "Epoch 1365\n",
      "-------------------------------\n",
      "loss: 0.270202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402854 \n",
      "\n",
      "Epoch 1366\n",
      "-------------------------------\n",
      "loss: 0.301463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402226 \n",
      "\n",
      "Epoch 1367\n",
      "-------------------------------\n",
      "loss: 0.296280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399293 \n",
      "\n",
      "Epoch 1368\n",
      "-------------------------------\n",
      "loss: 0.280712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397986 \n",
      "\n",
      "Epoch 1369\n",
      "-------------------------------\n",
      "loss: 0.284215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397234 \n",
      "\n",
      "Epoch 1370\n",
      "-------------------------------\n",
      "loss: 0.288760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396837 \n",
      "\n",
      "Epoch 1371\n",
      "-------------------------------\n",
      "loss: 0.297531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396858 \n",
      "\n",
      "Epoch 1372\n",
      "-------------------------------\n",
      "loss: 0.310208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398761 \n",
      "\n",
      "Epoch 1373\n",
      "-------------------------------\n",
      "loss: 0.275837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401142 \n",
      "\n",
      "Epoch 1374\n",
      "-------------------------------\n",
      "loss: 0.302450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401261 \n",
      "\n",
      "Epoch 1375\n",
      "-------------------------------\n",
      "loss: 0.305118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398646 \n",
      "\n",
      "Epoch 1376\n",
      "-------------------------------\n",
      "loss: 0.279879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396243 \n",
      "\n",
      "Epoch 1377\n",
      "-------------------------------\n",
      "loss: 0.276482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394461 \n",
      "\n",
      "Epoch 1378\n",
      "-------------------------------\n",
      "loss: 0.289444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393377 \n",
      "\n",
      "Epoch 1379\n",
      "-------------------------------\n",
      "loss: 0.303466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393396 \n",
      "\n",
      "Epoch 1380\n",
      "-------------------------------\n",
      "loss: 0.300792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394215 \n",
      "\n",
      "Epoch 1381\n",
      "-------------------------------\n",
      "loss: 0.278434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396011 \n",
      "\n",
      "Epoch 1382\n",
      "-------------------------------\n",
      "loss: 0.291611  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399119 \n",
      "\n",
      "Epoch 1383\n",
      "-------------------------------\n",
      "loss: 0.299421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401402 \n",
      "\n",
      "Epoch 1384\n",
      "-------------------------------\n",
      "loss: 0.287777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403570 \n",
      "\n",
      "Epoch 1385\n",
      "-------------------------------\n",
      "loss: 0.297662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402793 \n",
      "\n",
      "Epoch 1386\n",
      "-------------------------------\n",
      "loss: 0.287385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399597 \n",
      "\n",
      "Epoch 1387\n",
      "-------------------------------\n",
      "loss: 0.293949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396535 \n",
      "\n",
      "Epoch 1388\n",
      "-------------------------------\n",
      "loss: 0.289893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395929 \n",
      "\n",
      "Epoch 1389\n",
      "-------------------------------\n",
      "loss: 0.288680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396507 \n",
      "\n",
      "Epoch 1390\n",
      "-------------------------------\n",
      "loss: 0.301451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396894 \n",
      "\n",
      "Epoch 1391\n",
      "-------------------------------\n",
      "loss: 0.283512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396935 \n",
      "\n",
      "Epoch 1392\n",
      "-------------------------------\n",
      "loss: 0.302726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397047 \n",
      "\n",
      "Epoch 1393\n",
      "-------------------------------\n",
      "loss: 0.301645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397854 \n",
      "\n",
      "Epoch 1394\n",
      "-------------------------------\n",
      "loss: 0.291010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400166 \n",
      "\n",
      "Epoch 1395\n",
      "-------------------------------\n",
      "loss: 0.283793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401794 \n",
      "\n",
      "Epoch 1396\n",
      "-------------------------------\n",
      "loss: 0.294612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400342 \n",
      "\n",
      "Epoch 1397\n",
      "-------------------------------\n",
      "loss: 0.284557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399411 \n",
      "\n",
      "Epoch 1398\n",
      "-------------------------------\n",
      "loss: 0.304781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399335 \n",
      "\n",
      "Epoch 1399\n",
      "-------------------------------\n",
      "loss: 0.289902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399967 \n",
      "\n",
      "Epoch 1400\n",
      "-------------------------------\n",
      "loss: 0.295613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400765 \n",
      "\n",
      "Epoch 1401\n",
      "-------------------------------\n",
      "loss: 0.295356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402642 \n",
      "\n",
      "Epoch 1402\n",
      "-------------------------------\n",
      "loss: 0.305043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405366 \n",
      "\n",
      "Epoch 1403\n",
      "-------------------------------\n",
      "loss: 0.294694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409974 \n",
      "\n",
      "Epoch 1404\n",
      "-------------------------------\n",
      "loss: 0.288383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411772 \n",
      "\n",
      "Epoch 1405\n",
      "-------------------------------\n",
      "loss: 0.283534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409701 \n",
      "\n",
      "Epoch 1406\n",
      "-------------------------------\n",
      "loss: 0.294632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404446 \n",
      "\n",
      "Epoch 1407\n",
      "-------------------------------\n",
      "loss: 0.294764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400880 \n",
      "\n",
      "Epoch 1408\n",
      "-------------------------------\n",
      "loss: 0.296442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400197 \n",
      "\n",
      "Epoch 1409\n",
      "-------------------------------\n",
      "loss: 0.311803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399035 \n",
      "\n",
      "Epoch 1410\n",
      "-------------------------------\n",
      "loss: 0.300779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397310 \n",
      "\n",
      "Epoch 1411\n",
      "-------------------------------\n",
      "loss: 0.290514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396789 \n",
      "\n",
      "Epoch 1412\n",
      "-------------------------------\n",
      "loss: 0.286237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399306 \n",
      "\n",
      "Epoch 1413\n",
      "-------------------------------\n",
      "loss: 0.295226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401453 \n",
      "\n",
      "Epoch 1414\n",
      "-------------------------------\n",
      "loss: 0.304999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402571 \n",
      "\n",
      "Epoch 1415\n",
      "-------------------------------\n",
      "loss: 0.275580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401573 \n",
      "\n",
      "Epoch 1416\n",
      "-------------------------------\n",
      "loss: 0.298474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399608 \n",
      "\n",
      "Epoch 1417\n",
      "-------------------------------\n",
      "loss: 0.286040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399531 \n",
      "\n",
      "Epoch 1418\n",
      "-------------------------------\n",
      "loss: 0.293556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398832 \n",
      "\n",
      "Epoch 1419\n",
      "-------------------------------\n",
      "loss: 0.292310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398231 \n",
      "\n",
      "Epoch 1420\n",
      "-------------------------------\n",
      "loss: 0.299900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398292 \n",
      "\n",
      "Epoch 1421\n",
      "-------------------------------\n",
      "loss: 0.287552  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.398478 \n",
      "\n",
      "Epoch 1422\n",
      "-------------------------------\n",
      "loss: 0.277821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398036 \n",
      "\n",
      "Epoch 1423\n",
      "-------------------------------\n",
      "loss: 0.282954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398709 \n",
      "\n",
      "Epoch 1424\n",
      "-------------------------------\n",
      "loss: 0.294644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397256 \n",
      "\n",
      "Epoch 1425\n",
      "-------------------------------\n",
      "loss: 0.298664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394741 \n",
      "\n",
      "Epoch 1426\n",
      "-------------------------------\n",
      "loss: 0.284470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394567 \n",
      "\n",
      "Epoch 1427\n",
      "-------------------------------\n",
      "loss: 0.282378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394538 \n",
      "\n",
      "Epoch 1428\n",
      "-------------------------------\n",
      "loss: 0.271736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395014 \n",
      "\n",
      "Epoch 1429\n",
      "-------------------------------\n",
      "loss: 0.276931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395876 \n",
      "\n",
      "Epoch 1430\n",
      "-------------------------------\n",
      "loss: 0.287301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397450 \n",
      "\n",
      "Epoch 1431\n",
      "-------------------------------\n",
      "loss: 0.270973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399257 \n",
      "\n",
      "Epoch 1432\n",
      "-------------------------------\n",
      "loss: 0.306588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400263 \n",
      "\n",
      "Epoch 1433\n",
      "-------------------------------\n",
      "loss: 0.275920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399991 \n",
      "\n",
      "Epoch 1434\n",
      "-------------------------------\n",
      "loss: 0.287886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399465 \n",
      "\n",
      "Epoch 1435\n",
      "-------------------------------\n",
      "loss: 0.288856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400403 \n",
      "\n",
      "Epoch 1436\n",
      "-------------------------------\n",
      "loss: 0.290905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401416 \n",
      "\n",
      "Epoch 1437\n",
      "-------------------------------\n",
      "loss: 0.274265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403042 \n",
      "\n",
      "Epoch 1438\n",
      "-------------------------------\n",
      "loss: 0.269625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404770 \n",
      "\n",
      "Epoch 1439\n",
      "-------------------------------\n",
      "loss: 0.292297  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405356 \n",
      "\n",
      "Epoch 1440\n",
      "-------------------------------\n",
      "loss: 0.273981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405410 \n",
      "\n",
      "Epoch 1441\n",
      "-------------------------------\n",
      "loss: 0.271941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406725 \n",
      "\n",
      "Epoch 1442\n",
      "-------------------------------\n",
      "loss: 0.289673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407174 \n",
      "\n",
      "Epoch 1443\n",
      "-------------------------------\n",
      "loss: 0.293505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404896 \n",
      "\n",
      "Epoch 1444\n",
      "-------------------------------\n",
      "loss: 0.302357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401532 \n",
      "\n",
      "Epoch 1445\n",
      "-------------------------------\n",
      "loss: 0.280967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401278 \n",
      "\n",
      "Epoch 1446\n",
      "-------------------------------\n",
      "loss: 0.301191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401335 \n",
      "\n",
      "Epoch 1447\n",
      "-------------------------------\n",
      "loss: 0.296047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401370 \n",
      "\n",
      "Epoch 1448\n",
      "-------------------------------\n",
      "loss: 0.287707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401752 \n",
      "\n",
      "Epoch 1449\n",
      "-------------------------------\n",
      "loss: 0.279372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402561 \n",
      "\n",
      "Epoch 1450\n",
      "-------------------------------\n",
      "loss: 0.278804  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403961 \n",
      "\n",
      "Epoch 1451\n",
      "-------------------------------\n",
      "loss: 0.291298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403898 \n",
      "\n",
      "Epoch 1452\n",
      "-------------------------------\n",
      "loss: 0.277882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403207 \n",
      "\n",
      "Epoch 1453\n",
      "-------------------------------\n",
      "loss: 0.269214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403119 \n",
      "\n",
      "Epoch 1454\n",
      "-------------------------------\n",
      "loss: 0.294738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401347 \n",
      "\n",
      "Epoch 1455\n",
      "-------------------------------\n",
      "loss: 0.277591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401212 \n",
      "\n",
      "Epoch 1456\n",
      "-------------------------------\n",
      "loss: 0.291102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400386 \n",
      "\n",
      "Epoch 1457\n",
      "-------------------------------\n",
      "loss: 0.267151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400462 \n",
      "\n",
      "Epoch 1458\n",
      "-------------------------------\n",
      "loss: 0.273247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401020 \n",
      "\n",
      "Epoch 1459\n",
      "-------------------------------\n",
      "loss: 0.285801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401721 \n",
      "\n",
      "Epoch 1460\n",
      "-------------------------------\n",
      "loss: 0.295849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402491 \n",
      "\n",
      "Epoch 1461\n",
      "-------------------------------\n",
      "loss: 0.289613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403278 \n",
      "\n",
      "Epoch 1462\n",
      "-------------------------------\n",
      "loss: 0.288769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402800 \n",
      "\n",
      "Epoch 1463\n",
      "-------------------------------\n",
      "loss: 0.289887  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403379 \n",
      "\n",
      "Epoch 1464\n",
      "-------------------------------\n",
      "loss: 0.289594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403126 \n",
      "\n",
      "Epoch 1465\n",
      "-------------------------------\n",
      "loss: 0.298532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401125 \n",
      "\n",
      "Epoch 1466\n",
      "-------------------------------\n",
      "loss: 0.301723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399099 \n",
      "\n",
      "Epoch 1467\n",
      "-------------------------------\n",
      "loss: 0.265317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398692 \n",
      "\n",
      "Epoch 1468\n",
      "-------------------------------\n",
      "loss: 0.292211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398640 \n",
      "\n",
      "Epoch 1469\n",
      "-------------------------------\n",
      "loss: 0.297317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399481 \n",
      "\n",
      "Epoch 1470\n",
      "-------------------------------\n",
      "loss: 0.299675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401066 \n",
      "\n",
      "Epoch 1471\n",
      "-------------------------------\n",
      "loss: 0.273239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402428 \n",
      "\n",
      "Epoch 1472\n",
      "-------------------------------\n",
      "loss: 0.290676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401519 \n",
      "\n",
      "Epoch 1473\n",
      "-------------------------------\n",
      "loss: 0.288533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400188 \n",
      "\n",
      "Epoch 1474\n",
      "-------------------------------\n",
      "loss: 0.276147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398293 \n",
      "\n",
      "Epoch 1475\n",
      "-------------------------------\n",
      "loss: 0.283258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398280 \n",
      "\n",
      "Epoch 1476\n",
      "-------------------------------\n",
      "loss: 0.291509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399784 \n",
      "\n",
      "Epoch 1477\n",
      "-------------------------------\n",
      "loss: 0.277437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402645 \n",
      "\n",
      "Epoch 1478\n",
      "-------------------------------\n",
      "loss: 0.286303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407022 \n",
      "\n",
      "Epoch 1479\n",
      "-------------------------------\n",
      "loss: 0.289443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407808 \n",
      "\n",
      "Epoch 1480\n",
      "-------------------------------\n",
      "loss: 0.275569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407705 \n",
      "\n",
      "Epoch 1481\n",
      "-------------------------------\n",
      "loss: 0.305203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406920 \n",
      "\n",
      "Epoch 1482\n",
      "-------------------------------\n",
      "loss: 0.300734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404626 \n",
      "\n",
      "Epoch 1483\n",
      "-------------------------------\n",
      "loss: 0.301601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402716 \n",
      "\n",
      "Epoch 1484\n",
      "-------------------------------\n",
      "loss: 0.270507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401504 \n",
      "\n",
      "Epoch 1485\n",
      "-------------------------------\n",
      "loss: 0.286864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400841 \n",
      "\n",
      "Epoch 1486\n",
      "-------------------------------\n",
      "loss: 0.299707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399984 \n",
      "\n",
      "Epoch 1487\n",
      "-------------------------------\n",
      "loss: 0.291412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401116 \n",
      "\n",
      "Epoch 1488\n",
      "-------------------------------\n",
      "loss: 0.278083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402748 \n",
      "\n",
      "Epoch 1489\n",
      "-------------------------------\n",
      "loss: 0.293095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404782 \n",
      "\n",
      "Epoch 1490\n",
      "-------------------------------\n",
      "loss: 0.289133  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404262 \n",
      "\n",
      "Epoch 1491\n",
      "-------------------------------\n",
      "loss: 0.298976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401889 \n",
      "\n",
      "Epoch 1492\n",
      "-------------------------------\n",
      "loss: 0.275336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401676 \n",
      "\n",
      "Epoch 1493\n",
      "-------------------------------\n",
      "loss: 0.296936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401893 \n",
      "\n",
      "Epoch 1494\n",
      "-------------------------------\n",
      "loss: 0.289417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401749 \n",
      "\n",
      "Epoch 1495\n",
      "-------------------------------\n",
      "loss: 0.286076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401752 \n",
      "\n",
      "Epoch 1496\n",
      "-------------------------------\n",
      "loss: 0.288376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402804 \n",
      "\n",
      "Epoch 1497\n",
      "-------------------------------\n",
      "loss: 0.287149  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.407906 \n",
      "\n",
      "Epoch 1498\n",
      "-------------------------------\n",
      "loss: 0.285371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412973 \n",
      "\n",
      "Epoch 1499\n",
      "-------------------------------\n",
      "loss: 0.300336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410825 \n",
      "\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "loss: 0.295295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404420 \n",
      "\n",
      "Epoch 1501\n",
      "-------------------------------\n",
      "loss: 0.280581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400734 \n",
      "\n",
      "Epoch 1502\n",
      "-------------------------------\n",
      "loss: 0.278813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400689 \n",
      "\n",
      "Epoch 1503\n",
      "-------------------------------\n",
      "loss: 0.288460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403341 \n",
      "\n",
      "Epoch 1504\n",
      "-------------------------------\n",
      "loss: 0.284021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406055 \n",
      "\n",
      "Epoch 1505\n",
      "-------------------------------\n",
      "loss: 0.305380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402707 \n",
      "\n",
      "Epoch 1506\n",
      "-------------------------------\n",
      "loss: 0.291789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400400 \n",
      "\n",
      "Epoch 1507\n",
      "-------------------------------\n",
      "loss: 0.269034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404676 \n",
      "\n",
      "Epoch 1508\n",
      "-------------------------------\n",
      "loss: 0.298699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410529 \n",
      "\n",
      "Epoch 1509\n",
      "-------------------------------\n",
      "loss: 0.312580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412781 \n",
      "\n",
      "Epoch 1510\n",
      "-------------------------------\n",
      "loss: 0.278823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409447 \n",
      "\n",
      "Epoch 1511\n",
      "-------------------------------\n",
      "loss: 0.291957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405487 \n",
      "\n",
      "Epoch 1512\n",
      "-------------------------------\n",
      "loss: 0.276110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404882 \n",
      "\n",
      "Epoch 1513\n",
      "-------------------------------\n",
      "loss: 0.289834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405555 \n",
      "\n",
      "Epoch 1514\n",
      "-------------------------------\n",
      "loss: 0.284788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404979 \n",
      "\n",
      "Epoch 1515\n",
      "-------------------------------\n",
      "loss: 0.284097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402720 \n",
      "\n",
      "Epoch 1516\n",
      "-------------------------------\n",
      "loss: 0.292814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403382 \n",
      "\n",
      "Epoch 1517\n",
      "-------------------------------\n",
      "loss: 0.273507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408027 \n",
      "\n",
      "Epoch 1518\n",
      "-------------------------------\n",
      "loss: 0.279069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412179 \n",
      "\n",
      "Epoch 1519\n",
      "-------------------------------\n",
      "loss: 0.290571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410729 \n",
      "\n",
      "Epoch 1520\n",
      "-------------------------------\n",
      "loss: 0.295570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406609 \n",
      "\n",
      "Epoch 1521\n",
      "-------------------------------\n",
      "loss: 0.289510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400942 \n",
      "\n",
      "Epoch 1522\n",
      "-------------------------------\n",
      "loss: 0.291800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400064 \n",
      "\n",
      "Epoch 1523\n",
      "-------------------------------\n",
      "loss: 0.297481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401245 \n",
      "\n",
      "Epoch 1524\n",
      "-------------------------------\n",
      "loss: 0.314927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401644 \n",
      "\n",
      "Epoch 1525\n",
      "-------------------------------\n",
      "loss: 0.280607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402456 \n",
      "\n",
      "Epoch 1526\n",
      "-------------------------------\n",
      "loss: 0.281828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403744 \n",
      "\n",
      "Epoch 1527\n",
      "-------------------------------\n",
      "loss: 0.281146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404947 \n",
      "\n",
      "Epoch 1528\n",
      "-------------------------------\n",
      "loss: 0.285005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408735 \n",
      "\n",
      "Epoch 1529\n",
      "-------------------------------\n",
      "loss: 0.267947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411778 \n",
      "\n",
      "Epoch 1530\n",
      "-------------------------------\n",
      "loss: 0.274172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409579 \n",
      "\n",
      "Epoch 1531\n",
      "-------------------------------\n",
      "loss: 0.290131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406019 \n",
      "\n",
      "Epoch 1532\n",
      "-------------------------------\n",
      "loss: 0.275361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404295 \n",
      "\n",
      "Epoch 1533\n",
      "-------------------------------\n",
      "loss: 0.280567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404701 \n",
      "\n",
      "Epoch 1534\n",
      "-------------------------------\n",
      "loss: 0.291405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404702 \n",
      "\n",
      "Epoch 1535\n",
      "-------------------------------\n",
      "loss: 0.283759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402969 \n",
      "\n",
      "Epoch 1536\n",
      "-------------------------------\n",
      "loss: 0.300422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401223 \n",
      "\n",
      "Epoch 1537\n",
      "-------------------------------\n",
      "loss: 0.286953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402745 \n",
      "\n",
      "Epoch 1538\n",
      "-------------------------------\n",
      "loss: 0.285927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404797 \n",
      "\n",
      "Epoch 1539\n",
      "-------------------------------\n",
      "loss: 0.300002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402915 \n",
      "\n",
      "Epoch 1540\n",
      "-------------------------------\n",
      "loss: 0.281693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400078 \n",
      "\n",
      "Epoch 1541\n",
      "-------------------------------\n",
      "loss: 0.277167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399319 \n",
      "\n",
      "Epoch 1542\n",
      "-------------------------------\n",
      "loss: 0.275244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400258 \n",
      "\n",
      "Epoch 1543\n",
      "-------------------------------\n",
      "loss: 0.287105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400732 \n",
      "\n",
      "Epoch 1544\n",
      "-------------------------------\n",
      "loss: 0.304067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399541 \n",
      "\n",
      "Epoch 1545\n",
      "-------------------------------\n",
      "loss: 0.284151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398394 \n",
      "\n",
      "Epoch 1546\n",
      "-------------------------------\n",
      "loss: 0.275302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397913 \n",
      "\n",
      "Epoch 1547\n",
      "-------------------------------\n",
      "loss: 0.273875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397261 \n",
      "\n",
      "Epoch 1548\n",
      "-------------------------------\n",
      "loss: 0.286982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397152 \n",
      "\n",
      "Epoch 1549\n",
      "-------------------------------\n",
      "loss: 0.286839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398432 \n",
      "\n",
      "Epoch 1550\n",
      "-------------------------------\n",
      "loss: 0.281771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399665 \n",
      "\n",
      "Epoch 1551\n",
      "-------------------------------\n",
      "loss: 0.282268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400094 \n",
      "\n",
      "Epoch 1552\n",
      "-------------------------------\n",
      "loss: 0.263619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400596 \n",
      "\n",
      "Epoch 1553\n",
      "-------------------------------\n",
      "loss: 0.277227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400255 \n",
      "\n",
      "Epoch 1554\n",
      "-------------------------------\n",
      "loss: 0.276696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400005 \n",
      "\n",
      "Epoch 1555\n",
      "-------------------------------\n",
      "loss: 0.280229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400725 \n",
      "\n",
      "Epoch 1556\n",
      "-------------------------------\n",
      "loss: 0.270756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401519 \n",
      "\n",
      "Epoch 1557\n",
      "-------------------------------\n",
      "loss: 0.274516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401742 \n",
      "\n",
      "Epoch 1558\n",
      "-------------------------------\n",
      "loss: 0.280333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402949 \n",
      "\n",
      "Epoch 1559\n",
      "-------------------------------\n",
      "loss: 0.295329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406557 \n",
      "\n",
      "Epoch 1560\n",
      "-------------------------------\n",
      "loss: 0.275695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411393 \n",
      "\n",
      "Epoch 1561\n",
      "-------------------------------\n",
      "loss: 0.275428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415055 \n",
      "\n",
      "Epoch 1562\n",
      "-------------------------------\n",
      "loss: 0.268145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.417353 \n",
      "\n",
      "Epoch 1563\n",
      "-------------------------------\n",
      "loss: 0.262105  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415766 \n",
      "\n",
      "Epoch 1564\n",
      "-------------------------------\n",
      "loss: 0.261335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409880 \n",
      "\n",
      "Epoch 1565\n",
      "-------------------------------\n",
      "loss: 0.276575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403939 \n",
      "\n",
      "Epoch 1566\n",
      "-------------------------------\n",
      "loss: 0.277439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400507 \n",
      "\n",
      "Epoch 1567\n",
      "-------------------------------\n",
      "loss: 0.291358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399141 \n",
      "\n",
      "Epoch 1568\n",
      "-------------------------------\n",
      "loss: 0.284119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399058 \n",
      "\n",
      "Epoch 1569\n",
      "-------------------------------\n",
      "loss: 0.263792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400682 \n",
      "\n",
      "Epoch 1570\n",
      "-------------------------------\n",
      "loss: 0.286707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402094 \n",
      "\n",
      "Epoch 1571\n",
      "-------------------------------\n",
      "loss: 0.274441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402402 \n",
      "\n",
      "Epoch 1572\n",
      "-------------------------------\n",
      "loss: 0.274369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402406 \n",
      "\n",
      "Epoch 1573\n",
      "-------------------------------\n",
      "loss: 0.281144  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.401080 \n",
      "\n",
      "Epoch 1574\n",
      "-------------------------------\n",
      "loss: 0.285731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398379 \n",
      "\n",
      "Epoch 1575\n",
      "-------------------------------\n",
      "loss: 0.269653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396259 \n",
      "\n",
      "Epoch 1576\n",
      "-------------------------------\n",
      "loss: 0.285357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395493 \n",
      "\n",
      "Epoch 1577\n",
      "-------------------------------\n",
      "loss: 0.287963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396828 \n",
      "\n",
      "Epoch 1578\n",
      "-------------------------------\n",
      "loss: 0.278859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398981 \n",
      "\n",
      "Epoch 1579\n",
      "-------------------------------\n",
      "loss: 0.276842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401038 \n",
      "\n",
      "Epoch 1580\n",
      "-------------------------------\n",
      "loss: 0.272985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402603 \n",
      "\n",
      "Epoch 1581\n",
      "-------------------------------\n",
      "loss: 0.295695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404089 \n",
      "\n",
      "Epoch 1582\n",
      "-------------------------------\n",
      "loss: 0.297384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402971 \n",
      "\n",
      "Epoch 1583\n",
      "-------------------------------\n",
      "loss: 0.287922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399708 \n",
      "\n",
      "Epoch 1584\n",
      "-------------------------------\n",
      "loss: 0.291173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398154 \n",
      "\n",
      "Epoch 1585\n",
      "-------------------------------\n",
      "loss: 0.271082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398401 \n",
      "\n",
      "Epoch 1586\n",
      "-------------------------------\n",
      "loss: 0.278739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398632 \n",
      "\n",
      "Epoch 1587\n",
      "-------------------------------\n",
      "loss: 0.293529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398343 \n",
      "\n",
      "Epoch 1588\n",
      "-------------------------------\n",
      "loss: 0.306911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398773 \n",
      "\n",
      "Epoch 1589\n",
      "-------------------------------\n",
      "loss: 0.291589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402406 \n",
      "\n",
      "Epoch 1590\n",
      "-------------------------------\n",
      "loss: 0.283653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405283 \n",
      "\n",
      "Epoch 1591\n",
      "-------------------------------\n",
      "loss: 0.274021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402863 \n",
      "\n",
      "Epoch 1592\n",
      "-------------------------------\n",
      "loss: 0.282728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399224 \n",
      "\n",
      "Epoch 1593\n",
      "-------------------------------\n",
      "loss: 0.298068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396216 \n",
      "\n",
      "Epoch 1594\n",
      "-------------------------------\n",
      "loss: 0.285943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395219 \n",
      "\n",
      "Epoch 1595\n",
      "-------------------------------\n",
      "loss: 0.269117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395654 \n",
      "\n",
      "Epoch 1596\n",
      "-------------------------------\n",
      "loss: 0.284851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396569 \n",
      "\n",
      "Epoch 1597\n",
      "-------------------------------\n",
      "loss: 0.270810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397555 \n",
      "\n",
      "Epoch 1598\n",
      "-------------------------------\n",
      "loss: 0.277009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399568 \n",
      "\n",
      "Epoch 1599\n",
      "-------------------------------\n",
      "loss: 0.279328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401685 \n",
      "\n",
      "Epoch 1600\n",
      "-------------------------------\n",
      "loss: 0.296363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400576 \n",
      "\n",
      "Epoch 1601\n",
      "-------------------------------\n",
      "loss: 0.289425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400309 \n",
      "\n",
      "Epoch 1602\n",
      "-------------------------------\n",
      "loss: 0.270869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400800 \n",
      "\n",
      "Epoch 1603\n",
      "-------------------------------\n",
      "loss: 0.299781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402275 \n",
      "\n",
      "Epoch 1604\n",
      "-------------------------------\n",
      "loss: 0.268991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403880 \n",
      "\n",
      "Epoch 1605\n",
      "-------------------------------\n",
      "loss: 0.267177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406415 \n",
      "\n",
      "Epoch 1606\n",
      "-------------------------------\n",
      "loss: 0.294990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407701 \n",
      "\n",
      "Epoch 1607\n",
      "-------------------------------\n",
      "loss: 0.293885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407076 \n",
      "\n",
      "Epoch 1608\n",
      "-------------------------------\n",
      "loss: 0.268728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405408 \n",
      "\n",
      "Epoch 1609\n",
      "-------------------------------\n",
      "loss: 0.271429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404517 \n",
      "\n",
      "Epoch 1610\n",
      "-------------------------------\n",
      "loss: 0.271908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403043 \n",
      "\n",
      "Epoch 1611\n",
      "-------------------------------\n",
      "loss: 0.289813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402770 \n",
      "\n",
      "Epoch 1612\n",
      "-------------------------------\n",
      "loss: 0.284636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404575 \n",
      "\n",
      "Epoch 1613\n",
      "-------------------------------\n",
      "loss: 0.287864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405954 \n",
      "\n",
      "Epoch 1614\n",
      "-------------------------------\n",
      "loss: 0.272845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406746 \n",
      "\n",
      "Epoch 1615\n",
      "-------------------------------\n",
      "loss: 0.264397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407828 \n",
      "\n",
      "Epoch 1616\n",
      "-------------------------------\n",
      "loss: 0.269769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407790 \n",
      "\n",
      "Epoch 1617\n",
      "-------------------------------\n",
      "loss: 0.273742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404490 \n",
      "\n",
      "Epoch 1618\n",
      "-------------------------------\n",
      "loss: 0.281420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401172 \n",
      "\n",
      "Epoch 1619\n",
      "-------------------------------\n",
      "loss: 0.280068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399860 \n",
      "\n",
      "Epoch 1620\n",
      "-------------------------------\n",
      "loss: 0.278525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399471 \n",
      "\n",
      "Epoch 1621\n",
      "-------------------------------\n",
      "loss: 0.289304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398891 \n",
      "\n",
      "Epoch 1622\n",
      "-------------------------------\n",
      "loss: 0.286270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398720 \n",
      "\n",
      "Epoch 1623\n",
      "-------------------------------\n",
      "loss: 0.269282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400088 \n",
      "\n",
      "Epoch 1624\n",
      "-------------------------------\n",
      "loss: 0.282862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401844 \n",
      "\n",
      "Epoch 1625\n",
      "-------------------------------\n",
      "loss: 0.282731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404341 \n",
      "\n",
      "Epoch 1626\n",
      "-------------------------------\n",
      "loss: 0.268547  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403919 \n",
      "\n",
      "Epoch 1627\n",
      "-------------------------------\n",
      "loss: 0.284894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401728 \n",
      "\n",
      "Epoch 1628\n",
      "-------------------------------\n",
      "loss: 0.258615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399634 \n",
      "\n",
      "Epoch 1629\n",
      "-------------------------------\n",
      "loss: 0.269244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397671 \n",
      "\n",
      "Epoch 1630\n",
      "-------------------------------\n",
      "loss: 0.264367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397172 \n",
      "\n",
      "Epoch 1631\n",
      "-------------------------------\n",
      "loss: 0.310952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398521 \n",
      "\n",
      "Epoch 1632\n",
      "-------------------------------\n",
      "loss: 0.300816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400020 \n",
      "\n",
      "Epoch 1633\n",
      "-------------------------------\n",
      "loss: 0.256608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401886 \n",
      "\n",
      "Epoch 1634\n",
      "-------------------------------\n",
      "loss: 0.283803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402844 \n",
      "\n",
      "Epoch 1635\n",
      "-------------------------------\n",
      "loss: 0.299891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401303 \n",
      "\n",
      "Epoch 1636\n",
      "-------------------------------\n",
      "loss: 0.275173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399757 \n",
      "\n",
      "Epoch 1637\n",
      "-------------------------------\n",
      "loss: 0.279428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399082 \n",
      "\n",
      "Epoch 1638\n",
      "-------------------------------\n",
      "loss: 0.285190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398904 \n",
      "\n",
      "Epoch 1639\n",
      "-------------------------------\n",
      "loss: 0.283697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399528 \n",
      "\n",
      "Epoch 1640\n",
      "-------------------------------\n",
      "loss: 0.281680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399699 \n",
      "\n",
      "Epoch 1641\n",
      "-------------------------------\n",
      "loss: 0.285756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399309 \n",
      "\n",
      "Epoch 1642\n",
      "-------------------------------\n",
      "loss: 0.274047  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401404 \n",
      "\n",
      "Epoch 1643\n",
      "-------------------------------\n",
      "loss: 0.277078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404014 \n",
      "\n",
      "Epoch 1644\n",
      "-------------------------------\n",
      "loss: 0.272301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404458 \n",
      "\n",
      "Epoch 1645\n",
      "-------------------------------\n",
      "loss: 0.272208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401729 \n",
      "\n",
      "Epoch 1646\n",
      "-------------------------------\n",
      "loss: 0.273331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399725 \n",
      "\n",
      "Epoch 1647\n",
      "-------------------------------\n",
      "loss: 0.275372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399041 \n",
      "\n",
      "Epoch 1648\n",
      "-------------------------------\n",
      "loss: 0.293810  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399313 \n",
      "\n",
      "Epoch 1649\n",
      "-------------------------------\n",
      "loss: 0.299807  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400813 \n",
      "\n",
      "Epoch 1650\n",
      "-------------------------------\n",
      "loss: 0.296040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403247 \n",
      "\n",
      "Epoch 1651\n",
      "-------------------------------\n",
      "loss: 0.270425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405675 \n",
      "\n",
      "Epoch 1652\n",
      "-------------------------------\n",
      "loss: 0.255394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405883 \n",
      "\n",
      "Epoch 1653\n",
      "-------------------------------\n",
      "loss: 0.302950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404152 \n",
      "\n",
      "Epoch 1654\n",
      "-------------------------------\n",
      "loss: 0.271542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401539 \n",
      "\n",
      "Epoch 1655\n",
      "-------------------------------\n",
      "loss: 0.274457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399359 \n",
      "\n",
      "Epoch 1656\n",
      "-------------------------------\n",
      "loss: 0.270746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398627 \n",
      "\n",
      "Epoch 1657\n",
      "-------------------------------\n",
      "loss: 0.287850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400582 \n",
      "\n",
      "Epoch 1658\n",
      "-------------------------------\n",
      "loss: 0.271369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403626 \n",
      "\n",
      "Epoch 1659\n",
      "-------------------------------\n",
      "loss: 0.261330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405490 \n",
      "\n",
      "Epoch 1660\n",
      "-------------------------------\n",
      "loss: 0.268991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405656 \n",
      "\n",
      "Epoch 1661\n",
      "-------------------------------\n",
      "loss: 0.280423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401989 \n",
      "\n",
      "Epoch 1662\n",
      "-------------------------------\n",
      "loss: 0.279462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398706 \n",
      "\n",
      "Epoch 1663\n",
      "-------------------------------\n",
      "loss: 0.256237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398188 \n",
      "\n",
      "Epoch 1664\n",
      "-------------------------------\n",
      "loss: 0.279139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399091 \n",
      "\n",
      "Epoch 1665\n",
      "-------------------------------\n",
      "loss: 0.271359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399372 \n",
      "\n",
      "Epoch 1666\n",
      "-------------------------------\n",
      "loss: 0.267787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398791 \n",
      "\n",
      "Epoch 1667\n",
      "-------------------------------\n",
      "loss: 0.278618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398371 \n",
      "\n",
      "Epoch 1668\n",
      "-------------------------------\n",
      "loss: 0.272271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398185 \n",
      "\n",
      "Epoch 1669\n",
      "-------------------------------\n",
      "loss: 0.279535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398960 \n",
      "\n",
      "Epoch 1670\n",
      "-------------------------------\n",
      "loss: 0.279255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399390 \n",
      "\n",
      "Epoch 1671\n",
      "-------------------------------\n",
      "loss: 0.283977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398731 \n",
      "\n",
      "Epoch 1672\n",
      "-------------------------------\n",
      "loss: 0.269686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397899 \n",
      "\n",
      "Epoch 1673\n",
      "-------------------------------\n",
      "loss: 0.273880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397606 \n",
      "\n",
      "Epoch 1674\n",
      "-------------------------------\n",
      "loss: 0.282856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397393 \n",
      "\n",
      "Epoch 1675\n",
      "-------------------------------\n",
      "loss: 0.293100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396769 \n",
      "\n",
      "Epoch 1676\n",
      "-------------------------------\n",
      "loss: 0.292851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396984 \n",
      "\n",
      "Epoch 1677\n",
      "-------------------------------\n",
      "loss: 0.278650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396576 \n",
      "\n",
      "Epoch 1678\n",
      "-------------------------------\n",
      "loss: 0.263533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395816 \n",
      "\n",
      "Epoch 1679\n",
      "-------------------------------\n",
      "loss: 0.276923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397474 \n",
      "\n",
      "Epoch 1680\n",
      "-------------------------------\n",
      "loss: 0.287284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402106 \n",
      "\n",
      "Epoch 1681\n",
      "-------------------------------\n",
      "loss: 0.288166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402751 \n",
      "\n",
      "Epoch 1682\n",
      "-------------------------------\n",
      "loss: 0.268408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402267 \n",
      "\n",
      "Epoch 1683\n",
      "-------------------------------\n",
      "loss: 0.280687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399455 \n",
      "\n",
      "Epoch 1684\n",
      "-------------------------------\n",
      "loss: 0.278543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399339 \n",
      "\n",
      "Epoch 1685\n",
      "-------------------------------\n",
      "loss: 0.286923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399463 \n",
      "\n",
      "Epoch 1686\n",
      "-------------------------------\n",
      "loss: 0.284468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399127 \n",
      "\n",
      "Epoch 1687\n",
      "-------------------------------\n",
      "loss: 0.273963  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397874 \n",
      "\n",
      "Epoch 1688\n",
      "-------------------------------\n",
      "loss: 0.278774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398414 \n",
      "\n",
      "Epoch 1689\n",
      "-------------------------------\n",
      "loss: 0.285044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398769 \n",
      "\n",
      "Epoch 1690\n",
      "-------------------------------\n",
      "loss: 0.284278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398689 \n",
      "\n",
      "Epoch 1691\n",
      "-------------------------------\n",
      "loss: 0.275424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399268 \n",
      "\n",
      "Epoch 1692\n",
      "-------------------------------\n",
      "loss: 0.294797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398589 \n",
      "\n",
      "Epoch 1693\n",
      "-------------------------------\n",
      "loss: 0.267811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399551 \n",
      "\n",
      "Epoch 1694\n",
      "-------------------------------\n",
      "loss: 0.266077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402687 \n",
      "\n",
      "Epoch 1695\n",
      "-------------------------------\n",
      "loss: 0.286187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406251 \n",
      "\n",
      "Epoch 1696\n",
      "-------------------------------\n",
      "loss: 0.290154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405285 \n",
      "\n",
      "Epoch 1697\n",
      "-------------------------------\n",
      "loss: 0.278717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401928 \n",
      "\n",
      "Epoch 1698\n",
      "-------------------------------\n",
      "loss: 0.260037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400592 \n",
      "\n",
      "Epoch 1699\n",
      "-------------------------------\n",
      "loss: 0.267891  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400748 \n",
      "\n",
      "Epoch 1700\n",
      "-------------------------------\n",
      "loss: 0.263620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402472 \n",
      "\n",
      "Epoch 1701\n",
      "-------------------------------\n",
      "loss: 0.289186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403687 \n",
      "\n",
      "Epoch 1702\n",
      "-------------------------------\n",
      "loss: 0.279795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405720 \n",
      "\n",
      "Epoch 1703\n",
      "-------------------------------\n",
      "loss: 0.279255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406748 \n",
      "\n",
      "Epoch 1704\n",
      "-------------------------------\n",
      "loss: 0.282531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405061 \n",
      "\n",
      "Epoch 1705\n",
      "-------------------------------\n",
      "loss: 0.300526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401071 \n",
      "\n",
      "Epoch 1706\n",
      "-------------------------------\n",
      "loss: 0.290368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399236 \n",
      "\n",
      "Epoch 1707\n",
      "-------------------------------\n",
      "loss: 0.285173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399835 \n",
      "\n",
      "Epoch 1708\n",
      "-------------------------------\n",
      "loss: 0.281211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399492 \n",
      "\n",
      "Epoch 1709\n",
      "-------------------------------\n",
      "loss: 0.274790  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398037 \n",
      "\n",
      "Epoch 1710\n",
      "-------------------------------\n",
      "loss: 0.289944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399660 \n",
      "\n",
      "Epoch 1711\n",
      "-------------------------------\n",
      "loss: 0.294707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405328 \n",
      "\n",
      "Epoch 1712\n",
      "-------------------------------\n",
      "loss: 0.261860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408597 \n",
      "\n",
      "Epoch 1713\n",
      "-------------------------------\n",
      "loss: 0.309464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404115 \n",
      "\n",
      "Epoch 1714\n",
      "-------------------------------\n",
      "loss: 0.267756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399878 \n",
      "\n",
      "Epoch 1715\n",
      "-------------------------------\n",
      "loss: 0.279096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397941 \n",
      "\n",
      "Epoch 1716\n",
      "-------------------------------\n",
      "loss: 0.285462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398802 \n",
      "\n",
      "Epoch 1717\n",
      "-------------------------------\n",
      "loss: 0.277760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400400 \n",
      "\n",
      "Epoch 1718\n",
      "-------------------------------\n",
      "loss: 0.271659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401928 \n",
      "\n",
      "Epoch 1719\n",
      "-------------------------------\n",
      "loss: 0.272571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403688 \n",
      "\n",
      "Epoch 1720\n",
      "-------------------------------\n",
      "loss: 0.268784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407340 \n",
      "\n",
      "Epoch 1721\n",
      "-------------------------------\n",
      "loss: 0.292471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408813 \n",
      "\n",
      "Epoch 1722\n",
      "-------------------------------\n",
      "loss: 0.286379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405470 \n",
      "\n",
      "Epoch 1723\n",
      "-------------------------------\n",
      "loss: 0.249492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402763 \n",
      "\n",
      "Epoch 1724\n",
      "-------------------------------\n",
      "loss: 0.274572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400568 \n",
      "\n",
      "Epoch 1725\n",
      "-------------------------------\n",
      "loss: 0.265630  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399408 \n",
      "\n",
      "Epoch 1726\n",
      "-------------------------------\n",
      "loss: 0.280473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398674 \n",
      "\n",
      "Epoch 1727\n",
      "-------------------------------\n",
      "loss: 0.265018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398317 \n",
      "\n",
      "Epoch 1728\n",
      "-------------------------------\n",
      "loss: 0.280992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398668 \n",
      "\n",
      "Epoch 1729\n",
      "-------------------------------\n",
      "loss: 0.268669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398099 \n",
      "\n",
      "Epoch 1730\n",
      "-------------------------------\n",
      "loss: 0.271696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397271 \n",
      "\n",
      "Epoch 1731\n",
      "-------------------------------\n",
      "loss: 0.307721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396116 \n",
      "\n",
      "Epoch 1732\n",
      "-------------------------------\n",
      "loss: 0.279580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397051 \n",
      "\n",
      "Epoch 1733\n",
      "-------------------------------\n",
      "loss: 0.271620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398931 \n",
      "\n",
      "Epoch 1734\n",
      "-------------------------------\n",
      "loss: 0.253695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400750 \n",
      "\n",
      "Epoch 1735\n",
      "-------------------------------\n",
      "loss: 0.269499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400337 \n",
      "\n",
      "Epoch 1736\n",
      "-------------------------------\n",
      "loss: 0.277411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399748 \n",
      "\n",
      "Epoch 1737\n",
      "-------------------------------\n",
      "loss: 0.290677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398892 \n",
      "\n",
      "Epoch 1738\n",
      "-------------------------------\n",
      "loss: 0.278807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399203 \n",
      "\n",
      "Epoch 1739\n",
      "-------------------------------\n",
      "loss: 0.291822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399907 \n",
      "\n",
      "Epoch 1740\n",
      "-------------------------------\n",
      "loss: 0.263389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399886 \n",
      "\n",
      "Epoch 1741\n",
      "-------------------------------\n",
      "loss: 0.268079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399685 \n",
      "\n",
      "Epoch 1742\n",
      "-------------------------------\n",
      "loss: 0.251951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400482 \n",
      "\n",
      "Epoch 1743\n",
      "-------------------------------\n",
      "loss: 0.271452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401794 \n",
      "\n",
      "Epoch 1744\n",
      "-------------------------------\n",
      "loss: 0.285628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401900 \n",
      "\n",
      "Epoch 1745\n",
      "-------------------------------\n",
      "loss: 0.269142  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 1746\n",
      "-------------------------------\n",
      "loss: 0.272234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400077 \n",
      "\n",
      "Epoch 1747\n",
      "-------------------------------\n",
      "loss: 0.289715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399466 \n",
      "\n",
      "Epoch 1748\n",
      "-------------------------------\n",
      "loss: 0.283794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399250 \n",
      "\n",
      "Epoch 1749\n",
      "-------------------------------\n",
      "loss: 0.274060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399857 \n",
      "\n",
      "Epoch 1750\n",
      "-------------------------------\n",
      "loss: 0.276131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400857 \n",
      "\n",
      "Epoch 1751\n",
      "-------------------------------\n",
      "loss: 0.273311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401586 \n",
      "\n",
      "Epoch 1752\n",
      "-------------------------------\n",
      "loss: 0.274449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402031 \n",
      "\n",
      "Epoch 1753\n",
      "-------------------------------\n",
      "loss: 0.263327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401033 \n",
      "\n",
      "Epoch 1754\n",
      "-------------------------------\n",
      "loss: 0.272523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399562 \n",
      "\n",
      "Epoch 1755\n",
      "-------------------------------\n",
      "loss: 0.271517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398935 \n",
      "\n",
      "Epoch 1756\n",
      "-------------------------------\n",
      "loss: 0.265705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399231 \n",
      "\n",
      "Epoch 1757\n",
      "-------------------------------\n",
      "loss: 0.269263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400213 \n",
      "\n",
      "Epoch 1758\n",
      "-------------------------------\n",
      "loss: 0.281852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401192 \n",
      "\n",
      "Epoch 1759\n",
      "-------------------------------\n",
      "loss: 0.259255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402087 \n",
      "\n",
      "Epoch 1760\n",
      "-------------------------------\n",
      "loss: 0.261736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402607 \n",
      "\n",
      "Epoch 1761\n",
      "-------------------------------\n",
      "loss: 0.286049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400830 \n",
      "\n",
      "Epoch 1762\n",
      "-------------------------------\n",
      "loss: 0.290542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399362 \n",
      "\n",
      "Epoch 1763\n",
      "-------------------------------\n",
      "loss: 0.267082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398237 \n",
      "\n",
      "Epoch 1764\n",
      "-------------------------------\n",
      "loss: 0.267569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398378 \n",
      "\n",
      "Epoch 1765\n",
      "-------------------------------\n",
      "loss: 0.278406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400026 \n",
      "\n",
      "Epoch 1766\n",
      "-------------------------------\n",
      "loss: 0.266192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402658 \n",
      "\n",
      "Epoch 1767\n",
      "-------------------------------\n",
      "loss: 0.268799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404432 \n",
      "\n",
      "Epoch 1768\n",
      "-------------------------------\n",
      "loss: 0.272020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405361 \n",
      "\n",
      "Epoch 1769\n",
      "-------------------------------\n",
      "loss: 0.279268  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404996 \n",
      "\n",
      "Epoch 1770\n",
      "-------------------------------\n",
      "loss: 0.256022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406028 \n",
      "\n",
      "Epoch 1771\n",
      "-------------------------------\n",
      "loss: 0.272390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406760 \n",
      "\n",
      "Epoch 1772\n",
      "-------------------------------\n",
      "loss: 0.273981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404834 \n",
      "\n",
      "Epoch 1773\n",
      "-------------------------------\n",
      "loss: 0.288702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400816 \n",
      "\n",
      "Epoch 1774\n",
      "-------------------------------\n",
      "loss: 0.254071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398890 \n",
      "\n",
      "Epoch 1775\n",
      "-------------------------------\n",
      "loss: 0.267475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399006 \n",
      "\n",
      "Epoch 1776\n",
      "-------------------------------\n",
      "loss: 0.278380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399357 \n",
      "\n",
      "Epoch 1777\n",
      "-------------------------------\n",
      "loss: 0.287668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401051 \n",
      "\n",
      "Epoch 1778\n",
      "-------------------------------\n",
      "loss: 0.253359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405189 \n",
      "\n",
      "Epoch 1779\n",
      "-------------------------------\n",
      "loss: 0.265892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408713 \n",
      "\n",
      "Epoch 1780\n",
      "-------------------------------\n",
      "loss: 0.268126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408876 \n",
      "\n",
      "Epoch 1781\n",
      "-------------------------------\n",
      "loss: 0.291184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404506 \n",
      "\n",
      "Epoch 1782\n",
      "-------------------------------\n",
      "loss: 0.264380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399730 \n",
      "\n",
      "Epoch 1783\n",
      "-------------------------------\n",
      "loss: 0.299693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398409 \n",
      "\n",
      "Epoch 1784\n",
      "-------------------------------\n",
      "loss: 0.266244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398912 \n",
      "\n",
      "Epoch 1785\n",
      "-------------------------------\n",
      "loss: 0.290904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399942 \n",
      "\n",
      "Epoch 1786\n",
      "-------------------------------\n",
      "loss: 0.279439  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400593 \n",
      "\n",
      "Epoch 1787\n",
      "-------------------------------\n",
      "loss: 0.295797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400857 \n",
      "\n",
      "Epoch 1788\n",
      "-------------------------------\n",
      "loss: 0.260458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402572 \n",
      "\n",
      "Epoch 1789\n",
      "-------------------------------\n",
      "loss: 0.279198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407282 \n",
      "\n",
      "Epoch 1790\n",
      "-------------------------------\n",
      "loss: 0.298096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409904 \n",
      "\n",
      "Epoch 1791\n",
      "-------------------------------\n",
      "loss: 0.284338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409582 \n",
      "\n",
      "Epoch 1792\n",
      "-------------------------------\n",
      "loss: 0.271581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407661 \n",
      "\n",
      "Epoch 1793\n",
      "-------------------------------\n",
      "loss: 0.271069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405484 \n",
      "\n",
      "Epoch 1794\n",
      "-------------------------------\n",
      "loss: 0.265373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401998 \n",
      "\n",
      "Epoch 1795\n",
      "-------------------------------\n",
      "loss: 0.271260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399377 \n",
      "\n",
      "Epoch 1796\n",
      "-------------------------------\n",
      "loss: 0.283614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399892 \n",
      "\n",
      "Epoch 1797\n",
      "-------------------------------\n",
      "loss: 0.265094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401850 \n",
      "\n",
      "Epoch 1798\n",
      "-------------------------------\n",
      "loss: 0.266191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403439 \n",
      "\n",
      "Epoch 1799\n",
      "-------------------------------\n",
      "loss: 0.278437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402353 \n",
      "\n",
      "Epoch 1800\n",
      "-------------------------------\n",
      "loss: 0.267709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401440 \n",
      "\n",
      "Epoch 1801\n",
      "-------------------------------\n",
      "loss: 0.274328  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400483 \n",
      "\n",
      "Epoch 1802\n",
      "-------------------------------\n",
      "loss: 0.268858  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400518 \n",
      "\n",
      "Epoch 1803\n",
      "-------------------------------\n",
      "loss: 0.264516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400653 \n",
      "\n",
      "Epoch 1804\n",
      "-------------------------------\n",
      "loss: 0.273557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398984 \n",
      "\n",
      "Epoch 1805\n",
      "-------------------------------\n",
      "loss: 0.269622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398999 \n",
      "\n",
      "Epoch 1806\n",
      "-------------------------------\n",
      "loss: 0.272968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399009 \n",
      "\n",
      "Epoch 1807\n",
      "-------------------------------\n",
      "loss: 0.261299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399717 \n",
      "\n",
      "Epoch 1808\n",
      "-------------------------------\n",
      "loss: 0.265938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400966 \n",
      "\n",
      "Epoch 1809\n",
      "-------------------------------\n",
      "loss: 0.266931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403491 \n",
      "\n",
      "Epoch 1810\n",
      "-------------------------------\n",
      "loss: 0.268632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404882 \n",
      "\n",
      "Epoch 1811\n",
      "-------------------------------\n",
      "loss: 0.265637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404578 \n",
      "\n",
      "Epoch 1812\n",
      "-------------------------------\n",
      "loss: 0.277203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404719 \n",
      "\n",
      "Epoch 1813\n",
      "-------------------------------\n",
      "loss: 0.268950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404609 \n",
      "\n",
      "Epoch 1814\n",
      "-------------------------------\n",
      "loss: 0.270981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405803 \n",
      "\n",
      "Epoch 1815\n",
      "-------------------------------\n",
      "loss: 0.261450  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406589 \n",
      "\n",
      "Epoch 1816\n",
      "-------------------------------\n",
      "loss: 0.281984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404972 \n",
      "\n",
      "Epoch 1817\n",
      "-------------------------------\n",
      "loss: 0.279412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401578 \n",
      "\n",
      "Epoch 1818\n",
      "-------------------------------\n",
      "loss: 0.284865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400302 \n",
      "\n",
      "Epoch 1819\n",
      "-------------------------------\n",
      "loss: 0.265960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399749 \n",
      "\n",
      "Epoch 1820\n",
      "-------------------------------\n",
      "loss: 0.266837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399370 \n",
      "\n",
      "Epoch 1821\n",
      "-------------------------------\n",
      "loss: 0.272005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399374 \n",
      "\n",
      "Epoch 1822\n",
      "-------------------------------\n",
      "loss: 0.263631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399642 \n",
      "\n",
      "Epoch 1823\n",
      "-------------------------------\n",
      "loss: 0.256715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401667 \n",
      "\n",
      "Epoch 1824\n",
      "-------------------------------\n",
      "loss: 0.268983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401660 \n",
      "\n",
      "Epoch 1825\n",
      "-------------------------------\n",
      "loss: 0.256168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399250 \n",
      "\n",
      "Epoch 1826\n",
      "-------------------------------\n",
      "loss: 0.262734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397480 \n",
      "\n",
      "Epoch 1827\n",
      "-------------------------------\n",
      "loss: 0.278300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397125 \n",
      "\n",
      "Epoch 1828\n",
      "-------------------------------\n",
      "loss: 0.266179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397049 \n",
      "\n",
      "Epoch 1829\n",
      "-------------------------------\n",
      "loss: 0.268201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396393 \n",
      "\n",
      "Epoch 1830\n",
      "-------------------------------\n",
      "loss: 0.269713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396407 \n",
      "\n",
      "Epoch 1831\n",
      "-------------------------------\n",
      "loss: 0.280502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399204 \n",
      "\n",
      "Epoch 1832\n",
      "-------------------------------\n",
      "loss: 0.251122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404727 \n",
      "\n",
      "Epoch 1833\n",
      "-------------------------------\n",
      "loss: 0.269515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407344 \n",
      "\n",
      "Epoch 1834\n",
      "-------------------------------\n",
      "loss: 0.259948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406063 \n",
      "\n",
      "Epoch 1835\n",
      "-------------------------------\n",
      "loss: 0.269408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402684 \n",
      "\n",
      "Epoch 1836\n",
      "-------------------------------\n",
      "loss: 0.260527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400176 \n",
      "\n",
      "Epoch 1837\n",
      "-------------------------------\n",
      "loss: 0.263138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398948 \n",
      "\n",
      "Epoch 1838\n",
      "-------------------------------\n",
      "loss: 0.277277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398756 \n",
      "\n",
      "Epoch 1839\n",
      "-------------------------------\n",
      "loss: 0.279598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398762 \n",
      "\n",
      "Epoch 1840\n",
      "-------------------------------\n",
      "loss: 0.252595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399892 \n",
      "\n",
      "Epoch 1841\n",
      "-------------------------------\n",
      "loss: 0.271289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401280 \n",
      "\n",
      "Epoch 1842\n",
      "-------------------------------\n",
      "loss: 0.267322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403219 \n",
      "\n",
      "Epoch 1843\n",
      "-------------------------------\n",
      "loss: 0.274597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403322 \n",
      "\n",
      "Epoch 1844\n",
      "-------------------------------\n",
      "loss: 0.289849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404075 \n",
      "\n",
      "Epoch 1845\n",
      "-------------------------------\n",
      "loss: 0.277764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403899 \n",
      "\n",
      "Epoch 1846\n",
      "-------------------------------\n",
      "loss: 0.275072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402439 \n",
      "\n",
      "Epoch 1847\n",
      "-------------------------------\n",
      "loss: 0.267992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400877 \n",
      "\n",
      "Epoch 1848\n",
      "-------------------------------\n",
      "loss: 0.271221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400320 \n",
      "\n",
      "Epoch 1849\n",
      "-------------------------------\n",
      "loss: 0.267675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400578 \n",
      "\n",
      "Epoch 1850\n",
      "-------------------------------\n",
      "loss: 0.254619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401757 \n",
      "\n",
      "Epoch 1851\n",
      "-------------------------------\n",
      "loss: 0.270157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402100 \n",
      "\n",
      "Epoch 1852\n",
      "-------------------------------\n",
      "loss: 0.288863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400092 \n",
      "\n",
      "Epoch 1853\n",
      "-------------------------------\n",
      "loss: 0.260213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399041 \n",
      "\n",
      "Epoch 1854\n",
      "-------------------------------\n",
      "loss: 0.273088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399948 \n",
      "\n",
      "Epoch 1855\n",
      "-------------------------------\n",
      "loss: 0.275132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399874 \n",
      "\n",
      "Epoch 1856\n",
      "-------------------------------\n",
      "loss: 0.266994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400564 \n",
      "\n",
      "Epoch 1857\n",
      "-------------------------------\n",
      "loss: 0.273662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401144 \n",
      "\n",
      "Epoch 1858\n",
      "-------------------------------\n",
      "loss: 0.264290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402413 \n",
      "\n",
      "Epoch 1859\n",
      "-------------------------------\n",
      "loss: 0.272501  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402432 \n",
      "\n",
      "Epoch 1860\n",
      "-------------------------------\n",
      "loss: 0.274370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402652 \n",
      "\n",
      "Epoch 1861\n",
      "-------------------------------\n",
      "loss: 0.278048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400766 \n",
      "\n",
      "Epoch 1862\n",
      "-------------------------------\n",
      "loss: 0.256658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399889 \n",
      "\n",
      "Epoch 1863\n",
      "-------------------------------\n",
      "loss: 0.265376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400417 \n",
      "\n",
      "Epoch 1864\n",
      "-------------------------------\n",
      "loss: 0.260613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 1865\n",
      "-------------------------------\n",
      "loss: 0.274585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400681 \n",
      "\n",
      "Epoch 1866\n",
      "-------------------------------\n",
      "loss: 0.255939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399810 \n",
      "\n",
      "Epoch 1867\n",
      "-------------------------------\n",
      "loss: 0.260789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400477 \n",
      "\n",
      "Epoch 1868\n",
      "-------------------------------\n",
      "loss: 0.258010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402757 \n",
      "\n",
      "Epoch 1869\n",
      "-------------------------------\n",
      "loss: 0.262802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404134 \n",
      "\n",
      "Epoch 1870\n",
      "-------------------------------\n",
      "loss: 0.279065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404590 \n",
      "\n",
      "Epoch 1871\n",
      "-------------------------------\n",
      "loss: 0.277373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402544 \n",
      "\n",
      "Epoch 1872\n",
      "-------------------------------\n",
      "loss: 0.270407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399621 \n",
      "\n",
      "Epoch 1873\n",
      "-------------------------------\n",
      "loss: 0.265788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397560 \n",
      "\n",
      "Epoch 1874\n",
      "-------------------------------\n",
      "loss: 0.270924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396704 \n",
      "\n",
      "Epoch 1875\n",
      "-------------------------------\n",
      "loss: 0.279264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396889 \n",
      "\n",
      "Epoch 1876\n",
      "-------------------------------\n",
      "loss: 0.268943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397493 \n",
      "\n",
      "Epoch 1877\n",
      "-------------------------------\n",
      "loss: 0.275571  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.398257 \n",
      "\n",
      "Epoch 1878\n",
      "-------------------------------\n",
      "loss: 0.272225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397924 \n",
      "\n",
      "Epoch 1879\n",
      "-------------------------------\n",
      "loss: 0.293002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398889 \n",
      "\n",
      "Epoch 1880\n",
      "-------------------------------\n",
      "loss: 0.262206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401415 \n",
      "\n",
      "Epoch 1881\n",
      "-------------------------------\n",
      "loss: 0.278721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404738 \n",
      "\n",
      "Epoch 1882\n",
      "-------------------------------\n",
      "loss: 0.264608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405244 \n",
      "\n",
      "Epoch 1883\n",
      "-------------------------------\n",
      "loss: 0.268743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404715 \n",
      "\n",
      "Epoch 1884\n",
      "-------------------------------\n",
      "loss: 0.271201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401347 \n",
      "\n",
      "Epoch 1885\n",
      "-------------------------------\n",
      "loss: 0.253690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399040 \n",
      "\n",
      "Epoch 1886\n",
      "-------------------------------\n",
      "loss: 0.280499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397765 \n",
      "\n",
      "Epoch 1887\n",
      "-------------------------------\n",
      "loss: 0.274158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397983 \n",
      "\n",
      "Epoch 1888\n",
      "-------------------------------\n",
      "loss: 0.265949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399913 \n",
      "\n",
      "Epoch 1889\n",
      "-------------------------------\n",
      "loss: 0.277476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402786 \n",
      "\n",
      "Epoch 1890\n",
      "-------------------------------\n",
      "loss: 0.274978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405310 \n",
      "\n",
      "Epoch 1891\n",
      "-------------------------------\n",
      "loss: 0.261350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406072 \n",
      "\n",
      "Epoch 1892\n",
      "-------------------------------\n",
      "loss: 0.284119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404874 \n",
      "\n",
      "Epoch 1893\n",
      "-------------------------------\n",
      "loss: 0.276157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403094 \n",
      "\n",
      "Epoch 1894\n",
      "-------------------------------\n",
      "loss: 0.269219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403380 \n",
      "\n",
      "Epoch 1895\n",
      "-------------------------------\n",
      "loss: 0.277736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404880 \n",
      "\n",
      "Epoch 1896\n",
      "-------------------------------\n",
      "loss: 0.263346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407138 \n",
      "\n",
      "Epoch 1897\n",
      "-------------------------------\n",
      "loss: 0.306920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408833 \n",
      "\n",
      "Epoch 1898\n",
      "-------------------------------\n",
      "loss: 0.284704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409954 \n",
      "\n",
      "Epoch 1899\n",
      "-------------------------------\n",
      "loss: 0.274139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411476 \n",
      "\n",
      "Epoch 1900\n",
      "-------------------------------\n",
      "loss: 0.267292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412918 \n",
      "\n",
      "Epoch 1901\n",
      "-------------------------------\n",
      "loss: 0.300058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408939 \n",
      "\n",
      "Epoch 1902\n",
      "-------------------------------\n",
      "loss: 0.259676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405761 \n",
      "\n",
      "Epoch 1903\n",
      "-------------------------------\n",
      "loss: 0.278480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406160 \n",
      "\n",
      "Epoch 1904\n",
      "-------------------------------\n",
      "loss: 0.267426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406864 \n",
      "\n",
      "Epoch 1905\n",
      "-------------------------------\n",
      "loss: 0.265055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405817 \n",
      "\n",
      "Epoch 1906\n",
      "-------------------------------\n",
      "loss: 0.278725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403308 \n",
      "\n",
      "Epoch 1907\n",
      "-------------------------------\n",
      "loss: 0.254270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401368 \n",
      "\n",
      "Epoch 1908\n",
      "-------------------------------\n",
      "loss: 0.271992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399986 \n",
      "\n",
      "Epoch 1909\n",
      "-------------------------------\n",
      "loss: 0.261305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400092 \n",
      "\n",
      "Epoch 1910\n",
      "-------------------------------\n",
      "loss: 0.267586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402120 \n",
      "\n",
      "Epoch 1911\n",
      "-------------------------------\n",
      "loss: 0.279411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404801 \n",
      "\n",
      "Epoch 1912\n",
      "-------------------------------\n",
      "loss: 0.279905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405690 \n",
      "\n",
      "Epoch 1913\n",
      "-------------------------------\n",
      "loss: 0.284630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403919 \n",
      "\n",
      "Epoch 1914\n",
      "-------------------------------\n",
      "loss: 0.272068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401325 \n",
      "\n",
      "Epoch 1915\n",
      "-------------------------------\n",
      "loss: 0.269771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398440 \n",
      "\n",
      "Epoch 1916\n",
      "-------------------------------\n",
      "loss: 0.283876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397270 \n",
      "\n",
      "Epoch 1917\n",
      "-------------------------------\n",
      "loss: 0.264163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397766 \n",
      "\n",
      "Epoch 1918\n",
      "-------------------------------\n",
      "loss: 0.266679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399129 \n",
      "\n",
      "Epoch 1919\n",
      "-------------------------------\n",
      "loss: 0.255484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399754 \n",
      "\n",
      "Epoch 1920\n",
      "-------------------------------\n",
      "loss: 0.253070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400749 \n",
      "\n",
      "Epoch 1921\n",
      "-------------------------------\n",
      "loss: 0.266527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399577 \n",
      "\n",
      "Epoch 1922\n",
      "-------------------------------\n",
      "loss: 0.262992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398601 \n",
      "\n",
      "Epoch 1923\n",
      "-------------------------------\n",
      "loss: 0.250427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398723 \n",
      "\n",
      "Epoch 1924\n",
      "-------------------------------\n",
      "loss: 0.254370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400099 \n",
      "\n",
      "Epoch 1925\n",
      "-------------------------------\n",
      "loss: 0.267414  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402406 \n",
      "\n",
      "Epoch 1926\n",
      "-------------------------------\n",
      "loss: 0.256305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404961 \n",
      "\n",
      "Epoch 1927\n",
      "-------------------------------\n",
      "loss: 0.257841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406485 \n",
      "\n",
      "Epoch 1928\n",
      "-------------------------------\n",
      "loss: 0.284682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404776 \n",
      "\n",
      "Epoch 1929\n",
      "-------------------------------\n",
      "loss: 0.280015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400733 \n",
      "\n",
      "Epoch 1930\n",
      "-------------------------------\n",
      "loss: 0.258378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399106 \n",
      "\n",
      "Epoch 1931\n",
      "-------------------------------\n",
      "loss: 0.267139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399184 \n",
      "\n",
      "Epoch 1932\n",
      "-------------------------------\n",
      "loss: 0.273666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398533 \n",
      "\n",
      "Epoch 1933\n",
      "-------------------------------\n",
      "loss: 0.265429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397487 \n",
      "\n",
      "Epoch 1934\n",
      "-------------------------------\n",
      "loss: 0.286613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396630 \n",
      "\n",
      "Epoch 1935\n",
      "-------------------------------\n",
      "loss: 0.280464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395857 \n",
      "\n",
      "Epoch 1936\n",
      "-------------------------------\n",
      "loss: 0.260679  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396584 \n",
      "\n",
      "Epoch 1937\n",
      "-------------------------------\n",
      "loss: 0.269942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398865 \n",
      "\n",
      "Epoch 1938\n",
      "-------------------------------\n",
      "loss: 0.287506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400750 \n",
      "\n",
      "Epoch 1939\n",
      "-------------------------------\n",
      "loss: 0.274408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400758 \n",
      "\n",
      "Epoch 1940\n",
      "-------------------------------\n",
      "loss: 0.269055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399382 \n",
      "\n",
      "Epoch 1941\n",
      "-------------------------------\n",
      "loss: 0.278218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398873 \n",
      "\n",
      "Epoch 1942\n",
      "-------------------------------\n",
      "loss: 0.253815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399289 \n",
      "\n",
      "Epoch 1943\n",
      "-------------------------------\n",
      "loss: 0.263001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399512 \n",
      "\n",
      "Epoch 1944\n",
      "-------------------------------\n",
      "loss: 0.278051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398788 \n",
      "\n",
      "Epoch 1945\n",
      "-------------------------------\n",
      "loss: 0.256383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397082 \n",
      "\n",
      "Epoch 1946\n",
      "-------------------------------\n",
      "loss: 0.266712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396010 \n",
      "\n",
      "Epoch 1947\n",
      "-------------------------------\n",
      "loss: 0.278732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394593 \n",
      "\n",
      "Epoch 1948\n",
      "-------------------------------\n",
      "loss: 0.247013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393899 \n",
      "\n",
      "Epoch 1949\n",
      "-------------------------------\n",
      "loss: 0.264549  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394171 \n",
      "\n",
      "Epoch 1950\n",
      "-------------------------------\n",
      "loss: 0.268164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396729 \n",
      "\n",
      "Epoch 1951\n",
      "-------------------------------\n",
      "loss: 0.269812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399471 \n",
      "\n",
      "Epoch 1952\n",
      "-------------------------------\n",
      "loss: 0.265341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400403 \n",
      "\n",
      "Epoch 1953\n",
      "-------------------------------\n",
      "loss: 0.261502  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400795 \n",
      "\n",
      "Epoch 1954\n",
      "-------------------------------\n",
      "loss: 0.261648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400805 \n",
      "\n",
      "Epoch 1955\n",
      "-------------------------------\n",
      "loss: 0.267266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399348 \n",
      "\n",
      "Epoch 1956\n",
      "-------------------------------\n",
      "loss: 0.261314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397281 \n",
      "\n",
      "Epoch 1957\n",
      "-------------------------------\n",
      "loss: 0.269537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395601 \n",
      "\n",
      "Epoch 1958\n",
      "-------------------------------\n",
      "loss: 0.257221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394743 \n",
      "\n",
      "Epoch 1959\n",
      "-------------------------------\n",
      "loss: 0.267678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393804 \n",
      "\n",
      "Epoch 1960\n",
      "-------------------------------\n",
      "loss: 0.275161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393094 \n",
      "\n",
      "Epoch 1961\n",
      "-------------------------------\n",
      "loss: 0.258187  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393220 \n",
      "\n",
      "Epoch 1962\n",
      "-------------------------------\n",
      "loss: 0.271794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393072 \n",
      "\n",
      "Epoch 1963\n",
      "-------------------------------\n",
      "loss: 0.271008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393192 \n",
      "\n",
      "Epoch 1964\n",
      "-------------------------------\n",
      "loss: 0.262287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394206 \n",
      "\n",
      "Epoch 1965\n",
      "-------------------------------\n",
      "loss: 0.261882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395821 \n",
      "\n",
      "Epoch 1966\n",
      "-------------------------------\n",
      "loss: 0.244058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397143 \n",
      "\n",
      "Epoch 1967\n",
      "-------------------------------\n",
      "loss: 0.267536  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395954 \n",
      "\n",
      "Epoch 1968\n",
      "-------------------------------\n",
      "loss: 0.272824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394157 \n",
      "\n",
      "Epoch 1969\n",
      "-------------------------------\n",
      "loss: 0.286006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394210 \n",
      "\n",
      "Epoch 1970\n",
      "-------------------------------\n",
      "loss: 0.277795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394983 \n",
      "\n",
      "Epoch 1971\n",
      "-------------------------------\n",
      "loss: 0.279923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394128 \n",
      "\n",
      "Epoch 1972\n",
      "-------------------------------\n",
      "loss: 0.262189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393490 \n",
      "\n",
      "Epoch 1973\n",
      "-------------------------------\n",
      "loss: 0.255608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396474 \n",
      "\n",
      "Epoch 1974\n",
      "-------------------------------\n",
      "loss: 0.262965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400695 \n",
      "\n",
      "Epoch 1975\n",
      "-------------------------------\n",
      "loss: 0.281296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400537 \n",
      "\n",
      "Epoch 1976\n",
      "-------------------------------\n",
      "loss: 0.269738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397060 \n",
      "\n",
      "Epoch 1977\n",
      "-------------------------------\n",
      "loss: 0.249986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394928 \n",
      "\n",
      "Epoch 1978\n",
      "-------------------------------\n",
      "loss: 0.258479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394967 \n",
      "\n",
      "Epoch 1979\n",
      "-------------------------------\n",
      "loss: 0.265981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395932 \n",
      "\n",
      "Epoch 1980\n",
      "-------------------------------\n",
      "loss: 0.280118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396664 \n",
      "\n",
      "Epoch 1981\n",
      "-------------------------------\n",
      "loss: 0.260060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397847 \n",
      "\n",
      "Epoch 1982\n",
      "-------------------------------\n",
      "loss: 0.251678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399396 \n",
      "\n",
      "Epoch 1983\n",
      "-------------------------------\n",
      "loss: 0.277470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401793 \n",
      "\n",
      "Epoch 1984\n",
      "-------------------------------\n",
      "loss: 0.278049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404422 \n",
      "\n",
      "Epoch 1985\n",
      "-------------------------------\n",
      "loss: 0.275210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405476 \n",
      "\n",
      "Epoch 1986\n",
      "-------------------------------\n",
      "loss: 0.284175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403529 \n",
      "\n",
      "Epoch 1987\n",
      "-------------------------------\n",
      "loss: 0.269776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400655 \n",
      "\n",
      "Epoch 1988\n",
      "-------------------------------\n",
      "loss: 0.271697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399146 \n",
      "\n",
      "Epoch 1989\n",
      "-------------------------------\n",
      "loss: 0.271113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398136 \n",
      "\n",
      "Epoch 1990\n",
      "-------------------------------\n",
      "loss: 0.261333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396482 \n",
      "\n",
      "Epoch 1991\n",
      "-------------------------------\n",
      "loss: 0.270266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397180 \n",
      "\n",
      "Epoch 1992\n",
      "-------------------------------\n",
      "loss: 0.250525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402817 \n",
      "\n",
      "Epoch 1993\n",
      "-------------------------------\n",
      "loss: 0.261880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408690 \n",
      "\n",
      "Epoch 1994\n",
      "-------------------------------\n",
      "loss: 0.275671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405715 \n",
      "\n",
      "Epoch 1995\n",
      "-------------------------------\n",
      "loss: 0.273141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400662 \n",
      "\n",
      "Epoch 1996\n",
      "-------------------------------\n",
      "loss: 0.281338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396013 \n",
      "\n",
      "Epoch 1997\n",
      "-------------------------------\n",
      "loss: 0.260284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396782 \n",
      "\n",
      "Epoch 1998\n",
      "-------------------------------\n",
      "loss: 0.251591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397497 \n",
      "\n",
      "Epoch 1999\n",
      "-------------------------------\n",
      "loss: 0.262484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396555 \n",
      "\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "loss: 0.272627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396873 \n",
      "\n",
      "Epoch 2001\n",
      "-------------------------------\n",
      "loss: 0.270993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400553 \n",
      "\n",
      "Epoch 2002\n",
      "-------------------------------\n",
      "loss: 0.246146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408197 \n",
      "\n",
      "Epoch 2003\n",
      "-------------------------------\n",
      "loss: 0.263041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412368 \n",
      "\n",
      "Epoch 2004\n",
      "-------------------------------\n",
      "loss: 0.265793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409665 \n",
      "\n",
      "Epoch 2005\n",
      "-------------------------------\n",
      "loss: 0.267346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403761 \n",
      "\n",
      "Epoch 2006\n",
      "-------------------------------\n",
      "loss: 0.286918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397983 \n",
      "\n",
      "Epoch 2007\n",
      "-------------------------------\n",
      "loss: 0.270960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396403 \n",
      "\n",
      "Epoch 2008\n",
      "-------------------------------\n",
      "loss: 0.279821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397390 \n",
      "\n",
      "Epoch 2009\n",
      "-------------------------------\n",
      "loss: 0.280832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396604 \n",
      "\n",
      "Epoch 2010\n",
      "-------------------------------\n",
      "loss: 0.278519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396546 \n",
      "\n",
      "Epoch 2011\n",
      "-------------------------------\n",
      "loss: 0.255503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398351 \n",
      "\n",
      "Epoch 2012\n",
      "-------------------------------\n",
      "loss: 0.258563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403246 \n",
      "\n",
      "Epoch 2013\n",
      "-------------------------------\n",
      "loss: 0.279168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406669 \n",
      "\n",
      "Epoch 2014\n",
      "-------------------------------\n",
      "loss: 0.259041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406598 \n",
      "\n",
      "Epoch 2015\n",
      "-------------------------------\n",
      "loss: 0.258413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402040 \n",
      "\n",
      "Epoch 2016\n",
      "-------------------------------\n",
      "loss: 0.255237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398504 \n",
      "\n",
      "Epoch 2017\n",
      "-------------------------------\n",
      "loss: 0.265190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397671 \n",
      "\n",
      "Epoch 2018\n",
      "-------------------------------\n",
      "loss: 0.267985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398121 \n",
      "\n",
      "Epoch 2019\n",
      "-------------------------------\n",
      "loss: 0.267561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397394 \n",
      "\n",
      "Epoch 2020\n",
      "-------------------------------\n",
      "loss: 0.267924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397841 \n",
      "\n",
      "Epoch 2021\n",
      "-------------------------------\n",
      "loss: 0.259959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400337 \n",
      "\n",
      "Epoch 2022\n",
      "-------------------------------\n",
      "loss: 0.274917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405041 \n",
      "\n",
      "Epoch 2023\n",
      "-------------------------------\n",
      "loss: 0.261337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408807 \n",
      "\n",
      "Epoch 2024\n",
      "-------------------------------\n",
      "loss: 0.263763  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407823 \n",
      "\n",
      "Epoch 2025\n",
      "-------------------------------\n",
      "loss: 0.262386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403843 \n",
      "\n",
      "Epoch 2026\n",
      "-------------------------------\n",
      "loss: 0.283534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397826 \n",
      "\n",
      "Epoch 2027\n",
      "-------------------------------\n",
      "loss: 0.250271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395175 \n",
      "\n",
      "Epoch 2028\n",
      "-------------------------------\n",
      "loss: 0.258841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394901 \n",
      "\n",
      "Epoch 2029\n",
      "-------------------------------\n",
      "loss: 0.272519  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.394526 \n",
      "\n",
      "Epoch 2030\n",
      "-------------------------------\n",
      "loss: 0.267232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394920 \n",
      "\n",
      "Epoch 2031\n",
      "-------------------------------\n",
      "loss: 0.248699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399557 \n",
      "\n",
      "Epoch 2032\n",
      "-------------------------------\n",
      "loss: 0.246406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404217 \n",
      "\n",
      "Epoch 2033\n",
      "-------------------------------\n",
      "loss: 0.262210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402867 \n",
      "\n",
      "Epoch 2034\n",
      "-------------------------------\n",
      "loss: 0.255089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397729 \n",
      "\n",
      "Epoch 2035\n",
      "-------------------------------\n",
      "loss: 0.274788  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394813 \n",
      "\n",
      "Epoch 2036\n",
      "-------------------------------\n",
      "loss: 0.248432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396534 \n",
      "\n",
      "Epoch 2037\n",
      "-------------------------------\n",
      "loss: 0.278809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399808 \n",
      "\n",
      "Epoch 2038\n",
      "-------------------------------\n",
      "loss: 0.274052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401792 \n",
      "\n",
      "Epoch 2039\n",
      "-------------------------------\n",
      "loss: 0.267531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401520 \n",
      "\n",
      "Epoch 2040\n",
      "-------------------------------\n",
      "loss: 0.251959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402087 \n",
      "\n",
      "Epoch 2041\n",
      "-------------------------------\n",
      "loss: 0.263931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404804 \n",
      "\n",
      "Epoch 2042\n",
      "-------------------------------\n",
      "loss: 0.255046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406903 \n",
      "\n",
      "Epoch 2043\n",
      "-------------------------------\n",
      "loss: 0.261843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407142 \n",
      "\n",
      "Epoch 2044\n",
      "-------------------------------\n",
      "loss: 0.265604  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404592 \n",
      "\n",
      "Epoch 2045\n",
      "-------------------------------\n",
      "loss: 0.281250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400110 \n",
      "\n",
      "Epoch 2046\n",
      "-------------------------------\n",
      "loss: 0.258578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397607 \n",
      "\n",
      "Epoch 2047\n",
      "-------------------------------\n",
      "loss: 0.267211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396041 \n",
      "\n",
      "Epoch 2048\n",
      "-------------------------------\n",
      "loss: 0.270289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395009 \n",
      "\n",
      "Epoch 2049\n",
      "-------------------------------\n",
      "loss: 0.275373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395674 \n",
      "\n",
      "Epoch 2050\n",
      "-------------------------------\n",
      "loss: 0.242048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399954 \n",
      "\n",
      "Epoch 2051\n",
      "-------------------------------\n",
      "loss: 0.263091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401958 \n",
      "\n",
      "Epoch 2052\n",
      "-------------------------------\n",
      "loss: 0.252172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400627 \n",
      "\n",
      "Epoch 2053\n",
      "-------------------------------\n",
      "loss: 0.265332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397843 \n",
      "\n",
      "Epoch 2054\n",
      "-------------------------------\n",
      "loss: 0.257751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395700 \n",
      "\n",
      "Epoch 2055\n",
      "-------------------------------\n",
      "loss: 0.246441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394656 \n",
      "\n",
      "Epoch 2056\n",
      "-------------------------------\n",
      "loss: 0.258729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394687 \n",
      "\n",
      "Epoch 2057\n",
      "-------------------------------\n",
      "loss: 0.282849  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395353 \n",
      "\n",
      "Epoch 2058\n",
      "-------------------------------\n",
      "loss: 0.272174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396894 \n",
      "\n",
      "Epoch 2059\n",
      "-------------------------------\n",
      "loss: 0.257270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397553 \n",
      "\n",
      "Epoch 2060\n",
      "-------------------------------\n",
      "loss: 0.275238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398187 \n",
      "\n",
      "Epoch 2061\n",
      "-------------------------------\n",
      "loss: 0.260302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398719 \n",
      "\n",
      "Epoch 2062\n",
      "-------------------------------\n",
      "loss: 0.257251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399283 \n",
      "\n",
      "Epoch 2063\n",
      "-------------------------------\n",
      "loss: 0.251725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400047 \n",
      "\n",
      "Epoch 2064\n",
      "-------------------------------\n",
      "loss: 0.254295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401227 \n",
      "\n",
      "Epoch 2065\n",
      "-------------------------------\n",
      "loss: 0.255189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402098 \n",
      "\n",
      "Epoch 2066\n",
      "-------------------------------\n",
      "loss: 0.268656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402907 \n",
      "\n",
      "Epoch 2067\n",
      "-------------------------------\n",
      "loss: 0.245632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403289 \n",
      "\n",
      "Epoch 2068\n",
      "-------------------------------\n",
      "loss: 0.264396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401748 \n",
      "\n",
      "Epoch 2069\n",
      "-------------------------------\n",
      "loss: 0.254240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400348 \n",
      "\n",
      "Epoch 2070\n",
      "-------------------------------\n",
      "loss: 0.266981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397747 \n",
      "\n",
      "Epoch 2071\n",
      "-------------------------------\n",
      "loss: 0.283179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396931 \n",
      "\n",
      "Epoch 2072\n",
      "-------------------------------\n",
      "loss: 0.266429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396900 \n",
      "\n",
      "Epoch 2073\n",
      "-------------------------------\n",
      "loss: 0.264929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398052 \n",
      "\n",
      "Epoch 2074\n",
      "-------------------------------\n",
      "loss: 0.260076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400970 \n",
      "\n",
      "Epoch 2075\n",
      "-------------------------------\n",
      "loss: 0.256626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401986 \n",
      "\n",
      "Epoch 2076\n",
      "-------------------------------\n",
      "loss: 0.266295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401529 \n",
      "\n",
      "Epoch 2077\n",
      "-------------------------------\n",
      "loss: 0.268900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400220 \n",
      "\n",
      "Epoch 2078\n",
      "-------------------------------\n",
      "loss: 0.261540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399310 \n",
      "\n",
      "Epoch 2079\n",
      "-------------------------------\n",
      "loss: 0.262442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398688 \n",
      "\n",
      "Epoch 2080\n",
      "-------------------------------\n",
      "loss: 0.280156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397615 \n",
      "\n",
      "Epoch 2081\n",
      "-------------------------------\n",
      "loss: 0.269999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396030 \n",
      "\n",
      "Epoch 2082\n",
      "-------------------------------\n",
      "loss: 0.271173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396129 \n",
      "\n",
      "Epoch 2083\n",
      "-------------------------------\n",
      "loss: 0.252847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397727 \n",
      "\n",
      "Epoch 2084\n",
      "-------------------------------\n",
      "loss: 0.266336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401234 \n",
      "\n",
      "Epoch 2085\n",
      "-------------------------------\n",
      "loss: 0.260389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403476 \n",
      "\n",
      "Epoch 2086\n",
      "-------------------------------\n",
      "loss: 0.273425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402924 \n",
      "\n",
      "Epoch 2087\n",
      "-------------------------------\n",
      "loss: 0.271285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398101 \n",
      "\n",
      "Epoch 2088\n",
      "-------------------------------\n",
      "loss: 0.261705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393531 \n",
      "\n",
      "Epoch 2089\n",
      "-------------------------------\n",
      "loss: 0.274435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393204 \n",
      "\n",
      "Epoch 2090\n",
      "-------------------------------\n",
      "loss: 0.266127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393336 \n",
      "\n",
      "Epoch 2091\n",
      "-------------------------------\n",
      "loss: 0.255559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392330 \n",
      "\n",
      "Epoch 2092\n",
      "-------------------------------\n",
      "loss: 0.264119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393669 \n",
      "\n",
      "Epoch 2093\n",
      "-------------------------------\n",
      "loss: 0.258180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398543 \n",
      "\n",
      "Epoch 2094\n",
      "-------------------------------\n",
      "loss: 0.259465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405306 \n",
      "\n",
      "Epoch 2095\n",
      "-------------------------------\n",
      "loss: 0.294090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408655 \n",
      "\n",
      "Epoch 2096\n",
      "-------------------------------\n",
      "loss: 0.288942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406407 \n",
      "\n",
      "Epoch 2097\n",
      "-------------------------------\n",
      "loss: 0.270548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402060 \n",
      "\n",
      "Epoch 2098\n",
      "-------------------------------\n",
      "loss: 0.267721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400180 \n",
      "\n",
      "Epoch 2099\n",
      "-------------------------------\n",
      "loss: 0.257174  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399540 \n",
      "\n",
      "Epoch 2100\n",
      "-------------------------------\n",
      "loss: 0.268583  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399415 \n",
      "\n",
      "Epoch 2101\n",
      "-------------------------------\n",
      "loss: 0.269073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399066 \n",
      "\n",
      "Epoch 2102\n",
      "-------------------------------\n",
      "loss: 0.261488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399658 \n",
      "\n",
      "Epoch 2103\n",
      "-------------------------------\n",
      "loss: 0.251672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400133 \n",
      "\n",
      "Epoch 2104\n",
      "-------------------------------\n",
      "loss: 0.263561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398448 \n",
      "\n",
      "Epoch 2105\n",
      "-------------------------------\n",
      "loss: 0.259053  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.395442 \n",
      "\n",
      "Epoch 2106\n",
      "-------------------------------\n",
      "loss: 0.258478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392837 \n",
      "\n",
      "Epoch 2107\n",
      "-------------------------------\n",
      "loss: 0.260701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.392997 \n",
      "\n",
      "Epoch 2108\n",
      "-------------------------------\n",
      "loss: 0.267690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394100 \n",
      "\n",
      "Epoch 2109\n",
      "-------------------------------\n",
      "loss: 0.267035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394017 \n",
      "\n",
      "Epoch 2110\n",
      "-------------------------------\n",
      "loss: 0.270616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395201 \n",
      "\n",
      "Epoch 2111\n",
      "-------------------------------\n",
      "loss: 0.260952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397738 \n",
      "\n",
      "Epoch 2112\n",
      "-------------------------------\n",
      "loss: 0.257523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400825 \n",
      "\n",
      "Epoch 2113\n",
      "-------------------------------\n",
      "loss: 0.264605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402386 \n",
      "\n",
      "Epoch 2114\n",
      "-------------------------------\n",
      "loss: 0.264486  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400177 \n",
      "\n",
      "Epoch 2115\n",
      "-------------------------------\n",
      "loss: 0.263023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397199 \n",
      "\n",
      "Epoch 2116\n",
      "-------------------------------\n",
      "loss: 0.263056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395074 \n",
      "\n",
      "Epoch 2117\n",
      "-------------------------------\n",
      "loss: 0.271016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394873 \n",
      "\n",
      "Epoch 2118\n",
      "-------------------------------\n",
      "loss: 0.284672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394028 \n",
      "\n",
      "Epoch 2119\n",
      "-------------------------------\n",
      "loss: 0.277949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393733 \n",
      "\n",
      "Epoch 2120\n",
      "-------------------------------\n",
      "loss: 0.275386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395871 \n",
      "\n",
      "Epoch 2121\n",
      "-------------------------------\n",
      "loss: 0.250301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400682 \n",
      "\n",
      "Epoch 2122\n",
      "-------------------------------\n",
      "loss: 0.278657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406456 \n",
      "\n",
      "Epoch 2123\n",
      "-------------------------------\n",
      "loss: 0.287715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408411 \n",
      "\n",
      "Epoch 2124\n",
      "-------------------------------\n",
      "loss: 0.260919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406817 \n",
      "\n",
      "Epoch 2125\n",
      "-------------------------------\n",
      "loss: 0.271634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402718 \n",
      "\n",
      "Epoch 2126\n",
      "-------------------------------\n",
      "loss: 0.270714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399501 \n",
      "\n",
      "Epoch 2127\n",
      "-------------------------------\n",
      "loss: 0.250709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398308 \n",
      "\n",
      "Epoch 2128\n",
      "-------------------------------\n",
      "loss: 0.270032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399732 \n",
      "\n",
      "Epoch 2129\n",
      "-------------------------------\n",
      "loss: 0.269058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401126 \n",
      "\n",
      "Epoch 2130\n",
      "-------------------------------\n",
      "loss: 0.273896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401616 \n",
      "\n",
      "Epoch 2131\n",
      "-------------------------------\n",
      "loss: 0.274379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404170 \n",
      "\n",
      "Epoch 2132\n",
      "-------------------------------\n",
      "loss: 0.268170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406964 \n",
      "\n",
      "Epoch 2133\n",
      "-------------------------------\n",
      "loss: 0.257196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409357 \n",
      "\n",
      "Epoch 2134\n",
      "-------------------------------\n",
      "loss: 0.263269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409870 \n",
      "\n",
      "Epoch 2135\n",
      "-------------------------------\n",
      "loss: 0.252824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406673 \n",
      "\n",
      "Epoch 2136\n",
      "-------------------------------\n",
      "loss: 0.256806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403318 \n",
      "\n",
      "Epoch 2137\n",
      "-------------------------------\n",
      "loss: 0.252465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400984 \n",
      "\n",
      "Epoch 2138\n",
      "-------------------------------\n",
      "loss: 0.263039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400406 \n",
      "\n",
      "Epoch 2139\n",
      "-------------------------------\n",
      "loss: 0.256824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400203 \n",
      "\n",
      "Epoch 2140\n",
      "-------------------------------\n",
      "loss: 0.262900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400679 \n",
      "\n",
      "Epoch 2141\n",
      "-------------------------------\n",
      "loss: 0.258943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403038 \n",
      "\n",
      "Epoch 2142\n",
      "-------------------------------\n",
      "loss: 0.263850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406288 \n",
      "\n",
      "Epoch 2143\n",
      "-------------------------------\n",
      "loss: 0.287915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407334 \n",
      "\n",
      "Epoch 2144\n",
      "-------------------------------\n",
      "loss: 0.255461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405299 \n",
      "\n",
      "Epoch 2145\n",
      "-------------------------------\n",
      "loss: 0.277252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402746 \n",
      "\n",
      "Epoch 2146\n",
      "-------------------------------\n",
      "loss: 0.242386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401600 \n",
      "\n",
      "Epoch 2147\n",
      "-------------------------------\n",
      "loss: 0.254102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401219 \n",
      "\n",
      "Epoch 2148\n",
      "-------------------------------\n",
      "loss: 0.253323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401335 \n",
      "\n",
      "Epoch 2149\n",
      "-------------------------------\n",
      "loss: 0.250983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402117 \n",
      "\n",
      "Epoch 2150\n",
      "-------------------------------\n",
      "loss: 0.253365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401978 \n",
      "\n",
      "Epoch 2151\n",
      "-------------------------------\n",
      "loss: 0.272793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400961 \n",
      "\n",
      "Epoch 2152\n",
      "-------------------------------\n",
      "loss: 0.260765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400990 \n",
      "\n",
      "Epoch 2153\n",
      "-------------------------------\n",
      "loss: 0.237958  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404280 \n",
      "\n",
      "Epoch 2154\n",
      "-------------------------------\n",
      "loss: 0.263148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407989 \n",
      "\n",
      "Epoch 2155\n",
      "-------------------------------\n",
      "loss: 0.278724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405398 \n",
      "\n",
      "Epoch 2156\n",
      "-------------------------------\n",
      "loss: 0.245568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400183 \n",
      "\n",
      "Epoch 2157\n",
      "-------------------------------\n",
      "loss: 0.238148  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397351 \n",
      "\n",
      "Epoch 2158\n",
      "-------------------------------\n",
      "loss: 0.264219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396510 \n",
      "\n",
      "Epoch 2159\n",
      "-------------------------------\n",
      "loss: 0.269548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397127 \n",
      "\n",
      "Epoch 2160\n",
      "-------------------------------\n",
      "loss: 0.263342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398862 \n",
      "\n",
      "Epoch 2161\n",
      "-------------------------------\n",
      "loss: 0.256342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401590 \n",
      "\n",
      "Epoch 2162\n",
      "-------------------------------\n",
      "loss: 0.270116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402570 \n",
      "\n",
      "Epoch 2163\n",
      "-------------------------------\n",
      "loss: 0.258922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402325 \n",
      "\n",
      "Epoch 2164\n",
      "-------------------------------\n",
      "loss: 0.262337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401182 \n",
      "\n",
      "Epoch 2165\n",
      "-------------------------------\n",
      "loss: 0.251505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401450 \n",
      "\n",
      "Epoch 2166\n",
      "-------------------------------\n",
      "loss: 0.255328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402409 \n",
      "\n",
      "Epoch 2167\n",
      "-------------------------------\n",
      "loss: 0.253030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404422 \n",
      "\n",
      "Epoch 2168\n",
      "-------------------------------\n",
      "loss: 0.252480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407568 \n",
      "\n",
      "Epoch 2169\n",
      "-------------------------------\n",
      "loss: 0.270981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409802 \n",
      "\n",
      "Epoch 2170\n",
      "-------------------------------\n",
      "loss: 0.256708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409827 \n",
      "\n",
      "Epoch 2171\n",
      "-------------------------------\n",
      "loss: 0.271940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408712 \n",
      "\n",
      "Epoch 2172\n",
      "-------------------------------\n",
      "loss: 0.269759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405106 \n",
      "\n",
      "Epoch 2173\n",
      "-------------------------------\n",
      "loss: 0.255147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402103 \n",
      "\n",
      "Epoch 2174\n",
      "-------------------------------\n",
      "loss: 0.270008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401078 \n",
      "\n",
      "Epoch 2175\n",
      "-------------------------------\n",
      "loss: 0.256389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 2176\n",
      "-------------------------------\n",
      "loss: 0.262308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403301 \n",
      "\n",
      "Epoch 2177\n",
      "-------------------------------\n",
      "loss: 0.252892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405086 \n",
      "\n",
      "Epoch 2178\n",
      "-------------------------------\n",
      "loss: 0.257873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405323 \n",
      "\n",
      "Epoch 2179\n",
      "-------------------------------\n",
      "loss: 0.247570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404475 \n",
      "\n",
      "Epoch 2180\n",
      "-------------------------------\n",
      "loss: 0.252307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402728 \n",
      "\n",
      "Epoch 2181\n",
      "-------------------------------\n",
      "loss: 0.250147  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400987 \n",
      "\n",
      "Epoch 2182\n",
      "-------------------------------\n",
      "loss: 0.252167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399246 \n",
      "\n",
      "Epoch 2183\n",
      "-------------------------------\n",
      "loss: 0.254615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399569 \n",
      "\n",
      "Epoch 2184\n",
      "-------------------------------\n",
      "loss: 0.267163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400492 \n",
      "\n",
      "Epoch 2185\n",
      "-------------------------------\n",
      "loss: 0.261386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400235 \n",
      "\n",
      "Epoch 2186\n",
      "-------------------------------\n",
      "loss: 0.269975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400001 \n",
      "\n",
      "Epoch 2187\n",
      "-------------------------------\n",
      "loss: 0.273577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399453 \n",
      "\n",
      "Epoch 2188\n",
      "-------------------------------\n",
      "loss: 0.258904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399414 \n",
      "\n",
      "Epoch 2189\n",
      "-------------------------------\n",
      "loss: 0.259476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401493 \n",
      "\n",
      "Epoch 2190\n",
      "-------------------------------\n",
      "loss: 0.249967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402541 \n",
      "\n",
      "Epoch 2191\n",
      "-------------------------------\n",
      "loss: 0.266096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403395 \n",
      "\n",
      "Epoch 2192\n",
      "-------------------------------\n",
      "loss: 0.257519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403042 \n",
      "\n",
      "Epoch 2193\n",
      "-------------------------------\n",
      "loss: 0.247276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401821 \n",
      "\n",
      "Epoch 2194\n",
      "-------------------------------\n",
      "loss: 0.256975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400090 \n",
      "\n",
      "Epoch 2195\n",
      "-------------------------------\n",
      "loss: 0.276945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398376 \n",
      "\n",
      "Epoch 2196\n",
      "-------------------------------\n",
      "loss: 0.245825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396847 \n",
      "\n",
      "Epoch 2197\n",
      "-------------------------------\n",
      "loss: 0.253369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396677 \n",
      "\n",
      "Epoch 2198\n",
      "-------------------------------\n",
      "loss: 0.259630  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397840 \n",
      "\n",
      "Epoch 2199\n",
      "-------------------------------\n",
      "loss: 0.271107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400484 \n",
      "\n",
      "Epoch 2200\n",
      "-------------------------------\n",
      "loss: 0.254039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406219 \n",
      "\n",
      "Epoch 2201\n",
      "-------------------------------\n",
      "loss: 0.271945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409568 \n",
      "\n",
      "Epoch 2202\n",
      "-------------------------------\n",
      "loss: 0.254503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406381 \n",
      "\n",
      "Epoch 2203\n",
      "-------------------------------\n",
      "loss: 0.261569  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400431 \n",
      "\n",
      "Epoch 2204\n",
      "-------------------------------\n",
      "loss: 0.246253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396369 \n",
      "\n",
      "Epoch 2205\n",
      "-------------------------------\n",
      "loss: 0.263050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395173 \n",
      "\n",
      "Epoch 2206\n",
      "-------------------------------\n",
      "loss: 0.242715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395416 \n",
      "\n",
      "Epoch 2207\n",
      "-------------------------------\n",
      "loss: 0.264989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395346 \n",
      "\n",
      "Epoch 2208\n",
      "-------------------------------\n",
      "loss: 0.261086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395433 \n",
      "\n",
      "Epoch 2209\n",
      "-------------------------------\n",
      "loss: 0.259834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394725 \n",
      "\n",
      "Epoch 2210\n",
      "-------------------------------\n",
      "loss: 0.254918  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395078 \n",
      "\n",
      "Epoch 2211\n",
      "-------------------------------\n",
      "loss: 0.256820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396442 \n",
      "\n",
      "Epoch 2212\n",
      "-------------------------------\n",
      "loss: 0.254714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398986 \n",
      "\n",
      "Epoch 2213\n",
      "-------------------------------\n",
      "loss: 0.257557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400205 \n",
      "\n",
      "Epoch 2214\n",
      "-------------------------------\n",
      "loss: 0.281221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399637 \n",
      "\n",
      "Epoch 2215\n",
      "-------------------------------\n",
      "loss: 0.250807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399774 \n",
      "\n",
      "Epoch 2216\n",
      "-------------------------------\n",
      "loss: 0.250048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402447 \n",
      "\n",
      "Epoch 2217\n",
      "-------------------------------\n",
      "loss: 0.255205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403074 \n",
      "\n",
      "Epoch 2218\n",
      "-------------------------------\n",
      "loss: 0.259019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402027 \n",
      "\n",
      "Epoch 2219\n",
      "-------------------------------\n",
      "loss: 0.267002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400309 \n",
      "\n",
      "Epoch 2220\n",
      "-------------------------------\n",
      "loss: 0.257011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400171 \n",
      "\n",
      "Epoch 2221\n",
      "-------------------------------\n",
      "loss: 0.255505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401345 \n",
      "\n",
      "Epoch 2222\n",
      "-------------------------------\n",
      "loss: 0.242781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402750 \n",
      "\n",
      "Epoch 2223\n",
      "-------------------------------\n",
      "loss: 0.254665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403367 \n",
      "\n",
      "Epoch 2224\n",
      "-------------------------------\n",
      "loss: 0.268250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401613 \n",
      "\n",
      "Epoch 2225\n",
      "-------------------------------\n",
      "loss: 0.262491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399939 \n",
      "\n",
      "Epoch 2226\n",
      "-------------------------------\n",
      "loss: 0.277700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398258 \n",
      "\n",
      "Epoch 2227\n",
      "-------------------------------\n",
      "loss: 0.257653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396670 \n",
      "\n",
      "Epoch 2228\n",
      "-------------------------------\n",
      "loss: 0.252063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396265 \n",
      "\n",
      "Epoch 2229\n",
      "-------------------------------\n",
      "loss: 0.275118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396302 \n",
      "\n",
      "Epoch 2230\n",
      "-------------------------------\n",
      "loss: 0.257343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398992 \n",
      "\n",
      "Epoch 2231\n",
      "-------------------------------\n",
      "loss: 0.273151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399527 \n",
      "\n",
      "Epoch 2232\n",
      "-------------------------------\n",
      "loss: 0.256953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397405 \n",
      "\n",
      "Epoch 2233\n",
      "-------------------------------\n",
      "loss: 0.264478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394965 \n",
      "\n",
      "Epoch 2234\n",
      "-------------------------------\n",
      "loss: 0.249122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394253 \n",
      "\n",
      "Epoch 2235\n",
      "-------------------------------\n",
      "loss: 0.243229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394232 \n",
      "\n",
      "Epoch 2236\n",
      "-------------------------------\n",
      "loss: 0.246663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394689 \n",
      "\n",
      "Epoch 2237\n",
      "-------------------------------\n",
      "loss: 0.252848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396346 \n",
      "\n",
      "Epoch 2238\n",
      "-------------------------------\n",
      "loss: 0.243288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399329 \n",
      "\n",
      "Epoch 2239\n",
      "-------------------------------\n",
      "loss: 0.260809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402774 \n",
      "\n",
      "Epoch 2240\n",
      "-------------------------------\n",
      "loss: 0.268221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401903 \n",
      "\n",
      "Epoch 2241\n",
      "-------------------------------\n",
      "loss: 0.266289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399349 \n",
      "\n",
      "Epoch 2242\n",
      "-------------------------------\n",
      "loss: 0.237458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396918 \n",
      "\n",
      "Epoch 2243\n",
      "-------------------------------\n",
      "loss: 0.268229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395215 \n",
      "\n",
      "Epoch 2244\n",
      "-------------------------------\n",
      "loss: 0.254586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394728 \n",
      "\n",
      "Epoch 2245\n",
      "-------------------------------\n",
      "loss: 0.262618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395036 \n",
      "\n",
      "Epoch 2246\n",
      "-------------------------------\n",
      "loss: 0.247920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396251 \n",
      "\n",
      "Epoch 2247\n",
      "-------------------------------\n",
      "loss: 0.263427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397789 \n",
      "\n",
      "Epoch 2248\n",
      "-------------------------------\n",
      "loss: 0.276488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397572 \n",
      "\n",
      "Epoch 2249\n",
      "-------------------------------\n",
      "loss: 0.283189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395762 \n",
      "\n",
      "Epoch 2250\n",
      "-------------------------------\n",
      "loss: 0.276141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393869 \n",
      "\n",
      "Epoch 2251\n",
      "-------------------------------\n",
      "loss: 0.241155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394435 \n",
      "\n",
      "Epoch 2252\n",
      "-------------------------------\n",
      "loss: 0.259835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395881 \n",
      "\n",
      "Epoch 2253\n",
      "-------------------------------\n",
      "loss: 0.269784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397562 \n",
      "\n",
      "Epoch 2254\n",
      "-------------------------------\n",
      "loss: 0.246341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399523 \n",
      "\n",
      "Epoch 2255\n",
      "-------------------------------\n",
      "loss: 0.272785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399988 \n",
      "\n",
      "Epoch 2256\n",
      "-------------------------------\n",
      "loss: 0.262711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398202 \n",
      "\n",
      "Epoch 2257\n",
      "-------------------------------\n",
      "loss: 0.253257  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397800 \n",
      "\n",
      "Epoch 2258\n",
      "-------------------------------\n",
      "loss: 0.247635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398419 \n",
      "\n",
      "Epoch 2259\n",
      "-------------------------------\n",
      "loss: 0.254776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400044 \n",
      "\n",
      "Epoch 2260\n",
      "-------------------------------\n",
      "loss: 0.256044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400025 \n",
      "\n",
      "Epoch 2261\n",
      "-------------------------------\n",
      "loss: 0.243362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399543 \n",
      "\n",
      "Epoch 2262\n",
      "-------------------------------\n",
      "loss: 0.257871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399824 \n",
      "\n",
      "Epoch 2263\n",
      "-------------------------------\n",
      "loss: 0.248104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400684 \n",
      "\n",
      "Epoch 2264\n",
      "-------------------------------\n",
      "loss: 0.255875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401918 \n",
      "\n",
      "Epoch 2265\n",
      "-------------------------------\n",
      "loss: 0.259803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403538 \n",
      "\n",
      "Epoch 2266\n",
      "-------------------------------\n",
      "loss: 0.270014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405300 \n",
      "\n",
      "Epoch 2267\n",
      "-------------------------------\n",
      "loss: 0.246306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407345 \n",
      "\n",
      "Epoch 2268\n",
      "-------------------------------\n",
      "loss: 0.272313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407419 \n",
      "\n",
      "Epoch 2269\n",
      "-------------------------------\n",
      "loss: 0.257311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406499 \n",
      "\n",
      "Epoch 2270\n",
      "-------------------------------\n",
      "loss: 0.264532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404489 \n",
      "\n",
      "Epoch 2271\n",
      "-------------------------------\n",
      "loss: 0.261588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402276 \n",
      "\n",
      "Epoch 2272\n",
      "-------------------------------\n",
      "loss: 0.253228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401127 \n",
      "\n",
      "Epoch 2273\n",
      "-------------------------------\n",
      "loss: 0.244167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401474 \n",
      "\n",
      "Epoch 2274\n",
      "-------------------------------\n",
      "loss: 0.259652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402367 \n",
      "\n",
      "Epoch 2275\n",
      "-------------------------------\n",
      "loss: 0.255601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404148 \n",
      "\n",
      "Epoch 2276\n",
      "-------------------------------\n",
      "loss: 0.254601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407697 \n",
      "\n",
      "Epoch 2277\n",
      "-------------------------------\n",
      "loss: 0.258284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409293 \n",
      "\n",
      "Epoch 2278\n",
      "-------------------------------\n",
      "loss: 0.247762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408630 \n",
      "\n",
      "Epoch 2279\n",
      "-------------------------------\n",
      "loss: 0.241535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407321 \n",
      "\n",
      "Epoch 2280\n",
      "-------------------------------\n",
      "loss: 0.245734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405891 \n",
      "\n",
      "Epoch 2281\n",
      "-------------------------------\n",
      "loss: 0.256985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403913 \n",
      "\n",
      "Epoch 2282\n",
      "-------------------------------\n",
      "loss: 0.252559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401747 \n",
      "\n",
      "Epoch 2283\n",
      "-------------------------------\n",
      "loss: 0.263796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400113 \n",
      "\n",
      "Epoch 2284\n",
      "-------------------------------\n",
      "loss: 0.260055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399387 \n",
      "\n",
      "Epoch 2285\n",
      "-------------------------------\n",
      "loss: 0.253233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399541 \n",
      "\n",
      "Epoch 2286\n",
      "-------------------------------\n",
      "loss: 0.250932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399919 \n",
      "\n",
      "Epoch 2287\n",
      "-------------------------------\n",
      "loss: 0.260293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399626 \n",
      "\n",
      "Epoch 2288\n",
      "-------------------------------\n",
      "loss: 0.258606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399369 \n",
      "\n",
      "Epoch 2289\n",
      "-------------------------------\n",
      "loss: 0.242154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398769 \n",
      "\n",
      "Epoch 2290\n",
      "-------------------------------\n",
      "loss: 0.278227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399283 \n",
      "\n",
      "Epoch 2291\n",
      "-------------------------------\n",
      "loss: 0.250732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398538 \n",
      "\n",
      "Epoch 2292\n",
      "-------------------------------\n",
      "loss: 0.263104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399672 \n",
      "\n",
      "Epoch 2293\n",
      "-------------------------------\n",
      "loss: 0.259243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403202 \n",
      "\n",
      "Epoch 2294\n",
      "-------------------------------\n",
      "loss: 0.263528  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407659 \n",
      "\n",
      "Epoch 2295\n",
      "-------------------------------\n",
      "loss: 0.264801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411054 \n",
      "\n",
      "Epoch 2296\n",
      "-------------------------------\n",
      "loss: 0.252732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411071 \n",
      "\n",
      "Epoch 2297\n",
      "-------------------------------\n",
      "loss: 0.258026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409130 \n",
      "\n",
      "Epoch 2298\n",
      "-------------------------------\n",
      "loss: 0.278634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404395 \n",
      "\n",
      "Epoch 2299\n",
      "-------------------------------\n",
      "loss: 0.245389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402151 \n",
      "\n",
      "Epoch 2300\n",
      "-------------------------------\n",
      "loss: 0.267292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402201 \n",
      "\n",
      "Epoch 2301\n",
      "-------------------------------\n",
      "loss: 0.268154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402090 \n",
      "\n",
      "Epoch 2302\n",
      "-------------------------------\n",
      "loss: 0.259082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401315 \n",
      "\n",
      "Epoch 2303\n",
      "-------------------------------\n",
      "loss: 0.251529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403189 \n",
      "\n",
      "Epoch 2304\n",
      "-------------------------------\n",
      "loss: 0.250054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407419 \n",
      "\n",
      "Epoch 2305\n",
      "-------------------------------\n",
      "loss: 0.257643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410971 \n",
      "\n",
      "Epoch 2306\n",
      "-------------------------------\n",
      "loss: 0.249689  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412042 \n",
      "\n",
      "Epoch 2307\n",
      "-------------------------------\n",
      "loss: 0.241480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408628 \n",
      "\n",
      "Epoch 2308\n",
      "-------------------------------\n",
      "loss: 0.246452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405287 \n",
      "\n",
      "Epoch 2309\n",
      "-------------------------------\n",
      "loss: 0.264201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402631 \n",
      "\n",
      "Epoch 2310\n",
      "-------------------------------\n",
      "loss: 0.257609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401582 \n",
      "\n",
      "Epoch 2311\n",
      "-------------------------------\n",
      "loss: 0.254930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401361 \n",
      "\n",
      "Epoch 2312\n",
      "-------------------------------\n",
      "loss: 0.273838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401289 \n",
      "\n",
      "Epoch 2313\n",
      "-------------------------------\n",
      "loss: 0.267745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401180 \n",
      "\n",
      "Epoch 2314\n",
      "-------------------------------\n",
      "loss: 0.256169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401860 \n",
      "\n",
      "Epoch 2315\n",
      "-------------------------------\n",
      "loss: 0.267990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403033 \n",
      "\n",
      "Epoch 2316\n",
      "-------------------------------\n",
      "loss: 0.271003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403389 \n",
      "\n",
      "Epoch 2317\n",
      "-------------------------------\n",
      "loss: 0.248431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404055 \n",
      "\n",
      "Epoch 2318\n",
      "-------------------------------\n",
      "loss: 0.259955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402319 \n",
      "\n",
      "Epoch 2319\n",
      "-------------------------------\n",
      "loss: 0.269506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398482 \n",
      "\n",
      "Epoch 2320\n",
      "-------------------------------\n",
      "loss: 0.250153  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398050 \n",
      "\n",
      "Epoch 2321\n",
      "-------------------------------\n",
      "loss: 0.253447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399714 \n",
      "\n",
      "Epoch 2322\n",
      "-------------------------------\n",
      "loss: 0.262890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400510 \n",
      "\n",
      "Epoch 2323\n",
      "-------------------------------\n",
      "loss: 0.259778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400569 \n",
      "\n",
      "Epoch 2324\n",
      "-------------------------------\n",
      "loss: 0.253903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400660 \n",
      "\n",
      "Epoch 2325\n",
      "-------------------------------\n",
      "loss: 0.252020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400765 \n",
      "\n",
      "Epoch 2326\n",
      "-------------------------------\n",
      "loss: 0.250111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402075 \n",
      "\n",
      "Epoch 2327\n",
      "-------------------------------\n",
      "loss: 0.243008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404435 \n",
      "\n",
      "Epoch 2328\n",
      "-------------------------------\n",
      "loss: 0.258487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406861 \n",
      "\n",
      "Epoch 2329\n",
      "-------------------------------\n",
      "loss: 0.261210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407143 \n",
      "\n",
      "Epoch 2330\n",
      "-------------------------------\n",
      "loss: 0.262964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404344 \n",
      "\n",
      "Epoch 2331\n",
      "-------------------------------\n",
      "loss: 0.257424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401433 \n",
      "\n",
      "Epoch 2332\n",
      "-------------------------------\n",
      "loss: 0.252162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400900 \n",
      "\n",
      "Epoch 2333\n",
      "-------------------------------\n",
      "loss: 0.246696  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400844 \n",
      "\n",
      "Epoch 2334\n",
      "-------------------------------\n",
      "loss: 0.247566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402057 \n",
      "\n",
      "Epoch 2335\n",
      "-------------------------------\n",
      "loss: 0.255038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405318 \n",
      "\n",
      "Epoch 2336\n",
      "-------------------------------\n",
      "loss: 0.261471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408002 \n",
      "\n",
      "Epoch 2337\n",
      "-------------------------------\n",
      "loss: 0.265803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405396 \n",
      "\n",
      "Epoch 2338\n",
      "-------------------------------\n",
      "loss: 0.261696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401691 \n",
      "\n",
      "Epoch 2339\n",
      "-------------------------------\n",
      "loss: 0.249378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400497 \n",
      "\n",
      "Epoch 2340\n",
      "-------------------------------\n",
      "loss: 0.256676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400197 \n",
      "\n",
      "Epoch 2341\n",
      "-------------------------------\n",
      "loss: 0.266766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399526 \n",
      "\n",
      "Epoch 2342\n",
      "-------------------------------\n",
      "loss: 0.244024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398767 \n",
      "\n",
      "Epoch 2343\n",
      "-------------------------------\n",
      "loss: 0.260121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398492 \n",
      "\n",
      "Epoch 2344\n",
      "-------------------------------\n",
      "loss: 0.263344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398858 \n",
      "\n",
      "Epoch 2345\n",
      "-------------------------------\n",
      "loss: 0.250447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400268 \n",
      "\n",
      "Epoch 2346\n",
      "-------------------------------\n",
      "loss: 0.249516  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401582 \n",
      "\n",
      "Epoch 2347\n",
      "-------------------------------\n",
      "loss: 0.247968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401852 \n",
      "\n",
      "Epoch 2348\n",
      "-------------------------------\n",
      "loss: 0.241871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400598 \n",
      "\n",
      "Epoch 2349\n",
      "-------------------------------\n",
      "loss: 0.253903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398604 \n",
      "\n",
      "Epoch 2350\n",
      "-------------------------------\n",
      "loss: 0.258176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398828 \n",
      "\n",
      "Epoch 2351\n",
      "-------------------------------\n",
      "loss: 0.257425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398475 \n",
      "\n",
      "Epoch 2352\n",
      "-------------------------------\n",
      "loss: 0.251307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397111 \n",
      "\n",
      "Epoch 2353\n",
      "-------------------------------\n",
      "loss: 0.251408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396261 \n",
      "\n",
      "Epoch 2354\n",
      "-------------------------------\n",
      "loss: 0.236633  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395878 \n",
      "\n",
      "Epoch 2355\n",
      "-------------------------------\n",
      "loss: 0.243110  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396257 \n",
      "\n",
      "Epoch 2356\n",
      "-------------------------------\n",
      "loss: 0.252584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395794 \n",
      "\n",
      "Epoch 2357\n",
      "-------------------------------\n",
      "loss: 0.247361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396288 \n",
      "\n",
      "Epoch 2358\n",
      "-------------------------------\n",
      "loss: 0.253140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397086 \n",
      "\n",
      "Epoch 2359\n",
      "-------------------------------\n",
      "loss: 0.264273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397871 \n",
      "\n",
      "Epoch 2360\n",
      "-------------------------------\n",
      "loss: 0.245738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399397 \n",
      "\n",
      "Epoch 2361\n",
      "-------------------------------\n",
      "loss: 0.256939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400768 \n",
      "\n",
      "Epoch 2362\n",
      "-------------------------------\n",
      "loss: 0.263402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400910 \n",
      "\n",
      "Epoch 2363\n",
      "-------------------------------\n",
      "loss: 0.242127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400546 \n",
      "\n",
      "Epoch 2364\n",
      "-------------------------------\n",
      "loss: 0.267090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400290 \n",
      "\n",
      "Epoch 2365\n",
      "-------------------------------\n",
      "loss: 0.258386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399983 \n",
      "\n",
      "Epoch 2366\n",
      "-------------------------------\n",
      "loss: 0.259555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400480 \n",
      "\n",
      "Epoch 2367\n",
      "-------------------------------\n",
      "loss: 0.268458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399835 \n",
      "\n",
      "Epoch 2368\n",
      "-------------------------------\n",
      "loss: 0.247144  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398971 \n",
      "\n",
      "Epoch 2369\n",
      "-------------------------------\n",
      "loss: 0.247975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398995 \n",
      "\n",
      "Epoch 2370\n",
      "-------------------------------\n",
      "loss: 0.272226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398464 \n",
      "\n",
      "Epoch 2371\n",
      "-------------------------------\n",
      "loss: 0.249544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397460 \n",
      "\n",
      "Epoch 2372\n",
      "-------------------------------\n",
      "loss: 0.253681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395920 \n",
      "\n",
      "Epoch 2373\n",
      "-------------------------------\n",
      "loss: 0.251473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395818 \n",
      "\n",
      "Epoch 2374\n",
      "-------------------------------\n",
      "loss: 0.266286  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398436 \n",
      "\n",
      "Epoch 2375\n",
      "-------------------------------\n",
      "loss: 0.263796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402183 \n",
      "\n",
      "Epoch 2376\n",
      "-------------------------------\n",
      "loss: 0.262969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403810 \n",
      "\n",
      "Epoch 2377\n",
      "-------------------------------\n",
      "loss: 0.257257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401248 \n",
      "\n",
      "Epoch 2378\n",
      "-------------------------------\n",
      "loss: 0.256561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398514 \n",
      "\n",
      "Epoch 2379\n",
      "-------------------------------\n",
      "loss: 0.264490  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397219 \n",
      "\n",
      "Epoch 2380\n",
      "-------------------------------\n",
      "loss: 0.262840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397814 \n",
      "\n",
      "Epoch 2381\n",
      "-------------------------------\n",
      "loss: 0.249166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399702 \n",
      "\n",
      "Epoch 2382\n",
      "-------------------------------\n",
      "loss: 0.274538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399284 \n",
      "\n",
      "Epoch 2383\n",
      "-------------------------------\n",
      "loss: 0.262511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399022 \n",
      "\n",
      "Epoch 2384\n",
      "-------------------------------\n",
      "loss: 0.262013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399252 \n",
      "\n",
      "Epoch 2385\n",
      "-------------------------------\n",
      "loss: 0.246882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401433 \n",
      "\n",
      "Epoch 2386\n",
      "-------------------------------\n",
      "loss: 0.260006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401960 \n",
      "\n",
      "Epoch 2387\n",
      "-------------------------------\n",
      "loss: 0.258141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401470 \n",
      "\n",
      "Epoch 2388\n",
      "-------------------------------\n",
      "loss: 0.243119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400115 \n",
      "\n",
      "Epoch 2389\n",
      "-------------------------------\n",
      "loss: 0.261412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398472 \n",
      "\n",
      "Epoch 2390\n",
      "-------------------------------\n",
      "loss: 0.254395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397380 \n",
      "\n",
      "Epoch 2391\n",
      "-------------------------------\n",
      "loss: 0.250085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396810 \n",
      "\n",
      "Epoch 2392\n",
      "-------------------------------\n",
      "loss: 0.256451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397477 \n",
      "\n",
      "Epoch 2393\n",
      "-------------------------------\n",
      "loss: 0.248895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398662 \n",
      "\n",
      "Epoch 2394\n",
      "-------------------------------\n",
      "loss: 0.245820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400355 \n",
      "\n",
      "Epoch 2395\n",
      "-------------------------------\n",
      "loss: 0.251984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401786 \n",
      "\n",
      "Epoch 2396\n",
      "-------------------------------\n",
      "loss: 0.253361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402120 \n",
      "\n",
      "Epoch 2397\n",
      "-------------------------------\n",
      "loss: 0.245584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401591 \n",
      "\n",
      "Epoch 2398\n",
      "-------------------------------\n",
      "loss: 0.261644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399693 \n",
      "\n",
      "Epoch 2399\n",
      "-------------------------------\n",
      "loss: 0.265590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396424 \n",
      "\n",
      "Epoch 2400\n",
      "-------------------------------\n",
      "loss: 0.266102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395203 \n",
      "\n",
      "Epoch 2401\n",
      "-------------------------------\n",
      "loss: 0.252529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395890 \n",
      "\n",
      "Epoch 2402\n",
      "-------------------------------\n",
      "loss: 0.259427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398352 \n",
      "\n",
      "Epoch 2403\n",
      "-------------------------------\n",
      "loss: 0.259854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401759 \n",
      "\n",
      "Epoch 2404\n",
      "-------------------------------\n",
      "loss: 0.250591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405330 \n",
      "\n",
      "Epoch 2405\n",
      "-------------------------------\n",
      "loss: 0.258475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406914 \n",
      "\n",
      "Epoch 2406\n",
      "-------------------------------\n",
      "loss: 0.267376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405625 \n",
      "\n",
      "Epoch 2407\n",
      "-------------------------------\n",
      "loss: 0.268994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401611 \n",
      "\n",
      "Epoch 2408\n",
      "-------------------------------\n",
      "loss: 0.248001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398130 \n",
      "\n",
      "Epoch 2409\n",
      "-------------------------------\n",
      "loss: 0.240412  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397223 \n",
      "\n",
      "Epoch 2410\n",
      "-------------------------------\n",
      "loss: 0.250395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398274 \n",
      "\n",
      "Epoch 2411\n",
      "-------------------------------\n",
      "loss: 0.260618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399633 \n",
      "\n",
      "Epoch 2412\n",
      "-------------------------------\n",
      "loss: 0.251715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401263 \n",
      "\n",
      "Epoch 2413\n",
      "-------------------------------\n",
      "loss: 0.250565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402462 \n",
      "\n",
      "Epoch 2414\n",
      "-------------------------------\n",
      "loss: 0.238159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403011 \n",
      "\n",
      "Epoch 2415\n",
      "-------------------------------\n",
      "loss: 0.261104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404718 \n",
      "\n",
      "Epoch 2416\n",
      "-------------------------------\n",
      "loss: 0.241596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404833 \n",
      "\n",
      "Epoch 2417\n",
      "-------------------------------\n",
      "loss: 0.260333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404053 \n",
      "\n",
      "Epoch 2418\n",
      "-------------------------------\n",
      "loss: 0.249498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402932 \n",
      "\n",
      "Epoch 2419\n",
      "-------------------------------\n",
      "loss: 0.252636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401878 \n",
      "\n",
      "Epoch 2420\n",
      "-------------------------------\n",
      "loss: 0.267317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400559 \n",
      "\n",
      "Epoch 2421\n",
      "-------------------------------\n",
      "loss: 0.262258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399968 \n",
      "\n",
      "Epoch 2422\n",
      "-------------------------------\n",
      "loss: 0.258021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401308 \n",
      "\n",
      "Epoch 2423\n",
      "-------------------------------\n",
      "loss: 0.245159  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401706 \n",
      "\n",
      "Epoch 2424\n",
      "-------------------------------\n",
      "loss: 0.272628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398627 \n",
      "\n",
      "Epoch 2425\n",
      "-------------------------------\n",
      "loss: 0.262064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396803 \n",
      "\n",
      "Epoch 2426\n",
      "-------------------------------\n",
      "loss: 0.259773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397950 \n",
      "\n",
      "Epoch 2427\n",
      "-------------------------------\n",
      "loss: 0.255443  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399304 \n",
      "\n",
      "Epoch 2428\n",
      "-------------------------------\n",
      "loss: 0.255964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398501 \n",
      "\n",
      "Epoch 2429\n",
      "-------------------------------\n",
      "loss: 0.266898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398061 \n",
      "\n",
      "Epoch 2430\n",
      "-------------------------------\n",
      "loss: 0.263691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402381 \n",
      "\n",
      "Epoch 2431\n",
      "-------------------------------\n",
      "loss: 0.249908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409928 \n",
      "\n",
      "Epoch 2432\n",
      "-------------------------------\n",
      "loss: 0.264140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413700 \n",
      "\n",
      "Epoch 2433\n",
      "-------------------------------\n",
      "loss: 0.251666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411134 \n",
      "\n",
      "Epoch 2434\n",
      "-------------------------------\n",
      "loss: 0.249971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405782 \n",
      "\n",
      "Epoch 2435\n",
      "-------------------------------\n",
      "loss: 0.270659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402989 \n",
      "\n",
      "Epoch 2436\n",
      "-------------------------------\n",
      "loss: 0.260146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403122 \n",
      "\n",
      "Epoch 2437\n",
      "-------------------------------\n",
      "loss: 0.254000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403203 \n",
      "\n",
      "Epoch 2438\n",
      "-------------------------------\n",
      "loss: 0.265907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403912 \n",
      "\n",
      "Epoch 2439\n",
      "-------------------------------\n",
      "loss: 0.243137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406453 \n",
      "\n",
      "Epoch 2440\n",
      "-------------------------------\n",
      "loss: 0.224755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411732 \n",
      "\n",
      "Epoch 2441\n",
      "-------------------------------\n",
      "loss: 0.258797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413567 \n",
      "\n",
      "Epoch 2442\n",
      "-------------------------------\n",
      "loss: 0.279948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409146 \n",
      "\n",
      "Epoch 2443\n",
      "-------------------------------\n",
      "loss: 0.245741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402992 \n",
      "\n",
      "Epoch 2444\n",
      "-------------------------------\n",
      "loss: 0.265693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398998 \n",
      "\n",
      "Epoch 2445\n",
      "-------------------------------\n",
      "loss: 0.268112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397791 \n",
      "\n",
      "Epoch 2446\n",
      "-------------------------------\n",
      "loss: 0.260115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397719 \n",
      "\n",
      "Epoch 2447\n",
      "-------------------------------\n",
      "loss: 0.266665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397510 \n",
      "\n",
      "Epoch 2448\n",
      "-------------------------------\n",
      "loss: 0.262496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399983 \n",
      "\n",
      "Epoch 2449\n",
      "-------------------------------\n",
      "loss: 0.243494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404748 \n",
      "\n",
      "Epoch 2450\n",
      "-------------------------------\n",
      "loss: 0.248419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406623 \n",
      "\n",
      "Epoch 2451\n",
      "-------------------------------\n",
      "loss: 0.243034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406168 \n",
      "\n",
      "Epoch 2452\n",
      "-------------------------------\n",
      "loss: 0.258430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406116 \n",
      "\n",
      "Epoch 2453\n",
      "-------------------------------\n",
      "loss: 0.241477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404340 \n",
      "\n",
      "Epoch 2454\n",
      "-------------------------------\n",
      "loss: 0.245130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402081 \n",
      "\n",
      "Epoch 2455\n",
      "-------------------------------\n",
      "loss: 0.237819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400783 \n",
      "\n",
      "Epoch 2456\n",
      "-------------------------------\n",
      "loss: 0.247488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400512 \n",
      "\n",
      "Epoch 2457\n",
      "-------------------------------\n",
      "loss: 0.256145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400620 \n",
      "\n",
      "Epoch 2458\n",
      "-------------------------------\n",
      "loss: 0.247507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401335 \n",
      "\n",
      "Epoch 2459\n",
      "-------------------------------\n",
      "loss: 0.243056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402048 \n",
      "\n",
      "Epoch 2460\n",
      "-------------------------------\n",
      "loss: 0.245924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401719 \n",
      "\n",
      "Epoch 2461\n",
      "-------------------------------\n",
      "loss: 0.268132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400764 \n",
      "\n",
      "Epoch 2462\n",
      "-------------------------------\n",
      "loss: 0.244660  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400257 \n",
      "\n",
      "Epoch 2463\n",
      "-------------------------------\n",
      "loss: 0.249349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399722 \n",
      "\n",
      "Epoch 2464\n",
      "-------------------------------\n",
      "loss: 0.261116  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399704 \n",
      "\n",
      "Epoch 2465\n",
      "-------------------------------\n",
      "loss: 0.263568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399771 \n",
      "\n",
      "Epoch 2466\n",
      "-------------------------------\n",
      "loss: 0.238959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400309 \n",
      "\n",
      "Epoch 2467\n",
      "-------------------------------\n",
      "loss: 0.262928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401379 \n",
      "\n",
      "Epoch 2468\n",
      "-------------------------------\n",
      "loss: 0.245491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400988 \n",
      "\n",
      "Epoch 2469\n",
      "-------------------------------\n",
      "loss: 0.238477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400935 \n",
      "\n",
      "Epoch 2470\n",
      "-------------------------------\n",
      "loss: 0.249215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401435 \n",
      "\n",
      "Epoch 2471\n",
      "-------------------------------\n",
      "loss: 0.246792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402022 \n",
      "\n",
      "Epoch 2472\n",
      "-------------------------------\n",
      "loss: 0.256659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401734 \n",
      "\n",
      "Epoch 2473\n",
      "-------------------------------\n",
      "loss: 0.269334  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399681 \n",
      "\n",
      "Epoch 2474\n",
      "-------------------------------\n",
      "loss: 0.235359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399157 \n",
      "\n",
      "Epoch 2475\n",
      "-------------------------------\n",
      "loss: 0.244474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400046 \n",
      "\n",
      "Epoch 2476\n",
      "-------------------------------\n",
      "loss: 0.253176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400817 \n",
      "\n",
      "Epoch 2477\n",
      "-------------------------------\n",
      "loss: 0.260526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400800 \n",
      "\n",
      "Epoch 2478\n",
      "-------------------------------\n",
      "loss: 0.249526  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400359 \n",
      "\n",
      "Epoch 2479\n",
      "-------------------------------\n",
      "loss: 0.252957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402028 \n",
      "\n",
      "Epoch 2480\n",
      "-------------------------------\n",
      "loss: 0.245819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404795 \n",
      "\n",
      "Epoch 2481\n",
      "-------------------------------\n",
      "loss: 0.248745  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405208 \n",
      "\n",
      "Epoch 2482\n",
      "-------------------------------\n",
      "loss: 0.257157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404928 \n",
      "\n",
      "Epoch 2483\n",
      "-------------------------------\n",
      "loss: 0.230382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404333 \n",
      "\n",
      "Epoch 2484\n",
      "-------------------------------\n",
      "loss: 0.244984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401493 \n",
      "\n",
      "Epoch 2485\n",
      "-------------------------------\n",
      "loss: 0.239774  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399795 \n",
      "\n",
      "Epoch 2486\n",
      "-------------------------------\n",
      "loss: 0.256813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399704 \n",
      "\n",
      "Epoch 2487\n",
      "-------------------------------\n",
      "loss: 0.245900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399786 \n",
      "\n",
      "Epoch 2488\n",
      "-------------------------------\n",
      "loss: 0.263775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399200 \n",
      "\n",
      "Epoch 2489\n",
      "-------------------------------\n",
      "loss: 0.258765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399810 \n",
      "\n",
      "Epoch 2490\n",
      "-------------------------------\n",
      "loss: 0.235445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402971 \n",
      "\n",
      "Epoch 2491\n",
      "-------------------------------\n",
      "loss: 0.256278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405656 \n",
      "\n",
      "Epoch 2492\n",
      "-------------------------------\n",
      "loss: 0.254363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405414 \n",
      "\n",
      "Epoch 2493\n",
      "-------------------------------\n",
      "loss: 0.253032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403111 \n",
      "\n",
      "Epoch 2494\n",
      "-------------------------------\n",
      "loss: 0.239039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401695 \n",
      "\n",
      "Epoch 2495\n",
      "-------------------------------\n",
      "loss: 0.241680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400650 \n",
      "\n",
      "Epoch 2496\n",
      "-------------------------------\n",
      "loss: 0.245933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400526 \n",
      "\n",
      "Epoch 2497\n",
      "-------------------------------\n",
      "loss: 0.231162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400683 \n",
      "\n",
      "Epoch 2498\n",
      "-------------------------------\n",
      "loss: 0.248911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401215 \n",
      "\n",
      "Epoch 2499\n",
      "-------------------------------\n",
      "loss: 0.249278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402884 \n",
      "\n",
      "Epoch 2500\n",
      "-------------------------------\n",
      "loss: 0.250839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403440 \n",
      "\n",
      "Epoch 2501\n",
      "-------------------------------\n",
      "loss: 0.256985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402760 \n",
      "\n",
      "Epoch 2502\n",
      "-------------------------------\n",
      "loss: 0.243525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402153 \n",
      "\n",
      "Epoch 2503\n",
      "-------------------------------\n",
      "loss: 0.243998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401963 \n",
      "\n",
      "Epoch 2504\n",
      "-------------------------------\n",
      "loss: 0.242229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402711 \n",
      "\n",
      "Epoch 2505\n",
      "-------------------------------\n",
      "loss: 0.244488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402461 \n",
      "\n",
      "Epoch 2506\n",
      "-------------------------------\n",
      "loss: 0.254960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401447 \n",
      "\n",
      "Epoch 2507\n",
      "-------------------------------\n",
      "loss: 0.269655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400717 \n",
      "\n",
      "Epoch 2508\n",
      "-------------------------------\n",
      "loss: 0.256977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400102 \n",
      "\n",
      "Epoch 2509\n",
      "-------------------------------\n",
      "loss: 0.248459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400141 \n",
      "\n",
      "Epoch 2510\n",
      "-------------------------------\n",
      "loss: 0.244417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400304 \n",
      "\n",
      "Epoch 2511\n",
      "-------------------------------\n",
      "loss: 0.240317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401380 \n",
      "\n",
      "Epoch 2512\n",
      "-------------------------------\n",
      "loss: 0.248154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401695 \n",
      "\n",
      "Epoch 2513\n",
      "-------------------------------\n",
      "loss: 0.258441  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401221 \n",
      "\n",
      "Epoch 2514\n",
      "-------------------------------\n",
      "loss: 0.239451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400995 \n",
      "\n",
      "Epoch 2515\n",
      "-------------------------------\n",
      "loss: 0.271178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401208 \n",
      "\n",
      "Epoch 2516\n",
      "-------------------------------\n",
      "loss: 0.242948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401511 \n",
      "\n",
      "Epoch 2517\n",
      "-------------------------------\n",
      "loss: 0.236271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401659 \n",
      "\n",
      "Epoch 2518\n",
      "-------------------------------\n",
      "loss: 0.257973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402407 \n",
      "\n",
      "Epoch 2519\n",
      "-------------------------------\n",
      "loss: 0.258701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402821 \n",
      "\n",
      "Epoch 2520\n",
      "-------------------------------\n",
      "loss: 0.247911  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403881 \n",
      "\n",
      "Epoch 2521\n",
      "-------------------------------\n",
      "loss: 0.253757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404938 \n",
      "\n",
      "Epoch 2522\n",
      "-------------------------------\n",
      "loss: 0.261230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404535 \n",
      "\n",
      "Epoch 2523\n",
      "-------------------------------\n",
      "loss: 0.250668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403456 \n",
      "\n",
      "Epoch 2524\n",
      "-------------------------------\n",
      "loss: 0.247562  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402944 \n",
      "\n",
      "Epoch 2525\n",
      "-------------------------------\n",
      "loss: 0.253395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402731 \n",
      "\n",
      "Epoch 2526\n",
      "-------------------------------\n",
      "loss: 0.243667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402987 \n",
      "\n",
      "Epoch 2527\n",
      "-------------------------------\n",
      "loss: 0.246708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402942 \n",
      "\n",
      "Epoch 2528\n",
      "-------------------------------\n",
      "loss: 0.244040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403325 \n",
      "\n",
      "Epoch 2529\n",
      "-------------------------------\n",
      "loss: 0.256290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404471 \n",
      "\n",
      "Epoch 2530\n",
      "-------------------------------\n",
      "loss: 0.243904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405664 \n",
      "\n",
      "Epoch 2531\n",
      "-------------------------------\n",
      "loss: 0.255794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406260 \n",
      "\n",
      "Epoch 2532\n",
      "-------------------------------\n",
      "loss: 0.260348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405680 \n",
      "\n",
      "Epoch 2533\n",
      "-------------------------------\n",
      "loss: 0.247867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404604 \n",
      "\n",
      "Epoch 2534\n",
      "-------------------------------\n",
      "loss: 0.262277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403833 \n",
      "\n",
      "Epoch 2535\n",
      "-------------------------------\n",
      "loss: 0.253411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403881 \n",
      "\n",
      "Epoch 2536\n",
      "-------------------------------\n",
      "loss: 0.252514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405079 \n",
      "\n",
      "Epoch 2537\n",
      "-------------------------------\n",
      "loss: 0.256948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405394 \n",
      "\n",
      "Epoch 2538\n",
      "-------------------------------\n",
      "loss: 0.231251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404351 \n",
      "\n",
      "Epoch 2539\n",
      "-------------------------------\n",
      "loss: 0.248472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403697 \n",
      "\n",
      "Epoch 2540\n",
      "-------------------------------\n",
      "loss: 0.256240  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403577 \n",
      "\n",
      "Epoch 2541\n",
      "-------------------------------\n",
      "loss: 0.248426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403089 \n",
      "\n",
      "Epoch 2542\n",
      "-------------------------------\n",
      "loss: 0.242157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403406 \n",
      "\n",
      "Epoch 2543\n",
      "-------------------------------\n",
      "loss: 0.261696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401379 \n",
      "\n",
      "Epoch 2544\n",
      "-------------------------------\n",
      "loss: 0.225484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400208 \n",
      "\n",
      "Epoch 2545\n",
      "-------------------------------\n",
      "loss: 0.247718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399304 \n",
      "\n",
      "Epoch 2546\n",
      "-------------------------------\n",
      "loss: 0.259431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398498 \n",
      "\n",
      "Epoch 2547\n",
      "-------------------------------\n",
      "loss: 0.251375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397968 \n",
      "\n",
      "Epoch 2548\n",
      "-------------------------------\n",
      "loss: 0.243459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397731 \n",
      "\n",
      "Epoch 2549\n",
      "-------------------------------\n",
      "loss: 0.248306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399054 \n",
      "\n",
      "Epoch 2550\n",
      "-------------------------------\n",
      "loss: 0.257357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402376 \n",
      "\n",
      "Epoch 2551\n",
      "-------------------------------\n",
      "loss: 0.254460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404588 \n",
      "\n",
      "Epoch 2552\n",
      "-------------------------------\n",
      "loss: 0.244508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403688 \n",
      "\n",
      "Epoch 2553\n",
      "-------------------------------\n",
      "loss: 0.241147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401769 \n",
      "\n",
      "Epoch 2554\n",
      "-------------------------------\n",
      "loss: 0.242837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400470 \n",
      "\n",
      "Epoch 2555\n",
      "-------------------------------\n",
      "loss: 0.239077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399288 \n",
      "\n",
      "Epoch 2556\n",
      "-------------------------------\n",
      "loss: 0.244470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398396 \n",
      "\n",
      "Epoch 2557\n",
      "-------------------------------\n",
      "loss: 0.258580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398760 \n",
      "\n",
      "Epoch 2558\n",
      "-------------------------------\n",
      "loss: 0.235962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401220 \n",
      "\n",
      "Epoch 2559\n",
      "-------------------------------\n",
      "loss: 0.237980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404967 \n",
      "\n",
      "Epoch 2560\n",
      "-------------------------------\n",
      "loss: 0.256531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406129 \n",
      "\n",
      "Epoch 2561\n",
      "-------------------------------\n",
      "loss: 0.252140  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.405371 \n",
      "\n",
      "Epoch 2562\n",
      "-------------------------------\n",
      "loss: 0.267898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402967 \n",
      "\n",
      "Epoch 2563\n",
      "-------------------------------\n",
      "loss: 0.250426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400761 \n",
      "\n",
      "Epoch 2564\n",
      "-------------------------------\n",
      "loss: 0.251370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401151 \n",
      "\n",
      "Epoch 2565\n",
      "-------------------------------\n",
      "loss: 0.247580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401773 \n",
      "\n",
      "Epoch 2566\n",
      "-------------------------------\n",
      "loss: 0.270094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402145 \n",
      "\n",
      "Epoch 2567\n",
      "-------------------------------\n",
      "loss: 0.260483  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402271 \n",
      "\n",
      "Epoch 2568\n",
      "-------------------------------\n",
      "loss: 0.240601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402503 \n",
      "\n",
      "Epoch 2569\n",
      "-------------------------------\n",
      "loss: 0.249941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402063 \n",
      "\n",
      "Epoch 2570\n",
      "-------------------------------\n",
      "loss: 0.230816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403657 \n",
      "\n",
      "Epoch 2571\n",
      "-------------------------------\n",
      "loss: 0.247983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406254 \n",
      "\n",
      "Epoch 2572\n",
      "-------------------------------\n",
      "loss: 0.270578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404536 \n",
      "\n",
      "Epoch 2573\n",
      "-------------------------------\n",
      "loss: 0.229777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402701 \n",
      "\n",
      "Epoch 2574\n",
      "-------------------------------\n",
      "loss: 0.232805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401643 \n",
      "\n",
      "Epoch 2575\n",
      "-------------------------------\n",
      "loss: 0.238007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401076 \n",
      "\n",
      "Epoch 2576\n",
      "-------------------------------\n",
      "loss: 0.244706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400550 \n",
      "\n",
      "Epoch 2577\n",
      "-------------------------------\n",
      "loss: 0.241046  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400758 \n",
      "\n",
      "Epoch 2578\n",
      "-------------------------------\n",
      "loss: 0.237974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401496 \n",
      "\n",
      "Epoch 2579\n",
      "-------------------------------\n",
      "loss: 0.251306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403754 \n",
      "\n",
      "Epoch 2580\n",
      "-------------------------------\n",
      "loss: 0.249905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404628 \n",
      "\n",
      "Epoch 2581\n",
      "-------------------------------\n",
      "loss: 0.257415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404925 \n",
      "\n",
      "Epoch 2582\n",
      "-------------------------------\n",
      "loss: 0.258934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403484 \n",
      "\n",
      "Epoch 2583\n",
      "-------------------------------\n",
      "loss: 0.243642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402361 \n",
      "\n",
      "Epoch 2584\n",
      "-------------------------------\n",
      "loss: 0.261809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400588 \n",
      "\n",
      "Epoch 2585\n",
      "-------------------------------\n",
      "loss: 0.249580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400505 \n",
      "\n",
      "Epoch 2586\n",
      "-------------------------------\n",
      "loss: 0.242352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401116 \n",
      "\n",
      "Epoch 2587\n",
      "-------------------------------\n",
      "loss: 0.253351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403711 \n",
      "\n",
      "Epoch 2588\n",
      "-------------------------------\n",
      "loss: 0.256505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406679 \n",
      "\n",
      "Epoch 2589\n",
      "-------------------------------\n",
      "loss: 0.246540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409027 \n",
      "\n",
      "Epoch 2590\n",
      "-------------------------------\n",
      "loss: 0.240241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409806 \n",
      "\n",
      "Epoch 2591\n",
      "-------------------------------\n",
      "loss: 0.265052  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408085 \n",
      "\n",
      "Epoch 2592\n",
      "-------------------------------\n",
      "loss: 0.250458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405630 \n",
      "\n",
      "Epoch 2593\n",
      "-------------------------------\n",
      "loss: 0.245003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403757 \n",
      "\n",
      "Epoch 2594\n",
      "-------------------------------\n",
      "loss: 0.247244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402882 \n",
      "\n",
      "Epoch 2595\n",
      "-------------------------------\n",
      "loss: 0.236861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402847 \n",
      "\n",
      "Epoch 2596\n",
      "-------------------------------\n",
      "loss: 0.246941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403183 \n",
      "\n",
      "Epoch 2597\n",
      "-------------------------------\n",
      "loss: 0.242161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404904 \n",
      "\n",
      "Epoch 2598\n",
      "-------------------------------\n",
      "loss: 0.243346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405150 \n",
      "\n",
      "Epoch 2599\n",
      "-------------------------------\n",
      "loss: 0.240465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404535 \n",
      "\n",
      "Epoch 2600\n",
      "-------------------------------\n",
      "loss: 0.264505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401094 \n",
      "\n",
      "Epoch 2601\n",
      "-------------------------------\n",
      "loss: 0.244795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398359 \n",
      "\n",
      "Epoch 2602\n",
      "-------------------------------\n",
      "loss: 0.250682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398327 \n",
      "\n",
      "Epoch 2603\n",
      "-------------------------------\n",
      "loss: 0.244724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398813 \n",
      "\n",
      "Epoch 2604\n",
      "-------------------------------\n",
      "loss: 0.251166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398668 \n",
      "\n",
      "Epoch 2605\n",
      "-------------------------------\n",
      "loss: 0.258282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399237 \n",
      "\n",
      "Epoch 2606\n",
      "-------------------------------\n",
      "loss: 0.251494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400201 \n",
      "\n",
      "Epoch 2607\n",
      "-------------------------------\n",
      "loss: 0.248932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400123 \n",
      "\n",
      "Epoch 2608\n",
      "-------------------------------\n",
      "loss: 0.241324  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400579 \n",
      "\n",
      "Epoch 2609\n",
      "-------------------------------\n",
      "loss: 0.242303  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401156 \n",
      "\n",
      "Epoch 2610\n",
      "-------------------------------\n",
      "loss: 0.270263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 2611\n",
      "-------------------------------\n",
      "loss: 0.242995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401422 \n",
      "\n",
      "Epoch 2612\n",
      "-------------------------------\n",
      "loss: 0.243586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401378 \n",
      "\n",
      "Epoch 2613\n",
      "-------------------------------\n",
      "loss: 0.246351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401808 \n",
      "\n",
      "Epoch 2614\n",
      "-------------------------------\n",
      "loss: 0.249253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403206 \n",
      "\n",
      "Epoch 2615\n",
      "-------------------------------\n",
      "loss: 0.254512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403795 \n",
      "\n",
      "Epoch 2616\n",
      "-------------------------------\n",
      "loss: 0.255084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401906 \n",
      "\n",
      "Epoch 2617\n",
      "-------------------------------\n",
      "loss: 0.259366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400566 \n",
      "\n",
      "Epoch 2618\n",
      "-------------------------------\n",
      "loss: 0.253311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400946 \n",
      "\n",
      "Epoch 2619\n",
      "-------------------------------\n",
      "loss: 0.232852  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401437 \n",
      "\n",
      "Epoch 2620\n",
      "-------------------------------\n",
      "loss: 0.257706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402377 \n",
      "\n",
      "Epoch 2621\n",
      "-------------------------------\n",
      "loss: 0.251281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403554 \n",
      "\n",
      "Epoch 2622\n",
      "-------------------------------\n",
      "loss: 0.243387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404971 \n",
      "\n",
      "Epoch 2623\n",
      "-------------------------------\n",
      "loss: 0.234451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408708 \n",
      "\n",
      "Epoch 2624\n",
      "-------------------------------\n",
      "loss: 0.244351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411327 \n",
      "\n",
      "Epoch 2625\n",
      "-------------------------------\n",
      "loss: 0.265049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410003 \n",
      "\n",
      "Epoch 2626\n",
      "-------------------------------\n",
      "loss: 0.252409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405420 \n",
      "\n",
      "Epoch 2627\n",
      "-------------------------------\n",
      "loss: 0.234726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401746 \n",
      "\n",
      "Epoch 2628\n",
      "-------------------------------\n",
      "loss: 0.251657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401375 \n",
      "\n",
      "Epoch 2629\n",
      "-------------------------------\n",
      "loss: 0.255987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401925 \n",
      "\n",
      "Epoch 2630\n",
      "-------------------------------\n",
      "loss: 0.258329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401004 \n",
      "\n",
      "Epoch 2631\n",
      "-------------------------------\n",
      "loss: 0.252166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400861 \n",
      "\n",
      "Epoch 2632\n",
      "-------------------------------\n",
      "loss: 0.252056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403949 \n",
      "\n",
      "Epoch 2633\n",
      "-------------------------------\n",
      "loss: 0.252438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411348 \n",
      "\n",
      "Epoch 2634\n",
      "-------------------------------\n",
      "loss: 0.291590  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412820 \n",
      "\n",
      "Epoch 2635\n",
      "-------------------------------\n",
      "loss: 0.265398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408761 \n",
      "\n",
      "Epoch 2636\n",
      "-------------------------------\n",
      "loss: 0.256383  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402693 \n",
      "\n",
      "Epoch 2637\n",
      "-------------------------------\n",
      "loss: 0.279755  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399861 \n",
      "\n",
      "Epoch 2638\n",
      "-------------------------------\n",
      "loss: 0.258027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401998 \n",
      "\n",
      "Epoch 2639\n",
      "-------------------------------\n",
      "loss: 0.249830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403517 \n",
      "\n",
      "Epoch 2640\n",
      "-------------------------------\n",
      "loss: 0.261843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403137 \n",
      "\n",
      "Epoch 2641\n",
      "-------------------------------\n",
      "loss: 0.268129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404504 \n",
      "\n",
      "Epoch 2642\n",
      "-------------------------------\n",
      "loss: 0.256121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408111 \n",
      "\n",
      "Epoch 2643\n",
      "-------------------------------\n",
      "loss: 0.267317  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409974 \n",
      "\n",
      "Epoch 2644\n",
      "-------------------------------\n",
      "loss: 0.258238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407282 \n",
      "\n",
      "Epoch 2645\n",
      "-------------------------------\n",
      "loss: 0.246789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402309 \n",
      "\n",
      "Epoch 2646\n",
      "-------------------------------\n",
      "loss: 0.237938  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399627 \n",
      "\n",
      "Epoch 2647\n",
      "-------------------------------\n",
      "loss: 0.246713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399455 \n",
      "\n",
      "Epoch 2648\n",
      "-------------------------------\n",
      "loss: 0.242364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399792 \n",
      "\n",
      "Epoch 2649\n",
      "-------------------------------\n",
      "loss: 0.242061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400542 \n",
      "\n",
      "Epoch 2650\n",
      "-------------------------------\n",
      "loss: 0.243912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400545 \n",
      "\n",
      "Epoch 2651\n",
      "-------------------------------\n",
      "loss: 0.236712  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401493 \n",
      "\n",
      "Epoch 2652\n",
      "-------------------------------\n",
      "loss: 0.237813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403400 \n",
      "\n",
      "Epoch 2653\n",
      "-------------------------------\n",
      "loss: 0.257703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403668 \n",
      "\n",
      "Epoch 2654\n",
      "-------------------------------\n",
      "loss: 0.264476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402693 \n",
      "\n",
      "Epoch 2655\n",
      "-------------------------------\n",
      "loss: 0.242271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402578 \n",
      "\n",
      "Epoch 2656\n",
      "-------------------------------\n",
      "loss: 0.254346  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402369 \n",
      "\n",
      "Epoch 2657\n",
      "-------------------------------\n",
      "loss: 0.250246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402633 \n",
      "\n",
      "Epoch 2658\n",
      "-------------------------------\n",
      "loss: 0.260781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401868 \n",
      "\n",
      "Epoch 2659\n",
      "-------------------------------\n",
      "loss: 0.239606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400689 \n",
      "\n",
      "Epoch 2660\n",
      "-------------------------------\n",
      "loss: 0.252329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401175 \n",
      "\n",
      "Epoch 2661\n",
      "-------------------------------\n",
      "loss: 0.239104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402790 \n",
      "\n",
      "Epoch 2662\n",
      "-------------------------------\n",
      "loss: 0.259070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403937 \n",
      "\n",
      "Epoch 2663\n",
      "-------------------------------\n",
      "loss: 0.250771  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404440 \n",
      "\n",
      "Epoch 2664\n",
      "-------------------------------\n",
      "loss: 0.248363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403450 \n",
      "\n",
      "Epoch 2665\n",
      "-------------------------------\n",
      "loss: 0.254370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401764 \n",
      "\n",
      "Epoch 2666\n",
      "-------------------------------\n",
      "loss: 0.259723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400354 \n",
      "\n",
      "Epoch 2667\n",
      "-------------------------------\n",
      "loss: 0.244386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400032 \n",
      "\n",
      "Epoch 2668\n",
      "-------------------------------\n",
      "loss: 0.253751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400498 \n",
      "\n",
      "Epoch 2669\n",
      "-------------------------------\n",
      "loss: 0.239785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402382 \n",
      "\n",
      "Epoch 2670\n",
      "-------------------------------\n",
      "loss: 0.255988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404511 \n",
      "\n",
      "Epoch 2671\n",
      "-------------------------------\n",
      "loss: 0.248242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403752 \n",
      "\n",
      "Epoch 2672\n",
      "-------------------------------\n",
      "loss: 0.270541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400904 \n",
      "\n",
      "Epoch 2673\n",
      "-------------------------------\n",
      "loss: 0.248761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401725 \n",
      "\n",
      "Epoch 2674\n",
      "-------------------------------\n",
      "loss: 0.263302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404313 \n",
      "\n",
      "Epoch 2675\n",
      "-------------------------------\n",
      "loss: 0.265043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404919 \n",
      "\n",
      "Epoch 2676\n",
      "-------------------------------\n",
      "loss: 0.253054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404112 \n",
      "\n",
      "Epoch 2677\n",
      "-------------------------------\n",
      "loss: 0.235384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406407 \n",
      "\n",
      "Epoch 2678\n",
      "-------------------------------\n",
      "loss: 0.247568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409616 \n",
      "\n",
      "Epoch 2679\n",
      "-------------------------------\n",
      "loss: 0.235502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411950 \n",
      "\n",
      "Epoch 2680\n",
      "-------------------------------\n",
      "loss: 0.240773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413275 \n",
      "\n",
      "Epoch 2681\n",
      "-------------------------------\n",
      "loss: 0.244947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412231 \n",
      "\n",
      "Epoch 2682\n",
      "-------------------------------\n",
      "loss: 0.253492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409386 \n",
      "\n",
      "Epoch 2683\n",
      "-------------------------------\n",
      "loss: 0.243980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406529 \n",
      "\n",
      "Epoch 2684\n",
      "-------------------------------\n",
      "loss: 0.240412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404722 \n",
      "\n",
      "Epoch 2685\n",
      "-------------------------------\n",
      "loss: 0.247742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404056 \n",
      "\n",
      "Epoch 2686\n",
      "-------------------------------\n",
      "loss: 0.245555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402524 \n",
      "\n",
      "Epoch 2687\n",
      "-------------------------------\n",
      "loss: 0.246244  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400933 \n",
      "\n",
      "Epoch 2688\n",
      "-------------------------------\n",
      "loss: 0.254800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399369 \n",
      "\n",
      "Epoch 2689\n",
      "-------------------------------\n",
      "loss: 0.255326  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399269 \n",
      "\n",
      "Epoch 2690\n",
      "-------------------------------\n",
      "loss: 0.247281  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400949 \n",
      "\n",
      "Epoch 2691\n",
      "-------------------------------\n",
      "loss: 0.240359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404410 \n",
      "\n",
      "Epoch 2692\n",
      "-------------------------------\n",
      "loss: 0.266461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405355 \n",
      "\n",
      "Epoch 2693\n",
      "-------------------------------\n",
      "loss: 0.245231  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404135 \n",
      "\n",
      "Epoch 2694\n",
      "-------------------------------\n",
      "loss: 0.242922  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402715 \n",
      "\n",
      "Epoch 2695\n",
      "-------------------------------\n",
      "loss: 0.250929  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401835 \n",
      "\n",
      "Epoch 2696\n",
      "-------------------------------\n",
      "loss: 0.240585  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401417 \n",
      "\n",
      "Epoch 2697\n",
      "-------------------------------\n",
      "loss: 0.250748  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401807 \n",
      "\n",
      "Epoch 2698\n",
      "-------------------------------\n",
      "loss: 0.234342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402613 \n",
      "\n",
      "Epoch 2699\n",
      "-------------------------------\n",
      "loss: 0.248267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404459 \n",
      "\n",
      "Epoch 2700\n",
      "-------------------------------\n",
      "loss: 0.251164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406563 \n",
      "\n",
      "Epoch 2701\n",
      "-------------------------------\n",
      "loss: 0.237599  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407754 \n",
      "\n",
      "Epoch 2702\n",
      "-------------------------------\n",
      "loss: 0.238178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407656 \n",
      "\n",
      "Epoch 2703\n",
      "-------------------------------\n",
      "loss: 0.238775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408241 \n",
      "\n",
      "Epoch 2704\n",
      "-------------------------------\n",
      "loss: 0.242527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406758 \n",
      "\n",
      "Epoch 2705\n",
      "-------------------------------\n",
      "loss: 0.246774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406294 \n",
      "\n",
      "Epoch 2706\n",
      "-------------------------------\n",
      "loss: 0.247972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405351 \n",
      "\n",
      "Epoch 2707\n",
      "-------------------------------\n",
      "loss: 0.229639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405910 \n",
      "\n",
      "Epoch 2708\n",
      "-------------------------------\n",
      "loss: 0.242206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406019 \n",
      "\n",
      "Epoch 2709\n",
      "-------------------------------\n",
      "loss: 0.243482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405020 \n",
      "\n",
      "Epoch 2710\n",
      "-------------------------------\n",
      "loss: 0.242162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403639 \n",
      "\n",
      "Epoch 2711\n",
      "-------------------------------\n",
      "loss: 0.241250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403080 \n",
      "\n",
      "Epoch 2712\n",
      "-------------------------------\n",
      "loss: 0.239691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403530 \n",
      "\n",
      "Epoch 2713\n",
      "-------------------------------\n",
      "loss: 0.244021  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.404041 \n",
      "\n",
      "Epoch 2714\n",
      "-------------------------------\n",
      "loss: 0.241721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404943 \n",
      "\n",
      "Epoch 2715\n",
      "-------------------------------\n",
      "loss: 0.238207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406756 \n",
      "\n",
      "Epoch 2716\n",
      "-------------------------------\n",
      "loss: 0.237397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408126 \n",
      "\n",
      "Epoch 2717\n",
      "-------------------------------\n",
      "loss: 0.230841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407614 \n",
      "\n",
      "Epoch 2718\n",
      "-------------------------------\n",
      "loss: 0.235327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406983 \n",
      "\n",
      "Epoch 2719\n",
      "-------------------------------\n",
      "loss: 0.275514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405106 \n",
      "\n",
      "Epoch 2720\n",
      "-------------------------------\n",
      "loss: 0.236252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404124 \n",
      "\n",
      "Epoch 2721\n",
      "-------------------------------\n",
      "loss: 0.246234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404575 \n",
      "\n",
      "Epoch 2722\n",
      "-------------------------------\n",
      "loss: 0.259253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404417 \n",
      "\n",
      "Epoch 2723\n",
      "-------------------------------\n",
      "loss: 0.231551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404528 \n",
      "\n",
      "Epoch 2724\n",
      "-------------------------------\n",
      "loss: 0.245886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404215 \n",
      "\n",
      "Epoch 2725\n",
      "-------------------------------\n",
      "loss: 0.234093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403516 \n",
      "\n",
      "Epoch 2726\n",
      "-------------------------------\n",
      "loss: 0.251275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402331 \n",
      "\n",
      "Epoch 2727\n",
      "-------------------------------\n",
      "loss: 0.236274  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402373 \n",
      "\n",
      "Epoch 2728\n",
      "-------------------------------\n",
      "loss: 0.247696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402211 \n",
      "\n",
      "Epoch 2729\n",
      "-------------------------------\n",
      "loss: 0.242056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402525 \n",
      "\n",
      "Epoch 2730\n",
      "-------------------------------\n",
      "loss: 0.228094  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403075 \n",
      "\n",
      "Epoch 2731\n",
      "-------------------------------\n",
      "loss: 0.233405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403831 \n",
      "\n",
      "Epoch 2732\n",
      "-------------------------------\n",
      "loss: 0.241135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404724 \n",
      "\n",
      "Epoch 2733\n",
      "-------------------------------\n",
      "loss: 0.254172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404524 \n",
      "\n",
      "Epoch 2734\n",
      "-------------------------------\n",
      "loss: 0.243506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404497 \n",
      "\n",
      "Epoch 2735\n",
      "-------------------------------\n",
      "loss: 0.242405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403595 \n",
      "\n",
      "Epoch 2736\n",
      "-------------------------------\n",
      "loss: 0.247225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402757 \n",
      "\n",
      "Epoch 2737\n",
      "-------------------------------\n",
      "loss: 0.247941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400974 \n",
      "\n",
      "Epoch 2738\n",
      "-------------------------------\n",
      "loss: 0.237109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399827 \n",
      "\n",
      "Epoch 2739\n",
      "-------------------------------\n",
      "loss: 0.229740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399620 \n",
      "\n",
      "Epoch 2740\n",
      "-------------------------------\n",
      "loss: 0.254432  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399627 \n",
      "\n",
      "Epoch 2741\n",
      "-------------------------------\n",
      "loss: 0.242089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400820 \n",
      "\n",
      "Epoch 2742\n",
      "-------------------------------\n",
      "loss: 0.261926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402393 \n",
      "\n",
      "Epoch 2743\n",
      "-------------------------------\n",
      "loss: 0.243704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403530 \n",
      "\n",
      "Epoch 2744\n",
      "-------------------------------\n",
      "loss: 0.225431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404742 \n",
      "\n",
      "Epoch 2745\n",
      "-------------------------------\n",
      "loss: 0.252170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405596 \n",
      "\n",
      "Epoch 2746\n",
      "-------------------------------\n",
      "loss: 0.249717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404930 \n",
      "\n",
      "Epoch 2747\n",
      "-------------------------------\n",
      "loss: 0.243945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403668 \n",
      "\n",
      "Epoch 2748\n",
      "-------------------------------\n",
      "loss: 0.248961  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402914 \n",
      "\n",
      "Epoch 2749\n",
      "-------------------------------\n",
      "loss: 0.251487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402940 \n",
      "\n",
      "Epoch 2750\n",
      "-------------------------------\n",
      "loss: 0.245701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403275 \n",
      "\n",
      "Epoch 2751\n",
      "-------------------------------\n",
      "loss: 0.232455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404030 \n",
      "\n",
      "Epoch 2752\n",
      "-------------------------------\n",
      "loss: 0.237384  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404419 \n",
      "\n",
      "Epoch 2753\n",
      "-------------------------------\n",
      "loss: 0.245044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403644 \n",
      "\n",
      "Epoch 2754\n",
      "-------------------------------\n",
      "loss: 0.229525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402722 \n",
      "\n",
      "Epoch 2755\n",
      "-------------------------------\n",
      "loss: 0.247096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402197 \n",
      "\n",
      "Epoch 2756\n",
      "-------------------------------\n",
      "loss: 0.248413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401691 \n",
      "\n",
      "Epoch 2757\n",
      "-------------------------------\n",
      "loss: 0.241241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401491 \n",
      "\n",
      "Epoch 2758\n",
      "-------------------------------\n",
      "loss: 0.243896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400251 \n",
      "\n",
      "Epoch 2759\n",
      "-------------------------------\n",
      "loss: 0.262535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399603 \n",
      "\n",
      "Epoch 2760\n",
      "-------------------------------\n",
      "loss: 0.251329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399395 \n",
      "\n",
      "Epoch 2761\n",
      "-------------------------------\n",
      "loss: 0.246209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400073 \n",
      "\n",
      "Epoch 2762\n",
      "-------------------------------\n",
      "loss: 0.248839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402457 \n",
      "\n",
      "Epoch 2763\n",
      "-------------------------------\n",
      "loss: 0.266746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405922 \n",
      "\n",
      "Epoch 2764\n",
      "-------------------------------\n",
      "loss: 0.263237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407176 \n",
      "\n",
      "Epoch 2765\n",
      "-------------------------------\n",
      "loss: 0.253893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405766 \n",
      "\n",
      "Epoch 2766\n",
      "-------------------------------\n",
      "loss: 0.226652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403042 \n",
      "\n",
      "Epoch 2767\n",
      "-------------------------------\n",
      "loss: 0.250132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401688 \n",
      "\n",
      "Epoch 2768\n",
      "-------------------------------\n",
      "loss: 0.239664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401156 \n",
      "\n",
      "Epoch 2769\n",
      "-------------------------------\n",
      "loss: 0.250682  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401337 \n",
      "\n",
      "Epoch 2770\n",
      "-------------------------------\n",
      "loss: 0.242811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403320 \n",
      "\n",
      "Epoch 2771\n",
      "-------------------------------\n",
      "loss: 0.250640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404250 \n",
      "\n",
      "Epoch 2772\n",
      "-------------------------------\n",
      "loss: 0.254086  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403859 \n",
      "\n",
      "Epoch 2773\n",
      "-------------------------------\n",
      "loss: 0.257030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402568 \n",
      "\n",
      "Epoch 2774\n",
      "-------------------------------\n",
      "loss: 0.238664  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401128 \n",
      "\n",
      "Epoch 2775\n",
      "-------------------------------\n",
      "loss: 0.250776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401011 \n",
      "\n",
      "Epoch 2776\n",
      "-------------------------------\n",
      "loss: 0.229843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401646 \n",
      "\n",
      "Epoch 2777\n",
      "-------------------------------\n",
      "loss: 0.246995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402409 \n",
      "\n",
      "Epoch 2778\n",
      "-------------------------------\n",
      "loss: 0.238343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403556 \n",
      "\n",
      "Epoch 2779\n",
      "-------------------------------\n",
      "loss: 0.228132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404610 \n",
      "\n",
      "Epoch 2780\n",
      "-------------------------------\n",
      "loss: 0.248175  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406190 \n",
      "\n",
      "Epoch 2781\n",
      "-------------------------------\n",
      "loss: 0.235969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407878 \n",
      "\n",
      "Epoch 2782\n",
      "-------------------------------\n",
      "loss: 0.252016  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407549 \n",
      "\n",
      "Epoch 2783\n",
      "-------------------------------\n",
      "loss: 0.245121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406174 \n",
      "\n",
      "Epoch 2784\n",
      "-------------------------------\n",
      "loss: 0.245883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404538 \n",
      "\n",
      "Epoch 2785\n",
      "-------------------------------\n",
      "loss: 0.243946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403729 \n",
      "\n",
      "Epoch 2786\n",
      "-------------------------------\n",
      "loss: 0.248155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403798 \n",
      "\n",
      "Epoch 2787\n",
      "-------------------------------\n",
      "loss: 0.258513  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403475 \n",
      "\n",
      "Epoch 2788\n",
      "-------------------------------\n",
      "loss: 0.234990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403981 \n",
      "\n",
      "Epoch 2789\n",
      "-------------------------------\n",
      "loss: 0.235480  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.405327 \n",
      "\n",
      "Epoch 2790\n",
      "-------------------------------\n",
      "loss: 0.258063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404845 \n",
      "\n",
      "Epoch 2791\n",
      "-------------------------------\n",
      "loss: 0.248387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403783 \n",
      "\n",
      "Epoch 2792\n",
      "-------------------------------\n",
      "loss: 0.252901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402378 \n",
      "\n",
      "Epoch 2793\n",
      "-------------------------------\n",
      "loss: 0.239653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401782 \n",
      "\n",
      "Epoch 2794\n",
      "-------------------------------\n",
      "loss: 0.254534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401990 \n",
      "\n",
      "Epoch 2795\n",
      "-------------------------------\n",
      "loss: 0.247028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402842 \n",
      "\n",
      "Epoch 2796\n",
      "-------------------------------\n",
      "loss: 0.276354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403345 \n",
      "\n",
      "Epoch 2797\n",
      "-------------------------------\n",
      "loss: 0.247685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403187 \n",
      "\n",
      "Epoch 2798\n",
      "-------------------------------\n",
      "loss: 0.268736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402497 \n",
      "\n",
      "Epoch 2799\n",
      "-------------------------------\n",
      "loss: 0.255249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402753 \n",
      "\n",
      "Epoch 2800\n",
      "-------------------------------\n",
      "loss: 0.254005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402671 \n",
      "\n",
      "Epoch 2801\n",
      "-------------------------------\n",
      "loss: 0.254824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402942 \n",
      "\n",
      "Epoch 2802\n",
      "-------------------------------\n",
      "loss: 0.261880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404076 \n",
      "\n",
      "Epoch 2803\n",
      "-------------------------------\n",
      "loss: 0.256883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404255 \n",
      "\n",
      "Epoch 2804\n",
      "-------------------------------\n",
      "loss: 0.247344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404620 \n",
      "\n",
      "Epoch 2805\n",
      "-------------------------------\n",
      "loss: 0.235498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404497 \n",
      "\n",
      "Epoch 2806\n",
      "-------------------------------\n",
      "loss: 0.253805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403022 \n",
      "\n",
      "Epoch 2807\n",
      "-------------------------------\n",
      "loss: 0.238506  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401643 \n",
      "\n",
      "Epoch 2808\n",
      "-------------------------------\n",
      "loss: 0.234445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401696 \n",
      "\n",
      "Epoch 2809\n",
      "-------------------------------\n",
      "loss: 0.245752  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402109 \n",
      "\n",
      "Epoch 2810\n",
      "-------------------------------\n",
      "loss: 0.236779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402458 \n",
      "\n",
      "Epoch 2811\n",
      "-------------------------------\n",
      "loss: 0.248257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402608 \n",
      "\n",
      "Epoch 2812\n",
      "-------------------------------\n",
      "loss: 0.254865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400792 \n",
      "\n",
      "Epoch 2813\n",
      "-------------------------------\n",
      "loss: 0.257070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397796 \n",
      "\n",
      "Epoch 2814\n",
      "-------------------------------\n",
      "loss: 0.244399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397579 \n",
      "\n",
      "Epoch 2815\n",
      "-------------------------------\n",
      "loss: 0.261457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397824 \n",
      "\n",
      "Epoch 2816\n",
      "-------------------------------\n",
      "loss: 0.251313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397512 \n",
      "\n",
      "Epoch 2817\n",
      "-------------------------------\n",
      "loss: 0.250782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398080 \n",
      "\n",
      "Epoch 2818\n",
      "-------------------------------\n",
      "loss: 0.245796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400861 \n",
      "\n",
      "Epoch 2819\n",
      "-------------------------------\n",
      "loss: 0.230357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408054 \n",
      "\n",
      "Epoch 2820\n",
      "-------------------------------\n",
      "loss: 0.246760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414109 \n",
      "\n",
      "Epoch 2821\n",
      "-------------------------------\n",
      "loss: 0.250272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414145 \n",
      "\n",
      "Epoch 2822\n",
      "-------------------------------\n",
      "loss: 0.285465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408213 \n",
      "\n",
      "Epoch 2823\n",
      "-------------------------------\n",
      "loss: 0.237844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402886 \n",
      "\n",
      "Epoch 2824\n",
      "-------------------------------\n",
      "loss: 0.245495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403070 \n",
      "\n",
      "Epoch 2825\n",
      "-------------------------------\n",
      "loss: 0.265859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404774 \n",
      "\n",
      "Epoch 2826\n",
      "-------------------------------\n",
      "loss: 0.248127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405139 \n",
      "\n",
      "Epoch 2827\n",
      "-------------------------------\n",
      "loss: 0.256479  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404179 \n",
      "\n",
      "Epoch 2828\n",
      "-------------------------------\n",
      "loss: 0.240394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405412 \n",
      "\n",
      "Epoch 2829\n",
      "-------------------------------\n",
      "loss: 0.242181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409859 \n",
      "\n",
      "Epoch 2830\n",
      "-------------------------------\n",
      "loss: 0.256259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413220 \n",
      "\n",
      "Epoch 2831\n",
      "-------------------------------\n",
      "loss: 0.251203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411309 \n",
      "\n",
      "Epoch 2832\n",
      "-------------------------------\n",
      "loss: 0.255230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406968 \n",
      "\n",
      "Epoch 2833\n",
      "-------------------------------\n",
      "loss: 0.255517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404039 \n",
      "\n",
      "Epoch 2834\n",
      "-------------------------------\n",
      "loss: 0.249447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403852 \n",
      "\n",
      "Epoch 2835\n",
      "-------------------------------\n",
      "loss: 0.247907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403327 \n",
      "\n",
      "Epoch 2836\n",
      "-------------------------------\n",
      "loss: 0.242093  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402521 \n",
      "\n",
      "Epoch 2837\n",
      "-------------------------------\n",
      "loss: 0.243900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402745 \n",
      "\n",
      "Epoch 2838\n",
      "-------------------------------\n",
      "loss: 0.241649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404043 \n",
      "\n",
      "Epoch 2839\n",
      "-------------------------------\n",
      "loss: 0.244050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406182 \n",
      "\n",
      "Epoch 2840\n",
      "-------------------------------\n",
      "loss: 0.235565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406599 \n",
      "\n",
      "Epoch 2841\n",
      "-------------------------------\n",
      "loss: 0.257666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402595 \n",
      "\n",
      "Epoch 2842\n",
      "-------------------------------\n",
      "loss: 0.249348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398713 \n",
      "\n",
      "Epoch 2843\n",
      "-------------------------------\n",
      "loss: 0.248166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397773 \n",
      "\n",
      "Epoch 2844\n",
      "-------------------------------\n",
      "loss: 0.262242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398542 \n",
      "\n",
      "Epoch 2845\n",
      "-------------------------------\n",
      "loss: 0.253999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398842 \n",
      "\n",
      "Epoch 2846\n",
      "-------------------------------\n",
      "loss: 0.239313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399461 \n",
      "\n",
      "Epoch 2847\n",
      "-------------------------------\n",
      "loss: 0.255478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399979 \n",
      "\n",
      "Epoch 2848\n",
      "-------------------------------\n",
      "loss: 0.256053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400399 \n",
      "\n",
      "Epoch 2849\n",
      "-------------------------------\n",
      "loss: 0.251395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400431 \n",
      "\n",
      "Epoch 2850\n",
      "-------------------------------\n",
      "loss: 0.237088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400338 \n",
      "\n",
      "Epoch 2851\n",
      "-------------------------------\n",
      "loss: 0.239802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400157 \n",
      "\n",
      "Epoch 2852\n",
      "-------------------------------\n",
      "loss: 0.254474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400215 \n",
      "\n",
      "Epoch 2853\n",
      "-------------------------------\n",
      "loss: 0.244095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400771 \n",
      "\n",
      "Epoch 2854\n",
      "-------------------------------\n",
      "loss: 0.235358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401357 \n",
      "\n",
      "Epoch 2855\n",
      "-------------------------------\n",
      "loss: 0.255707  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401091 \n",
      "\n",
      "Epoch 2856\n",
      "-------------------------------\n",
      "loss: 0.242692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399623 \n",
      "\n",
      "Epoch 2857\n",
      "-------------------------------\n",
      "loss: 0.255168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398549 \n",
      "\n",
      "Epoch 2858\n",
      "-------------------------------\n",
      "loss: 0.252808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397303 \n",
      "\n",
      "Epoch 2859\n",
      "-------------------------------\n",
      "loss: 0.239886  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396001 \n",
      "\n",
      "Epoch 2860\n",
      "-------------------------------\n",
      "loss: 0.256250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395503 \n",
      "\n",
      "Epoch 2861\n",
      "-------------------------------\n",
      "loss: 0.241801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395757 \n",
      "\n",
      "Epoch 2862\n",
      "-------------------------------\n",
      "loss: 0.234559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397298 \n",
      "\n",
      "Epoch 2863\n",
      "-------------------------------\n",
      "loss: 0.246381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398348 \n",
      "\n",
      "Epoch 2864\n",
      "-------------------------------\n",
      "loss: 0.249246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397732 \n",
      "\n",
      "Epoch 2865\n",
      "-------------------------------\n",
      "loss: 0.238358  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.397189 \n",
      "\n",
      "Epoch 2866\n",
      "-------------------------------\n",
      "loss: 0.242658  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397303 \n",
      "\n",
      "Epoch 2867\n",
      "-------------------------------\n",
      "loss: 0.250730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396554 \n",
      "\n",
      "Epoch 2868\n",
      "-------------------------------\n",
      "loss: 0.242609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396342 \n",
      "\n",
      "Epoch 2869\n",
      "-------------------------------\n",
      "loss: 0.244056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397247 \n",
      "\n",
      "Epoch 2870\n",
      "-------------------------------\n",
      "loss: 0.233179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399778 \n",
      "\n",
      "Epoch 2871\n",
      "-------------------------------\n",
      "loss: 0.235899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402396 \n",
      "\n",
      "Epoch 2872\n",
      "-------------------------------\n",
      "loss: 0.251813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402273 \n",
      "\n",
      "Epoch 2873\n",
      "-------------------------------\n",
      "loss: 0.255770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400039 \n",
      "\n",
      "Epoch 2874\n",
      "-------------------------------\n",
      "loss: 0.247732  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398715 \n",
      "\n",
      "Epoch 2875\n",
      "-------------------------------\n",
      "loss: 0.239462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398689 \n",
      "\n",
      "Epoch 2876\n",
      "-------------------------------\n",
      "loss: 0.252097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400268 \n",
      "\n",
      "Epoch 2877\n",
      "-------------------------------\n",
      "loss: 0.247594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401519 \n",
      "\n",
      "Epoch 2878\n",
      "-------------------------------\n",
      "loss: 0.228199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401855 \n",
      "\n",
      "Epoch 2879\n",
      "-------------------------------\n",
      "loss: 0.254801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401541 \n",
      "\n",
      "Epoch 2880\n",
      "-------------------------------\n",
      "loss: 0.244365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402071 \n",
      "\n",
      "Epoch 2881\n",
      "-------------------------------\n",
      "loss: 0.246740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401034 \n",
      "\n",
      "Epoch 2882\n",
      "-------------------------------\n",
      "loss: 0.248997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401227 \n",
      "\n",
      "Epoch 2883\n",
      "-------------------------------\n",
      "loss: 0.248211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402424 \n",
      "\n",
      "Epoch 2884\n",
      "-------------------------------\n",
      "loss: 0.257495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404886 \n",
      "\n",
      "Epoch 2885\n",
      "-------------------------------\n",
      "loss: 0.252073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408720 \n",
      "\n",
      "Epoch 2886\n",
      "-------------------------------\n",
      "loss: 0.237191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411051 \n",
      "\n",
      "Epoch 2887\n",
      "-------------------------------\n",
      "loss: 0.257079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410050 \n",
      "\n",
      "Epoch 2888\n",
      "-------------------------------\n",
      "loss: 0.245471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406176 \n",
      "\n",
      "Epoch 2889\n",
      "-------------------------------\n",
      "loss: 0.246074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403153 \n",
      "\n",
      "Epoch 2890\n",
      "-------------------------------\n",
      "loss: 0.249176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401190 \n",
      "\n",
      "Epoch 2891\n",
      "-------------------------------\n",
      "loss: 0.241282  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400802 \n",
      "\n",
      "Epoch 2892\n",
      "-------------------------------\n",
      "loss: 0.230592  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401369 \n",
      "\n",
      "Epoch 2893\n",
      "-------------------------------\n",
      "loss: 0.242676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401829 \n",
      "\n",
      "Epoch 2894\n",
      "-------------------------------\n",
      "loss: 0.242662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402120 \n",
      "\n",
      "Epoch 2895\n",
      "-------------------------------\n",
      "loss: 0.237809  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402883 \n",
      "\n",
      "Epoch 2896\n",
      "-------------------------------\n",
      "loss: 0.230475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403846 \n",
      "\n",
      "Epoch 2897\n",
      "-------------------------------\n",
      "loss: 0.246137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404076 \n",
      "\n",
      "Epoch 2898\n",
      "-------------------------------\n",
      "loss: 0.250527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403219 \n",
      "\n",
      "Epoch 2899\n",
      "-------------------------------\n",
      "loss: 0.257553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401469 \n",
      "\n",
      "Epoch 2900\n",
      "-------------------------------\n",
      "loss: 0.235398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400919 \n",
      "\n",
      "Epoch 2901\n",
      "-------------------------------\n",
      "loss: 0.251473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400314 \n",
      "\n",
      "Epoch 2902\n",
      "-------------------------------\n",
      "loss: 0.258278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399485 \n",
      "\n",
      "Epoch 2903\n",
      "-------------------------------\n",
      "loss: 0.249936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399810 \n",
      "\n",
      "Epoch 2904\n",
      "-------------------------------\n",
      "loss: 0.230492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403030 \n",
      "\n",
      "Epoch 2905\n",
      "-------------------------------\n",
      "loss: 0.240532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406677 \n",
      "\n",
      "Epoch 2906\n",
      "-------------------------------\n",
      "loss: 0.250778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406904 \n",
      "\n",
      "Epoch 2907\n",
      "-------------------------------\n",
      "loss: 0.250270  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403793 \n",
      "\n",
      "Epoch 2908\n",
      "-------------------------------\n",
      "loss: 0.230903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400028 \n",
      "\n",
      "Epoch 2909\n",
      "-------------------------------\n",
      "loss: 0.231669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398502 \n",
      "\n",
      "Epoch 2910\n",
      "-------------------------------\n",
      "loss: 0.231470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398719 \n",
      "\n",
      "Epoch 2911\n",
      "-------------------------------\n",
      "loss: 0.251581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398835 \n",
      "\n",
      "Epoch 2912\n",
      "-------------------------------\n",
      "loss: 0.255759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398878 \n",
      "\n",
      "Epoch 2913\n",
      "-------------------------------\n",
      "loss: 0.254756  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399782 \n",
      "\n",
      "Epoch 2914\n",
      "-------------------------------\n",
      "loss: 0.231903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401098 \n",
      "\n",
      "Epoch 2915\n",
      "-------------------------------\n",
      "loss: 0.250514  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402596 \n",
      "\n",
      "Epoch 2916\n",
      "-------------------------------\n",
      "loss: 0.232475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404473 \n",
      "\n",
      "Epoch 2917\n",
      "-------------------------------\n",
      "loss: 0.226390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404267 \n",
      "\n",
      "Epoch 2918\n",
      "-------------------------------\n",
      "loss: 0.262949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400122 \n",
      "\n",
      "Epoch 2919\n",
      "-------------------------------\n",
      "loss: 0.250696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398183 \n",
      "\n",
      "Epoch 2920\n",
      "-------------------------------\n",
      "loss: 0.251943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399229 \n",
      "\n",
      "Epoch 2921\n",
      "-------------------------------\n",
      "loss: 0.251995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400566 \n",
      "\n",
      "Epoch 2922\n",
      "-------------------------------\n",
      "loss: 0.246948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401891 \n",
      "\n",
      "Epoch 2923\n",
      "-------------------------------\n",
      "loss: 0.256011  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404416 \n",
      "\n",
      "Epoch 2924\n",
      "-------------------------------\n",
      "loss: 0.236904  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409827 \n",
      "\n",
      "Epoch 2925\n",
      "-------------------------------\n",
      "loss: 0.258946  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415371 \n",
      "\n",
      "Epoch 2926\n",
      "-------------------------------\n",
      "loss: 0.256300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416249 \n",
      "\n",
      "Epoch 2927\n",
      "-------------------------------\n",
      "loss: 0.237568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412175 \n",
      "\n",
      "Epoch 2928\n",
      "-------------------------------\n",
      "loss: 0.236694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408540 \n",
      "\n",
      "Epoch 2929\n",
      "-------------------------------\n",
      "loss: 0.230206  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406176 \n",
      "\n",
      "Epoch 2930\n",
      "-------------------------------\n",
      "loss: 0.230813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404962 \n",
      "\n",
      "Epoch 2931\n",
      "-------------------------------\n",
      "loss: 0.252158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404179 \n",
      "\n",
      "Epoch 2932\n",
      "-------------------------------\n",
      "loss: 0.243761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403576 \n",
      "\n",
      "Epoch 2933\n",
      "-------------------------------\n",
      "loss: 0.274285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401903 \n",
      "\n",
      "Epoch 2934\n",
      "-------------------------------\n",
      "loss: 0.245734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402557 \n",
      "\n",
      "Epoch 2935\n",
      "-------------------------------\n",
      "loss: 0.232610  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405542 \n",
      "\n",
      "Epoch 2936\n",
      "-------------------------------\n",
      "loss: 0.260754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405270 \n",
      "\n",
      "Epoch 2937\n",
      "-------------------------------\n",
      "loss: 0.234597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402705 \n",
      "\n",
      "Epoch 2938\n",
      "-------------------------------\n",
      "loss: 0.250203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399125 \n",
      "\n",
      "Epoch 2939\n",
      "-------------------------------\n",
      "loss: 0.238366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398544 \n",
      "\n",
      "Epoch 2940\n",
      "-------------------------------\n",
      "loss: 0.246554  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400504 \n",
      "\n",
      "Epoch 2941\n",
      "-------------------------------\n",
      "loss: 0.263977  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.401347 \n",
      "\n",
      "Epoch 2942\n",
      "-------------------------------\n",
      "loss: 0.255271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398691 \n",
      "\n",
      "Epoch 2943\n",
      "-------------------------------\n",
      "loss: 0.253354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397552 \n",
      "\n",
      "Epoch 2944\n",
      "-------------------------------\n",
      "loss: 0.238850  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402711 \n",
      "\n",
      "Epoch 2945\n",
      "-------------------------------\n",
      "loss: 0.257329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406128 \n",
      "\n",
      "Epoch 2946\n",
      "-------------------------------\n",
      "loss: 0.257034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405494 \n",
      "\n",
      "Epoch 2947\n",
      "-------------------------------\n",
      "loss: 0.239935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402630 \n",
      "\n",
      "Epoch 2948\n",
      "-------------------------------\n",
      "loss: 0.237000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398459 \n",
      "\n",
      "Epoch 2949\n",
      "-------------------------------\n",
      "loss: 0.248372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395649 \n",
      "\n",
      "Epoch 2950\n",
      "-------------------------------\n",
      "loss: 0.238653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394567 \n",
      "\n",
      "Epoch 2951\n",
      "-------------------------------\n",
      "loss: 0.243220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394072 \n",
      "\n",
      "Epoch 2952\n",
      "-------------------------------\n",
      "loss: 0.233480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394039 \n",
      "\n",
      "Epoch 2953\n",
      "-------------------------------\n",
      "loss: 0.263067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393794 \n",
      "\n",
      "Epoch 2954\n",
      "-------------------------------\n",
      "loss: 0.250827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395822 \n",
      "\n",
      "Epoch 2955\n",
      "-------------------------------\n",
      "loss: 0.228614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400002 \n",
      "\n",
      "Epoch 2956\n",
      "-------------------------------\n",
      "loss: 0.238524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402634 \n",
      "\n",
      "Epoch 2957\n",
      "-------------------------------\n",
      "loss: 0.251030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401753 \n",
      "\n",
      "Epoch 2958\n",
      "-------------------------------\n",
      "loss: 0.252690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400171 \n",
      "\n",
      "Epoch 2959\n",
      "-------------------------------\n",
      "loss: 0.260783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398457 \n",
      "\n",
      "Epoch 2960\n",
      "-------------------------------\n",
      "loss: 0.246049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398149 \n",
      "\n",
      "Epoch 2961\n",
      "-------------------------------\n",
      "loss: 0.242158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398151 \n",
      "\n",
      "Epoch 2962\n",
      "-------------------------------\n",
      "loss: 0.247640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398193 \n",
      "\n",
      "Epoch 2963\n",
      "-------------------------------\n",
      "loss: 0.236740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399243 \n",
      "\n",
      "Epoch 2964\n",
      "-------------------------------\n",
      "loss: 0.231124  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402580 \n",
      "\n",
      "Epoch 2965\n",
      "-------------------------------\n",
      "loss: 0.241868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404725 \n",
      "\n",
      "Epoch 2966\n",
      "-------------------------------\n",
      "loss: 0.261863  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403734 \n",
      "\n",
      "Epoch 2967\n",
      "-------------------------------\n",
      "loss: 0.248794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399696 \n",
      "\n",
      "Epoch 2968\n",
      "-------------------------------\n",
      "loss: 0.235545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398021 \n",
      "\n",
      "Epoch 2969\n",
      "-------------------------------\n",
      "loss: 0.232054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399174 \n",
      "\n",
      "Epoch 2970\n",
      "-------------------------------\n",
      "loss: 0.254013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400234 \n",
      "\n",
      "Epoch 2971\n",
      "-------------------------------\n",
      "loss: 0.254026  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400092 \n",
      "\n",
      "Epoch 2972\n",
      "-------------------------------\n",
      "loss: 0.236729  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399957 \n",
      "\n",
      "Epoch 2973\n",
      "-------------------------------\n",
      "loss: 0.242088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401799 \n",
      "\n",
      "Epoch 2974\n",
      "-------------------------------\n",
      "loss: 0.228750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405158 \n",
      "\n",
      "Epoch 2975\n",
      "-------------------------------\n",
      "loss: 0.246237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406731 \n",
      "\n",
      "Epoch 2976\n",
      "-------------------------------\n",
      "loss: 0.256812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404705 \n",
      "\n",
      "Epoch 2977\n",
      "-------------------------------\n",
      "loss: 0.232213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401699 \n",
      "\n",
      "Epoch 2978\n",
      "-------------------------------\n",
      "loss: 0.243261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399930 \n",
      "\n",
      "Epoch 2979\n",
      "-------------------------------\n",
      "loss: 0.239138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399316 \n",
      "\n",
      "Epoch 2980\n",
      "-------------------------------\n",
      "loss: 0.245321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398915 \n",
      "\n",
      "Epoch 2981\n",
      "-------------------------------\n",
      "loss: 0.250823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398808 \n",
      "\n",
      "Epoch 2982\n",
      "-------------------------------\n",
      "loss: 0.237784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399798 \n",
      "\n",
      "Epoch 2983\n",
      "-------------------------------\n",
      "loss: 0.244229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401287 \n",
      "\n",
      "Epoch 2984\n",
      "-------------------------------\n",
      "loss: 0.231986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403360 \n",
      "\n",
      "Epoch 2985\n",
      "-------------------------------\n",
      "loss: 0.233423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403514 \n",
      "\n",
      "Epoch 2986\n",
      "-------------------------------\n",
      "loss: 0.238520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403052 \n",
      "\n",
      "Epoch 2987\n",
      "-------------------------------\n",
      "loss: 0.238092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401363 \n",
      "\n",
      "Epoch 2988\n",
      "-------------------------------\n",
      "loss: 0.241213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400517 \n",
      "\n",
      "Epoch 2989\n",
      "-------------------------------\n",
      "loss: 0.237644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400487 \n",
      "\n",
      "Epoch 2990\n",
      "-------------------------------\n",
      "loss: 0.249489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400694 \n",
      "\n",
      "Epoch 2991\n",
      "-------------------------------\n",
      "loss: 0.244928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400314 \n",
      "\n",
      "Epoch 2992\n",
      "-------------------------------\n",
      "loss: 0.241511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399952 \n",
      "\n",
      "Epoch 2993\n",
      "-------------------------------\n",
      "loss: 0.227830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400026 \n",
      "\n",
      "Epoch 2994\n",
      "-------------------------------\n",
      "loss: 0.236694  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401953 \n",
      "\n",
      "Epoch 2995\n",
      "-------------------------------\n",
      "loss: 0.239451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405003 \n",
      "\n",
      "Epoch 2996\n",
      "-------------------------------\n",
      "loss: 0.240672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405864 \n",
      "\n",
      "Epoch 2997\n",
      "-------------------------------\n",
      "loss: 0.244781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403839 \n",
      "\n",
      "Epoch 2998\n",
      "-------------------------------\n",
      "loss: 0.254634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400980 \n",
      "\n",
      "Epoch 2999\n",
      "-------------------------------\n",
      "loss: 0.240129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399584 \n",
      "\n",
      "Epoch 3000\n",
      "-------------------------------\n",
      "loss: 0.251755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397504 \n",
      "\n",
      "Epoch 3001\n",
      "-------------------------------\n",
      "loss: 0.244879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395754 \n",
      "\n",
      "Epoch 3002\n",
      "-------------------------------\n",
      "loss: 0.248572  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395675 \n",
      "\n",
      "Epoch 3003\n",
      "-------------------------------\n",
      "loss: 0.238640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398190 \n",
      "\n",
      "Epoch 3004\n",
      "-------------------------------\n",
      "loss: 0.237986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403660 \n",
      "\n",
      "Epoch 3005\n",
      "-------------------------------\n",
      "loss: 0.247140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405467 \n",
      "\n",
      "Epoch 3006\n",
      "-------------------------------\n",
      "loss: 0.273445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402909 \n",
      "\n",
      "Epoch 3007\n",
      "-------------------------------\n",
      "loss: 0.250126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398821 \n",
      "\n",
      "Epoch 3008\n",
      "-------------------------------\n",
      "loss: 0.244291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397481 \n",
      "\n",
      "Epoch 3009\n",
      "-------------------------------\n",
      "loss: 0.250406  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399269 \n",
      "\n",
      "Epoch 3010\n",
      "-------------------------------\n",
      "loss: 0.248639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 3011\n",
      "-------------------------------\n",
      "loss: 0.264478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399729 \n",
      "\n",
      "Epoch 3012\n",
      "-------------------------------\n",
      "loss: 0.232960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398347 \n",
      "\n",
      "Epoch 3013\n",
      "-------------------------------\n",
      "loss: 0.252358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399276 \n",
      "\n",
      "Epoch 3014\n",
      "-------------------------------\n",
      "loss: 0.226584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402915 \n",
      "\n",
      "Epoch 3015\n",
      "-------------------------------\n",
      "loss: 0.233465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409168 \n",
      "\n",
      "Epoch 3016\n",
      "-------------------------------\n",
      "loss: 0.243659  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413526 \n",
      "\n",
      "Epoch 3017\n",
      "-------------------------------\n",
      "loss: 0.256951  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.411264 \n",
      "\n",
      "Epoch 3018\n",
      "-------------------------------\n",
      "loss: 0.261635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405541 \n",
      "\n",
      "Epoch 3019\n",
      "-------------------------------\n",
      "loss: 0.236980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402264 \n",
      "\n",
      "Epoch 3020\n",
      "-------------------------------\n",
      "loss: 0.234803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403245 \n",
      "\n",
      "Epoch 3021\n",
      "-------------------------------\n",
      "loss: 0.241446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405119 \n",
      "\n",
      "Epoch 3022\n",
      "-------------------------------\n",
      "loss: 0.245600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404082 \n",
      "\n",
      "Epoch 3023\n",
      "-------------------------------\n",
      "loss: 0.253620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402571 \n",
      "\n",
      "Epoch 3024\n",
      "-------------------------------\n",
      "loss: 0.237071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402911 \n",
      "\n",
      "Epoch 3025\n",
      "-------------------------------\n",
      "loss: 0.251227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404352 \n",
      "\n",
      "Epoch 3026\n",
      "-------------------------------\n",
      "loss: 0.246373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404951 \n",
      "\n",
      "Epoch 3027\n",
      "-------------------------------\n",
      "loss: 0.250616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403784 \n",
      "\n",
      "Epoch 3028\n",
      "-------------------------------\n",
      "loss: 0.237229  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400994 \n",
      "\n",
      "Epoch 3029\n",
      "-------------------------------\n",
      "loss: 0.247989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399900 \n",
      "\n",
      "Epoch 3030\n",
      "-------------------------------\n",
      "loss: 0.241315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400326 \n",
      "\n",
      "Epoch 3031\n",
      "-------------------------------\n",
      "loss: 0.240830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401598 \n",
      "\n",
      "Epoch 3032\n",
      "-------------------------------\n",
      "loss: 0.241764  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402980 \n",
      "\n",
      "Epoch 3033\n",
      "-------------------------------\n",
      "loss: 0.234234  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403192 \n",
      "\n",
      "Epoch 3034\n",
      "-------------------------------\n",
      "loss: 0.229848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404975 \n",
      "\n",
      "Epoch 3035\n",
      "-------------------------------\n",
      "loss: 0.228258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404863 \n",
      "\n",
      "Epoch 3036\n",
      "-------------------------------\n",
      "loss: 0.242137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403830 \n",
      "\n",
      "Epoch 3037\n",
      "-------------------------------\n",
      "loss: 0.232014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403862 \n",
      "\n",
      "Epoch 3038\n",
      "-------------------------------\n",
      "loss: 0.242698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404456 \n",
      "\n",
      "Epoch 3039\n",
      "-------------------------------\n",
      "loss: 0.246469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404376 \n",
      "\n",
      "Epoch 3040\n",
      "-------------------------------\n",
      "loss: 0.243753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403552 \n",
      "\n",
      "Epoch 3041\n",
      "-------------------------------\n",
      "loss: 0.243832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403753 \n",
      "\n",
      "Epoch 3042\n",
      "-------------------------------\n",
      "loss: 0.248203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403457 \n",
      "\n",
      "Epoch 3043\n",
      "-------------------------------\n",
      "loss: 0.239661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402518 \n",
      "\n",
      "Epoch 3044\n",
      "-------------------------------\n",
      "loss: 0.249672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401555 \n",
      "\n",
      "Epoch 3045\n",
      "-------------------------------\n",
      "loss: 0.225097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401993 \n",
      "\n",
      "Epoch 3046\n",
      "-------------------------------\n",
      "loss: 0.248291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402186 \n",
      "\n",
      "Epoch 3047\n",
      "-------------------------------\n",
      "loss: 0.233532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400627 \n",
      "\n",
      "Epoch 3048\n",
      "-------------------------------\n",
      "loss: 0.229800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399196 \n",
      "\n",
      "Epoch 3049\n",
      "-------------------------------\n",
      "loss: 0.243260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398050 \n",
      "\n",
      "Epoch 3050\n",
      "-------------------------------\n",
      "loss: 0.236517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398268 \n",
      "\n",
      "Epoch 3051\n",
      "-------------------------------\n",
      "loss: 0.246220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399019 \n",
      "\n",
      "Epoch 3052\n",
      "-------------------------------\n",
      "loss: 0.238469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400475 \n",
      "\n",
      "Epoch 3053\n",
      "-------------------------------\n",
      "loss: 0.234489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402409 \n",
      "\n",
      "Epoch 3054\n",
      "-------------------------------\n",
      "loss: 0.239642  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405452 \n",
      "\n",
      "Epoch 3055\n",
      "-------------------------------\n",
      "loss: 0.238776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406756 \n",
      "\n",
      "Epoch 3056\n",
      "-------------------------------\n",
      "loss: 0.229563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406830 \n",
      "\n",
      "Epoch 3057\n",
      "-------------------------------\n",
      "loss: 0.236857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406846 \n",
      "\n",
      "Epoch 3058\n",
      "-------------------------------\n",
      "loss: 0.236113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406231 \n",
      "\n",
      "Epoch 3059\n",
      "-------------------------------\n",
      "loss: 0.231740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406079 \n",
      "\n",
      "Epoch 3060\n",
      "-------------------------------\n",
      "loss: 0.249345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405952 \n",
      "\n",
      "Epoch 3061\n",
      "-------------------------------\n",
      "loss: 0.228141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406139 \n",
      "\n",
      "Epoch 3062\n",
      "-------------------------------\n",
      "loss: 0.239433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406185 \n",
      "\n",
      "Epoch 3063\n",
      "-------------------------------\n",
      "loss: 0.234873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405338 \n",
      "\n",
      "Epoch 3064\n",
      "-------------------------------\n",
      "loss: 0.241596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404521 \n",
      "\n",
      "Epoch 3065\n",
      "-------------------------------\n",
      "loss: 0.238811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403213 \n",
      "\n",
      "Epoch 3066\n",
      "-------------------------------\n",
      "loss: 0.241568  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401620 \n",
      "\n",
      "Epoch 3067\n",
      "-------------------------------\n",
      "loss: 0.229824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400293 \n",
      "\n",
      "Epoch 3068\n",
      "-------------------------------\n",
      "loss: 0.249701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399601 \n",
      "\n",
      "Epoch 3069\n",
      "-------------------------------\n",
      "loss: 0.240925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399270 \n",
      "\n",
      "Epoch 3070\n",
      "-------------------------------\n",
      "loss: 0.237558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398995 \n",
      "\n",
      "Epoch 3071\n",
      "-------------------------------\n",
      "loss: 0.247284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398413 \n",
      "\n",
      "Epoch 3072\n",
      "-------------------------------\n",
      "loss: 0.230127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398389 \n",
      "\n",
      "Epoch 3073\n",
      "-------------------------------\n",
      "loss: 0.233493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398406 \n",
      "\n",
      "Epoch 3074\n",
      "-------------------------------\n",
      "loss: 0.249031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397948 \n",
      "\n",
      "Epoch 3075\n",
      "-------------------------------\n",
      "loss: 0.243132  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398006 \n",
      "\n",
      "Epoch 3076\n",
      "-------------------------------\n",
      "loss: 0.240241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398156 \n",
      "\n",
      "Epoch 3077\n",
      "-------------------------------\n",
      "loss: 0.238505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398759 \n",
      "\n",
      "Epoch 3078\n",
      "-------------------------------\n",
      "loss: 0.249777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399872 \n",
      "\n",
      "Epoch 3079\n",
      "-------------------------------\n",
      "loss: 0.224871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400253 \n",
      "\n",
      "Epoch 3080\n",
      "-------------------------------\n",
      "loss: 0.250389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401289 \n",
      "\n",
      "Epoch 3081\n",
      "-------------------------------\n",
      "loss: 0.233699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403979 \n",
      "\n",
      "Epoch 3082\n",
      "-------------------------------\n",
      "loss: 0.234393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407140 \n",
      "\n",
      "Epoch 3083\n",
      "-------------------------------\n",
      "loss: 0.249211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409606 \n",
      "\n",
      "Epoch 3084\n",
      "-------------------------------\n",
      "loss: 0.232538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409816 \n",
      "\n",
      "Epoch 3085\n",
      "-------------------------------\n",
      "loss: 0.264190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406555 \n",
      "\n",
      "Epoch 3086\n",
      "-------------------------------\n",
      "loss: 0.246235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403705 \n",
      "\n",
      "Epoch 3087\n",
      "-------------------------------\n",
      "loss: 0.229390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404485 \n",
      "\n",
      "Epoch 3088\n",
      "-------------------------------\n",
      "loss: 0.223221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405751 \n",
      "\n",
      "Epoch 3089\n",
      "-------------------------------\n",
      "loss: 0.246130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406726 \n",
      "\n",
      "Epoch 3090\n",
      "-------------------------------\n",
      "loss: 0.243969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406346 \n",
      "\n",
      "Epoch 3091\n",
      "-------------------------------\n",
      "loss: 0.255287  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406586 \n",
      "\n",
      "Epoch 3092\n",
      "-------------------------------\n",
      "loss: 0.230716  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407206 \n",
      "\n",
      "Epoch 3093\n",
      "-------------------------------\n",
      "loss: 0.253518  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.406723 \n",
      "\n",
      "Epoch 3094\n",
      "-------------------------------\n",
      "loss: 0.231900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406270 \n",
      "\n",
      "Epoch 3095\n",
      "-------------------------------\n",
      "loss: 0.236034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404825 \n",
      "\n",
      "Epoch 3096\n",
      "-------------------------------\n",
      "loss: 0.238917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403248 \n",
      "\n",
      "Epoch 3097\n",
      "-------------------------------\n",
      "loss: 0.240534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402377 \n",
      "\n",
      "Epoch 3098\n",
      "-------------------------------\n",
      "loss: 0.233202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400705 \n",
      "\n",
      "Epoch 3099\n",
      "-------------------------------\n",
      "loss: 0.244903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398707 \n",
      "\n",
      "Epoch 3100\n",
      "-------------------------------\n",
      "loss: 0.241014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397830 \n",
      "\n",
      "Epoch 3101\n",
      "-------------------------------\n",
      "loss: 0.241862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399887 \n",
      "\n",
      "Epoch 3102\n",
      "-------------------------------\n",
      "loss: 0.235786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404091 \n",
      "\n",
      "Epoch 3103\n",
      "-------------------------------\n",
      "loss: 0.232457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406206 \n",
      "\n",
      "Epoch 3104\n",
      "-------------------------------\n",
      "loss: 0.267880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402890 \n",
      "\n",
      "Epoch 3105\n",
      "-------------------------------\n",
      "loss: 0.230257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398819 \n",
      "\n",
      "Epoch 3106\n",
      "-------------------------------\n",
      "loss: 0.232834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396375 \n",
      "\n",
      "Epoch 3107\n",
      "-------------------------------\n",
      "loss: 0.233553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394497 \n",
      "\n",
      "Epoch 3108\n",
      "-------------------------------\n",
      "loss: 0.235905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393380 \n",
      "\n",
      "Epoch 3109\n",
      "-------------------------------\n",
      "loss: 0.233615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393711 \n",
      "\n",
      "Epoch 3110\n",
      "-------------------------------\n",
      "loss: 0.236380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396395 \n",
      "\n",
      "Epoch 3111\n",
      "-------------------------------\n",
      "loss: 0.242031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402197 \n",
      "\n",
      "Epoch 3112\n",
      "-------------------------------\n",
      "loss: 0.242597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405049 \n",
      "\n",
      "Epoch 3113\n",
      "-------------------------------\n",
      "loss: 0.257039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403954 \n",
      "\n",
      "Epoch 3114\n",
      "-------------------------------\n",
      "loss: 0.250316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400120 \n",
      "\n",
      "Epoch 3115\n",
      "-------------------------------\n",
      "loss: 0.240795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397379 \n",
      "\n",
      "Epoch 3116\n",
      "-------------------------------\n",
      "loss: 0.231870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397017 \n",
      "\n",
      "Epoch 3117\n",
      "-------------------------------\n",
      "loss: 0.246362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400095 \n",
      "\n",
      "Epoch 3118\n",
      "-------------------------------\n",
      "loss: 0.251994  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402949 \n",
      "\n",
      "Epoch 3119\n",
      "-------------------------------\n",
      "loss: 0.249048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403059 \n",
      "\n",
      "Epoch 3120\n",
      "-------------------------------\n",
      "loss: 0.259205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401298 \n",
      "\n",
      "Epoch 3121\n",
      "-------------------------------\n",
      "loss: 0.242718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400460 \n",
      "\n",
      "Epoch 3122\n",
      "-------------------------------\n",
      "loss: 0.242718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405293 \n",
      "\n",
      "Epoch 3123\n",
      "-------------------------------\n",
      "loss: 0.250215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408555 \n",
      "\n",
      "Epoch 3124\n",
      "-------------------------------\n",
      "loss: 0.251272  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405378 \n",
      "\n",
      "Epoch 3125\n",
      "-------------------------------\n",
      "loss: 0.250476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399715 \n",
      "\n",
      "Epoch 3126\n",
      "-------------------------------\n",
      "loss: 0.246150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397869 \n",
      "\n",
      "Epoch 3127\n",
      "-------------------------------\n",
      "loss: 0.240357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397464 \n",
      "\n",
      "Epoch 3128\n",
      "-------------------------------\n",
      "loss: 0.238119  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396739 \n",
      "\n",
      "Epoch 3129\n",
      "-------------------------------\n",
      "loss: 0.243681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396710 \n",
      "\n",
      "Epoch 3130\n",
      "-------------------------------\n",
      "loss: 0.241307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398975 \n",
      "\n",
      "Epoch 3131\n",
      "-------------------------------\n",
      "loss: 0.233381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401993 \n",
      "\n",
      "Epoch 3132\n",
      "-------------------------------\n",
      "loss: 0.241721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403826 \n",
      "\n",
      "Epoch 3133\n",
      "-------------------------------\n",
      "loss: 0.222903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403107 \n",
      "\n",
      "Epoch 3134\n",
      "-------------------------------\n",
      "loss: 0.232715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400907 \n",
      "\n",
      "Epoch 3135\n",
      "-------------------------------\n",
      "loss: 0.252775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398542 \n",
      "\n",
      "Epoch 3136\n",
      "-------------------------------\n",
      "loss: 0.235344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397224 \n",
      "\n",
      "Epoch 3137\n",
      "-------------------------------\n",
      "loss: 0.231224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396341 \n",
      "\n",
      "Epoch 3138\n",
      "-------------------------------\n",
      "loss: 0.230372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396678 \n",
      "\n",
      "Epoch 3139\n",
      "-------------------------------\n",
      "loss: 0.238227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397294 \n",
      "\n",
      "Epoch 3140\n",
      "-------------------------------\n",
      "loss: 0.243668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398822 \n",
      "\n",
      "Epoch 3141\n",
      "-------------------------------\n",
      "loss: 0.230846  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400197 \n",
      "\n",
      "Epoch 3142\n",
      "-------------------------------\n",
      "loss: 0.233040  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401190 \n",
      "\n",
      "Epoch 3143\n",
      "-------------------------------\n",
      "loss: 0.237711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400764 \n",
      "\n",
      "Epoch 3144\n",
      "-------------------------------\n",
      "loss: 0.243945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398630 \n",
      "\n",
      "Epoch 3145\n",
      "-------------------------------\n",
      "loss: 0.231090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396819 \n",
      "\n",
      "Epoch 3146\n",
      "-------------------------------\n",
      "loss: 0.245261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396336 \n",
      "\n",
      "Epoch 3147\n",
      "-------------------------------\n",
      "loss: 0.240305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397724 \n",
      "\n",
      "Epoch 3148\n",
      "-------------------------------\n",
      "loss: 0.244262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398545 \n",
      "\n",
      "Epoch 3149\n",
      "-------------------------------\n",
      "loss: 0.233311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398489 \n",
      "\n",
      "Epoch 3150\n",
      "-------------------------------\n",
      "loss: 0.237839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399285 \n",
      "\n",
      "Epoch 3151\n",
      "-------------------------------\n",
      "loss: 0.228494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402005 \n",
      "\n",
      "Epoch 3152\n",
      "-------------------------------\n",
      "loss: 0.238819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406207 \n",
      "\n",
      "Epoch 3153\n",
      "-------------------------------\n",
      "loss: 0.253319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408818 \n",
      "\n",
      "Epoch 3154\n",
      "-------------------------------\n",
      "loss: 0.238456  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406411 \n",
      "\n",
      "Epoch 3155\n",
      "-------------------------------\n",
      "loss: 0.240030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401543 \n",
      "\n",
      "Epoch 3156\n",
      "-------------------------------\n",
      "loss: 0.235275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399844 \n",
      "\n",
      "Epoch 3157\n",
      "-------------------------------\n",
      "loss: 0.236275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399550 \n",
      "\n",
      "Epoch 3158\n",
      "-------------------------------\n",
      "loss: 0.236266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400127 \n",
      "\n",
      "Epoch 3159\n",
      "-------------------------------\n",
      "loss: 0.238875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399768 \n",
      "\n",
      "Epoch 3160\n",
      "-------------------------------\n",
      "loss: 0.256464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399880 \n",
      "\n",
      "Epoch 3161\n",
      "-------------------------------\n",
      "loss: 0.231420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402103 \n",
      "\n",
      "Epoch 3162\n",
      "-------------------------------\n",
      "loss: 0.244622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404994 \n",
      "\n",
      "Epoch 3163\n",
      "-------------------------------\n",
      "loss: 0.236298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405256 \n",
      "\n",
      "Epoch 3164\n",
      "-------------------------------\n",
      "loss: 0.233328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404212 \n",
      "\n",
      "Epoch 3165\n",
      "-------------------------------\n",
      "loss: 0.239145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403542 \n",
      "\n",
      "Epoch 3166\n",
      "-------------------------------\n",
      "loss: 0.232190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403961 \n",
      "\n",
      "Epoch 3167\n",
      "-------------------------------\n",
      "loss: 0.241491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403977 \n",
      "\n",
      "Epoch 3168\n",
      "-------------------------------\n",
      "loss: 0.236453  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403825 \n",
      "\n",
      "Epoch 3169\n",
      "-------------------------------\n",
      "loss: 0.237125  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403705 \n",
      "\n",
      "Epoch 3170\n",
      "-------------------------------\n",
      "loss: 0.238983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404624 \n",
      "\n",
      "Epoch 3171\n",
      "-------------------------------\n",
      "loss: 0.238505  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405818 \n",
      "\n",
      "Epoch 3172\n",
      "-------------------------------\n",
      "loss: 0.228884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406853 \n",
      "\n",
      "Epoch 3173\n",
      "-------------------------------\n",
      "loss: 0.257075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406353 \n",
      "\n",
      "Epoch 3174\n",
      "-------------------------------\n",
      "loss: 0.242170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404907 \n",
      "\n",
      "Epoch 3175\n",
      "-------------------------------\n",
      "loss: 0.239417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402961 \n",
      "\n",
      "Epoch 3176\n",
      "-------------------------------\n",
      "loss: 0.233357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402087 \n",
      "\n",
      "Epoch 3177\n",
      "-------------------------------\n",
      "loss: 0.240856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402325 \n",
      "\n",
      "Epoch 3178\n",
      "-------------------------------\n",
      "loss: 0.235741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403021 \n",
      "\n",
      "Epoch 3179\n",
      "-------------------------------\n",
      "loss: 0.245928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402856 \n",
      "\n",
      "Epoch 3180\n",
      "-------------------------------\n",
      "loss: 0.239781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402684 \n",
      "\n",
      "Epoch 3181\n",
      "-------------------------------\n",
      "loss: 0.254845  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401956 \n",
      "\n",
      "Epoch 3182\n",
      "-------------------------------\n",
      "loss: 0.226429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401609 \n",
      "\n",
      "Epoch 3183\n",
      "-------------------------------\n",
      "loss: 0.241398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401223 \n",
      "\n",
      "Epoch 3184\n",
      "-------------------------------\n",
      "loss: 0.232952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401325 \n",
      "\n",
      "Epoch 3185\n",
      "-------------------------------\n",
      "loss: 0.246473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400722 \n",
      "\n",
      "Epoch 3186\n",
      "-------------------------------\n",
      "loss: 0.238423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399538 \n",
      "\n",
      "Epoch 3187\n",
      "-------------------------------\n",
      "loss: 0.233588  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397723 \n",
      "\n",
      "Epoch 3188\n",
      "-------------------------------\n",
      "loss: 0.250239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396108 \n",
      "\n",
      "Epoch 3189\n",
      "-------------------------------\n",
      "loss: 0.232508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395849 \n",
      "\n",
      "Epoch 3190\n",
      "-------------------------------\n",
      "loss: 0.238799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396326 \n",
      "\n",
      "Epoch 3191\n",
      "-------------------------------\n",
      "loss: 0.235645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396776 \n",
      "\n",
      "Epoch 3192\n",
      "-------------------------------\n",
      "loss: 0.240948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398092 \n",
      "\n",
      "Epoch 3193\n",
      "-------------------------------\n",
      "loss: 0.259800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400902 \n",
      "\n",
      "Epoch 3194\n",
      "-------------------------------\n",
      "loss: 0.231405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402873 \n",
      "\n",
      "Epoch 3195\n",
      "-------------------------------\n",
      "loss: 0.233548  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404892 \n",
      "\n",
      "Epoch 3196\n",
      "-------------------------------\n",
      "loss: 0.230073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405723 \n",
      "\n",
      "Epoch 3197\n",
      "-------------------------------\n",
      "loss: 0.247675  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406081 \n",
      "\n",
      "Epoch 3198\n",
      "-------------------------------\n",
      "loss: 0.242342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405349 \n",
      "\n",
      "Epoch 3199\n",
      "-------------------------------\n",
      "loss: 0.237075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402993 \n",
      "\n",
      "Epoch 3200\n",
      "-------------------------------\n",
      "loss: 0.241754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401052 \n",
      "\n",
      "Epoch 3201\n",
      "-------------------------------\n",
      "loss: 0.229719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400676 \n",
      "\n",
      "Epoch 3202\n",
      "-------------------------------\n",
      "loss: 0.243527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401107 \n",
      "\n",
      "Epoch 3203\n",
      "-------------------------------\n",
      "loss: 0.243923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400528 \n",
      "\n",
      "Epoch 3204\n",
      "-------------------------------\n",
      "loss: 0.237695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401250 \n",
      "\n",
      "Epoch 3205\n",
      "-------------------------------\n",
      "loss: 0.243212  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402626 \n",
      "\n",
      "Epoch 3206\n",
      "-------------------------------\n",
      "loss: 0.241667  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404426 \n",
      "\n",
      "Epoch 3207\n",
      "-------------------------------\n",
      "loss: 0.233232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406496 \n",
      "\n",
      "Epoch 3208\n",
      "-------------------------------\n",
      "loss: 0.246214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407122 \n",
      "\n",
      "Epoch 3209\n",
      "-------------------------------\n",
      "loss: 0.238719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406070 \n",
      "\n",
      "Epoch 3210\n",
      "-------------------------------\n",
      "loss: 0.241294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405306 \n",
      "\n",
      "Epoch 3211\n",
      "-------------------------------\n",
      "loss: 0.237140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404965 \n",
      "\n",
      "Epoch 3212\n",
      "-------------------------------\n",
      "loss: 0.238077  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403655 \n",
      "\n",
      "Epoch 3213\n",
      "-------------------------------\n",
      "loss: 0.239117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402939 \n",
      "\n",
      "Epoch 3214\n",
      "-------------------------------\n",
      "loss: 0.247523  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403379 \n",
      "\n",
      "Epoch 3215\n",
      "-------------------------------\n",
      "loss: 0.237088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404476 \n",
      "\n",
      "Epoch 3216\n",
      "-------------------------------\n",
      "loss: 0.237020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405085 \n",
      "\n",
      "Epoch 3217\n",
      "-------------------------------\n",
      "loss: 0.245530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405277 \n",
      "\n",
      "Epoch 3218\n",
      "-------------------------------\n",
      "loss: 0.244115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403154 \n",
      "\n",
      "Epoch 3219\n",
      "-------------------------------\n",
      "loss: 0.248700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401076 \n",
      "\n",
      "Epoch 3220\n",
      "-------------------------------\n",
      "loss: 0.250754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400457 \n",
      "\n",
      "Epoch 3221\n",
      "-------------------------------\n",
      "loss: 0.224423  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400536 \n",
      "\n",
      "Epoch 3222\n",
      "-------------------------------\n",
      "loss: 0.244600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400855 \n",
      "\n",
      "Epoch 3223\n",
      "-------------------------------\n",
      "loss: 0.243608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400672 \n",
      "\n",
      "Epoch 3224\n",
      "-------------------------------\n",
      "loss: 0.229162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400265 \n",
      "\n",
      "Epoch 3225\n",
      "-------------------------------\n",
      "loss: 0.232005  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400685 \n",
      "\n",
      "Epoch 3226\n",
      "-------------------------------\n",
      "loss: 0.248330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400453 \n",
      "\n",
      "Epoch 3227\n",
      "-------------------------------\n",
      "loss: 0.247521  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399586 \n",
      "\n",
      "Epoch 3228\n",
      "-------------------------------\n",
      "loss: 0.232811  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399468 \n",
      "\n",
      "Epoch 3229\n",
      "-------------------------------\n",
      "loss: 0.228059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400002 \n",
      "\n",
      "Epoch 3230\n",
      "-------------------------------\n",
      "loss: 0.235865  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401076 \n",
      "\n",
      "Epoch 3231\n",
      "-------------------------------\n",
      "loss: 0.238294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401257 \n",
      "\n",
      "Epoch 3232\n",
      "-------------------------------\n",
      "loss: 0.243915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403128 \n",
      "\n",
      "Epoch 3233\n",
      "-------------------------------\n",
      "loss: 0.239649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405939 \n",
      "\n",
      "Epoch 3234\n",
      "-------------------------------\n",
      "loss: 0.239485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406170 \n",
      "\n",
      "Epoch 3235\n",
      "-------------------------------\n",
      "loss: 0.245701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404339 \n",
      "\n",
      "Epoch 3236\n",
      "-------------------------------\n",
      "loss: 0.247818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402363 \n",
      "\n",
      "Epoch 3237\n",
      "-------------------------------\n",
      "loss: 0.238942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400510 \n",
      "\n",
      "Epoch 3238\n",
      "-------------------------------\n",
      "loss: 0.227617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399232 \n",
      "\n",
      "Epoch 3239\n",
      "-------------------------------\n",
      "loss: 0.240275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397445 \n",
      "\n",
      "Epoch 3240\n",
      "-------------------------------\n",
      "loss: 0.247578  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396604 \n",
      "\n",
      "Epoch 3241\n",
      "-------------------------------\n",
      "loss: 0.234720  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397318 \n",
      "\n",
      "Epoch 3242\n",
      "-------------------------------\n",
      "loss: 0.222409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400449 \n",
      "\n",
      "Epoch 3243\n",
      "-------------------------------\n",
      "loss: 0.246996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404435 \n",
      "\n",
      "Epoch 3244\n",
      "-------------------------------\n",
      "loss: 0.231350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406026 \n",
      "\n",
      "Epoch 3245\n",
      "-------------------------------\n",
      "loss: 0.242640  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.406529 \n",
      "\n",
      "Epoch 3246\n",
      "-------------------------------\n",
      "loss: 0.257320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405061 \n",
      "\n",
      "Epoch 3247\n",
      "-------------------------------\n",
      "loss: 0.236777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402173 \n",
      "\n",
      "Epoch 3248\n",
      "-------------------------------\n",
      "loss: 0.228898  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400137 \n",
      "\n",
      "Epoch 3249\n",
      "-------------------------------\n",
      "loss: 0.232626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399634 \n",
      "\n",
      "Epoch 3250\n",
      "-------------------------------\n",
      "loss: 0.242676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399885 \n",
      "\n",
      "Epoch 3251\n",
      "-------------------------------\n",
      "loss: 0.257332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399610 \n",
      "\n",
      "Epoch 3252\n",
      "-------------------------------\n",
      "loss: 0.240571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400595 \n",
      "\n",
      "Epoch 3253\n",
      "-------------------------------\n",
      "loss: 0.223755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403179 \n",
      "\n",
      "Epoch 3254\n",
      "-------------------------------\n",
      "loss: 0.244787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405701 \n",
      "\n",
      "Epoch 3255\n",
      "-------------------------------\n",
      "loss: 0.236237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409126 \n",
      "\n",
      "Epoch 3256\n",
      "-------------------------------\n",
      "loss: 0.247612  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410192 \n",
      "\n",
      "Epoch 3257\n",
      "-------------------------------\n",
      "loss: 0.255743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407676 \n",
      "\n",
      "Epoch 3258\n",
      "-------------------------------\n",
      "loss: 0.239296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404855 \n",
      "\n",
      "Epoch 3259\n",
      "-------------------------------\n",
      "loss: 0.215928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403233 \n",
      "\n",
      "Epoch 3260\n",
      "-------------------------------\n",
      "loss: 0.238115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403100 \n",
      "\n",
      "Epoch 3261\n",
      "-------------------------------\n",
      "loss: 0.239580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402430 \n",
      "\n",
      "Epoch 3262\n",
      "-------------------------------\n",
      "loss: 0.243038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401621 \n",
      "\n",
      "Epoch 3263\n",
      "-------------------------------\n",
      "loss: 0.227761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400672 \n",
      "\n",
      "Epoch 3264\n",
      "-------------------------------\n",
      "loss: 0.235419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401018 \n",
      "\n",
      "Epoch 3265\n",
      "-------------------------------\n",
      "loss: 0.231755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402809 \n",
      "\n",
      "Epoch 3266\n",
      "-------------------------------\n",
      "loss: 0.242616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404091 \n",
      "\n",
      "Epoch 3267\n",
      "-------------------------------\n",
      "loss: 0.229635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405573 \n",
      "\n",
      "Epoch 3268\n",
      "-------------------------------\n",
      "loss: 0.228402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406057 \n",
      "\n",
      "Epoch 3269\n",
      "-------------------------------\n",
      "loss: 0.237737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404005 \n",
      "\n",
      "Epoch 3270\n",
      "-------------------------------\n",
      "loss: 0.246591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401090 \n",
      "\n",
      "Epoch 3271\n",
      "-------------------------------\n",
      "loss: 0.241833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399450 \n",
      "\n",
      "Epoch 3272\n",
      "-------------------------------\n",
      "loss: 0.232255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399996 \n",
      "\n",
      "Epoch 3273\n",
      "-------------------------------\n",
      "loss: 0.221760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401040 \n",
      "\n",
      "Epoch 3274\n",
      "-------------------------------\n",
      "loss: 0.235575  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401715 \n",
      "\n",
      "Epoch 3275\n",
      "-------------------------------\n",
      "loss: 0.239955  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402598 \n",
      "\n",
      "Epoch 3276\n",
      "-------------------------------\n",
      "loss: 0.227197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403556 \n",
      "\n",
      "Epoch 3277\n",
      "-------------------------------\n",
      "loss: 0.224260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405223 \n",
      "\n",
      "Epoch 3278\n",
      "-------------------------------\n",
      "loss: 0.252051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404489 \n",
      "\n",
      "Epoch 3279\n",
      "-------------------------------\n",
      "loss: 0.247263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402739 \n",
      "\n",
      "Epoch 3280\n",
      "-------------------------------\n",
      "loss: 0.228680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401994 \n",
      "\n",
      "Epoch 3281\n",
      "-------------------------------\n",
      "loss: 0.243027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401166 \n",
      "\n",
      "Epoch 3282\n",
      "-------------------------------\n",
      "loss: 0.239352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 3283\n",
      "-------------------------------\n",
      "loss: 0.234039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400118 \n",
      "\n",
      "Epoch 3284\n",
      "-------------------------------\n",
      "loss: 0.258306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400705 \n",
      "\n",
      "Epoch 3285\n",
      "-------------------------------\n",
      "loss: 0.226985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402015 \n",
      "\n",
      "Epoch 3286\n",
      "-------------------------------\n",
      "loss: 0.233190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402419 \n",
      "\n",
      "Epoch 3287\n",
      "-------------------------------\n",
      "loss: 0.234249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402217 \n",
      "\n",
      "Epoch 3288\n",
      "-------------------------------\n",
      "loss: 0.242438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401092 \n",
      "\n",
      "Epoch 3289\n",
      "-------------------------------\n",
      "loss: 0.247692  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399409 \n",
      "\n",
      "Epoch 3290\n",
      "-------------------------------\n",
      "loss: 0.233192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398785 \n",
      "\n",
      "Epoch 3291\n",
      "-------------------------------\n",
      "loss: 0.246989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397683 \n",
      "\n",
      "Epoch 3292\n",
      "-------------------------------\n",
      "loss: 0.239183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397536 \n",
      "\n",
      "Epoch 3293\n",
      "-------------------------------\n",
      "loss: 0.237734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398927 \n",
      "\n",
      "Epoch 3294\n",
      "-------------------------------\n",
      "loss: 0.229594  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401743 \n",
      "\n",
      "Epoch 3295\n",
      "-------------------------------\n",
      "loss: 0.245651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402696 \n",
      "\n",
      "Epoch 3296\n",
      "-------------------------------\n",
      "loss: 0.238508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402810 \n",
      "\n",
      "Epoch 3297\n",
      "-------------------------------\n",
      "loss: 0.249909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402306 \n",
      "\n",
      "Epoch 3298\n",
      "-------------------------------\n",
      "loss: 0.244322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404033 \n",
      "\n",
      "Epoch 3299\n",
      "-------------------------------\n",
      "loss: 0.230407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405422 \n",
      "\n",
      "Epoch 3300\n",
      "-------------------------------\n",
      "loss: 0.235767  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406530 \n",
      "\n",
      "Epoch 3301\n",
      "-------------------------------\n",
      "loss: 0.228510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404759 \n",
      "\n",
      "Epoch 3302\n",
      "-------------------------------\n",
      "loss: 0.235437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403138 \n",
      "\n",
      "Epoch 3303\n",
      "-------------------------------\n",
      "loss: 0.241596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401535 \n",
      "\n",
      "Epoch 3304\n",
      "-------------------------------\n",
      "loss: 0.233662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400530 \n",
      "\n",
      "Epoch 3305\n",
      "-------------------------------\n",
      "loss: 0.251053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400120 \n",
      "\n",
      "Epoch 3306\n",
      "-------------------------------\n",
      "loss: 0.220434  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399811 \n",
      "\n",
      "Epoch 3307\n",
      "-------------------------------\n",
      "loss: 0.247737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399782 \n",
      "\n",
      "Epoch 3308\n",
      "-------------------------------\n",
      "loss: 0.243301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400897 \n",
      "\n",
      "Epoch 3309\n",
      "-------------------------------\n",
      "loss: 0.225022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402036 \n",
      "\n",
      "Epoch 3310\n",
      "-------------------------------\n",
      "loss: 0.244381  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400809 \n",
      "\n",
      "Epoch 3311\n",
      "-------------------------------\n",
      "loss: 0.232323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399471 \n",
      "\n",
      "Epoch 3312\n",
      "-------------------------------\n",
      "loss: 0.231749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398569 \n",
      "\n",
      "Epoch 3313\n",
      "-------------------------------\n",
      "loss: 0.229042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397971 \n",
      "\n",
      "Epoch 3314\n",
      "-------------------------------\n",
      "loss: 0.229962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397630 \n",
      "\n",
      "Epoch 3315\n",
      "-------------------------------\n",
      "loss: 0.241429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398017 \n",
      "\n",
      "Epoch 3316\n",
      "-------------------------------\n",
      "loss: 0.234859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399132 \n",
      "\n",
      "Epoch 3317\n",
      "-------------------------------\n",
      "loss: 0.242980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401031 \n",
      "\n",
      "Epoch 3318\n",
      "-------------------------------\n",
      "loss: 0.238902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401453 \n",
      "\n",
      "Epoch 3319\n",
      "-------------------------------\n",
      "loss: 0.238028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401241 \n",
      "\n",
      "Epoch 3320\n",
      "-------------------------------\n",
      "loss: 0.220118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400451 \n",
      "\n",
      "Epoch 3321\n",
      "-------------------------------\n",
      "loss: 0.234002  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399835 \n",
      "\n",
      "Epoch 3322\n",
      "-------------------------------\n",
      "loss: 0.237813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399713 \n",
      "\n",
      "Epoch 3323\n",
      "-------------------------------\n",
      "loss: 0.241894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400582 \n",
      "\n",
      "Epoch 3324\n",
      "-------------------------------\n",
      "loss: 0.245357  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401659 \n",
      "\n",
      "Epoch 3325\n",
      "-------------------------------\n",
      "loss: 0.238879  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402474 \n",
      "\n",
      "Epoch 3326\n",
      "-------------------------------\n",
      "loss: 0.226446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402664 \n",
      "\n",
      "Epoch 3327\n",
      "-------------------------------\n",
      "loss: 0.235054  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402080 \n",
      "\n",
      "Epoch 3328\n",
      "-------------------------------\n",
      "loss: 0.222693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402261 \n",
      "\n",
      "Epoch 3329\n",
      "-------------------------------\n",
      "loss: 0.239060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402500 \n",
      "\n",
      "Epoch 3330\n",
      "-------------------------------\n",
      "loss: 0.233663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402734 \n",
      "\n",
      "Epoch 3331\n",
      "-------------------------------\n",
      "loss: 0.245376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402639 \n",
      "\n",
      "Epoch 3332\n",
      "-------------------------------\n",
      "loss: 0.226862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402416 \n",
      "\n",
      "Epoch 3333\n",
      "-------------------------------\n",
      "loss: 0.245995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401863 \n",
      "\n",
      "Epoch 3334\n",
      "-------------------------------\n",
      "loss: 0.239713  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401066 \n",
      "\n",
      "Epoch 3335\n",
      "-------------------------------\n",
      "loss: 0.225089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 3336\n",
      "-------------------------------\n",
      "loss: 0.232787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400965 \n",
      "\n",
      "Epoch 3337\n",
      "-------------------------------\n",
      "loss: 0.227344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401414 \n",
      "\n",
      "Epoch 3338\n",
      "-------------------------------\n",
      "loss: 0.239386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401820 \n",
      "\n",
      "Epoch 3339\n",
      "-------------------------------\n",
      "loss: 0.248832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401687 \n",
      "\n",
      "Epoch 3340\n",
      "-------------------------------\n",
      "loss: 0.237896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400699 \n",
      "\n",
      "Epoch 3341\n",
      "-------------------------------\n",
      "loss: 0.226905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399122 \n",
      "\n",
      "Epoch 3342\n",
      "-------------------------------\n",
      "loss: 0.221139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398467 \n",
      "\n",
      "Epoch 3343\n",
      "-------------------------------\n",
      "loss: 0.231589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398132 \n",
      "\n",
      "Epoch 3344\n",
      "-------------------------------\n",
      "loss: 0.248349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397499 \n",
      "\n",
      "Epoch 3345\n",
      "-------------------------------\n",
      "loss: 0.243376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396631 \n",
      "\n",
      "Epoch 3346\n",
      "-------------------------------\n",
      "loss: 0.232662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396978 \n",
      "\n",
      "Epoch 3347\n",
      "-------------------------------\n",
      "loss: 0.217078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397036 \n",
      "\n",
      "Epoch 3348\n",
      "-------------------------------\n",
      "loss: 0.233923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397530 \n",
      "\n",
      "Epoch 3349\n",
      "-------------------------------\n",
      "loss: 0.245882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398152 \n",
      "\n",
      "Epoch 3350\n",
      "-------------------------------\n",
      "loss: 0.222719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398733 \n",
      "\n",
      "Epoch 3351\n",
      "-------------------------------\n",
      "loss: 0.231498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399390 \n",
      "\n",
      "Epoch 3352\n",
      "-------------------------------\n",
      "loss: 0.234543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400266 \n",
      "\n",
      "Epoch 3353\n",
      "-------------------------------\n",
      "loss: 0.235157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399445 \n",
      "\n",
      "Epoch 3354\n",
      "-------------------------------\n",
      "loss: 0.238147  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399116 \n",
      "\n",
      "Epoch 3355\n",
      "-------------------------------\n",
      "loss: 0.246602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398783 \n",
      "\n",
      "Epoch 3356\n",
      "-------------------------------\n",
      "loss: 0.226095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399150 \n",
      "\n",
      "Epoch 3357\n",
      "-------------------------------\n",
      "loss: 0.226064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400020 \n",
      "\n",
      "Epoch 3358\n",
      "-------------------------------\n",
      "loss: 0.229107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400361 \n",
      "\n",
      "Epoch 3359\n",
      "-------------------------------\n",
      "loss: 0.232145  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401957 \n",
      "\n",
      "Epoch 3360\n",
      "-------------------------------\n",
      "loss: 0.228024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404362 \n",
      "\n",
      "Epoch 3361\n",
      "-------------------------------\n",
      "loss: 0.240427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405452 \n",
      "\n",
      "Epoch 3362\n",
      "-------------------------------\n",
      "loss: 0.254035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402097 \n",
      "\n",
      "Epoch 3363\n",
      "-------------------------------\n",
      "loss: 0.233398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398444 \n",
      "\n",
      "Epoch 3364\n",
      "-------------------------------\n",
      "loss: 0.233060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397851 \n",
      "\n",
      "Epoch 3365\n",
      "-------------------------------\n",
      "loss: 0.238964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399456 \n",
      "\n",
      "Epoch 3366\n",
      "-------------------------------\n",
      "loss: 0.253851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399818 \n",
      "\n",
      "Epoch 3367\n",
      "-------------------------------\n",
      "loss: 0.239939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398706 \n",
      "\n",
      "Epoch 3368\n",
      "-------------------------------\n",
      "loss: 0.220412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399485 \n",
      "\n",
      "Epoch 3369\n",
      "-------------------------------\n",
      "loss: 0.237820  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401657 \n",
      "\n",
      "Epoch 3370\n",
      "-------------------------------\n",
      "loss: 0.244649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403233 \n",
      "\n",
      "Epoch 3371\n",
      "-------------------------------\n",
      "loss: 0.247415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403733 \n",
      "\n",
      "Epoch 3372\n",
      "-------------------------------\n",
      "loss: 0.220318  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403571 \n",
      "\n",
      "Epoch 3373\n",
      "-------------------------------\n",
      "loss: 0.240478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401887 \n",
      "\n",
      "Epoch 3374\n",
      "-------------------------------\n",
      "loss: 0.240561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401742 \n",
      "\n",
      "Epoch 3375\n",
      "-------------------------------\n",
      "loss: 0.250250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402906 \n",
      "\n",
      "Epoch 3376\n",
      "-------------------------------\n",
      "loss: 0.233561  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403317 \n",
      "\n",
      "Epoch 3377\n",
      "-------------------------------\n",
      "loss: 0.240496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402946 \n",
      "\n",
      "Epoch 3378\n",
      "-------------------------------\n",
      "loss: 0.233826  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402338 \n",
      "\n",
      "Epoch 3379\n",
      "-------------------------------\n",
      "loss: 0.234186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401502 \n",
      "\n",
      "Epoch 3380\n",
      "-------------------------------\n",
      "loss: 0.235092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402301 \n",
      "\n",
      "Epoch 3381\n",
      "-------------------------------\n",
      "loss: 0.237733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403087 \n",
      "\n",
      "Epoch 3382\n",
      "-------------------------------\n",
      "loss: 0.228298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403005 \n",
      "\n",
      "Epoch 3383\n",
      "-------------------------------\n",
      "loss: 0.245842  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401765 \n",
      "\n",
      "Epoch 3384\n",
      "-------------------------------\n",
      "loss: 0.220235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399914 \n",
      "\n",
      "Epoch 3385\n",
      "-------------------------------\n",
      "loss: 0.234700  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399175 \n",
      "\n",
      "Epoch 3386\n",
      "-------------------------------\n",
      "loss: 0.243420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398430 \n",
      "\n",
      "Epoch 3387\n",
      "-------------------------------\n",
      "loss: 0.232418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398340 \n",
      "\n",
      "Epoch 3388\n",
      "-------------------------------\n",
      "loss: 0.237690  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397247 \n",
      "\n",
      "Epoch 3389\n",
      "-------------------------------\n",
      "loss: 0.235445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396243 \n",
      "\n",
      "Epoch 3390\n",
      "-------------------------------\n",
      "loss: 0.238249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396137 \n",
      "\n",
      "Epoch 3391\n",
      "-------------------------------\n",
      "loss: 0.226008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396608 \n",
      "\n",
      "Epoch 3392\n",
      "-------------------------------\n",
      "loss: 0.231055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398656 \n",
      "\n",
      "Epoch 3393\n",
      "-------------------------------\n",
      "loss: 0.244954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401280 \n",
      "\n",
      "Epoch 3394\n",
      "-------------------------------\n",
      "loss: 0.232838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403527 \n",
      "\n",
      "Epoch 3395\n",
      "-------------------------------\n",
      "loss: 0.238710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402951 \n",
      "\n",
      "Epoch 3396\n",
      "-------------------------------\n",
      "loss: 0.235378  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400531 \n",
      "\n",
      "Epoch 3397\n",
      "-------------------------------\n",
      "loss: 0.222569  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399984 \n",
      "\n",
      "Epoch 3398\n",
      "-------------------------------\n",
      "loss: 0.226816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400679 \n",
      "\n",
      "Epoch 3399\n",
      "-------------------------------\n",
      "loss: 0.226625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401333 \n",
      "\n",
      "Epoch 3400\n",
      "-------------------------------\n",
      "loss: 0.240969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401613 \n",
      "\n",
      "Epoch 3401\n",
      "-------------------------------\n",
      "loss: 0.245920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401637 \n",
      "\n",
      "Epoch 3402\n",
      "-------------------------------\n",
      "loss: 0.240320  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402249 \n",
      "\n",
      "Epoch 3403\n",
      "-------------------------------\n",
      "loss: 0.222836  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403007 \n",
      "\n",
      "Epoch 3404\n",
      "-------------------------------\n",
      "loss: 0.244199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403550 \n",
      "\n",
      "Epoch 3405\n",
      "-------------------------------\n",
      "loss: 0.226722  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403986 \n",
      "\n",
      "Epoch 3406\n",
      "-------------------------------\n",
      "loss: 0.244951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404360 \n",
      "\n",
      "Epoch 3407\n",
      "-------------------------------\n",
      "loss: 0.234498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404806 \n",
      "\n",
      "Epoch 3408\n",
      "-------------------------------\n",
      "loss: 0.231149  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405865 \n",
      "\n",
      "Epoch 3409\n",
      "-------------------------------\n",
      "loss: 0.241586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406611 \n",
      "\n",
      "Epoch 3410\n",
      "-------------------------------\n",
      "loss: 0.218055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406991 \n",
      "\n",
      "Epoch 3411\n",
      "-------------------------------\n",
      "loss: 0.229341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406157 \n",
      "\n",
      "Epoch 3412\n",
      "-------------------------------\n",
      "loss: 0.232754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405547 \n",
      "\n",
      "Epoch 3413\n",
      "-------------------------------\n",
      "loss: 0.222322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405478 \n",
      "\n",
      "Epoch 3414\n",
      "-------------------------------\n",
      "loss: 0.240848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405853 \n",
      "\n",
      "Epoch 3415\n",
      "-------------------------------\n",
      "loss: 0.220431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406164 \n",
      "\n",
      "Epoch 3416\n",
      "-------------------------------\n",
      "loss: 0.240786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406240 \n",
      "\n",
      "Epoch 3417\n",
      "-------------------------------\n",
      "loss: 0.254906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406991 \n",
      "\n",
      "Epoch 3418\n",
      "-------------------------------\n",
      "loss: 0.249001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408445 \n",
      "\n",
      "Epoch 3419\n",
      "-------------------------------\n",
      "loss: 0.236367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409495 \n",
      "\n",
      "Epoch 3420\n",
      "-------------------------------\n",
      "loss: 0.247829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408247 \n",
      "\n",
      "Epoch 3421\n",
      "-------------------------------\n",
      "loss: 0.224681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406299 \n",
      "\n",
      "Epoch 3422\n",
      "-------------------------------\n",
      "loss: 0.231743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405899 \n",
      "\n",
      "Epoch 3423\n",
      "-------------------------------\n",
      "loss: 0.220571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405799 \n",
      "\n",
      "Epoch 3424\n",
      "-------------------------------\n",
      "loss: 0.228699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405826 \n",
      "\n",
      "Epoch 3425\n",
      "-------------------------------\n",
      "loss: 0.241262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405739 \n",
      "\n",
      "Epoch 3426\n",
      "-------------------------------\n",
      "loss: 0.235341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405872 \n",
      "\n",
      "Epoch 3427\n",
      "-------------------------------\n",
      "loss: 0.240680  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405479 \n",
      "\n",
      "Epoch 3428\n",
      "-------------------------------\n",
      "loss: 0.235964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404088 \n",
      "\n",
      "Epoch 3429\n",
      "-------------------------------\n",
      "loss: 0.234165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402444 \n",
      "\n",
      "Epoch 3430\n",
      "-------------------------------\n",
      "loss: 0.219342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401643 \n",
      "\n",
      "Epoch 3431\n",
      "-------------------------------\n",
      "loss: 0.221740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401669 \n",
      "\n",
      "Epoch 3432\n",
      "-------------------------------\n",
      "loss: 0.241607  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403153 \n",
      "\n",
      "Epoch 3433\n",
      "-------------------------------\n",
      "loss: 0.217137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403990 \n",
      "\n",
      "Epoch 3434\n",
      "-------------------------------\n",
      "loss: 0.225205  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403438 \n",
      "\n",
      "Epoch 3435\n",
      "-------------------------------\n",
      "loss: 0.229742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402615 \n",
      "\n",
      "Epoch 3436\n",
      "-------------------------------\n",
      "loss: 0.231474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402121 \n",
      "\n",
      "Epoch 3437\n",
      "-------------------------------\n",
      "loss: 0.241812  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401388 \n",
      "\n",
      "Epoch 3438\n",
      "-------------------------------\n",
      "loss: 0.226553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401302 \n",
      "\n",
      "Epoch 3439\n",
      "-------------------------------\n",
      "loss: 0.228797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401852 \n",
      "\n",
      "Epoch 3440\n",
      "-------------------------------\n",
      "loss: 0.229567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403152 \n",
      "\n",
      "Epoch 3441\n",
      "-------------------------------\n",
      "loss: 0.229263  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406075 \n",
      "\n",
      "Epoch 3442\n",
      "-------------------------------\n",
      "loss: 0.214172  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409315 \n",
      "\n",
      "Epoch 3443\n",
      "-------------------------------\n",
      "loss: 0.263491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408196 \n",
      "\n",
      "Epoch 3444\n",
      "-------------------------------\n",
      "loss: 0.223984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404383 \n",
      "\n",
      "Epoch 3445\n",
      "-------------------------------\n",
      "loss: 0.240802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400196 \n",
      "\n",
      "Epoch 3446\n",
      "-------------------------------\n",
      "loss: 0.235681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398767 \n",
      "\n",
      "Epoch 3447\n",
      "-------------------------------\n",
      "loss: 0.225941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398585 \n",
      "\n",
      "Epoch 3448\n",
      "-------------------------------\n",
      "loss: 0.240100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398004 \n",
      "\n",
      "Epoch 3449\n",
      "-------------------------------\n",
      "loss: 0.227522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397080 \n",
      "\n",
      "Epoch 3450\n",
      "-------------------------------\n",
      "loss: 0.217032  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397305 \n",
      "\n",
      "Epoch 3451\n",
      "-------------------------------\n",
      "loss: 0.229178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401205 \n",
      "\n",
      "Epoch 3452\n",
      "-------------------------------\n",
      "loss: 0.224387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406630 \n",
      "\n",
      "Epoch 3453\n",
      "-------------------------------\n",
      "loss: 0.249163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407205 \n",
      "\n",
      "Epoch 3454\n",
      "-------------------------------\n",
      "loss: 0.232882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403950 \n",
      "\n",
      "Epoch 3455\n",
      "-------------------------------\n",
      "loss: 0.247405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399574 \n",
      "\n",
      "Epoch 3456\n",
      "-------------------------------\n",
      "loss: 0.239965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397724 \n",
      "\n",
      "Epoch 3457\n",
      "-------------------------------\n",
      "loss: 0.242248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398465 \n",
      "\n",
      "Epoch 3458\n",
      "-------------------------------\n",
      "loss: 0.241760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399099 \n",
      "\n",
      "Epoch 3459\n",
      "-------------------------------\n",
      "loss: 0.222688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398385 \n",
      "\n",
      "Epoch 3460\n",
      "-------------------------------\n",
      "loss: 0.232515  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399203 \n",
      "\n",
      "Epoch 3461\n",
      "-------------------------------\n",
      "loss: 0.245161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402245 \n",
      "\n",
      "Epoch 3462\n",
      "-------------------------------\n",
      "loss: 0.230560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405770 \n",
      "\n",
      "Epoch 3463\n",
      "-------------------------------\n",
      "loss: 0.230893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407115 \n",
      "\n",
      "Epoch 3464\n",
      "-------------------------------\n",
      "loss: 0.234541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407039 \n",
      "\n",
      "Epoch 3465\n",
      "-------------------------------\n",
      "loss: 0.219779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404780 \n",
      "\n",
      "Epoch 3466\n",
      "-------------------------------\n",
      "loss: 0.236113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402937 \n",
      "\n",
      "Epoch 3467\n",
      "-------------------------------\n",
      "loss: 0.236422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402103 \n",
      "\n",
      "Epoch 3468\n",
      "-------------------------------\n",
      "loss: 0.238143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401581 \n",
      "\n",
      "Epoch 3469\n",
      "-------------------------------\n",
      "loss: 0.230766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401353 \n",
      "\n",
      "Epoch 3470\n",
      "-------------------------------\n",
      "loss: 0.220458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401774 \n",
      "\n",
      "Epoch 3471\n",
      "-------------------------------\n",
      "loss: 0.225661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403345 \n",
      "\n",
      "Epoch 3472\n",
      "-------------------------------\n",
      "loss: 0.234783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406466 \n",
      "\n",
      "Epoch 3473\n",
      "-------------------------------\n",
      "loss: 0.239348  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.407948 \n",
      "\n",
      "Epoch 3474\n",
      "-------------------------------\n",
      "loss: 0.246902  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405168 \n",
      "\n",
      "Epoch 3475\n",
      "-------------------------------\n",
      "loss: 0.232920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400922 \n",
      "\n",
      "Epoch 3476\n",
      "-------------------------------\n",
      "loss: 0.238717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398977 \n",
      "\n",
      "Epoch 3477\n",
      "-------------------------------\n",
      "loss: 0.245931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398646 \n",
      "\n",
      "Epoch 3478\n",
      "-------------------------------\n",
      "loss: 0.228542  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398901 \n",
      "\n",
      "Epoch 3479\n",
      "-------------------------------\n",
      "loss: 0.237257  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399130 \n",
      "\n",
      "Epoch 3480\n",
      "-------------------------------\n",
      "loss: 0.225931  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400474 \n",
      "\n",
      "Epoch 3481\n",
      "-------------------------------\n",
      "loss: 0.231975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402691 \n",
      "\n",
      "Epoch 3482\n",
      "-------------------------------\n",
      "loss: 0.232332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403834 \n",
      "\n",
      "Epoch 3483\n",
      "-------------------------------\n",
      "loss: 0.233924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403921 \n",
      "\n",
      "Epoch 3484\n",
      "-------------------------------\n",
      "loss: 0.239940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402368 \n",
      "\n",
      "Epoch 3485\n",
      "-------------------------------\n",
      "loss: 0.242834  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400915 \n",
      "\n",
      "Epoch 3486\n",
      "-------------------------------\n",
      "loss: 0.232586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401151 \n",
      "\n",
      "Epoch 3487\n",
      "-------------------------------\n",
      "loss: 0.252678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401559 \n",
      "\n",
      "Epoch 3488\n",
      "-------------------------------\n",
      "loss: 0.239714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401624 \n",
      "\n",
      "Epoch 3489\n",
      "-------------------------------\n",
      "loss: 0.254726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401111 \n",
      "\n",
      "Epoch 3490\n",
      "-------------------------------\n",
      "loss: 0.236481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400742 \n",
      "\n",
      "Epoch 3491\n",
      "-------------------------------\n",
      "loss: 0.217684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402156 \n",
      "\n",
      "Epoch 3492\n",
      "-------------------------------\n",
      "loss: 0.232122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403499 \n",
      "\n",
      "Epoch 3493\n",
      "-------------------------------\n",
      "loss: 0.224301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403548 \n",
      "\n",
      "Epoch 3494\n",
      "-------------------------------\n",
      "loss: 0.236986  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404263 \n",
      "\n",
      "Epoch 3495\n",
      "-------------------------------\n",
      "loss: 0.235550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404507 \n",
      "\n",
      "Epoch 3496\n",
      "-------------------------------\n",
      "loss: 0.230332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403559 \n",
      "\n",
      "Epoch 3497\n",
      "-------------------------------\n",
      "loss: 0.222025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403592 \n",
      "\n",
      "Epoch 3498\n",
      "-------------------------------\n",
      "loss: 0.252656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403085 \n",
      "\n",
      "Epoch 3499\n",
      "-------------------------------\n",
      "loss: 0.241176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402333 \n",
      "\n",
      "Epoch 3500\n",
      "-------------------------------\n",
      "loss: 0.230613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401716 \n",
      "\n",
      "Epoch 3501\n",
      "-------------------------------\n",
      "loss: 0.242304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401357 \n",
      "\n",
      "Epoch 3502\n",
      "-------------------------------\n",
      "loss: 0.222498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401168 \n",
      "\n",
      "Epoch 3503\n",
      "-------------------------------\n",
      "loss: 0.224868  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401874 \n",
      "\n",
      "Epoch 3504\n",
      "-------------------------------\n",
      "loss: 0.229577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402804 \n",
      "\n",
      "Epoch 3505\n",
      "-------------------------------\n",
      "loss: 0.239198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403221 \n",
      "\n",
      "Epoch 3506\n",
      "-------------------------------\n",
      "loss: 0.239977  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403020 \n",
      "\n",
      "Epoch 3507\n",
      "-------------------------------\n",
      "loss: 0.231029  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401585 \n",
      "\n",
      "Epoch 3508\n",
      "-------------------------------\n",
      "loss: 0.226343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401005 \n",
      "\n",
      "Epoch 3509\n",
      "-------------------------------\n",
      "loss: 0.234306  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400747 \n",
      "\n",
      "Epoch 3510\n",
      "-------------------------------\n",
      "loss: 0.230494  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400890 \n",
      "\n",
      "Epoch 3511\n",
      "-------------------------------\n",
      "loss: 0.239861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401607 \n",
      "\n",
      "Epoch 3512\n",
      "-------------------------------\n",
      "loss: 0.227766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402775 \n",
      "\n",
      "Epoch 3513\n",
      "-------------------------------\n",
      "loss: 0.238146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404863 \n",
      "\n",
      "Epoch 3514\n",
      "-------------------------------\n",
      "loss: 0.228912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404968 \n",
      "\n",
      "Epoch 3515\n",
      "-------------------------------\n",
      "loss: 0.229979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403143 \n",
      "\n",
      "Epoch 3516\n",
      "-------------------------------\n",
      "loss: 0.236685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402573 \n",
      "\n",
      "Epoch 3517\n",
      "-------------------------------\n",
      "loss: 0.237010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402582 \n",
      "\n",
      "Epoch 3518\n",
      "-------------------------------\n",
      "loss: 0.250315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402433 \n",
      "\n",
      "Epoch 3519\n",
      "-------------------------------\n",
      "loss: 0.219163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402564 \n",
      "\n",
      "Epoch 3520\n",
      "-------------------------------\n",
      "loss: 0.247622  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402568 \n",
      "\n",
      "Epoch 3521\n",
      "-------------------------------\n",
      "loss: 0.223454  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402187 \n",
      "\n",
      "Epoch 3522\n",
      "-------------------------------\n",
      "loss: 0.233509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401454 \n",
      "\n",
      "Epoch 3523\n",
      "-------------------------------\n",
      "loss: 0.222822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400447 \n",
      "\n",
      "Epoch 3524\n",
      "-------------------------------\n",
      "loss: 0.237733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399445 \n",
      "\n",
      "Epoch 3525\n",
      "-------------------------------\n",
      "loss: 0.234330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399166 \n",
      "\n",
      "Epoch 3526\n",
      "-------------------------------\n",
      "loss: 0.240492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398564 \n",
      "\n",
      "Epoch 3527\n",
      "-------------------------------\n",
      "loss: 0.229024  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398095 \n",
      "\n",
      "Epoch 3528\n",
      "-------------------------------\n",
      "loss: 0.228699  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400768 \n",
      "\n",
      "Epoch 3529\n",
      "-------------------------------\n",
      "loss: 0.235079  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405551 \n",
      "\n",
      "Epoch 3530\n",
      "-------------------------------\n",
      "loss: 0.241856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407570 \n",
      "\n",
      "Epoch 3531\n",
      "-------------------------------\n",
      "loss: 0.230325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406280 \n",
      "\n",
      "Epoch 3532\n",
      "-------------------------------\n",
      "loss: 0.214039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403437 \n",
      "\n",
      "Epoch 3533\n",
      "-------------------------------\n",
      "loss: 0.226194  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401276 \n",
      "\n",
      "Epoch 3534\n",
      "-------------------------------\n",
      "loss: 0.218249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399397 \n",
      "\n",
      "Epoch 3535\n",
      "-------------------------------\n",
      "loss: 0.240312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397606 \n",
      "\n",
      "Epoch 3536\n",
      "-------------------------------\n",
      "loss: 0.231164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396579 \n",
      "\n",
      "Epoch 3537\n",
      "-------------------------------\n",
      "loss: 0.222663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396375 \n",
      "\n",
      "Epoch 3538\n",
      "-------------------------------\n",
      "loss: 0.219855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398010 \n",
      "\n",
      "Epoch 3539\n",
      "-------------------------------\n",
      "loss: 0.233671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398473 \n",
      "\n",
      "Epoch 3540\n",
      "-------------------------------\n",
      "loss: 0.239823  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397413 \n",
      "\n",
      "Epoch 3541\n",
      "-------------------------------\n",
      "loss: 0.223245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397366 \n",
      "\n",
      "Epoch 3542\n",
      "-------------------------------\n",
      "loss: 0.224629  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397430 \n",
      "\n",
      "Epoch 3543\n",
      "-------------------------------\n",
      "loss: 0.234708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397454 \n",
      "\n",
      "Epoch 3544\n",
      "-------------------------------\n",
      "loss: 0.231508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398068 \n",
      "\n",
      "Epoch 3545\n",
      "-------------------------------\n",
      "loss: 0.236374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399199 \n",
      "\n",
      "Epoch 3546\n",
      "-------------------------------\n",
      "loss: 0.236693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400546 \n",
      "\n",
      "Epoch 3547\n",
      "-------------------------------\n",
      "loss: 0.251557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403817 \n",
      "\n",
      "Epoch 3548\n",
      "-------------------------------\n",
      "loss: 0.233838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407537 \n",
      "\n",
      "Epoch 3549\n",
      "-------------------------------\n",
      "loss: 0.247058  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.408861 \n",
      "\n",
      "Epoch 3550\n",
      "-------------------------------\n",
      "loss: 0.253685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407220 \n",
      "\n",
      "Epoch 3551\n",
      "-------------------------------\n",
      "loss: 0.226467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405845 \n",
      "\n",
      "Epoch 3552\n",
      "-------------------------------\n",
      "loss: 0.227051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403588 \n",
      "\n",
      "Epoch 3553\n",
      "-------------------------------\n",
      "loss: 0.232510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402115 \n",
      "\n",
      "Epoch 3554\n",
      "-------------------------------\n",
      "loss: 0.217316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402105 \n",
      "\n",
      "Epoch 3555\n",
      "-------------------------------\n",
      "loss: 0.238139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402108 \n",
      "\n",
      "Epoch 3556\n",
      "-------------------------------\n",
      "loss: 0.223488  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402002 \n",
      "\n",
      "Epoch 3557\n",
      "-------------------------------\n",
      "loss: 0.225780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402721 \n",
      "\n",
      "Epoch 3558\n",
      "-------------------------------\n",
      "loss: 0.232006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404075 \n",
      "\n",
      "Epoch 3559\n",
      "-------------------------------\n",
      "loss: 0.234546  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404072 \n",
      "\n",
      "Epoch 3560\n",
      "-------------------------------\n",
      "loss: 0.236398  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403439 \n",
      "\n",
      "Epoch 3561\n",
      "-------------------------------\n",
      "loss: 0.233685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401641 \n",
      "\n",
      "Epoch 3562\n",
      "-------------------------------\n",
      "loss: 0.240034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400612 \n",
      "\n",
      "Epoch 3563\n",
      "-------------------------------\n",
      "loss: 0.229211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400653 \n",
      "\n",
      "Epoch 3564\n",
      "-------------------------------\n",
      "loss: 0.223755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401190 \n",
      "\n",
      "Epoch 3565\n",
      "-------------------------------\n",
      "loss: 0.232316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401629 \n",
      "\n",
      "Epoch 3566\n",
      "-------------------------------\n",
      "loss: 0.236044  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401610 \n",
      "\n",
      "Epoch 3567\n",
      "-------------------------------\n",
      "loss: 0.230121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402199 \n",
      "\n",
      "Epoch 3568\n",
      "-------------------------------\n",
      "loss: 0.241104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402620 \n",
      "\n",
      "Epoch 3569\n",
      "-------------------------------\n",
      "loss: 0.244641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402178 \n",
      "\n",
      "Epoch 3570\n",
      "-------------------------------\n",
      "loss: 0.232956  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402270 \n",
      "\n",
      "Epoch 3571\n",
      "-------------------------------\n",
      "loss: 0.224064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402774 \n",
      "\n",
      "Epoch 3572\n",
      "-------------------------------\n",
      "loss: 0.240833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403069 \n",
      "\n",
      "Epoch 3573\n",
      "-------------------------------\n",
      "loss: 0.243473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401636 \n",
      "\n",
      "Epoch 3574\n",
      "-------------------------------\n",
      "loss: 0.229413  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399173 \n",
      "\n",
      "Epoch 3575\n",
      "-------------------------------\n",
      "loss: 0.237697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398140 \n",
      "\n",
      "Epoch 3576\n",
      "-------------------------------\n",
      "loss: 0.240015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401313 \n",
      "\n",
      "Epoch 3577\n",
      "-------------------------------\n",
      "loss: 0.237188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406570 \n",
      "\n",
      "Epoch 3578\n",
      "-------------------------------\n",
      "loss: 0.243983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410590 \n",
      "\n",
      "Epoch 3579\n",
      "-------------------------------\n",
      "loss: 0.244491  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410005 \n",
      "\n",
      "Epoch 3580\n",
      "-------------------------------\n",
      "loss: 0.251249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407275 \n",
      "\n",
      "Epoch 3581\n",
      "-------------------------------\n",
      "loss: 0.255560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404831 \n",
      "\n",
      "Epoch 3582\n",
      "-------------------------------\n",
      "loss: 0.238074  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403655 \n",
      "\n",
      "Epoch 3583\n",
      "-------------------------------\n",
      "loss: 0.229534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403383 \n",
      "\n",
      "Epoch 3584\n",
      "-------------------------------\n",
      "loss: 0.230294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403308 \n",
      "\n",
      "Epoch 3585\n",
      "-------------------------------\n",
      "loss: 0.243627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404312 \n",
      "\n",
      "Epoch 3586\n",
      "-------------------------------\n",
      "loss: 0.232908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408518 \n",
      "\n",
      "Epoch 3587\n",
      "-------------------------------\n",
      "loss: 0.224392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.413187 \n",
      "\n",
      "Epoch 3588\n",
      "-------------------------------\n",
      "loss: 0.240704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.415982 \n",
      "\n",
      "Epoch 3589\n",
      "-------------------------------\n",
      "loss: 0.244220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416345 \n",
      "\n",
      "Epoch 3590\n",
      "-------------------------------\n",
      "loss: 0.241487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412097 \n",
      "\n",
      "Epoch 3591\n",
      "-------------------------------\n",
      "loss: 0.228230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408674 \n",
      "\n",
      "Epoch 3592\n",
      "-------------------------------\n",
      "loss: 0.225109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406858 \n",
      "\n",
      "Epoch 3593\n",
      "-------------------------------\n",
      "loss: 0.225438  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405563 \n",
      "\n",
      "Epoch 3594\n",
      "-------------------------------\n",
      "loss: 0.242973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405555 \n",
      "\n",
      "Epoch 3595\n",
      "-------------------------------\n",
      "loss: 0.233480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406151 \n",
      "\n",
      "Epoch 3596\n",
      "-------------------------------\n",
      "loss: 0.236555  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406804 \n",
      "\n",
      "Epoch 3597\n",
      "-------------------------------\n",
      "loss: 0.238517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404616 \n",
      "\n",
      "Epoch 3598\n",
      "-------------------------------\n",
      "loss: 0.230577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402463 \n",
      "\n",
      "Epoch 3599\n",
      "-------------------------------\n",
      "loss: 0.235833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401257 \n",
      "\n",
      "Epoch 3600\n",
      "-------------------------------\n",
      "loss: 0.232157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400796 \n",
      "\n",
      "Epoch 3601\n",
      "-------------------------------\n",
      "loss: 0.239080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400685 \n",
      "\n",
      "Epoch 3602\n",
      "-------------------------------\n",
      "loss: 0.235329  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400805 \n",
      "\n",
      "Epoch 3603\n",
      "-------------------------------\n",
      "loss: 0.227586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400806 \n",
      "\n",
      "Epoch 3604\n",
      "-------------------------------\n",
      "loss: 0.236992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400237 \n",
      "\n",
      "Epoch 3605\n",
      "-------------------------------\n",
      "loss: 0.220795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400293 \n",
      "\n",
      "Epoch 3606\n",
      "-------------------------------\n",
      "loss: 0.229482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399657 \n",
      "\n",
      "Epoch 3607\n",
      "-------------------------------\n",
      "loss: 0.215421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398862 \n",
      "\n",
      "Epoch 3608\n",
      "-------------------------------\n",
      "loss: 0.216315  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398237 \n",
      "\n",
      "Epoch 3609\n",
      "-------------------------------\n",
      "loss: 0.227314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397879 \n",
      "\n",
      "Epoch 3610\n",
      "-------------------------------\n",
      "loss: 0.232366  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397997 \n",
      "\n",
      "Epoch 3611\n",
      "-------------------------------\n",
      "loss: 0.233932  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397574 \n",
      "\n",
      "Epoch 3612\n",
      "-------------------------------\n",
      "loss: 0.231221  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398030 \n",
      "\n",
      "Epoch 3613\n",
      "-------------------------------\n",
      "loss: 0.232601  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398245 \n",
      "\n",
      "Epoch 3614\n",
      "-------------------------------\n",
      "loss: 0.223458  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399603 \n",
      "\n",
      "Epoch 3615\n",
      "-------------------------------\n",
      "loss: 0.240143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400360 \n",
      "\n",
      "Epoch 3616\n",
      "-------------------------------\n",
      "loss: 0.224668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401668 \n",
      "\n",
      "Epoch 3617\n",
      "-------------------------------\n",
      "loss: 0.231222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402290 \n",
      "\n",
      "Epoch 3618\n",
      "-------------------------------\n",
      "loss: 0.222290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403554 \n",
      "\n",
      "Epoch 3619\n",
      "-------------------------------\n",
      "loss: 0.229473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402989 \n",
      "\n",
      "Epoch 3620\n",
      "-------------------------------\n",
      "loss: 0.232874  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400316 \n",
      "\n",
      "Epoch 3621\n",
      "-------------------------------\n",
      "loss: 0.225470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399682 \n",
      "\n",
      "Epoch 3622\n",
      "-------------------------------\n",
      "loss: 0.227910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400241 \n",
      "\n",
      "Epoch 3623\n",
      "-------------------------------\n",
      "loss: 0.232907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400672 \n",
      "\n",
      "Epoch 3624\n",
      "-------------------------------\n",
      "loss: 0.233224  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402620 \n",
      "\n",
      "Epoch 3625\n",
      "-------------------------------\n",
      "loss: 0.246203  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403756 \n",
      "\n",
      "Epoch 3626\n",
      "-------------------------------\n",
      "loss: 0.223328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403413 \n",
      "\n",
      "Epoch 3627\n",
      "-------------------------------\n",
      "loss: 0.241880  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401989 \n",
      "\n",
      "Epoch 3628\n",
      "-------------------------------\n",
      "loss: 0.244068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401562 \n",
      "\n",
      "Epoch 3629\n",
      "-------------------------------\n",
      "loss: 0.232405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402133 \n",
      "\n",
      "Epoch 3630\n",
      "-------------------------------\n",
      "loss: 0.241095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402299 \n",
      "\n",
      "Epoch 3631\n",
      "-------------------------------\n",
      "loss: 0.233855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402196 \n",
      "\n",
      "Epoch 3632\n",
      "-------------------------------\n",
      "loss: 0.224674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402091 \n",
      "\n",
      "Epoch 3633\n",
      "-------------------------------\n",
      "loss: 0.240678  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401381 \n",
      "\n",
      "Epoch 3634\n",
      "-------------------------------\n",
      "loss: 0.226840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401846 \n",
      "\n",
      "Epoch 3635\n",
      "-------------------------------\n",
      "loss: 0.228715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402983 \n",
      "\n",
      "Epoch 3636\n",
      "-------------------------------\n",
      "loss: 0.235135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402663 \n",
      "\n",
      "Epoch 3637\n",
      "-------------------------------\n",
      "loss: 0.235146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401342 \n",
      "\n",
      "Epoch 3638\n",
      "-------------------------------\n",
      "loss: 0.220573  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400812 \n",
      "\n",
      "Epoch 3639\n",
      "-------------------------------\n",
      "loss: 0.230416  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400528 \n",
      "\n",
      "Epoch 3640\n",
      "-------------------------------\n",
      "loss: 0.228687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400146 \n",
      "\n",
      "Epoch 3641\n",
      "-------------------------------\n",
      "loss: 0.236017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400217 \n",
      "\n",
      "Epoch 3642\n",
      "-------------------------------\n",
      "loss: 0.232936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401146 \n",
      "\n",
      "Epoch 3643\n",
      "-------------------------------\n",
      "loss: 0.236327  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404282 \n",
      "\n",
      "Epoch 3644\n",
      "-------------------------------\n",
      "loss: 0.222816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408258 \n",
      "\n",
      "Epoch 3645\n",
      "-------------------------------\n",
      "loss: 0.237657  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409012 \n",
      "\n",
      "Epoch 3646\n",
      "-------------------------------\n",
      "loss: 0.237900  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406255 \n",
      "\n",
      "Epoch 3647\n",
      "-------------------------------\n",
      "loss: 0.255971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401116 \n",
      "\n",
      "Epoch 3648\n",
      "-------------------------------\n",
      "loss: 0.234401  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400188 \n",
      "\n",
      "Epoch 3649\n",
      "-------------------------------\n",
      "loss: 0.236352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402437 \n",
      "\n",
      "Epoch 3650\n",
      "-------------------------------\n",
      "loss: 0.229663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403232 \n",
      "\n",
      "Epoch 3651\n",
      "-------------------------------\n",
      "loss: 0.251258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400494 \n",
      "\n",
      "Epoch 3652\n",
      "-------------------------------\n",
      "loss: 0.248138  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399038 \n",
      "\n",
      "Epoch 3653\n",
      "-------------------------------\n",
      "loss: 0.238861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402496 \n",
      "\n",
      "Epoch 3654\n",
      "-------------------------------\n",
      "loss: 0.217258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407764 \n",
      "\n",
      "Epoch 3655\n",
      "-------------------------------\n",
      "loss: 0.250783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407672 \n",
      "\n",
      "Epoch 3656\n",
      "-------------------------------\n",
      "loss: 0.255906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402759 \n",
      "\n",
      "Epoch 3657\n",
      "-------------------------------\n",
      "loss: 0.235129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397915 \n",
      "\n",
      "Epoch 3658\n",
      "-------------------------------\n",
      "loss: 0.229225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396162 \n",
      "\n",
      "Epoch 3659\n",
      "-------------------------------\n",
      "loss: 0.241861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396525 \n",
      "\n",
      "Epoch 3660\n",
      "-------------------------------\n",
      "loss: 0.244085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396298 \n",
      "\n",
      "Epoch 3661\n",
      "-------------------------------\n",
      "loss: 0.242967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394569 \n",
      "\n",
      "Epoch 3662\n",
      "-------------------------------\n",
      "loss: 0.229056  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394298 \n",
      "\n",
      "Epoch 3663\n",
      "-------------------------------\n",
      "loss: 0.225466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396643 \n",
      "\n",
      "Epoch 3664\n",
      "-------------------------------\n",
      "loss: 0.244580  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400125 \n",
      "\n",
      "Epoch 3665\n",
      "-------------------------------\n",
      "loss: 0.218991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402804 \n",
      "\n",
      "Epoch 3666\n",
      "-------------------------------\n",
      "loss: 0.240949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402190 \n",
      "\n",
      "Epoch 3667\n",
      "-------------------------------\n",
      "loss: 0.226553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398908 \n",
      "\n",
      "Epoch 3668\n",
      "-------------------------------\n",
      "loss: 0.230550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397429 \n",
      "\n",
      "Epoch 3669\n",
      "-------------------------------\n",
      "loss: 0.230892  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399297 \n",
      "\n",
      "Epoch 3670\n",
      "-------------------------------\n",
      "loss: 0.236280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401428 \n",
      "\n",
      "Epoch 3671\n",
      "-------------------------------\n",
      "loss: 0.250341  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399918 \n",
      "\n",
      "Epoch 3672\n",
      "-------------------------------\n",
      "loss: 0.239838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399259 \n",
      "\n",
      "Epoch 3673\n",
      "-------------------------------\n",
      "loss: 0.227379  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402179 \n",
      "\n",
      "Epoch 3674\n",
      "-------------------------------\n",
      "loss: 0.233704  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406198 \n",
      "\n",
      "Epoch 3675\n",
      "-------------------------------\n",
      "loss: 0.226833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408487 \n",
      "\n",
      "Epoch 3676\n",
      "-------------------------------\n",
      "loss: 0.238027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407861 \n",
      "\n",
      "Epoch 3677\n",
      "-------------------------------\n",
      "loss: 0.237118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404414 \n",
      "\n",
      "Epoch 3678\n",
      "-------------------------------\n",
      "loss: 0.222321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401396 \n",
      "\n",
      "Epoch 3679\n",
      "-------------------------------\n",
      "loss: 0.233553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400138 \n",
      "\n",
      "Epoch 3680\n",
      "-------------------------------\n",
      "loss: 0.233895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399220 \n",
      "\n",
      "Epoch 3681\n",
      "-------------------------------\n",
      "loss: 0.224794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398452 \n",
      "\n",
      "Epoch 3682\n",
      "-------------------------------\n",
      "loss: 0.228376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399456 \n",
      "\n",
      "Epoch 3683\n",
      "-------------------------------\n",
      "loss: 0.233815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402231 \n",
      "\n",
      "Epoch 3684\n",
      "-------------------------------\n",
      "loss: 0.229254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403316 \n",
      "\n",
      "Epoch 3685\n",
      "-------------------------------\n",
      "loss: 0.228828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402416 \n",
      "\n",
      "Epoch 3686\n",
      "-------------------------------\n",
      "loss: 0.232470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400550 \n",
      "\n",
      "Epoch 3687\n",
      "-------------------------------\n",
      "loss: 0.228819  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398707 \n",
      "\n",
      "Epoch 3688\n",
      "-------------------------------\n",
      "loss: 0.224253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398402 \n",
      "\n",
      "Epoch 3689\n",
      "-------------------------------\n",
      "loss: 0.237104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399156 \n",
      "\n",
      "Epoch 3690\n",
      "-------------------------------\n",
      "loss: 0.236644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400086 \n",
      "\n",
      "Epoch 3691\n",
      "-------------------------------\n",
      "loss: 0.233941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401774 \n",
      "\n",
      "Epoch 3692\n",
      "-------------------------------\n",
      "loss: 0.235314  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403532 \n",
      "\n",
      "Epoch 3693\n",
      "-------------------------------\n",
      "loss: 0.237896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405380 \n",
      "\n",
      "Epoch 3694\n",
      "-------------------------------\n",
      "loss: 0.236277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405388 \n",
      "\n",
      "Epoch 3695\n",
      "-------------------------------\n",
      "loss: 0.248023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403428 \n",
      "\n",
      "Epoch 3696\n",
      "-------------------------------\n",
      "loss: 0.229186  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402197 \n",
      "\n",
      "Epoch 3697\n",
      "-------------------------------\n",
      "loss: 0.240841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402228 \n",
      "\n",
      "Epoch 3698\n",
      "-------------------------------\n",
      "loss: 0.227181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402046 \n",
      "\n",
      "Epoch 3699\n",
      "-------------------------------\n",
      "loss: 0.227089  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402036 \n",
      "\n",
      "Epoch 3700\n",
      "-------------------------------\n",
      "loss: 0.240869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402660 \n",
      "\n",
      "Epoch 3701\n",
      "-------------------------------\n",
      "loss: 0.234615  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.404176 \n",
      "\n",
      "Epoch 3702\n",
      "-------------------------------\n",
      "loss: 0.229844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406692 \n",
      "\n",
      "Epoch 3703\n",
      "-------------------------------\n",
      "loss: 0.230537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408411 \n",
      "\n",
      "Epoch 3704\n",
      "-------------------------------\n",
      "loss: 0.237734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406736 \n",
      "\n",
      "Epoch 3705\n",
      "-------------------------------\n",
      "loss: 0.230045  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405517 \n",
      "\n",
      "Epoch 3706\n",
      "-------------------------------\n",
      "loss: 0.227340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405696 \n",
      "\n",
      "Epoch 3707\n",
      "-------------------------------\n",
      "loss: 0.237615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405875 \n",
      "\n",
      "Epoch 3708\n",
      "-------------------------------\n",
      "loss: 0.232576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405836 \n",
      "\n",
      "Epoch 3709\n",
      "-------------------------------\n",
      "loss: 0.248262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405734 \n",
      "\n",
      "Epoch 3710\n",
      "-------------------------------\n",
      "loss: 0.249560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405434 \n",
      "\n",
      "Epoch 3711\n",
      "-------------------------------\n",
      "loss: 0.235163  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408748 \n",
      "\n",
      "Epoch 3712\n",
      "-------------------------------\n",
      "loss: 0.232104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414645 \n",
      "\n",
      "Epoch 3713\n",
      "-------------------------------\n",
      "loss: 0.231428  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.418573 \n",
      "\n",
      "Epoch 3714\n",
      "-------------------------------\n",
      "loss: 0.260908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.416673 \n",
      "\n",
      "Epoch 3715\n",
      "-------------------------------\n",
      "loss: 0.257478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410584 \n",
      "\n",
      "Epoch 3716\n",
      "-------------------------------\n",
      "loss: 0.208862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405962 \n",
      "\n",
      "Epoch 3717\n",
      "-------------------------------\n",
      "loss: 0.216533  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403261 \n",
      "\n",
      "Epoch 3718\n",
      "-------------------------------\n",
      "loss: 0.233792  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403126 \n",
      "\n",
      "Epoch 3719\n",
      "-------------------------------\n",
      "loss: 0.241936  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403082 \n",
      "\n",
      "Epoch 3720\n",
      "-------------------------------\n",
      "loss: 0.231662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402470 \n",
      "\n",
      "Epoch 3721\n",
      "-------------------------------\n",
      "loss: 0.230655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401746 \n",
      "\n",
      "Epoch 3722\n",
      "-------------------------------\n",
      "loss: 0.228069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403286 \n",
      "\n",
      "Epoch 3723\n",
      "-------------------------------\n",
      "loss: 0.229096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406396 \n",
      "\n",
      "Epoch 3724\n",
      "-------------------------------\n",
      "loss: 0.224037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407898 \n",
      "\n",
      "Epoch 3725\n",
      "-------------------------------\n",
      "loss: 0.250411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406739 \n",
      "\n",
      "Epoch 3726\n",
      "-------------------------------\n",
      "loss: 0.222265  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405104 \n",
      "\n",
      "Epoch 3727\n",
      "-------------------------------\n",
      "loss: 0.218064  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404770 \n",
      "\n",
      "Epoch 3728\n",
      "-------------------------------\n",
      "loss: 0.226558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404301 \n",
      "\n",
      "Epoch 3729\n",
      "-------------------------------\n",
      "loss: 0.230440  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403602 \n",
      "\n",
      "Epoch 3730\n",
      "-------------------------------\n",
      "loss: 0.231095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403150 \n",
      "\n",
      "Epoch 3731\n",
      "-------------------------------\n",
      "loss: 0.232253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402621 \n",
      "\n",
      "Epoch 3732\n",
      "-------------------------------\n",
      "loss: 0.236511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401192 \n",
      "\n",
      "Epoch 3733\n",
      "-------------------------------\n",
      "loss: 0.220170  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400483 \n",
      "\n",
      "Epoch 3734\n",
      "-------------------------------\n",
      "loss: 0.224487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400180 \n",
      "\n",
      "Epoch 3735\n",
      "-------------------------------\n",
      "loss: 0.232587  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399574 \n",
      "\n",
      "Epoch 3736\n",
      "-------------------------------\n",
      "loss: 0.230698  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399089 \n",
      "\n",
      "Epoch 3737\n",
      "-------------------------------\n",
      "loss: 0.227695  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398913 \n",
      "\n",
      "Epoch 3738\n",
      "-------------------------------\n",
      "loss: 0.252751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398313 \n",
      "\n",
      "Epoch 3739\n",
      "-------------------------------\n",
      "loss: 0.229653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397705 \n",
      "\n",
      "Epoch 3740\n",
      "-------------------------------\n",
      "loss: 0.222208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397913 \n",
      "\n",
      "Epoch 3741\n",
      "-------------------------------\n",
      "loss: 0.234668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397917 \n",
      "\n",
      "Epoch 3742\n",
      "-------------------------------\n",
      "loss: 0.242365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397842 \n",
      "\n",
      "Epoch 3743\n",
      "-------------------------------\n",
      "loss: 0.231631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398119 \n",
      "\n",
      "Epoch 3744\n",
      "-------------------------------\n",
      "loss: 0.231392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399371 \n",
      "\n",
      "Epoch 3745\n",
      "-------------------------------\n",
      "loss: 0.217382  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401384 \n",
      "\n",
      "Epoch 3746\n",
      "-------------------------------\n",
      "loss: 0.233302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403743 \n",
      "\n",
      "Epoch 3747\n",
      "-------------------------------\n",
      "loss: 0.230015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405921 \n",
      "\n",
      "Epoch 3748\n",
      "-------------------------------\n",
      "loss: 0.248636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406635 \n",
      "\n",
      "Epoch 3749\n",
      "-------------------------------\n",
      "loss: 0.230990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404828 \n",
      "\n",
      "Epoch 3750\n",
      "-------------------------------\n",
      "loss: 0.236795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402604 \n",
      "\n",
      "Epoch 3751\n",
      "-------------------------------\n",
      "loss: 0.226855  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401232 \n",
      "\n",
      "Epoch 3752\n",
      "-------------------------------\n",
      "loss: 0.224107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400386 \n",
      "\n",
      "Epoch 3753\n",
      "-------------------------------\n",
      "loss: 0.224337  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400912 \n",
      "\n",
      "Epoch 3754\n",
      "-------------------------------\n",
      "loss: 0.218835  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401804 \n",
      "\n",
      "Epoch 3755\n",
      "-------------------------------\n",
      "loss: 0.237645  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401792 \n",
      "\n",
      "Epoch 3756\n",
      "-------------------------------\n",
      "loss: 0.239816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402439 \n",
      "\n",
      "Epoch 3757\n",
      "-------------------------------\n",
      "loss: 0.217906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403107 \n",
      "\n",
      "Epoch 3758\n",
      "-------------------------------\n",
      "loss: 0.247532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401930 \n",
      "\n",
      "Epoch 3759\n",
      "-------------------------------\n",
      "loss: 0.245252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399577 \n",
      "\n",
      "Epoch 3760\n",
      "-------------------------------\n",
      "loss: 0.234023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399771 \n",
      "\n",
      "Epoch 3761\n",
      "-------------------------------\n",
      "loss: 0.235069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400595 \n",
      "\n",
      "Epoch 3762\n",
      "-------------------------------\n",
      "loss: 0.226537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400648 \n",
      "\n",
      "Epoch 3763\n",
      "-------------------------------\n",
      "loss: 0.228825  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399992 \n",
      "\n",
      "Epoch 3764\n",
      "-------------------------------\n",
      "loss: 0.234706  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400013 \n",
      "\n",
      "Epoch 3765\n",
      "-------------------------------\n",
      "loss: 0.230402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401127 \n",
      "\n",
      "Epoch 3766\n",
      "-------------------------------\n",
      "loss: 0.222626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403195 \n",
      "\n",
      "Epoch 3767\n",
      "-------------------------------\n",
      "loss: 0.228737  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404789 \n",
      "\n",
      "Epoch 3768\n",
      "-------------------------------\n",
      "loss: 0.236650  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403027 \n",
      "\n",
      "Epoch 3769\n",
      "-------------------------------\n",
      "loss: 0.254988  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400235 \n",
      "\n",
      "Epoch 3770\n",
      "-------------------------------\n",
      "loss: 0.218007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400127 \n",
      "\n",
      "Epoch 3771\n",
      "-------------------------------\n",
      "loss: 0.238534  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400347 \n",
      "\n",
      "Epoch 3772\n",
      "-------------------------------\n",
      "loss: 0.236277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399569 \n",
      "\n",
      "Epoch 3773\n",
      "-------------------------------\n",
      "loss: 0.229570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399440 \n",
      "\n",
      "Epoch 3774\n",
      "-------------------------------\n",
      "loss: 0.227292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401219 \n",
      "\n",
      "Epoch 3775\n",
      "-------------------------------\n",
      "loss: 0.231869  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402938 \n",
      "\n",
      "Epoch 3776\n",
      "-------------------------------\n",
      "loss: 0.230354  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402383 \n",
      "\n",
      "Epoch 3777\n",
      "-------------------------------\n",
      "loss: 0.217263  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400701 \n",
      "\n",
      "Epoch 3778\n",
      "-------------------------------\n",
      "loss: 0.217576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398304 \n",
      "\n",
      "Epoch 3779\n",
      "-------------------------------\n",
      "loss: 0.230251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398111 \n",
      "\n",
      "Epoch 3780\n",
      "-------------------------------\n",
      "loss: 0.238570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398438 \n",
      "\n",
      "Epoch 3781\n",
      "-------------------------------\n",
      "loss: 0.225345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398263 \n",
      "\n",
      "Epoch 3782\n",
      "-------------------------------\n",
      "loss: 0.223937  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398053 \n",
      "\n",
      "Epoch 3783\n",
      "-------------------------------\n",
      "loss: 0.218596  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398496 \n",
      "\n",
      "Epoch 3784\n",
      "-------------------------------\n",
      "loss: 0.250867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398264 \n",
      "\n",
      "Epoch 3785\n",
      "-------------------------------\n",
      "loss: 0.221606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398431 \n",
      "\n",
      "Epoch 3786\n",
      "-------------------------------\n",
      "loss: 0.222889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398313 \n",
      "\n",
      "Epoch 3787\n",
      "-------------------------------\n",
      "loss: 0.230503  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398466 \n",
      "\n",
      "Epoch 3788\n",
      "-------------------------------\n",
      "loss: 0.238028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397728 \n",
      "\n",
      "Epoch 3789\n",
      "-------------------------------\n",
      "loss: 0.231574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397425 \n",
      "\n",
      "Epoch 3790\n",
      "-------------------------------\n",
      "loss: 0.232220  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397197 \n",
      "\n",
      "Epoch 3791\n",
      "-------------------------------\n",
      "loss: 0.237856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397945 \n",
      "\n",
      "Epoch 3792\n",
      "-------------------------------\n",
      "loss: 0.227300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399079 \n",
      "\n",
      "Epoch 3793\n",
      "-------------------------------\n",
      "loss: 0.225427  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401201 \n",
      "\n",
      "Epoch 3794\n",
      "-------------------------------\n",
      "loss: 0.228912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403939 \n",
      "\n",
      "Epoch 3795\n",
      "-------------------------------\n",
      "loss: 0.234131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406602 \n",
      "\n",
      "Epoch 3796\n",
      "-------------------------------\n",
      "loss: 0.233776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406669 \n",
      "\n",
      "Epoch 3797\n",
      "-------------------------------\n",
      "loss: 0.227390  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405827 \n",
      "\n",
      "Epoch 3798\n",
      "-------------------------------\n",
      "loss: 0.223312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405133 \n",
      "\n",
      "Epoch 3799\n",
      "-------------------------------\n",
      "loss: 0.213742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404966 \n",
      "\n",
      "Epoch 3800\n",
      "-------------------------------\n",
      "loss: 0.221325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404505 \n",
      "\n",
      "Epoch 3801\n",
      "-------------------------------\n",
      "loss: 0.227156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404365 \n",
      "\n",
      "Epoch 3802\n",
      "-------------------------------\n",
      "loss: 0.234143  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404812 \n",
      "\n",
      "Epoch 3803\n",
      "-------------------------------\n",
      "loss: 0.227864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405543 \n",
      "\n",
      "Epoch 3804\n",
      "-------------------------------\n",
      "loss: 0.239593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407119 \n",
      "\n",
      "Epoch 3805\n",
      "-------------------------------\n",
      "loss: 0.248120  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407108 \n",
      "\n",
      "Epoch 3806\n",
      "-------------------------------\n",
      "loss: 0.239709  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405878 \n",
      "\n",
      "Epoch 3807\n",
      "-------------------------------\n",
      "loss: 0.221556  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404056 \n",
      "\n",
      "Epoch 3808\n",
      "-------------------------------\n",
      "loss: 0.214407  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403146 \n",
      "\n",
      "Epoch 3809\n",
      "-------------------------------\n",
      "loss: 0.225841  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402467 \n",
      "\n",
      "Epoch 3810\n",
      "-------------------------------\n",
      "loss: 0.240787  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401443 \n",
      "\n",
      "Epoch 3811\n",
      "-------------------------------\n",
      "loss: 0.228873  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401373 \n",
      "\n",
      "Epoch 3812\n",
      "-------------------------------\n",
      "loss: 0.225477  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402419 \n",
      "\n",
      "Epoch 3813\n",
      "-------------------------------\n",
      "loss: 0.235385  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403205 \n",
      "\n",
      "Epoch 3814\n",
      "-------------------------------\n",
      "loss: 0.225211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403430 \n",
      "\n",
      "Epoch 3815\n",
      "-------------------------------\n",
      "loss: 0.244060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402667 \n",
      "\n",
      "Epoch 3816\n",
      "-------------------------------\n",
      "loss: 0.243332  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401519 \n",
      "\n",
      "Epoch 3817\n",
      "-------------------------------\n",
      "loss: 0.221770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400929 \n",
      "\n",
      "Epoch 3818\n",
      "-------------------------------\n",
      "loss: 0.234057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400088 \n",
      "\n",
      "Epoch 3819\n",
      "-------------------------------\n",
      "loss: 0.235289  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400438 \n",
      "\n",
      "Epoch 3820\n",
      "-------------------------------\n",
      "loss: 0.221192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402710 \n",
      "\n",
      "Epoch 3821\n",
      "-------------------------------\n",
      "loss: 0.225758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405554 \n",
      "\n",
      "Epoch 3822\n",
      "-------------------------------\n",
      "loss: 0.239430  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406045 \n",
      "\n",
      "Epoch 3823\n",
      "-------------------------------\n",
      "loss: 0.220789  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402721 \n",
      "\n",
      "Epoch 3824\n",
      "-------------------------------\n",
      "loss: 0.238051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399316 \n",
      "\n",
      "Epoch 3825\n",
      "-------------------------------\n",
      "loss: 0.227211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398309 \n",
      "\n",
      "Epoch 3826\n",
      "-------------------------------\n",
      "loss: 0.232755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398419 \n",
      "\n",
      "Epoch 3827\n",
      "-------------------------------\n",
      "loss: 0.227905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398462 \n",
      "\n",
      "Epoch 3828\n",
      "-------------------------------\n",
      "loss: 0.240387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398192 \n",
      "\n",
      "Epoch 3829\n",
      "-------------------------------\n",
      "loss: 0.232543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398617 \n",
      "\n",
      "Epoch 3830\n",
      "-------------------------------\n",
      "loss: 0.215783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399535 \n",
      "\n",
      "Epoch 3831\n",
      "-------------------------------\n",
      "loss: 0.222747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399777 \n",
      "\n",
      "Epoch 3832\n",
      "-------------------------------\n",
      "loss: 0.225747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399822 \n",
      "\n",
      "Epoch 3833\n",
      "-------------------------------\n",
      "loss: 0.212435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399647 \n",
      "\n",
      "Epoch 3834\n",
      "-------------------------------\n",
      "loss: 0.247350  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399540 \n",
      "\n",
      "Epoch 3835\n",
      "-------------------------------\n",
      "loss: 0.221890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398816 \n",
      "\n",
      "Epoch 3836\n",
      "-------------------------------\n",
      "loss: 0.220107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398370 \n",
      "\n",
      "Epoch 3837\n",
      "-------------------------------\n",
      "loss: 0.231020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398226 \n",
      "\n",
      "Epoch 3838\n",
      "-------------------------------\n",
      "loss: 0.240925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398701 \n",
      "\n",
      "Epoch 3839\n",
      "-------------------------------\n",
      "loss: 0.224248  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399452 \n",
      "\n",
      "Epoch 3840\n",
      "-------------------------------\n",
      "loss: 0.219000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400662 \n",
      "\n",
      "Epoch 3841\n",
      "-------------------------------\n",
      "loss: 0.219461  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401501 \n",
      "\n",
      "Epoch 3842\n",
      "-------------------------------\n",
      "loss: 0.223208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401616 \n",
      "\n",
      "Epoch 3843\n",
      "-------------------------------\n",
      "loss: 0.225335  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401417 \n",
      "\n",
      "Epoch 3844\n",
      "-------------------------------\n",
      "loss: 0.226035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401268 \n",
      "\n",
      "Epoch 3845\n",
      "-------------------------------\n",
      "loss: 0.214070  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401406 \n",
      "\n",
      "Epoch 3846\n",
      "-------------------------------\n",
      "loss: 0.226666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401942 \n",
      "\n",
      "Epoch 3847\n",
      "-------------------------------\n",
      "loss: 0.221666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402255 \n",
      "\n",
      "Epoch 3848\n",
      "-------------------------------\n",
      "loss: 0.224039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403269 \n",
      "\n",
      "Epoch 3849\n",
      "-------------------------------\n",
      "loss: 0.221883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403159 \n",
      "\n",
      "Epoch 3850\n",
      "-------------------------------\n",
      "loss: 0.236277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402095 \n",
      "\n",
      "Epoch 3851\n",
      "-------------------------------\n",
      "loss: 0.234941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401688 \n",
      "\n",
      "Epoch 3852\n",
      "-------------------------------\n",
      "loss: 0.219462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401078 \n",
      "\n",
      "Epoch 3853\n",
      "-------------------------------\n",
      "loss: 0.225097  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400617 \n",
      "\n",
      "Epoch 3854\n",
      "-------------------------------\n",
      "loss: 0.230978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401231 \n",
      "\n",
      "Epoch 3855\n",
      "-------------------------------\n",
      "loss: 0.236606  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401874 \n",
      "\n",
      "Epoch 3856\n",
      "-------------------------------\n",
      "loss: 0.221847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401812 \n",
      "\n",
      "Epoch 3857\n",
      "-------------------------------\n",
      "loss: 0.238424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401724 \n",
      "\n",
      "Epoch 3858\n",
      "-------------------------------\n",
      "loss: 0.238827  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401760 \n",
      "\n",
      "Epoch 3859\n",
      "-------------------------------\n",
      "loss: 0.230166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402059 \n",
      "\n",
      "Epoch 3860\n",
      "-------------------------------\n",
      "loss: 0.228009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403067 \n",
      "\n",
      "Epoch 3861\n",
      "-------------------------------\n",
      "loss: 0.226952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404280 \n",
      "\n",
      "Epoch 3862\n",
      "-------------------------------\n",
      "loss: 0.218776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405016 \n",
      "\n",
      "Epoch 3863\n",
      "-------------------------------\n",
      "loss: 0.238924  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405054 \n",
      "\n",
      "Epoch 3864\n",
      "-------------------------------\n",
      "loss: 0.225531  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404905 \n",
      "\n",
      "Epoch 3865\n",
      "-------------------------------\n",
      "loss: 0.227465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404531 \n",
      "\n",
      "Epoch 3866\n",
      "-------------------------------\n",
      "loss: 0.240481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403701 \n",
      "\n",
      "Epoch 3867\n",
      "-------------------------------\n",
      "loss: 0.223429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403068 \n",
      "\n",
      "Epoch 3868\n",
      "-------------------------------\n",
      "loss: 0.228188  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402968 \n",
      "\n",
      "Epoch 3869\n",
      "-------------------------------\n",
      "loss: 0.217259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403533 \n",
      "\n",
      "Epoch 3870\n",
      "-------------------------------\n",
      "loss: 0.226884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404744 \n",
      "\n",
      "Epoch 3871\n",
      "-------------------------------\n",
      "loss: 0.226806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405943 \n",
      "\n",
      "Epoch 3872\n",
      "-------------------------------\n",
      "loss: 0.256673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406627 \n",
      "\n",
      "Epoch 3873\n",
      "-------------------------------\n",
      "loss: 0.226867  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406713 \n",
      "\n",
      "Epoch 3874\n",
      "-------------------------------\n",
      "loss: 0.233191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406023 \n",
      "\n",
      "Epoch 3875\n",
      "-------------------------------\n",
      "loss: 0.228517  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405607 \n",
      "\n",
      "Epoch 3876\n",
      "-------------------------------\n",
      "loss: 0.218279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405127 \n",
      "\n",
      "Epoch 3877\n",
      "-------------------------------\n",
      "loss: 0.232893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404353 \n",
      "\n",
      "Epoch 3878\n",
      "-------------------------------\n",
      "loss: 0.237774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403906 \n",
      "\n",
      "Epoch 3879\n",
      "-------------------------------\n",
      "loss: 0.237999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403334 \n",
      "\n",
      "Epoch 3880\n",
      "-------------------------------\n",
      "loss: 0.223492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402584 \n",
      "\n",
      "Epoch 3881\n",
      "-------------------------------\n",
      "loss: 0.221703  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402682 \n",
      "\n",
      "Epoch 3882\n",
      "-------------------------------\n",
      "loss: 0.223907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404029 \n",
      "\n",
      "Epoch 3883\n",
      "-------------------------------\n",
      "loss: 0.210053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407492 \n",
      "\n",
      "Epoch 3884\n",
      "-------------------------------\n",
      "loss: 0.224603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409885 \n",
      "\n",
      "Epoch 3885\n",
      "-------------------------------\n",
      "loss: 0.222027  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410547 \n",
      "\n",
      "Epoch 3886\n",
      "-------------------------------\n",
      "loss: 0.219864  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409138 \n",
      "\n",
      "Epoch 3887\n",
      "-------------------------------\n",
      "loss: 0.232628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405787 \n",
      "\n",
      "Epoch 3888\n",
      "-------------------------------\n",
      "loss: 0.234115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403314 \n",
      "\n",
      "Epoch 3889\n",
      "-------------------------------\n",
      "loss: 0.227907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401461 \n",
      "\n",
      "Epoch 3890\n",
      "-------------------------------\n",
      "loss: 0.225507  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401203 \n",
      "\n",
      "Epoch 3891\n",
      "-------------------------------\n",
      "loss: 0.224510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402277 \n",
      "\n",
      "Epoch 3892\n",
      "-------------------------------\n",
      "loss: 0.222742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403345 \n",
      "\n",
      "Epoch 3893\n",
      "-------------------------------\n",
      "loss: 0.241773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403517 \n",
      "\n",
      "Epoch 3894\n",
      "-------------------------------\n",
      "loss: 0.237019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404241 \n",
      "\n",
      "Epoch 3895\n",
      "-------------------------------\n",
      "loss: 0.244333  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403378 \n",
      "\n",
      "Epoch 3896\n",
      "-------------------------------\n",
      "loss: 0.222586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402533 \n",
      "\n",
      "Epoch 3897\n",
      "-------------------------------\n",
      "loss: 0.223754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403038 \n",
      "\n",
      "Epoch 3898\n",
      "-------------------------------\n",
      "loss: 0.211828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403398 \n",
      "\n",
      "Epoch 3899\n",
      "-------------------------------\n",
      "loss: 0.237968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403759 \n",
      "\n",
      "Epoch 3900\n",
      "-------------------------------\n",
      "loss: 0.221878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403609 \n",
      "\n",
      "Epoch 3901\n",
      "-------------------------------\n",
      "loss: 0.242589  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403014 \n",
      "\n",
      "Epoch 3902\n",
      "-------------------------------\n",
      "loss: 0.239237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402302 \n",
      "\n",
      "Epoch 3903\n",
      "-------------------------------\n",
      "loss: 0.231939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402412 \n",
      "\n",
      "Epoch 3904\n",
      "-------------------------------\n",
      "loss: 0.231730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403735 \n",
      "\n",
      "Epoch 3905\n",
      "-------------------------------\n",
      "loss: 0.240563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404034 \n",
      "\n",
      "Epoch 3906\n",
      "-------------------------------\n",
      "loss: 0.225197  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404585 \n",
      "\n",
      "Epoch 3907\n",
      "-------------------------------\n",
      "loss: 0.234321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404607 \n",
      "\n",
      "Epoch 3908\n",
      "-------------------------------\n",
      "loss: 0.228614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404153 \n",
      "\n",
      "Epoch 3909\n",
      "-------------------------------\n",
      "loss: 0.227871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402626 \n",
      "\n",
      "Epoch 3910\n",
      "-------------------------------\n",
      "loss: 0.220757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401848 \n",
      "\n",
      "Epoch 3911\n",
      "-------------------------------\n",
      "loss: 0.228459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401470 \n",
      "\n",
      "Epoch 3912\n",
      "-------------------------------\n",
      "loss: 0.237437  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401027 \n",
      "\n",
      "Epoch 3913\n",
      "-------------------------------\n",
      "loss: 0.229253  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401035 \n",
      "\n",
      "Epoch 3914\n",
      "-------------------------------\n",
      "loss: 0.236529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401341 \n",
      "\n",
      "Epoch 3915\n",
      "-------------------------------\n",
      "loss: 0.215022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403073 \n",
      "\n",
      "Epoch 3916\n",
      "-------------------------------\n",
      "loss: 0.226833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405847 \n",
      "\n",
      "Epoch 3917\n",
      "-------------------------------\n",
      "loss: 0.215235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408794 \n",
      "\n",
      "Epoch 3918\n",
      "-------------------------------\n",
      "loss: 0.242063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408583 \n",
      "\n",
      "Epoch 3919\n",
      "-------------------------------\n",
      "loss: 0.221889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407402 \n",
      "\n",
      "Epoch 3920\n",
      "-------------------------------\n",
      "loss: 0.240067  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403545 \n",
      "\n",
      "Epoch 3921\n",
      "-------------------------------\n",
      "loss: 0.224055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400077 \n",
      "\n",
      "Epoch 3922\n",
      "-------------------------------\n",
      "loss: 0.235773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399156 \n",
      "\n",
      "Epoch 3923\n",
      "-------------------------------\n",
      "loss: 0.243018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399300 \n",
      "\n",
      "Epoch 3924\n",
      "-------------------------------\n",
      "loss: 0.223772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399290 \n",
      "\n",
      "Epoch 3925\n",
      "-------------------------------\n",
      "loss: 0.234365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398996 \n",
      "\n",
      "Epoch 3926\n",
      "-------------------------------\n",
      "loss: 0.225914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401318 \n",
      "\n",
      "Epoch 3927\n",
      "-------------------------------\n",
      "loss: 0.232113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404487 \n",
      "\n",
      "Epoch 3928\n",
      "-------------------------------\n",
      "loss: 0.229492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404838 \n",
      "\n",
      "Epoch 3929\n",
      "-------------------------------\n",
      "loss: 0.232547  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.402698 \n",
      "\n",
      "Epoch 3930\n",
      "-------------------------------\n",
      "loss: 0.240002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398809 \n",
      "\n",
      "Epoch 3931\n",
      "-------------------------------\n",
      "loss: 0.225731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396503 \n",
      "\n",
      "Epoch 3932\n",
      "-------------------------------\n",
      "loss: 0.235840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396766 \n",
      "\n",
      "Epoch 3933\n",
      "-------------------------------\n",
      "loss: 0.233688  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396961 \n",
      "\n",
      "Epoch 3934\n",
      "-------------------------------\n",
      "loss: 0.264883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396661 \n",
      "\n",
      "Epoch 3935\n",
      "-------------------------------\n",
      "loss: 0.224021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398341 \n",
      "\n",
      "Epoch 3936\n",
      "-------------------------------\n",
      "loss: 0.235772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403183 \n",
      "\n",
      "Epoch 3937\n",
      "-------------------------------\n",
      "loss: 0.253042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406865 \n",
      "\n",
      "Epoch 3938\n",
      "-------------------------------\n",
      "loss: 0.225903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405927 \n",
      "\n",
      "Epoch 3939\n",
      "-------------------------------\n",
      "loss: 0.260476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401318 \n",
      "\n",
      "Epoch 3940\n",
      "-------------------------------\n",
      "loss: 0.232217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397136 \n",
      "\n",
      "Epoch 3941\n",
      "-------------------------------\n",
      "loss: 0.216411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395661 \n",
      "\n",
      "Epoch 3942\n",
      "-------------------------------\n",
      "loss: 0.223992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395286 \n",
      "\n",
      "Epoch 3943\n",
      "-------------------------------\n",
      "loss: 0.221092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395689 \n",
      "\n",
      "Epoch 3944\n",
      "-------------------------------\n",
      "loss: 0.241794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396566 \n",
      "\n",
      "Epoch 3945\n",
      "-------------------------------\n",
      "loss: 0.217459  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397768 \n",
      "\n",
      "Epoch 3946\n",
      "-------------------------------\n",
      "loss: 0.218096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400222 \n",
      "\n",
      "Epoch 3947\n",
      "-------------------------------\n",
      "loss: 0.236584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400623 \n",
      "\n",
      "Epoch 3948\n",
      "-------------------------------\n",
      "loss: 0.222421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399035 \n",
      "\n",
      "Epoch 3949\n",
      "-------------------------------\n",
      "loss: 0.222733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396697 \n",
      "\n",
      "Epoch 3950\n",
      "-------------------------------\n",
      "loss: 0.213262  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395202 \n",
      "\n",
      "Epoch 3951\n",
      "-------------------------------\n",
      "loss: 0.219570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394496 \n",
      "\n",
      "Epoch 3952\n",
      "-------------------------------\n",
      "loss: 0.225824  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394502 \n",
      "\n",
      "Epoch 3953\n",
      "-------------------------------\n",
      "loss: 0.222676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395164 \n",
      "\n",
      "Epoch 3954\n",
      "-------------------------------\n",
      "loss: 0.242970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397439 \n",
      "\n",
      "Epoch 3955\n",
      "-------------------------------\n",
      "loss: 0.227883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398658 \n",
      "\n",
      "Epoch 3956\n",
      "-------------------------------\n",
      "loss: 0.230817  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399248 \n",
      "\n",
      "Epoch 3957\n",
      "-------------------------------\n",
      "loss: 0.225226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399234 \n",
      "\n",
      "Epoch 3958\n",
      "-------------------------------\n",
      "loss: 0.218109  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399785 \n",
      "\n",
      "Epoch 3959\n",
      "-------------------------------\n",
      "loss: 0.229193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399530 \n",
      "\n",
      "Epoch 3960\n",
      "-------------------------------\n",
      "loss: 0.226652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399128 \n",
      "\n",
      "Epoch 3961\n",
      "-------------------------------\n",
      "loss: 0.242757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398684 \n",
      "\n",
      "Epoch 3962\n",
      "-------------------------------\n",
      "loss: 0.230470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399118 \n",
      "\n",
      "Epoch 3963\n",
      "-------------------------------\n",
      "loss: 0.220616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399547 \n",
      "\n",
      "Epoch 3964\n",
      "-------------------------------\n",
      "loss: 0.224685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400245 \n",
      "\n",
      "Epoch 3965\n",
      "-------------------------------\n",
      "loss: 0.224280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401082 \n",
      "\n",
      "Epoch 3966\n",
      "-------------------------------\n",
      "loss: 0.245388  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399569 \n",
      "\n",
      "Epoch 3967\n",
      "-------------------------------\n",
      "loss: 0.211470  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397288 \n",
      "\n",
      "Epoch 3968\n",
      "-------------------------------\n",
      "loss: 0.223403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397180 \n",
      "\n",
      "Epoch 3969\n",
      "-------------------------------\n",
      "loss: 0.230426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396800 \n",
      "\n",
      "Epoch 3970\n",
      "-------------------------------\n",
      "loss: 0.233636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396103 \n",
      "\n",
      "Epoch 3971\n",
      "-------------------------------\n",
      "loss: 0.235321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396792 \n",
      "\n",
      "Epoch 3972\n",
      "-------------------------------\n",
      "loss: 0.228449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398331 \n",
      "\n",
      "Epoch 3973\n",
      "-------------------------------\n",
      "loss: 0.215496  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400516 \n",
      "\n",
      "Epoch 3974\n",
      "-------------------------------\n",
      "loss: 0.234236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401803 \n",
      "\n",
      "Epoch 3975\n",
      "-------------------------------\n",
      "loss: 0.225057  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401762 \n",
      "\n",
      "Epoch 3976\n",
      "-------------------------------\n",
      "loss: 0.231152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400402 \n",
      "\n",
      "Epoch 3977\n",
      "-------------------------------\n",
      "loss: 0.228960  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398465 \n",
      "\n",
      "Epoch 3978\n",
      "-------------------------------\n",
      "loss: 0.217489  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398416 \n",
      "\n",
      "Epoch 3979\n",
      "-------------------------------\n",
      "loss: 0.222626  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399640 \n",
      "\n",
      "Epoch 3980\n",
      "-------------------------------\n",
      "loss: 0.228576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400170 \n",
      "\n",
      "Epoch 3981\n",
      "-------------------------------\n",
      "loss: 0.226359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399822 \n",
      "\n",
      "Epoch 3982\n",
      "-------------------------------\n",
      "loss: 0.226731  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400827 \n",
      "\n",
      "Epoch 3983\n",
      "-------------------------------\n",
      "loss: 0.217670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402625 \n",
      "\n",
      "Epoch 3984\n",
      "-------------------------------\n",
      "loss: 0.217940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404354 \n",
      "\n",
      "Epoch 3985\n",
      "-------------------------------\n",
      "loss: 0.222945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406895 \n",
      "\n",
      "Epoch 3986\n",
      "-------------------------------\n",
      "loss: 0.207639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408638 \n",
      "\n",
      "Epoch 3987\n",
      "-------------------------------\n",
      "loss: 0.240519  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408889 \n",
      "\n",
      "Epoch 3988\n",
      "-------------------------------\n",
      "loss: 0.236201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408898 \n",
      "\n",
      "Epoch 3989\n",
      "-------------------------------\n",
      "loss: 0.230854  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407071 \n",
      "\n",
      "Epoch 3990\n",
      "-------------------------------\n",
      "loss: 0.225293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404884 \n",
      "\n",
      "Epoch 3991\n",
      "-------------------------------\n",
      "loss: 0.226166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403994 \n",
      "\n",
      "Epoch 3992\n",
      "-------------------------------\n",
      "loss: 0.238796  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403986 \n",
      "\n",
      "Epoch 3993\n",
      "-------------------------------\n",
      "loss: 0.234389  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404255 \n",
      "\n",
      "Epoch 3994\n",
      "-------------------------------\n",
      "loss: 0.219913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404174 \n",
      "\n",
      "Epoch 3995\n",
      "-------------------------------\n",
      "loss: 0.224553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404535 \n",
      "\n",
      "Epoch 3996\n",
      "-------------------------------\n",
      "loss: 0.232909  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405122 \n",
      "\n",
      "Epoch 3997\n",
      "-------------------------------\n",
      "loss: 0.228743  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404788 \n",
      "\n",
      "Epoch 3998\n",
      "-------------------------------\n",
      "loss: 0.227331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403683 \n",
      "\n",
      "Epoch 3999\n",
      "-------------------------------\n",
      "loss: 0.242980  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402290 \n",
      "\n",
      "Epoch 4000\n",
      "-------------------------------\n",
      "loss: 0.212162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401512 \n",
      "\n",
      "Epoch 4001\n",
      "-------------------------------\n",
      "loss: 0.221230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400863 \n",
      "\n",
      "Epoch 4002\n",
      "-------------------------------\n",
      "loss: 0.224781  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400183 \n",
      "\n",
      "Epoch 4003\n",
      "-------------------------------\n",
      "loss: 0.223199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400100 \n",
      "\n",
      "Epoch 4004\n",
      "-------------------------------\n",
      "loss: 0.233259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400098 \n",
      "\n",
      "Epoch 4005\n",
      "-------------------------------\n",
      "loss: 0.229386  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400067 \n",
      "\n",
      "Epoch 4006\n",
      "-------------------------------\n",
      "loss: 0.209786  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400689 \n",
      "\n",
      "Epoch 4007\n",
      "-------------------------------\n",
      "loss: 0.225446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401352 \n",
      "\n",
      "Epoch 4008\n",
      "-------------------------------\n",
      "loss: 0.231983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401521 \n",
      "\n",
      "Epoch 4009\n",
      "-------------------------------\n",
      "loss: 0.227772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402101 \n",
      "\n",
      "Epoch 4010\n",
      "-------------------------------\n",
      "loss: 0.202247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402458 \n",
      "\n",
      "Epoch 4011\n",
      "-------------------------------\n",
      "loss: 0.213060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403058 \n",
      "\n",
      "Epoch 4012\n",
      "-------------------------------\n",
      "loss: 0.225112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403438 \n",
      "\n",
      "Epoch 4013\n",
      "-------------------------------\n",
      "loss: 0.238760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403009 \n",
      "\n",
      "Epoch 4014\n",
      "-------------------------------\n",
      "loss: 0.225952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402162 \n",
      "\n",
      "Epoch 4015\n",
      "-------------------------------\n",
      "loss: 0.226983  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401878 \n",
      "\n",
      "Epoch 4016\n",
      "-------------------------------\n",
      "loss: 0.225471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401676 \n",
      "\n",
      "Epoch 4017\n",
      "-------------------------------\n",
      "loss: 0.224750  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402358 \n",
      "\n",
      "Epoch 4018\n",
      "-------------------------------\n",
      "loss: 0.233952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402441 \n",
      "\n",
      "Epoch 4019\n",
      "-------------------------------\n",
      "loss: 0.232168  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402309 \n",
      "\n",
      "Epoch 4020\n",
      "-------------------------------\n",
      "loss: 0.212631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403175 \n",
      "\n",
      "Epoch 4021\n",
      "-------------------------------\n",
      "loss: 0.221499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404679 \n",
      "\n",
      "Epoch 4022\n",
      "-------------------------------\n",
      "loss: 0.235579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404459 \n",
      "\n",
      "Epoch 4023\n",
      "-------------------------------\n",
      "loss: 0.214541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402991 \n",
      "\n",
      "Epoch 4024\n",
      "-------------------------------\n",
      "loss: 0.230073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399737 \n",
      "\n",
      "Epoch 4025\n",
      "-------------------------------\n",
      "loss: 0.242367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398283 \n",
      "\n",
      "Epoch 4026\n",
      "-------------------------------\n",
      "loss: 0.216749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397627 \n",
      "\n",
      "Epoch 4027\n",
      "-------------------------------\n",
      "loss: 0.222949  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397666 \n",
      "\n",
      "Epoch 4028\n",
      "-------------------------------\n",
      "loss: 0.228761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397992 \n",
      "\n",
      "Epoch 4029\n",
      "-------------------------------\n",
      "loss: 0.218331  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398567 \n",
      "\n",
      "Epoch 4030\n",
      "-------------------------------\n",
      "loss: 0.214527  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398553 \n",
      "\n",
      "Epoch 4031\n",
      "-------------------------------\n",
      "loss: 0.228043  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398470 \n",
      "\n",
      "Epoch 4032\n",
      "-------------------------------\n",
      "loss: 0.214997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397518 \n",
      "\n",
      "Epoch 4033\n",
      "-------------------------------\n",
      "loss: 0.219535  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397316 \n",
      "\n",
      "Epoch 4034\n",
      "-------------------------------\n",
      "loss: 0.220814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397636 \n",
      "\n",
      "Epoch 4035\n",
      "-------------------------------\n",
      "loss: 0.225276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397653 \n",
      "\n",
      "Epoch 4036\n",
      "-------------------------------\n",
      "loss: 0.236915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397793 \n",
      "\n",
      "Epoch 4037\n",
      "-------------------------------\n",
      "loss: 0.222402  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398454 \n",
      "\n",
      "Epoch 4038\n",
      "-------------------------------\n",
      "loss: 0.232740  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399779 \n",
      "\n",
      "Epoch 4039\n",
      "-------------------------------\n",
      "loss: 0.228544  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402054 \n",
      "\n",
      "Epoch 4040\n",
      "-------------------------------\n",
      "loss: 0.218959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404024 \n",
      "\n",
      "Epoch 4041\n",
      "-------------------------------\n",
      "loss: 0.255957  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402607 \n",
      "\n",
      "Epoch 4042\n",
      "-------------------------------\n",
      "loss: 0.204269  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401093 \n",
      "\n",
      "Epoch 4043\n",
      "-------------------------------\n",
      "loss: 0.218219  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400685 \n",
      "\n",
      "Epoch 4044\n",
      "-------------------------------\n",
      "loss: 0.226375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401155 \n",
      "\n",
      "Epoch 4045\n",
      "-------------------------------\n",
      "loss: 0.238225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401004 \n",
      "\n",
      "Epoch 4046\n",
      "-------------------------------\n",
      "loss: 0.241108  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403067 \n",
      "\n",
      "Epoch 4047\n",
      "-------------------------------\n",
      "loss: 0.228191  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407309 \n",
      "\n",
      "Epoch 4048\n",
      "-------------------------------\n",
      "loss: 0.231681  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409830 \n",
      "\n",
      "Epoch 4049\n",
      "-------------------------------\n",
      "loss: 0.218805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410172 \n",
      "\n",
      "Epoch 4050\n",
      "-------------------------------\n",
      "loss: 0.227615  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406665 \n",
      "\n",
      "Epoch 4051\n",
      "-------------------------------\n",
      "loss: 0.228753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402443 \n",
      "\n",
      "Epoch 4052\n",
      "-------------------------------\n",
      "loss: 0.223031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399555 \n",
      "\n",
      "Epoch 4053\n",
      "-------------------------------\n",
      "loss: 0.229447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398530 \n",
      "\n",
      "Epoch 4054\n",
      "-------------------------------\n",
      "loss: 0.213728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398547 \n",
      "\n",
      "Epoch 4055\n",
      "-------------------------------\n",
      "loss: 0.224746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399067 \n",
      "\n",
      "Epoch 4056\n",
      "-------------------------------\n",
      "loss: 0.220976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400368 \n",
      "\n",
      "Epoch 4057\n",
      "-------------------------------\n",
      "loss: 0.215199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402688 \n",
      "\n",
      "Epoch 4058\n",
      "-------------------------------\n",
      "loss: 0.225135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405295 \n",
      "\n",
      "Epoch 4059\n",
      "-------------------------------\n",
      "loss: 0.239801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403026 \n",
      "\n",
      "Epoch 4060\n",
      "-------------------------------\n",
      "loss: 0.233374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399254 \n",
      "\n",
      "Epoch 4061\n",
      "-------------------------------\n",
      "loss: 0.217933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397521 \n",
      "\n",
      "Epoch 4062\n",
      "-------------------------------\n",
      "loss: 0.222524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397680 \n",
      "\n",
      "Epoch 4063\n",
      "-------------------------------\n",
      "loss: 0.220227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398057 \n",
      "\n",
      "Epoch 4064\n",
      "-------------------------------\n",
      "loss: 0.225751  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397648 \n",
      "\n",
      "Epoch 4065\n",
      "-------------------------------\n",
      "loss: 0.218294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397607 \n",
      "\n",
      "Epoch 4066\n",
      "-------------------------------\n",
      "loss: 0.235245  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398785 \n",
      "\n",
      "Epoch 4067\n",
      "-------------------------------\n",
      "loss: 0.236901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399762 \n",
      "\n",
      "Epoch 4068\n",
      "-------------------------------\n",
      "loss: 0.222233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400436 \n",
      "\n",
      "Epoch 4069\n",
      "-------------------------------\n",
      "loss: 0.229677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399323 \n",
      "\n",
      "Epoch 4070\n",
      "-------------------------------\n",
      "loss: 0.236418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397962 \n",
      "\n",
      "Epoch 4071\n",
      "-------------------------------\n",
      "loss: 0.202532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398668 \n",
      "\n",
      "Epoch 4072\n",
      "-------------------------------\n",
      "loss: 0.238474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399735 \n",
      "\n",
      "Epoch 4073\n",
      "-------------------------------\n",
      "loss: 0.215803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399742 \n",
      "\n",
      "Epoch 4074\n",
      "-------------------------------\n",
      "loss: 0.233275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399427 \n",
      "\n",
      "Epoch 4075\n",
      "-------------------------------\n",
      "loss: 0.225559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402711 \n",
      "\n",
      "Epoch 4076\n",
      "-------------------------------\n",
      "loss: 0.227933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408670 \n",
      "\n",
      "Epoch 4077\n",
      "-------------------------------\n",
      "loss: 0.244772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409457 \n",
      "\n",
      "Epoch 4078\n",
      "-------------------------------\n",
      "loss: 0.231785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405833 \n",
      "\n",
      "Epoch 4079\n",
      "-------------------------------\n",
      "loss: 0.213393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402915 \n",
      "\n",
      "Epoch 4080\n",
      "-------------------------------\n",
      "loss: 0.237411  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401051 \n",
      "\n",
      "Epoch 4081\n",
      "-------------------------------\n",
      "loss: 0.235381  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.401192 \n",
      "\n",
      "Epoch 4082\n",
      "-------------------------------\n",
      "loss: 0.224538  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401310 \n",
      "\n",
      "Epoch 4083\n",
      "-------------------------------\n",
      "loss: 0.226847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401321 \n",
      "\n",
      "Epoch 4084\n",
      "-------------------------------\n",
      "loss: 0.221783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401930 \n",
      "\n",
      "Epoch 4085\n",
      "-------------------------------\n",
      "loss: 0.221920  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403511 \n",
      "\n",
      "Epoch 4086\n",
      "-------------------------------\n",
      "loss: 0.207571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407570 \n",
      "\n",
      "Epoch 4087\n",
      "-------------------------------\n",
      "loss: 0.226260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410212 \n",
      "\n",
      "Epoch 4088\n",
      "-------------------------------\n",
      "loss: 0.214628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410357 \n",
      "\n",
      "Epoch 4089\n",
      "-------------------------------\n",
      "loss: 0.239991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407212 \n",
      "\n",
      "Epoch 4090\n",
      "-------------------------------\n",
      "loss: 0.237249  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403698 \n",
      "\n",
      "Epoch 4091\n",
      "-------------------------------\n",
      "loss: 0.219754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403713 \n",
      "\n",
      "Epoch 4092\n",
      "-------------------------------\n",
      "loss: 0.228530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403553 \n",
      "\n",
      "Epoch 4093\n",
      "-------------------------------\n",
      "loss: 0.240797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402766 \n",
      "\n",
      "Epoch 4094\n",
      "-------------------------------\n",
      "loss: 0.227283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401713 \n",
      "\n",
      "Epoch 4095\n",
      "-------------------------------\n",
      "loss: 0.223117  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402225 \n",
      "\n",
      "Epoch 4096\n",
      "-------------------------------\n",
      "loss: 0.223038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403714 \n",
      "\n",
      "Epoch 4097\n",
      "-------------------------------\n",
      "loss: 0.220019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404241 \n",
      "\n",
      "Epoch 4098\n",
      "-------------------------------\n",
      "loss: 0.236773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402802 \n",
      "\n",
      "Epoch 4099\n",
      "-------------------------------\n",
      "loss: 0.230976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400508 \n",
      "\n",
      "Epoch 4100\n",
      "-------------------------------\n",
      "loss: 0.231405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399604 \n",
      "\n",
      "Epoch 4101\n",
      "-------------------------------\n",
      "loss: 0.231861  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398935 \n",
      "\n",
      "Epoch 4102\n",
      "-------------------------------\n",
      "loss: 0.219058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399556 \n",
      "\n",
      "Epoch 4103\n",
      "-------------------------------\n",
      "loss: 0.232473  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400652 \n",
      "\n",
      "Epoch 4104\n",
      "-------------------------------\n",
      "loss: 0.230800  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401749 \n",
      "\n",
      "Epoch 4105\n",
      "-------------------------------\n",
      "loss: 0.221096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401967 \n",
      "\n",
      "Epoch 4106\n",
      "-------------------------------\n",
      "loss: 0.244425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401223 \n",
      "\n",
      "Epoch 4107\n",
      "-------------------------------\n",
      "loss: 0.203674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400905 \n",
      "\n",
      "Epoch 4108\n",
      "-------------------------------\n",
      "loss: 0.222797  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400532 \n",
      "\n",
      "Epoch 4109\n",
      "-------------------------------\n",
      "loss: 0.221638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399871 \n",
      "\n",
      "Epoch 4110\n",
      "-------------------------------\n",
      "loss: 0.217818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400081 \n",
      "\n",
      "Epoch 4111\n",
      "-------------------------------\n",
      "loss: 0.238726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399578 \n",
      "\n",
      "Epoch 4112\n",
      "-------------------------------\n",
      "loss: 0.225308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399596 \n",
      "\n",
      "Epoch 4113\n",
      "-------------------------------\n",
      "loss: 0.227718  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400127 \n",
      "\n",
      "Epoch 4114\n",
      "-------------------------------\n",
      "loss: 0.229685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400885 \n",
      "\n",
      "Epoch 4115\n",
      "-------------------------------\n",
      "loss: 0.218570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402038 \n",
      "\n",
      "Epoch 4116\n",
      "-------------------------------\n",
      "loss: 0.208628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403406 \n",
      "\n",
      "Epoch 4117\n",
      "-------------------------------\n",
      "loss: 0.235635  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403769 \n",
      "\n",
      "Epoch 4118\n",
      "-------------------------------\n",
      "loss: 0.210593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403646 \n",
      "\n",
      "Epoch 4119\n",
      "-------------------------------\n",
      "loss: 0.224632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402748 \n",
      "\n",
      "Epoch 4120\n",
      "-------------------------------\n",
      "loss: 0.224469  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401505 \n",
      "\n",
      "Epoch 4121\n",
      "-------------------------------\n",
      "loss: 0.228082  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400617 \n",
      "\n",
      "Epoch 4122\n",
      "-------------------------------\n",
      "loss: 0.219173  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400626 \n",
      "\n",
      "Epoch 4123\n",
      "-------------------------------\n",
      "loss: 0.229360  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400227 \n",
      "\n",
      "Epoch 4124\n",
      "-------------------------------\n",
      "loss: 0.235099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401227 \n",
      "\n",
      "Epoch 4125\n",
      "-------------------------------\n",
      "loss: 0.222619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402413 \n",
      "\n",
      "Epoch 4126\n",
      "-------------------------------\n",
      "loss: 0.213348  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404738 \n",
      "\n",
      "Epoch 4127\n",
      "-------------------------------\n",
      "loss: 0.230199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405169 \n",
      "\n",
      "Epoch 4128\n",
      "-------------------------------\n",
      "loss: 0.222176  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404387 \n",
      "\n",
      "Epoch 4129\n",
      "-------------------------------\n",
      "loss: 0.226973  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403300 \n",
      "\n",
      "Epoch 4130\n",
      "-------------------------------\n",
      "loss: 0.231785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402892 \n",
      "\n",
      "Epoch 4131\n",
      "-------------------------------\n",
      "loss: 0.243344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402860 \n",
      "\n",
      "Epoch 4132\n",
      "-------------------------------\n",
      "loss: 0.212991  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402966 \n",
      "\n",
      "Epoch 4133\n",
      "-------------------------------\n",
      "loss: 0.240099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403189 \n",
      "\n",
      "Epoch 4134\n",
      "-------------------------------\n",
      "loss: 0.229033  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404469 \n",
      "\n",
      "Epoch 4135\n",
      "-------------------------------\n",
      "loss: 0.229387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405223 \n",
      "\n",
      "Epoch 4136\n",
      "-------------------------------\n",
      "loss: 0.228567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404698 \n",
      "\n",
      "Epoch 4137\n",
      "-------------------------------\n",
      "loss: 0.238971  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402964 \n",
      "\n",
      "Epoch 4138\n",
      "-------------------------------\n",
      "loss: 0.213216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401841 \n",
      "\n",
      "Epoch 4139\n",
      "-------------------------------\n",
      "loss: 0.219923  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400109 \n",
      "\n",
      "Epoch 4140\n",
      "-------------------------------\n",
      "loss: 0.244848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398465 \n",
      "\n",
      "Epoch 4141\n",
      "-------------------------------\n",
      "loss: 0.220619  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398381 \n",
      "\n",
      "Epoch 4142\n",
      "-------------------------------\n",
      "loss: 0.229111  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399321 \n",
      "\n",
      "Epoch 4143\n",
      "-------------------------------\n",
      "loss: 0.215808  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404394 \n",
      "\n",
      "Epoch 4144\n",
      "-------------------------------\n",
      "loss: 0.223208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409018 \n",
      "\n",
      "Epoch 4145\n",
      "-------------------------------\n",
      "loss: 0.226581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408817 \n",
      "\n",
      "Epoch 4146\n",
      "-------------------------------\n",
      "loss: 0.245608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402878 \n",
      "\n",
      "Epoch 4147\n",
      "-------------------------------\n",
      "loss: 0.214018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398430 \n",
      "\n",
      "Epoch 4148\n",
      "-------------------------------\n",
      "loss: 0.228992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397684 \n",
      "\n",
      "Epoch 4149\n",
      "-------------------------------\n",
      "loss: 0.219833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398273 \n",
      "\n",
      "Epoch 4150\n",
      "-------------------------------\n",
      "loss: 0.246724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398666 \n",
      "\n",
      "Epoch 4151\n",
      "-------------------------------\n",
      "loss: 0.219395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398898 \n",
      "\n",
      "Epoch 4152\n",
      "-------------------------------\n",
      "loss: 0.227853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399120 \n",
      "\n",
      "Epoch 4153\n",
      "-------------------------------\n",
      "loss: 0.214822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399914 \n",
      "\n",
      "Epoch 4154\n",
      "-------------------------------\n",
      "loss: 0.224291  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401163 \n",
      "\n",
      "Epoch 4155\n",
      "-------------------------------\n",
      "loss: 0.219602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401273 \n",
      "\n",
      "Epoch 4156\n",
      "-------------------------------\n",
      "loss: 0.229972  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400378 \n",
      "\n",
      "Epoch 4157\n",
      "-------------------------------\n",
      "loss: 0.220197  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399164 \n",
      "\n",
      "Epoch 4158\n",
      "-------------------------------\n",
      "loss: 0.228984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398289 \n",
      "\n",
      "Epoch 4159\n",
      "-------------------------------\n",
      "loss: 0.239593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397903 \n",
      "\n",
      "Epoch 4160\n",
      "-------------------------------\n",
      "loss: 0.230661  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397234 \n",
      "\n",
      "Epoch 4161\n",
      "-------------------------------\n",
      "loss: 0.240866  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396673 \n",
      "\n",
      "Epoch 4162\n",
      "-------------------------------\n",
      "loss: 0.214130  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396507 \n",
      "\n",
      "Epoch 4163\n",
      "-------------------------------\n",
      "loss: 0.238815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395961 \n",
      "\n",
      "Epoch 4164\n",
      "-------------------------------\n",
      "loss: 0.228522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395593 \n",
      "\n",
      "Epoch 4165\n",
      "-------------------------------\n",
      "loss: 0.219299  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395609 \n",
      "\n",
      "Epoch 4166\n",
      "-------------------------------\n",
      "loss: 0.236856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395566 \n",
      "\n",
      "Epoch 4167\n",
      "-------------------------------\n",
      "loss: 0.230090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396450 \n",
      "\n",
      "Epoch 4168\n",
      "-------------------------------\n",
      "loss: 0.218344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398347 \n",
      "\n",
      "Epoch 4169\n",
      "-------------------------------\n",
      "loss: 0.216640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400933 \n",
      "\n",
      "Epoch 4170\n",
      "-------------------------------\n",
      "loss: 0.213019  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402453 \n",
      "\n",
      "Epoch 4171\n",
      "-------------------------------\n",
      "loss: 0.233883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401003 \n",
      "\n",
      "Epoch 4172\n",
      "-------------------------------\n",
      "loss: 0.211890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400726 \n",
      "\n",
      "Epoch 4173\n",
      "-------------------------------\n",
      "loss: 0.218584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399691 \n",
      "\n",
      "Epoch 4174\n",
      "-------------------------------\n",
      "loss: 0.224784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399101 \n",
      "\n",
      "Epoch 4175\n",
      "-------------------------------\n",
      "loss: 0.231474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399696 \n",
      "\n",
      "Epoch 4176\n",
      "-------------------------------\n",
      "loss: 0.225127  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399809 \n",
      "\n",
      "Epoch 4177\n",
      "-------------------------------\n",
      "loss: 0.229164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400068 \n",
      "\n",
      "Epoch 4178\n",
      "-------------------------------\n",
      "loss: 0.221829  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401267 \n",
      "\n",
      "Epoch 4179\n",
      "-------------------------------\n",
      "loss: 0.217228  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401955 \n",
      "\n",
      "Epoch 4180\n",
      "-------------------------------\n",
      "loss: 0.222161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401810 \n",
      "\n",
      "Epoch 4181\n",
      "-------------------------------\n",
      "loss: 0.230884  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400890 \n",
      "\n",
      "Epoch 4182\n",
      "-------------------------------\n",
      "loss: 0.217106  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399324 \n",
      "\n",
      "Epoch 4183\n",
      "-------------------------------\n",
      "loss: 0.226085  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399434 \n",
      "\n",
      "Epoch 4184\n",
      "-------------------------------\n",
      "loss: 0.218302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400781 \n",
      "\n",
      "Epoch 4185\n",
      "-------------------------------\n",
      "loss: 0.219952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402511 \n",
      "\n",
      "Epoch 4186\n",
      "-------------------------------\n",
      "loss: 0.240551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401039 \n",
      "\n",
      "Epoch 4187\n",
      "-------------------------------\n",
      "loss: 0.241104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397458 \n",
      "\n",
      "Epoch 4188\n",
      "-------------------------------\n",
      "loss: 0.226160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394954 \n",
      "\n",
      "Epoch 4189\n",
      "-------------------------------\n",
      "loss: 0.216155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393615 \n",
      "\n",
      "Epoch 4190\n",
      "-------------------------------\n",
      "loss: 0.217104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394009 \n",
      "\n",
      "Epoch 4191\n",
      "-------------------------------\n",
      "loss: 0.221495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394949 \n",
      "\n",
      "Epoch 4192\n",
      "-------------------------------\n",
      "loss: 0.229446  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396720 \n",
      "\n",
      "Epoch 4193\n",
      "-------------------------------\n",
      "loss: 0.225267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398498 \n",
      "\n",
      "Epoch 4194\n",
      "-------------------------------\n",
      "loss: 0.221734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399812 \n",
      "\n",
      "Epoch 4195\n",
      "-------------------------------\n",
      "loss: 0.241452  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398729 \n",
      "\n",
      "Epoch 4196\n",
      "-------------------------------\n",
      "loss: 0.222319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398080 \n",
      "\n",
      "Epoch 4197\n",
      "-------------------------------\n",
      "loss: 0.228838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398151 \n",
      "\n",
      "Epoch 4198\n",
      "-------------------------------\n",
      "loss: 0.229157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397854 \n",
      "\n",
      "Epoch 4199\n",
      "-------------------------------\n",
      "loss: 0.230954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398032 \n",
      "\n",
      "Epoch 4200\n",
      "-------------------------------\n",
      "loss: 0.217634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398934 \n",
      "\n",
      "Epoch 4201\n",
      "-------------------------------\n",
      "loss: 0.227218  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400199 \n",
      "\n",
      "Epoch 4202\n",
      "-------------------------------\n",
      "loss: 0.243349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400065 \n",
      "\n",
      "Epoch 4203\n",
      "-------------------------------\n",
      "loss: 0.223015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400042 \n",
      "\n",
      "Epoch 4204\n",
      "-------------------------------\n",
      "loss: 0.233749  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399888 \n",
      "\n",
      "Epoch 4205\n",
      "-------------------------------\n",
      "loss: 0.220669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399848 \n",
      "\n",
      "Epoch 4206\n",
      "-------------------------------\n",
      "loss: 0.237225  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398963 \n",
      "\n",
      "Epoch 4207\n",
      "-------------------------------\n",
      "loss: 0.215894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398514 \n",
      "\n",
      "Epoch 4208\n",
      "-------------------------------\n",
      "loss: 0.234386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398400 \n",
      "\n",
      "Epoch 4209\n",
      "-------------------------------\n",
      "loss: 0.233693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398607 \n",
      "\n",
      "Epoch 4210\n",
      "-------------------------------\n",
      "loss: 0.231691  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398868 \n",
      "\n",
      "Epoch 4211\n",
      "-------------------------------\n",
      "loss: 0.215100  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399231 \n",
      "\n",
      "Epoch 4212\n",
      "-------------------------------\n",
      "loss: 0.229328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399756 \n",
      "\n",
      "Epoch 4213\n",
      "-------------------------------\n",
      "loss: 0.220151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401413 \n",
      "\n",
      "Epoch 4214\n",
      "-------------------------------\n",
      "loss: 0.244878  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403637 \n",
      "\n",
      "Epoch 4215\n",
      "-------------------------------\n",
      "loss: 0.217641  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404689 \n",
      "\n",
      "Epoch 4216\n",
      "-------------------------------\n",
      "loss: 0.227139  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404677 \n",
      "\n",
      "Epoch 4217\n",
      "-------------------------------\n",
      "loss: 0.223097  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404334 \n",
      "\n",
      "Epoch 4218\n",
      "-------------------------------\n",
      "loss: 0.223010  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404333 \n",
      "\n",
      "Epoch 4219\n",
      "-------------------------------\n",
      "loss: 0.216831  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403377 \n",
      "\n",
      "Epoch 4220\n",
      "-------------------------------\n",
      "loss: 0.215636  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402084 \n",
      "\n",
      "Epoch 4221\n",
      "-------------------------------\n",
      "loss: 0.230184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400598 \n",
      "\n",
      "Epoch 4222\n",
      "-------------------------------\n",
      "loss: 0.227444  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400222 \n",
      "\n",
      "Epoch 4223\n",
      "-------------------------------\n",
      "loss: 0.215169  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400922 \n",
      "\n",
      "Epoch 4224\n",
      "-------------------------------\n",
      "loss: 0.229405  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401342 \n",
      "\n",
      "Epoch 4225\n",
      "-------------------------------\n",
      "loss: 0.227686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401662 \n",
      "\n",
      "Epoch 4226\n",
      "-------------------------------\n",
      "loss: 0.221632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403178 \n",
      "\n",
      "Epoch 4227\n",
      "-------------------------------\n",
      "loss: 0.219252  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404872 \n",
      "\n",
      "Epoch 4228\n",
      "-------------------------------\n",
      "loss: 0.217238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405129 \n",
      "\n",
      "Epoch 4229\n",
      "-------------------------------\n",
      "loss: 0.219113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405476 \n",
      "\n",
      "Epoch 4230\n",
      "-------------------------------\n",
      "loss: 0.222543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405370 \n",
      "\n",
      "Epoch 4231\n",
      "-------------------------------\n",
      "loss: 0.224053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404539 \n",
      "\n",
      "Epoch 4232\n",
      "-------------------------------\n",
      "loss: 0.228368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403517 \n",
      "\n",
      "Epoch 4233\n",
      "-------------------------------\n",
      "loss: 0.227507  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.404317 \n",
      "\n",
      "Epoch 4234\n",
      "-------------------------------\n",
      "loss: 0.224251  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404618 \n",
      "\n",
      "Epoch 4235\n",
      "-------------------------------\n",
      "loss: 0.230342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404509 \n",
      "\n",
      "Epoch 4236\n",
      "-------------------------------\n",
      "loss: 0.226055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404986 \n",
      "\n",
      "Epoch 4237\n",
      "-------------------------------\n",
      "loss: 0.219189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406418 \n",
      "\n",
      "Epoch 4238\n",
      "-------------------------------\n",
      "loss: 0.234591  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406218 \n",
      "\n",
      "Epoch 4239\n",
      "-------------------------------\n",
      "loss: 0.223509  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404637 \n",
      "\n",
      "Epoch 4240\n",
      "-------------------------------\n",
      "loss: 0.211966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402927 \n",
      "\n",
      "Epoch 4241\n",
      "-------------------------------\n",
      "loss: 0.222184  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401668 \n",
      "\n",
      "Epoch 4242\n",
      "-------------------------------\n",
      "loss: 0.227185  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401080 \n",
      "\n",
      "Epoch 4243\n",
      "-------------------------------\n",
      "loss: 0.221778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401184 \n",
      "\n",
      "Epoch 4244\n",
      "-------------------------------\n",
      "loss: 0.228951  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400914 \n",
      "\n",
      "Epoch 4245\n",
      "-------------------------------\n",
      "loss: 0.239793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400370 \n",
      "\n",
      "Epoch 4246\n",
      "-------------------------------\n",
      "loss: 0.228003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399966 \n",
      "\n",
      "Epoch 4247\n",
      "-------------------------------\n",
      "loss: 0.234365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398879 \n",
      "\n",
      "Epoch 4248\n",
      "-------------------------------\n",
      "loss: 0.229156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397685 \n",
      "\n",
      "Epoch 4249\n",
      "-------------------------------\n",
      "loss: 0.228237  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397617 \n",
      "\n",
      "Epoch 4250\n",
      "-------------------------------\n",
      "loss: 0.223840  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398279 \n",
      "\n",
      "Epoch 4251\n",
      "-------------------------------\n",
      "loss: 0.214140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399573 \n",
      "\n",
      "Epoch 4252\n",
      "-------------------------------\n",
      "loss: 0.239271  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400723 \n",
      "\n",
      "Epoch 4253\n",
      "-------------------------------\n",
      "loss: 0.237167  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401748 \n",
      "\n",
      "Epoch 4254\n",
      "-------------------------------\n",
      "loss: 0.221183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402092 \n",
      "\n",
      "Epoch 4255\n",
      "-------------------------------\n",
      "loss: 0.218710  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403622 \n",
      "\n",
      "Epoch 4256\n",
      "-------------------------------\n",
      "loss: 0.235913  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404213 \n",
      "\n",
      "Epoch 4257\n",
      "-------------------------------\n",
      "loss: 0.214559  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403849 \n",
      "\n",
      "Epoch 4258\n",
      "-------------------------------\n",
      "loss: 0.221896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403349 \n",
      "\n",
      "Epoch 4259\n",
      "-------------------------------\n",
      "loss: 0.236090  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402934 \n",
      "\n",
      "Epoch 4260\n",
      "-------------------------------\n",
      "loss: 0.232772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402318 \n",
      "\n",
      "Epoch 4261\n",
      "-------------------------------\n",
      "loss: 0.223290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401445 \n",
      "\n",
      "Epoch 4262\n",
      "-------------------------------\n",
      "loss: 0.211435  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401458 \n",
      "\n",
      "Epoch 4263\n",
      "-------------------------------\n",
      "loss: 0.230183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402020 \n",
      "\n",
      "Epoch 4264\n",
      "-------------------------------\n",
      "loss: 0.223362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402143 \n",
      "\n",
      "Epoch 4265\n",
      "-------------------------------\n",
      "loss: 0.221539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402771 \n",
      "\n",
      "Epoch 4266\n",
      "-------------------------------\n",
      "loss: 0.228498  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403493 \n",
      "\n",
      "Epoch 4267\n",
      "-------------------------------\n",
      "loss: 0.218018  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403828 \n",
      "\n",
      "Epoch 4268\n",
      "-------------------------------\n",
      "loss: 0.222058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402901 \n",
      "\n",
      "Epoch 4269\n",
      "-------------------------------\n",
      "loss: 0.236295  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402013 \n",
      "\n",
      "Epoch 4270\n",
      "-------------------------------\n",
      "loss: 0.230910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401029 \n",
      "\n",
      "Epoch 4271\n",
      "-------------------------------\n",
      "loss: 0.227975  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400576 \n",
      "\n",
      "Epoch 4272\n",
      "-------------------------------\n",
      "loss: 0.236632  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400207 \n",
      "\n",
      "Epoch 4273\n",
      "-------------------------------\n",
      "loss: 0.216321  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399665 \n",
      "\n",
      "Epoch 4274\n",
      "-------------------------------\n",
      "loss: 0.232393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398523 \n",
      "\n",
      "Epoch 4275\n",
      "-------------------------------\n",
      "loss: 0.211950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397594 \n",
      "\n",
      "Epoch 4276\n",
      "-------------------------------\n",
      "loss: 0.228258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397455 \n",
      "\n",
      "Epoch 4277\n",
      "-------------------------------\n",
      "loss: 0.226467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398924 \n",
      "\n",
      "Epoch 4278\n",
      "-------------------------------\n",
      "loss: 0.228757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402250 \n",
      "\n",
      "Epoch 4279\n",
      "-------------------------------\n",
      "loss: 0.228345  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402954 \n",
      "\n",
      "Epoch 4280\n",
      "-------------------------------\n",
      "loss: 0.223586  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402232 \n",
      "\n",
      "Epoch 4281\n",
      "-------------------------------\n",
      "loss: 0.220687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400342 \n",
      "\n",
      "Epoch 4282\n",
      "-------------------------------\n",
      "loss: 0.229164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398606 \n",
      "\n",
      "Epoch 4283\n",
      "-------------------------------\n",
      "loss: 0.223021  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397121 \n",
      "\n",
      "Epoch 4284\n",
      "-------------------------------\n",
      "loss: 0.207376  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396382 \n",
      "\n",
      "Epoch 4285\n",
      "-------------------------------\n",
      "loss: 0.231242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396666 \n",
      "\n",
      "Epoch 4286\n",
      "-------------------------------\n",
      "loss: 0.226543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398342 \n",
      "\n",
      "Epoch 4287\n",
      "-------------------------------\n",
      "loss: 0.213304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401467 \n",
      "\n",
      "Epoch 4288\n",
      "-------------------------------\n",
      "loss: 0.221380  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404826 \n",
      "\n",
      "Epoch 4289\n",
      "-------------------------------\n",
      "loss: 0.227256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405029 \n",
      "\n",
      "Epoch 4290\n",
      "-------------------------------\n",
      "loss: 0.216979  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403148 \n",
      "\n",
      "Epoch 4291\n",
      "-------------------------------\n",
      "loss: 0.227784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400436 \n",
      "\n",
      "Epoch 4292\n",
      "-------------------------------\n",
      "loss: 0.224532  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398155 \n",
      "\n",
      "Epoch 4293\n",
      "-------------------------------\n",
      "loss: 0.203028  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397624 \n",
      "\n",
      "Epoch 4294\n",
      "-------------------------------\n",
      "loss: 0.232730  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397484 \n",
      "\n",
      "Epoch 4295\n",
      "-------------------------------\n",
      "loss: 0.218156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397682 \n",
      "\n",
      "Epoch 4296\n",
      "-------------------------------\n",
      "loss: 0.215403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398689 \n",
      "\n",
      "Epoch 4297\n",
      "-------------------------------\n",
      "loss: 0.219336  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400440 \n",
      "\n",
      "Epoch 4298\n",
      "-------------------------------\n",
      "loss: 0.232196  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401506 \n",
      "\n",
      "Epoch 4299\n",
      "-------------------------------\n",
      "loss: 0.238801  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400091 \n",
      "\n",
      "Epoch 4300\n",
      "-------------------------------\n",
      "loss: 0.220901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398953 \n",
      "\n",
      "Epoch 4301\n",
      "-------------------------------\n",
      "loss: 0.204201  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399153 \n",
      "\n",
      "Epoch 4302\n",
      "-------------------------------\n",
      "loss: 0.212512  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400844 \n",
      "\n",
      "Epoch 4303\n",
      "-------------------------------\n",
      "loss: 0.225370  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403325 \n",
      "\n",
      "Epoch 4304\n",
      "-------------------------------\n",
      "loss: 0.233782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403924 \n",
      "\n",
      "Epoch 4305\n",
      "-------------------------------\n",
      "loss: 0.228999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403075 \n",
      "\n",
      "Epoch 4306\n",
      "-------------------------------\n",
      "loss: 0.229964  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402076 \n",
      "\n",
      "Epoch 4307\n",
      "-------------------------------\n",
      "loss: 0.225736  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401348 \n",
      "\n",
      "Epoch 4308\n",
      "-------------------------------\n",
      "loss: 0.226309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401923 \n",
      "\n",
      "Epoch 4309\n",
      "-------------------------------\n",
      "loss: 0.236770  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403299 \n",
      "\n",
      "Epoch 4310\n",
      "-------------------------------\n",
      "loss: 0.217342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404758 \n",
      "\n",
      "Epoch 4311\n",
      "-------------------------------\n",
      "loss: 0.223425  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405123 \n",
      "\n",
      "Epoch 4312\n",
      "-------------------------------\n",
      "loss: 0.216705  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405402 \n",
      "\n",
      "Epoch 4313\n",
      "-------------------------------\n",
      "loss: 0.223002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405672 \n",
      "\n",
      "Epoch 4314\n",
      "-------------------------------\n",
      "loss: 0.218349  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404573 \n",
      "\n",
      "Epoch 4315\n",
      "-------------------------------\n",
      "loss: 0.223424  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403629 \n",
      "\n",
      "Epoch 4316\n",
      "-------------------------------\n",
      "loss: 0.235723  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401787 \n",
      "\n",
      "Epoch 4317\n",
      "-------------------------------\n",
      "loss: 0.215795  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400629 \n",
      "\n",
      "Epoch 4318\n",
      "-------------------------------\n",
      "loss: 0.235208  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400951 \n",
      "\n",
      "Epoch 4319\n",
      "-------------------------------\n",
      "loss: 0.223662  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404292 \n",
      "\n",
      "Epoch 4320\n",
      "-------------------------------\n",
      "loss: 0.220223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406587 \n",
      "\n",
      "Epoch 4321\n",
      "-------------------------------\n",
      "loss: 0.219508  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406683 \n",
      "\n",
      "Epoch 4322\n",
      "-------------------------------\n",
      "loss: 0.230393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403901 \n",
      "\n",
      "Epoch 4323\n",
      "-------------------------------\n",
      "loss: 0.224460  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400512 \n",
      "\n",
      "Epoch 4324\n",
      "-------------------------------\n",
      "loss: 0.216465  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399041 \n",
      "\n",
      "Epoch 4325\n",
      "-------------------------------\n",
      "loss: 0.214352  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397561 \n",
      "\n",
      "Epoch 4326\n",
      "-------------------------------\n",
      "loss: 0.231763  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397585 \n",
      "\n",
      "Epoch 4327\n",
      "-------------------------------\n",
      "loss: 0.213359  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398531 \n",
      "\n",
      "Epoch 4328\n",
      "-------------------------------\n",
      "loss: 0.218996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399684 \n",
      "\n",
      "Epoch 4329\n",
      "-------------------------------\n",
      "loss: 0.233258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399270 \n",
      "\n",
      "Epoch 4330\n",
      "-------------------------------\n",
      "loss: 0.233760  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398826 \n",
      "\n",
      "Epoch 4331\n",
      "-------------------------------\n",
      "loss: 0.239540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398144 \n",
      "\n",
      "Epoch 4332\n",
      "-------------------------------\n",
      "loss: 0.215475  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398447 \n",
      "\n",
      "Epoch 4333\n",
      "-------------------------------\n",
      "loss: 0.220634  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399529 \n",
      "\n",
      "Epoch 4334\n",
      "-------------------------------\n",
      "loss: 0.228967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400537 \n",
      "\n",
      "Epoch 4335\n",
      "-------------------------------\n",
      "loss: 0.217765  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402513 \n",
      "\n",
      "Epoch 4336\n",
      "-------------------------------\n",
      "loss: 0.202493  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403933 \n",
      "\n",
      "Epoch 4337\n",
      "-------------------------------\n",
      "loss: 0.245152  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403104 \n",
      "\n",
      "Epoch 4338\n",
      "-------------------------------\n",
      "loss: 0.219419  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402414 \n",
      "\n",
      "Epoch 4339\n",
      "-------------------------------\n",
      "loss: 0.224717  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402141 \n",
      "\n",
      "Epoch 4340\n",
      "-------------------------------\n",
      "loss: 0.224876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401876 \n",
      "\n",
      "Epoch 4341\n",
      "-------------------------------\n",
      "loss: 0.227499  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401963 \n",
      "\n",
      "Epoch 4342\n",
      "-------------------------------\n",
      "loss: 0.219638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401756 \n",
      "\n",
      "Epoch 4343\n",
      "-------------------------------\n",
      "loss: 0.231254  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402406 \n",
      "\n",
      "Epoch 4344\n",
      "-------------------------------\n",
      "loss: 0.230392  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403896 \n",
      "\n",
      "Epoch 4345\n",
      "-------------------------------\n",
      "loss: 0.218343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405580 \n",
      "\n",
      "Epoch 4346\n",
      "-------------------------------\n",
      "loss: 0.220912  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405882 \n",
      "\n",
      "Epoch 4347\n",
      "-------------------------------\n",
      "loss: 0.223754  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405525 \n",
      "\n",
      "Epoch 4348\n",
      "-------------------------------\n",
      "loss: 0.231481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404791 \n",
      "\n",
      "Epoch 4349\n",
      "-------------------------------\n",
      "loss: 0.215362  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404474 \n",
      "\n",
      "Epoch 4350\n",
      "-------------------------------\n",
      "loss: 0.227387  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403360 \n",
      "\n",
      "Epoch 4351\n",
      "-------------------------------\n",
      "loss: 0.210893  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403866 \n",
      "\n",
      "Epoch 4352\n",
      "-------------------------------\n",
      "loss: 0.220065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404442 \n",
      "\n",
      "Epoch 4353\n",
      "-------------------------------\n",
      "loss: 0.222241  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405317 \n",
      "\n",
      "Epoch 4354\n",
      "-------------------------------\n",
      "loss: 0.245309  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405979 \n",
      "\n",
      "Epoch 4355\n",
      "-------------------------------\n",
      "loss: 0.234702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405588 \n",
      "\n",
      "Epoch 4356\n",
      "-------------------------------\n",
      "loss: 0.215676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404408 \n",
      "\n",
      "Epoch 4357\n",
      "-------------------------------\n",
      "loss: 0.214839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403313 \n",
      "\n",
      "Epoch 4358\n",
      "-------------------------------\n",
      "loss: 0.220969  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402476 \n",
      "\n",
      "Epoch 4359\n",
      "-------------------------------\n",
      "loss: 0.223875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402260 \n",
      "\n",
      "Epoch 4360\n",
      "-------------------------------\n",
      "loss: 0.215155  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401911 \n",
      "\n",
      "Epoch 4361\n",
      "-------------------------------\n",
      "loss: 0.224640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402491 \n",
      "\n",
      "Epoch 4362\n",
      "-------------------------------\n",
      "loss: 0.218608  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403462 \n",
      "\n",
      "Epoch 4363\n",
      "-------------------------------\n",
      "loss: 0.228009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403679 \n",
      "\n",
      "Epoch 4364\n",
      "-------------------------------\n",
      "loss: 0.224235  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403592 \n",
      "\n",
      "Epoch 4365\n",
      "-------------------------------\n",
      "loss: 0.219871  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403219 \n",
      "\n",
      "Epoch 4366\n",
      "-------------------------------\n",
      "loss: 0.216101  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402957 \n",
      "\n",
      "Epoch 4367\n",
      "-------------------------------\n",
      "loss: 0.214897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402858 \n",
      "\n",
      "Epoch 4368\n",
      "-------------------------------\n",
      "loss: 0.217199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402889 \n",
      "\n",
      "Epoch 4369\n",
      "-------------------------------\n",
      "loss: 0.221822  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402324 \n",
      "\n",
      "Epoch 4370\n",
      "-------------------------------\n",
      "loss: 0.227209  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401824 \n",
      "\n",
      "Epoch 4371\n",
      "-------------------------------\n",
      "loss: 0.220436  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401251 \n",
      "\n",
      "Epoch 4372\n",
      "-------------------------------\n",
      "loss: 0.220742  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401165 \n",
      "\n",
      "Epoch 4373\n",
      "-------------------------------\n",
      "loss: 0.231103  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401692 \n",
      "\n",
      "Epoch 4374\n",
      "-------------------------------\n",
      "loss: 0.221036  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401968 \n",
      "\n",
      "Epoch 4375\n",
      "-------------------------------\n",
      "loss: 0.230246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401160 \n",
      "\n",
      "Epoch 4376\n",
      "-------------------------------\n",
      "loss: 0.211663  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401041 \n",
      "\n",
      "Epoch 4377\n",
      "-------------------------------\n",
      "loss: 0.221734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400463 \n",
      "\n",
      "Epoch 4378\n",
      "-------------------------------\n",
      "loss: 0.223550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399153 \n",
      "\n",
      "Epoch 4379\n",
      "-------------------------------\n",
      "loss: 0.225340  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398387 \n",
      "\n",
      "Epoch 4380\n",
      "-------------------------------\n",
      "loss: 0.221848  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397875 \n",
      "\n",
      "Epoch 4381\n",
      "-------------------------------\n",
      "loss: 0.231204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398204 \n",
      "\n",
      "Epoch 4382\n",
      "-------------------------------\n",
      "loss: 0.227088  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398325 \n",
      "\n",
      "Epoch 4383\n",
      "-------------------------------\n",
      "loss: 0.224894  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399372 \n",
      "\n",
      "Epoch 4384\n",
      "-------------------------------\n",
      "loss: 0.224896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400217 \n",
      "\n",
      "Epoch 4385\n",
      "-------------------------------\n",
      "loss: 0.228276  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400852 \n",
      "\n",
      "Epoch 4386\n",
      "-------------------------------\n",
      "loss: 0.216552  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401672 \n",
      "\n",
      "Epoch 4387\n",
      "-------------------------------\n",
      "loss: 0.230084  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402370 \n",
      "\n",
      "Epoch 4388\n",
      "-------------------------------\n",
      "loss: 0.217563  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402672 \n",
      "\n",
      "Epoch 4389\n",
      "-------------------------------\n",
      "loss: 0.223344  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402672 \n",
      "\n",
      "Epoch 4390\n",
      "-------------------------------\n",
      "loss: 0.229631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402447 \n",
      "\n",
      "Epoch 4391\n",
      "-------------------------------\n",
      "loss: 0.219216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402334 \n",
      "\n",
      "Epoch 4392\n",
      "-------------------------------\n",
      "loss: 0.224091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401550 \n",
      "\n",
      "Epoch 4393\n",
      "-------------------------------\n",
      "loss: 0.215609  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400525 \n",
      "\n",
      "Epoch 4394\n",
      "-------------------------------\n",
      "loss: 0.222551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401042 \n",
      "\n",
      "Epoch 4395\n",
      "-------------------------------\n",
      "loss: 0.219041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402188 \n",
      "\n",
      "Epoch 4396\n",
      "-------------------------------\n",
      "loss: 0.212579  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403606 \n",
      "\n",
      "Epoch 4397\n",
      "-------------------------------\n",
      "loss: 0.209216  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405019 \n",
      "\n",
      "Epoch 4398\n",
      "-------------------------------\n",
      "loss: 0.233843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404824 \n",
      "\n",
      "Epoch 4399\n",
      "-------------------------------\n",
      "loss: 0.224779  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403107 \n",
      "\n",
      "Epoch 4400\n",
      "-------------------------------\n",
      "loss: 0.220724  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401806 \n",
      "\n",
      "Epoch 4401\n",
      "-------------------------------\n",
      "loss: 0.225798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402645 \n",
      "\n",
      "Epoch 4402\n",
      "-------------------------------\n",
      "loss: 0.211992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402724 \n",
      "\n",
      "Epoch 4403\n",
      "-------------------------------\n",
      "loss: 0.231412  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402308 \n",
      "\n",
      "Epoch 4404\n",
      "-------------------------------\n",
      "loss: 0.217284  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404288 \n",
      "\n",
      "Epoch 4405\n",
      "-------------------------------\n",
      "loss: 0.218375  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408888 \n",
      "\n",
      "Epoch 4406\n",
      "-------------------------------\n",
      "loss: 0.206305  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.412303 \n",
      "\n",
      "Epoch 4407\n",
      "-------------------------------\n",
      "loss: 0.226102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411935 \n",
      "\n",
      "Epoch 4408\n",
      "-------------------------------\n",
      "loss: 0.246278  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408610 \n",
      "\n",
      "Epoch 4409\n",
      "-------------------------------\n",
      "loss: 0.239648  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405781 \n",
      "\n",
      "Epoch 4410\n",
      "-------------------------------\n",
      "loss: 0.227386  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404851 \n",
      "\n",
      "Epoch 4411\n",
      "-------------------------------\n",
      "loss: 0.218338  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404877 \n",
      "\n",
      "Epoch 4412\n",
      "-------------------------------\n",
      "loss: 0.218628  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404902 \n",
      "\n",
      "Epoch 4413\n",
      "-------------------------------\n",
      "loss: 0.226715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404684 \n",
      "\n",
      "Epoch 4414\n",
      "-------------------------------\n",
      "loss: 0.214214  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404388 \n",
      "\n",
      "Epoch 4415\n",
      "-------------------------------\n",
      "loss: 0.225121  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404787 \n",
      "\n",
      "Epoch 4416\n",
      "-------------------------------\n",
      "loss: 0.225525  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403527 \n",
      "\n",
      "Epoch 4417\n",
      "-------------------------------\n",
      "loss: 0.218721  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402375 \n",
      "\n",
      "Epoch 4418\n",
      "-------------------------------\n",
      "loss: 0.215312  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400494 \n",
      "\n",
      "Epoch 4419\n",
      "-------------------------------\n",
      "loss: 0.230455  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399342 \n",
      "\n",
      "Epoch 4420\n",
      "-------------------------------\n",
      "loss: 0.217584  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398492 \n",
      "\n",
      "Epoch 4421\n",
      "-------------------------------\n",
      "loss: 0.219041  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398367 \n",
      "\n",
      "Epoch 4422\n",
      "-------------------------------\n",
      "loss: 0.228255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399843 \n",
      "\n",
      "Epoch 4423\n",
      "-------------------------------\n",
      "loss: 0.219301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402537 \n",
      "\n",
      "Epoch 4424\n",
      "-------------------------------\n",
      "loss: 0.255076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403507 \n",
      "\n",
      "Epoch 4425\n",
      "-------------------------------\n",
      "loss: 0.213939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404305 \n",
      "\n",
      "Epoch 4426\n",
      "-------------------------------\n",
      "loss: 0.216520  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406526 \n",
      "\n",
      "Epoch 4427\n",
      "-------------------------------\n",
      "loss: 0.244049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407378 \n",
      "\n",
      "Epoch 4428\n",
      "-------------------------------\n",
      "loss: 0.238618  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406494 \n",
      "\n",
      "Epoch 4429\n",
      "-------------------------------\n",
      "loss: 0.217933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405401 \n",
      "\n",
      "Epoch 4430\n",
      "-------------------------------\n",
      "loss: 0.226828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404557 \n",
      "\n",
      "Epoch 4431\n",
      "-------------------------------\n",
      "loss: 0.230976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403718 \n",
      "\n",
      "Epoch 4432\n",
      "-------------------------------\n",
      "loss: 0.221882  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403066 \n",
      "\n",
      "Epoch 4433\n",
      "-------------------------------\n",
      "loss: 0.235204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402002 \n",
      "\n",
      "Epoch 4434\n",
      "-------------------------------\n",
      "loss: 0.216298  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402424 \n",
      "\n",
      "Epoch 4435\n",
      "-------------------------------\n",
      "loss: 0.216113  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404941 \n",
      "\n",
      "Epoch 4436\n",
      "-------------------------------\n",
      "loss: 0.246290  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407208 \n",
      "\n",
      "Epoch 4437\n",
      "-------------------------------\n",
      "loss: 0.235476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407274 \n",
      "\n",
      "Epoch 4438\n",
      "-------------------------------\n",
      "loss: 0.225686  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405845 \n",
      "\n",
      "Epoch 4439\n",
      "-------------------------------\n",
      "loss: 0.203485  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404706 \n",
      "\n",
      "Epoch 4440\n",
      "-------------------------------\n",
      "loss: 0.227078  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402424 \n",
      "\n",
      "Epoch 4441\n",
      "-------------------------------\n",
      "loss: 0.210656  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399968 \n",
      "\n",
      "Epoch 4442\n",
      "-------------------------------\n",
      "loss: 0.215762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398773 \n",
      "\n",
      "Epoch 4443\n",
      "-------------------------------\n",
      "loss: 0.212782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398832 \n",
      "\n",
      "Epoch 4444\n",
      "-------------------------------\n",
      "loss: 0.226907  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398880 \n",
      "\n",
      "Epoch 4445\n",
      "-------------------------------\n",
      "loss: 0.227484  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400278 \n",
      "\n",
      "Epoch 4446\n",
      "-------------------------------\n",
      "loss: 0.218002  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401612 \n",
      "\n",
      "Epoch 4447\n",
      "-------------------------------\n",
      "loss: 0.218945  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402278 \n",
      "\n",
      "Epoch 4448\n",
      "-------------------------------\n",
      "loss: 0.222674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401620 \n",
      "\n",
      "Epoch 4449\n",
      "-------------------------------\n",
      "loss: 0.226919  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401088 \n",
      "\n",
      "Epoch 4450\n",
      "-------------------------------\n",
      "loss: 0.217860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401211 \n",
      "\n",
      "Epoch 4451\n",
      "-------------------------------\n",
      "loss: 0.223614  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402281 \n",
      "\n",
      "Epoch 4452\n",
      "-------------------------------\n",
      "loss: 0.218158  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403670 \n",
      "\n",
      "Epoch 4453\n",
      "-------------------------------\n",
      "loss: 0.228003  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403381 \n",
      "\n",
      "Epoch 4454\n",
      "-------------------------------\n",
      "loss: 0.218353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401901 \n",
      "\n",
      "Epoch 4455\n",
      "-------------------------------\n",
      "loss: 0.230242  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400901 \n",
      "\n",
      "Epoch 4456\n",
      "-------------------------------\n",
      "loss: 0.208243  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400736 \n",
      "\n",
      "Epoch 4457\n",
      "-------------------------------\n",
      "loss: 0.227685  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401473 \n",
      "\n",
      "Epoch 4458\n",
      "-------------------------------\n",
      "loss: 0.214051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401596 \n",
      "\n",
      "Epoch 4459\n",
      "-------------------------------\n",
      "loss: 0.216156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401634 \n",
      "\n",
      "Epoch 4460\n",
      "-------------------------------\n",
      "loss: 0.219773  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401969 \n",
      "\n",
      "Epoch 4461\n",
      "-------------------------------\n",
      "loss: 0.212278  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.401369 \n",
      "\n",
      "Epoch 4462\n",
      "-------------------------------\n",
      "loss: 0.212934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400312 \n",
      "\n",
      "Epoch 4463\n",
      "-------------------------------\n",
      "loss: 0.226408  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398152 \n",
      "\n",
      "Epoch 4464\n",
      "-------------------------------\n",
      "loss: 0.231637  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397334 \n",
      "\n",
      "Epoch 4465\n",
      "-------------------------------\n",
      "loss: 0.227075  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396734 \n",
      "\n",
      "Epoch 4466\n",
      "-------------------------------\n",
      "loss: 0.219908  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397122 \n",
      "\n",
      "Epoch 4467\n",
      "-------------------------------\n",
      "loss: 0.221083  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398332 \n",
      "\n",
      "Epoch 4468\n",
      "-------------------------------\n",
      "loss: 0.214150  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399514 \n",
      "\n",
      "Epoch 4469\n",
      "-------------------------------\n",
      "loss: 0.221862  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401471 \n",
      "\n",
      "Epoch 4470\n",
      "-------------------------------\n",
      "loss: 0.228876  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402618 \n",
      "\n",
      "Epoch 4471\n",
      "-------------------------------\n",
      "loss: 0.202821  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402582 \n",
      "\n",
      "Epoch 4472\n",
      "-------------------------------\n",
      "loss: 0.213468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402454 \n",
      "\n",
      "Epoch 4473\n",
      "-------------------------------\n",
      "loss: 0.241095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400374 \n",
      "\n",
      "Epoch 4474\n",
      "-------------------------------\n",
      "loss: 0.230885  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398856 \n",
      "\n",
      "Epoch 4475\n",
      "-------------------------------\n",
      "loss: 0.230620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398533 \n",
      "\n",
      "Epoch 4476\n",
      "-------------------------------\n",
      "loss: 0.227421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400016 \n",
      "\n",
      "Epoch 4477\n",
      "-------------------------------\n",
      "loss: 0.222537  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402296 \n",
      "\n",
      "Epoch 4478\n",
      "-------------------------------\n",
      "loss: 0.228292  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403737 \n",
      "\n",
      "Epoch 4479\n",
      "-------------------------------\n",
      "loss: 0.244099  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403879 \n",
      "\n",
      "Epoch 4480\n",
      "-------------------------------\n",
      "loss: 0.232128  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402942 \n",
      "\n",
      "Epoch 4481\n",
      "-------------------------------\n",
      "loss: 0.219976  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401890 \n",
      "\n",
      "Epoch 4482\n",
      "-------------------------------\n",
      "loss: 0.224177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401214 \n",
      "\n",
      "Epoch 4483\n",
      "-------------------------------\n",
      "loss: 0.216777  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402001 \n",
      "\n",
      "Epoch 4484\n",
      "-------------------------------\n",
      "loss: 0.226227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402838 \n",
      "\n",
      "Epoch 4485\n",
      "-------------------------------\n",
      "loss: 0.216157  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403557 \n",
      "\n",
      "Epoch 4486\n",
      "-------------------------------\n",
      "loss: 0.237851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403756 \n",
      "\n",
      "Epoch 4487\n",
      "-------------------------------\n",
      "loss: 0.233307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402358 \n",
      "\n",
      "Epoch 4488\n",
      "-------------------------------\n",
      "loss: 0.235943  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400973 \n",
      "\n",
      "Epoch 4489\n",
      "-------------------------------\n",
      "loss: 0.221049  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400738 \n",
      "\n",
      "Epoch 4490\n",
      "-------------------------------\n",
      "loss: 0.230545  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401606 \n",
      "\n",
      "Epoch 4491\n",
      "-------------------------------\n",
      "loss: 0.221638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403689 \n",
      "\n",
      "Epoch 4492\n",
      "-------------------------------\n",
      "loss: 0.221009  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404888 \n",
      "\n",
      "Epoch 4493\n",
      "-------------------------------\n",
      "loss: 0.224540  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404572 \n",
      "\n",
      "Epoch 4494\n",
      "-------------------------------\n",
      "loss: 0.212890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403698 \n",
      "\n",
      "Epoch 4495\n",
      "-------------------------------\n",
      "loss: 0.245565  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401677 \n",
      "\n",
      "Epoch 4496\n",
      "-------------------------------\n",
      "loss: 0.205702  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400506 \n",
      "\n",
      "Epoch 4497\n",
      "-------------------------------\n",
      "loss: 0.229697  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399970 \n",
      "\n",
      "Epoch 4498\n",
      "-------------------------------\n",
      "loss: 0.225739  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400112 \n",
      "\n",
      "Epoch 4499\n",
      "-------------------------------\n",
      "loss: 0.213063  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402102 \n",
      "\n",
      "Epoch 4500\n",
      "-------------------------------\n",
      "loss: 0.236053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405329 \n",
      "\n",
      "Epoch 4501\n",
      "-------------------------------\n",
      "loss: 0.220023  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408871 \n",
      "\n",
      "Epoch 4502\n",
      "-------------------------------\n",
      "loss: 0.206999  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.411107 \n",
      "\n",
      "Epoch 4503\n",
      "-------------------------------\n",
      "loss: 0.217602  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409646 \n",
      "\n",
      "Epoch 4504\n",
      "-------------------------------\n",
      "loss: 0.214373  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406473 \n",
      "\n",
      "Epoch 4505\n",
      "-------------------------------\n",
      "loss: 0.240038  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403633 \n",
      "\n",
      "Epoch 4506\n",
      "-------------------------------\n",
      "loss: 0.231631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401788 \n",
      "\n",
      "Epoch 4507\n",
      "-------------------------------\n",
      "loss: 0.226570  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402119 \n",
      "\n",
      "Epoch 4508\n",
      "-------------------------------\n",
      "loss: 0.220343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402213 \n",
      "\n",
      "Epoch 4509\n",
      "-------------------------------\n",
      "loss: 0.229107  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401163 \n",
      "\n",
      "Epoch 4510\n",
      "-------------------------------\n",
      "loss: 0.217830  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400884 \n",
      "\n",
      "Epoch 4511\n",
      "-------------------------------\n",
      "loss: 0.227061  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400551 \n",
      "\n",
      "Epoch 4512\n",
      "-------------------------------\n",
      "loss: 0.229415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401410 \n",
      "\n",
      "Epoch 4513\n",
      "-------------------------------\n",
      "loss: 0.219652  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403132 \n",
      "\n",
      "Epoch 4514\n",
      "-------------------------------\n",
      "loss: 0.229238  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403578 \n",
      "\n",
      "Epoch 4515\n",
      "-------------------------------\n",
      "loss: 0.220993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401715 \n",
      "\n",
      "Epoch 4516\n",
      "-------------------------------\n",
      "loss: 0.256203  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397315 \n",
      "\n",
      "Epoch 4517\n",
      "-------------------------------\n",
      "loss: 0.212065  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395967 \n",
      "\n",
      "Epoch 4518\n",
      "-------------------------------\n",
      "loss: 0.227129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395735 \n",
      "\n",
      "Epoch 4519\n",
      "-------------------------------\n",
      "loss: 0.226259  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396242 \n",
      "\n",
      "Epoch 4520\n",
      "-------------------------------\n",
      "loss: 0.239944  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396951 \n",
      "\n",
      "Epoch 4521\n",
      "-------------------------------\n",
      "loss: 0.218395  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397491 \n",
      "\n",
      "Epoch 4522\n",
      "-------------------------------\n",
      "loss: 0.231987  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398053 \n",
      "\n",
      "Epoch 4523\n",
      "-------------------------------\n",
      "loss: 0.231928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399421 \n",
      "\n",
      "Epoch 4524\n",
      "-------------------------------\n",
      "loss: 0.223815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402846 \n",
      "\n",
      "Epoch 4525\n",
      "-------------------------------\n",
      "loss: 0.227839  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407604 \n",
      "\n",
      "Epoch 4526\n",
      "-------------------------------\n",
      "loss: 0.232881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409456 \n",
      "\n",
      "Epoch 4527\n",
      "-------------------------------\n",
      "loss: 0.216316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408277 \n",
      "\n",
      "Epoch 4528\n",
      "-------------------------------\n",
      "loss: 0.232415  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403891 \n",
      "\n",
      "Epoch 4529\n",
      "-------------------------------\n",
      "loss: 0.223316  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400572 \n",
      "\n",
      "Epoch 4530\n",
      "-------------------------------\n",
      "loss: 0.221377  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399668 \n",
      "\n",
      "Epoch 4531\n",
      "-------------------------------\n",
      "loss: 0.233715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400154 \n",
      "\n",
      "Epoch 4532\n",
      "-------------------------------\n",
      "loss: 0.234091  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400071 \n",
      "\n",
      "Epoch 4533\n",
      "-------------------------------\n",
      "loss: 0.235550  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401079 \n",
      "\n",
      "Epoch 4534\n",
      "-------------------------------\n",
      "loss: 0.224780  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402855 \n",
      "\n",
      "Epoch 4535\n",
      "-------------------------------\n",
      "loss: 0.223115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405073 \n",
      "\n",
      "Epoch 4536\n",
      "-------------------------------\n",
      "loss: 0.219059  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407143 \n",
      "\n",
      "Epoch 4537\n",
      "-------------------------------\n",
      "loss: 0.213518  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.408031 \n",
      "\n",
      "Epoch 4538\n",
      "-------------------------------\n",
      "loss: 0.211794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407743 \n",
      "\n",
      "Epoch 4539\n",
      "-------------------------------\n",
      "loss: 0.223255  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404047 \n",
      "\n",
      "Epoch 4540\n",
      "-------------------------------\n",
      "loss: 0.218039  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399736 \n",
      "\n",
      "Epoch 4541\n",
      "-------------------------------\n",
      "loss: 0.223042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397260 \n",
      "\n",
      "Epoch 4542\n",
      "-------------------------------\n",
      "loss: 0.223008  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396010 \n",
      "\n",
      "Epoch 4543\n",
      "-------------------------------\n",
      "loss: 0.214670  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395500 \n",
      "\n",
      "Epoch 4544\n",
      "-------------------------------\n",
      "loss: 0.218803  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395128 \n",
      "\n",
      "Epoch 4545\n",
      "-------------------------------\n",
      "loss: 0.221207  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394926 \n",
      "\n",
      "Epoch 4546\n",
      "-------------------------------\n",
      "loss: 0.228757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396426 \n",
      "\n",
      "Epoch 4547\n",
      "-------------------------------\n",
      "loss: 0.219294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398291 \n",
      "\n",
      "Epoch 4548\n",
      "-------------------------------\n",
      "loss: 0.215279  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399940 \n",
      "\n",
      "Epoch 4549\n",
      "-------------------------------\n",
      "loss: 0.214844  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400224 \n",
      "\n",
      "Epoch 4550\n",
      "-------------------------------\n",
      "loss: 0.219001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400577 \n",
      "\n",
      "Epoch 4551\n",
      "-------------------------------\n",
      "loss: 0.220030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400681 \n",
      "\n",
      "Epoch 4552\n",
      "-------------------------------\n",
      "loss: 0.215502  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400390 \n",
      "\n",
      "Epoch 4553\n",
      "-------------------------------\n",
      "loss: 0.225015  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400350 \n",
      "\n",
      "Epoch 4554\n",
      "-------------------------------\n",
      "loss: 0.237942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400158 \n",
      "\n",
      "Epoch 4555\n",
      "-------------------------------\n",
      "loss: 0.206222  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401017 \n",
      "\n",
      "Epoch 4556\n",
      "-------------------------------\n",
      "loss: 0.212017  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402629 \n",
      "\n",
      "Epoch 4557\n",
      "-------------------------------\n",
      "loss: 0.221928  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403756 \n",
      "\n",
      "Epoch 4558\n",
      "-------------------------------\n",
      "loss: 0.228154  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403460 \n",
      "\n",
      "Epoch 4559\n",
      "-------------------------------\n",
      "loss: 0.212948  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402668 \n",
      "\n",
      "Epoch 4560\n",
      "-------------------------------\n",
      "loss: 0.214256  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402041 \n",
      "\n",
      "Epoch 4561\n",
      "-------------------------------\n",
      "loss: 0.216178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402258 \n",
      "\n",
      "Epoch 4562\n",
      "-------------------------------\n",
      "loss: 0.231471  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401864 \n",
      "\n",
      "Epoch 4563\n",
      "-------------------------------\n",
      "loss: 0.220598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400882 \n",
      "\n",
      "Epoch 4564\n",
      "-------------------------------\n",
      "loss: 0.220189  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400786 \n",
      "\n",
      "Epoch 4565\n",
      "-------------------------------\n",
      "loss: 0.225319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400499 \n",
      "\n",
      "Epoch 4566\n",
      "-------------------------------\n",
      "loss: 0.224968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400528 \n",
      "\n",
      "Epoch 4567\n",
      "-------------------------------\n",
      "loss: 0.221445  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401191 \n",
      "\n",
      "Epoch 4568\n",
      "-------------------------------\n",
      "loss: 0.212914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402099 \n",
      "\n",
      "Epoch 4569\n",
      "-------------------------------\n",
      "loss: 0.223050  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403822 \n",
      "\n",
      "Epoch 4570\n",
      "-------------------------------\n",
      "loss: 0.219478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404415 \n",
      "\n",
      "Epoch 4571\n",
      "-------------------------------\n",
      "loss: 0.216215  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403257 \n",
      "\n",
      "Epoch 4572\n",
      "-------------------------------\n",
      "loss: 0.227190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401960 \n",
      "\n",
      "Epoch 4573\n",
      "-------------------------------\n",
      "loss: 0.218693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401767 \n",
      "\n",
      "Epoch 4574\n",
      "-------------------------------\n",
      "loss: 0.218000  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403211 \n",
      "\n",
      "Epoch 4575\n",
      "-------------------------------\n",
      "loss: 0.212511  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404134 \n",
      "\n",
      "Epoch 4576\n",
      "-------------------------------\n",
      "loss: 0.214581  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404164 \n",
      "\n",
      "Epoch 4577\n",
      "-------------------------------\n",
      "loss: 0.217814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404376 \n",
      "\n",
      "Epoch 4578\n",
      "-------------------------------\n",
      "loss: 0.216617  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403625 \n",
      "\n",
      "Epoch 4579\n",
      "-------------------------------\n",
      "loss: 0.230649  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401082 \n",
      "\n",
      "Epoch 4580\n",
      "-------------------------------\n",
      "loss: 0.216758  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398970 \n",
      "\n",
      "Epoch 4581\n",
      "-------------------------------\n",
      "loss: 0.212674  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398623 \n",
      "\n",
      "Epoch 4582\n",
      "-------------------------------\n",
      "loss: 0.215541  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398605 \n",
      "\n",
      "Epoch 4583\n",
      "-------------------------------\n",
      "loss: 0.211246  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398806 \n",
      "\n",
      "Epoch 4584\n",
      "-------------------------------\n",
      "loss: 0.228198  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399659 \n",
      "\n",
      "Epoch 4585\n",
      "-------------------------------\n",
      "loss: 0.211711  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401615 \n",
      "\n",
      "Epoch 4586\n",
      "-------------------------------\n",
      "loss: 0.210687  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404628 \n",
      "\n",
      "Epoch 4587\n",
      "-------------------------------\n",
      "loss: 0.201034  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407749 \n",
      "\n",
      "Epoch 4588\n",
      "-------------------------------\n",
      "loss: 0.216213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408811 \n",
      "\n",
      "Epoch 4589\n",
      "-------------------------------\n",
      "loss: 0.223772  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407479 \n",
      "\n",
      "Epoch 4590\n",
      "-------------------------------\n",
      "loss: 0.222566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404163 \n",
      "\n",
      "Epoch 4591\n",
      "-------------------------------\n",
      "loss: 0.212073  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401774 \n",
      "\n",
      "Epoch 4592\n",
      "-------------------------------\n",
      "loss: 0.209014  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400246 \n",
      "\n",
      "Epoch 4593\n",
      "-------------------------------\n",
      "loss: 0.233952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399099 \n",
      "\n",
      "Epoch 4594\n",
      "-------------------------------\n",
      "loss: 0.223374  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398471 \n",
      "\n",
      "Epoch 4595\n",
      "-------------------------------\n",
      "loss: 0.220178  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397590 \n",
      "\n",
      "Epoch 4596\n",
      "-------------------------------\n",
      "loss: 0.216261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397431 \n",
      "\n",
      "Epoch 4597\n",
      "-------------------------------\n",
      "loss: 0.227275  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399157 \n",
      "\n",
      "Epoch 4598\n",
      "-------------------------------\n",
      "loss: 0.212807  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401715 \n",
      "\n",
      "Epoch 4599\n",
      "-------------------------------\n",
      "loss: 0.230793  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403293 \n",
      "\n",
      "Epoch 4600\n",
      "-------------------------------\n",
      "loss: 0.246022  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401393 \n",
      "\n",
      "Epoch 4601\n",
      "-------------------------------\n",
      "loss: 0.211053  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399069 \n",
      "\n",
      "Epoch 4602\n",
      "-------------------------------\n",
      "loss: 0.224013  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397774 \n",
      "\n",
      "Epoch 4603\n",
      "-------------------------------\n",
      "loss: 0.219449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398128 \n",
      "\n",
      "Epoch 4604\n",
      "-------------------------------\n",
      "loss: 0.226741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400456 \n",
      "\n",
      "Epoch 4605\n",
      "-------------------------------\n",
      "loss: 0.240916  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402104 \n",
      "\n",
      "Epoch 4606\n",
      "-------------------------------\n",
      "loss: 0.238950  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402777 \n",
      "\n",
      "Epoch 4607\n",
      "-------------------------------\n",
      "loss: 0.217283  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401895 \n",
      "\n",
      "Epoch 4608\n",
      "-------------------------------\n",
      "loss: 0.224947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400581 \n",
      "\n",
      "Epoch 4609\n",
      "-------------------------------\n",
      "loss: 0.216901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400771 \n",
      "\n",
      "Epoch 4610\n",
      "-------------------------------\n",
      "loss: 0.209774  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401265 \n",
      "\n",
      "Epoch 4611\n",
      "-------------------------------\n",
      "loss: 0.228258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401394 \n",
      "\n",
      "Epoch 4612\n",
      "-------------------------------\n",
      "loss: 0.212560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402361 \n",
      "\n",
      "Epoch 4613\n",
      "-------------------------------\n",
      "loss: 0.213439  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.405232 \n",
      "\n",
      "Epoch 4614\n",
      "-------------------------------\n",
      "loss: 0.214875  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410961 \n",
      "\n",
      "Epoch 4615\n",
      "-------------------------------\n",
      "loss: 0.241715  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414277 \n",
      "\n",
      "Epoch 4616\n",
      "-------------------------------\n",
      "loss: 0.221560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.414106 \n",
      "\n",
      "Epoch 4617\n",
      "-------------------------------\n",
      "loss: 0.220426  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.410314 \n",
      "\n",
      "Epoch 4618\n",
      "-------------------------------\n",
      "loss: 0.228418  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405644 \n",
      "\n",
      "Epoch 4619\n",
      "-------------------------------\n",
      "loss: 0.206140  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403149 \n",
      "\n",
      "Epoch 4620\n",
      "-------------------------------\n",
      "loss: 0.230007  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403285 \n",
      "\n",
      "Epoch 4621\n",
      "-------------------------------\n",
      "loss: 0.231815  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402141 \n",
      "\n",
      "Epoch 4622\n",
      "-------------------------------\n",
      "loss: 0.243118  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399873 \n",
      "\n",
      "Epoch 4623\n",
      "-------------------------------\n",
      "loss: 0.232755  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398751 \n",
      "\n",
      "Epoch 4624\n",
      "-------------------------------\n",
      "loss: 0.211288  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401736 \n",
      "\n",
      "Epoch 4625\n",
      "-------------------------------\n",
      "loss: 0.234935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404075 \n",
      "\n",
      "Epoch 4626\n",
      "-------------------------------\n",
      "loss: 0.240627  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403363 \n",
      "\n",
      "Epoch 4627\n",
      "-------------------------------\n",
      "loss: 0.212851  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402169 \n",
      "\n",
      "Epoch 4628\n",
      "-------------------------------\n",
      "loss: 0.225889  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399454 \n",
      "\n",
      "Epoch 4629\n",
      "-------------------------------\n",
      "loss: 0.207261  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397241 \n",
      "\n",
      "Epoch 4630\n",
      "-------------------------------\n",
      "loss: 0.217351  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395239 \n",
      "\n",
      "Epoch 4631\n",
      "-------------------------------\n",
      "loss: 0.227859  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394867 \n",
      "\n",
      "Epoch 4632\n",
      "-------------------------------\n",
      "loss: 0.217529  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395311 \n",
      "\n",
      "Epoch 4633\n",
      "-------------------------------\n",
      "loss: 0.212837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396178 \n",
      "\n",
      "Epoch 4634\n",
      "-------------------------------\n",
      "loss: 0.219131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398094 \n",
      "\n",
      "Epoch 4635\n",
      "-------------------------------\n",
      "loss: 0.212467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401841 \n",
      "\n",
      "Epoch 4636\n",
      "-------------------------------\n",
      "loss: 0.205311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405334 \n",
      "\n",
      "Epoch 4637\n",
      "-------------------------------\n",
      "loss: 0.223524  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406636 \n",
      "\n",
      "Epoch 4638\n",
      "-------------------------------\n",
      "loss: 0.239639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403746 \n",
      "\n",
      "Epoch 4639\n",
      "-------------------------------\n",
      "loss: 0.234897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398822 \n",
      "\n",
      "Epoch 4640\n",
      "-------------------------------\n",
      "loss: 0.203464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397025 \n",
      "\n",
      "Epoch 4641\n",
      "-------------------------------\n",
      "loss: 0.251655  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397697 \n",
      "\n",
      "Epoch 4642\n",
      "-------------------------------\n",
      "loss: 0.223267  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398727 \n",
      "\n",
      "Epoch 4643\n",
      "-------------------------------\n",
      "loss: 0.217744  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399394 \n",
      "\n",
      "Epoch 4644\n",
      "-------------------------------\n",
      "loss: 0.219199  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401555 \n",
      "\n",
      "Epoch 4645\n",
      "-------------------------------\n",
      "loss: 0.206640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404383 \n",
      "\n",
      "Epoch 4646\n",
      "-------------------------------\n",
      "loss: 0.226193  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405508 \n",
      "\n",
      "Epoch 4647\n",
      "-------------------------------\n",
      "loss: 0.216060  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405652 \n",
      "\n",
      "Epoch 4648\n",
      "-------------------------------\n",
      "loss: 0.217068  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405131 \n",
      "\n",
      "Epoch 4649\n",
      "-------------------------------\n",
      "loss: 0.230226  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403888 \n",
      "\n",
      "Epoch 4650\n",
      "-------------------------------\n",
      "loss: 0.214883  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403230 \n",
      "\n",
      "Epoch 4651\n",
      "-------------------------------\n",
      "loss: 0.217733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403090 \n",
      "\n",
      "Epoch 4652\n",
      "-------------------------------\n",
      "loss: 0.221677  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402977 \n",
      "\n",
      "Epoch 4653\n",
      "-------------------------------\n",
      "loss: 0.217302  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403266 \n",
      "\n",
      "Epoch 4654\n",
      "-------------------------------\n",
      "loss: 0.216996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402977 \n",
      "\n",
      "Epoch 4655\n",
      "-------------------------------\n",
      "loss: 0.229597  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403652 \n",
      "\n",
      "Epoch 4656\n",
      "-------------------------------\n",
      "loss: 0.213643  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404714 \n",
      "\n",
      "Epoch 4657\n",
      "-------------------------------\n",
      "loss: 0.233399  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405183 \n",
      "\n",
      "Epoch 4658\n",
      "-------------------------------\n",
      "loss: 0.225769  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404369 \n",
      "\n",
      "Epoch 4659\n",
      "-------------------------------\n",
      "loss: 0.217947  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403159 \n",
      "\n",
      "Epoch 4660\n",
      "-------------------------------\n",
      "loss: 0.209328  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402367 \n",
      "\n",
      "Epoch 4661\n",
      "-------------------------------\n",
      "loss: 0.222311  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399913 \n",
      "\n",
      "Epoch 4662\n",
      "-------------------------------\n",
      "loss: 0.222474  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398587 \n",
      "\n",
      "Epoch 4663\n",
      "-------------------------------\n",
      "loss: 0.221025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397531 \n",
      "\n",
      "Epoch 4664\n",
      "-------------------------------\n",
      "loss: 0.217356  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397294 \n",
      "\n",
      "Epoch 4665\n",
      "-------------------------------\n",
      "loss: 0.223613  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397496 \n",
      "\n",
      "Epoch 4666\n",
      "-------------------------------\n",
      "loss: 0.227833  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398342 \n",
      "\n",
      "Epoch 4667\n",
      "-------------------------------\n",
      "loss: 0.217996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400047 \n",
      "\n",
      "Epoch 4668\n",
      "-------------------------------\n",
      "loss: 0.216342  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403327 \n",
      "\n",
      "Epoch 4669\n",
      "-------------------------------\n",
      "loss: 0.213696  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406462 \n",
      "\n",
      "Epoch 4670\n",
      "-------------------------------\n",
      "loss: 0.220277  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407898 \n",
      "\n",
      "Epoch 4671\n",
      "-------------------------------\n",
      "loss: 0.248757  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404408 \n",
      "\n",
      "Epoch 4672\n",
      "-------------------------------\n",
      "loss: 0.214684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399655 \n",
      "\n",
      "Epoch 4673\n",
      "-------------------------------\n",
      "loss: 0.214857  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397630 \n",
      "\n",
      "Epoch 4674\n",
      "-------------------------------\n",
      "loss: 0.249856  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397909 \n",
      "\n",
      "Epoch 4675\n",
      "-------------------------------\n",
      "loss: 0.227543  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398384 \n",
      "\n",
      "Epoch 4676\n",
      "-------------------------------\n",
      "loss: 0.233182  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397646 \n",
      "\n",
      "Epoch 4677\n",
      "-------------------------------\n",
      "loss: 0.233802  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399228 \n",
      "\n",
      "Epoch 4678\n",
      "-------------------------------\n",
      "loss: 0.218759  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403690 \n",
      "\n",
      "Epoch 4679\n",
      "-------------------------------\n",
      "loss: 0.221914  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408196 \n",
      "\n",
      "Epoch 4680\n",
      "-------------------------------\n",
      "loss: 0.209785  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408799 \n",
      "\n",
      "Epoch 4681\n",
      "-------------------------------\n",
      "loss: 0.230990  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405335 \n",
      "\n",
      "Epoch 4682\n",
      "-------------------------------\n",
      "loss: 0.218746  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402460 \n",
      "\n",
      "Epoch 4683\n",
      "-------------------------------\n",
      "loss: 0.224462  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400995 \n",
      "\n",
      "Epoch 4684\n",
      "-------------------------------\n",
      "loss: 0.211522  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401477 \n",
      "\n",
      "Epoch 4685\n",
      "-------------------------------\n",
      "loss: 0.228442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401728 \n",
      "\n",
      "Epoch 4686\n",
      "-------------------------------\n",
      "loss: 0.236092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402024 \n",
      "\n",
      "Epoch 4687\n",
      "-------------------------------\n",
      "loss: 0.210814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403893 \n",
      "\n",
      "Epoch 4688\n",
      "-------------------------------\n",
      "loss: 0.227530  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404798 \n",
      "\n",
      "Epoch 4689\n",
      "-------------------------------\n",
      "loss: 0.230883  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.404185 \n",
      "\n",
      "Epoch 4690\n",
      "-------------------------------\n",
      "loss: 0.229156  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402454 \n",
      "\n",
      "Epoch 4691\n",
      "-------------------------------\n",
      "loss: 0.212190  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402224 \n",
      "\n",
      "Epoch 4692\n",
      "-------------------------------\n",
      "loss: 0.212227  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401745 \n",
      "\n",
      "Epoch 4693\n",
      "-------------------------------\n",
      "loss: 0.221778  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402253 \n",
      "\n",
      "Epoch 4694\n",
      "-------------------------------\n",
      "loss: 0.218104  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401892 \n",
      "\n",
      "Epoch 4695\n",
      "-------------------------------\n",
      "loss: 0.218910  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400922 \n",
      "\n",
      "Epoch 4696\n",
      "-------------------------------\n",
      "loss: 0.218233  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400718 \n",
      "\n",
      "Epoch 4697\n",
      "-------------------------------\n",
      "loss: 0.242899  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400077 \n",
      "\n",
      "Epoch 4698\n",
      "-------------------------------\n",
      "loss: 0.223343  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400589 \n",
      "\n",
      "Epoch 4699\n",
      "-------------------------------\n",
      "loss: 0.229728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401635 \n",
      "\n",
      "Epoch 4700\n",
      "-------------------------------\n",
      "loss: 0.218982  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403373 \n",
      "\n",
      "Epoch 4701\n",
      "-------------------------------\n",
      "loss: 0.240567  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404426 \n",
      "\n",
      "Epoch 4702\n",
      "-------------------------------\n",
      "loss: 0.223409  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405121 \n",
      "\n",
      "Epoch 4703\n",
      "-------------------------------\n",
      "loss: 0.228896  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405019 \n",
      "\n",
      "Epoch 4704\n",
      "-------------------------------\n",
      "loss: 0.218433  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405245 \n",
      "\n",
      "Epoch 4705\n",
      "-------------------------------\n",
      "loss: 0.233560  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404173 \n",
      "\n",
      "Epoch 4706\n",
      "-------------------------------\n",
      "loss: 0.213092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403490 \n",
      "\n",
      "Epoch 4707\n",
      "-------------------------------\n",
      "loss: 0.219603  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401822 \n",
      "\n",
      "Epoch 4708\n",
      "-------------------------------\n",
      "loss: 0.215762  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401314 \n",
      "\n",
      "Epoch 4709\n",
      "-------------------------------\n",
      "loss: 0.214551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401208 \n",
      "\n",
      "Epoch 4710\n",
      "-------------------------------\n",
      "loss: 0.220363  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401779 \n",
      "\n",
      "Epoch 4711\n",
      "-------------------------------\n",
      "loss: 0.211847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402791 \n",
      "\n",
      "Epoch 4712\n",
      "-------------------------------\n",
      "loss: 0.210371  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404200 \n",
      "\n",
      "Epoch 4713\n",
      "-------------------------------\n",
      "loss: 0.215753  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403595 \n",
      "\n",
      "Epoch 4714\n",
      "-------------------------------\n",
      "loss: 0.210487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402323 \n",
      "\n",
      "Epoch 4715\n",
      "-------------------------------\n",
      "loss: 0.214260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399972 \n",
      "\n",
      "Epoch 4716\n",
      "-------------------------------\n",
      "loss: 0.226146  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398397 \n",
      "\n",
      "Epoch 4717\n",
      "-------------------------------\n",
      "loss: 0.220421  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397978 \n",
      "\n",
      "Epoch 4718\n",
      "-------------------------------\n",
      "loss: 0.216285  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397206 \n",
      "\n",
      "Epoch 4719\n",
      "-------------------------------\n",
      "loss: 0.212223  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397783 \n",
      "\n",
      "Epoch 4720\n",
      "-------------------------------\n",
      "loss: 0.215890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398324 \n",
      "\n",
      "Epoch 4721\n",
      "-------------------------------\n",
      "loss: 0.215358  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399210 \n",
      "\n",
      "Epoch 4722\n",
      "-------------------------------\n",
      "loss: 0.210250  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399901 \n",
      "\n",
      "Epoch 4723\n",
      "-------------------------------\n",
      "loss: 0.212719  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399476 \n",
      "\n",
      "Epoch 4724\n",
      "-------------------------------\n",
      "loss: 0.228504  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398004 \n",
      "\n",
      "Epoch 4725\n",
      "-------------------------------\n",
      "loss: 0.207915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396761 \n",
      "\n",
      "Epoch 4726\n",
      "-------------------------------\n",
      "loss: 0.218160  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396239 \n",
      "\n",
      "Epoch 4727\n",
      "-------------------------------\n",
      "loss: 0.210942  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396031 \n",
      "\n",
      "Epoch 4728\n",
      "-------------------------------\n",
      "loss: 0.217962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395505 \n",
      "\n",
      "Epoch 4729\n",
      "-------------------------------\n",
      "loss: 0.223895  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395503 \n",
      "\n",
      "Epoch 4730\n",
      "-------------------------------\n",
      "loss: 0.222926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396445 \n",
      "\n",
      "Epoch 4731\n",
      "-------------------------------\n",
      "loss: 0.217213  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397551 \n",
      "\n",
      "Epoch 4732\n",
      "-------------------------------\n",
      "loss: 0.222725  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400102 \n",
      "\n",
      "Epoch 4733\n",
      "-------------------------------\n",
      "loss: 0.214042  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402383 \n",
      "\n",
      "Epoch 4734\n",
      "-------------------------------\n",
      "loss: 0.243782  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401522 \n",
      "\n",
      "Epoch 4735\n",
      "-------------------------------\n",
      "loss: 0.210476  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399104 \n",
      "\n",
      "Epoch 4736\n",
      "-------------------------------\n",
      "loss: 0.208122  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398318 \n",
      "\n",
      "Epoch 4737\n",
      "-------------------------------\n",
      "loss: 0.211467  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397303 \n",
      "\n",
      "Epoch 4738\n",
      "-------------------------------\n",
      "loss: 0.219903  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398015 \n",
      "\n",
      "Epoch 4739\n",
      "-------------------------------\n",
      "loss: 0.221239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398797 \n",
      "\n",
      "Epoch 4740\n",
      "-------------------------------\n",
      "loss: 0.220978  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398827 \n",
      "\n",
      "Epoch 4741\n",
      "-------------------------------\n",
      "loss: 0.214593  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398288 \n",
      "\n",
      "Epoch 4742\n",
      "-------------------------------\n",
      "loss: 0.228576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398606 \n",
      "\n",
      "Epoch 4743\n",
      "-------------------------------\n",
      "loss: 0.217394  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399781 \n",
      "\n",
      "Epoch 4744\n",
      "-------------------------------\n",
      "loss: 0.203480  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402799 \n",
      "\n",
      "Epoch 4745\n",
      "-------------------------------\n",
      "loss: 0.223798  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403586 \n",
      "\n",
      "Epoch 4746\n",
      "-------------------------------\n",
      "loss: 0.227906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402845 \n",
      "\n",
      "Epoch 4747\n",
      "-------------------------------\n",
      "loss: 0.229072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400290 \n",
      "\n",
      "Epoch 4748\n",
      "-------------------------------\n",
      "loss: 0.231025  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399362 \n",
      "\n",
      "Epoch 4749\n",
      "-------------------------------\n",
      "loss: 0.222805  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399415 \n",
      "\n",
      "Epoch 4750\n",
      "-------------------------------\n",
      "loss: 0.223666  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398795 \n",
      "\n",
      "Epoch 4751\n",
      "-------------------------------\n",
      "loss: 0.215901  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398279 \n",
      "\n",
      "Epoch 4752\n",
      "-------------------------------\n",
      "loss: 0.214616  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398806 \n",
      "\n",
      "Epoch 4753\n",
      "-------------------------------\n",
      "loss: 0.223998  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399998 \n",
      "\n",
      "Epoch 4754\n",
      "-------------------------------\n",
      "loss: 0.206595  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401481 \n",
      "\n",
      "Epoch 4755\n",
      "-------------------------------\n",
      "loss: 0.224273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403228 \n",
      "\n",
      "Epoch 4756\n",
      "-------------------------------\n",
      "loss: 0.215620  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404307 \n",
      "\n",
      "Epoch 4757\n",
      "-------------------------------\n",
      "loss: 0.210553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402994 \n",
      "\n",
      "Epoch 4758\n",
      "-------------------------------\n",
      "loss: 0.212260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401098 \n",
      "\n",
      "Epoch 4759\n",
      "-------------------------------\n",
      "loss: 0.222492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399785 \n",
      "\n",
      "Epoch 4760\n",
      "-------------------------------\n",
      "loss: 0.217487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398922 \n",
      "\n",
      "Epoch 4761\n",
      "-------------------------------\n",
      "loss: 0.220941  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398694 \n",
      "\n",
      "Epoch 4762\n",
      "-------------------------------\n",
      "loss: 0.228247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398944 \n",
      "\n",
      "Epoch 4763\n",
      "-------------------------------\n",
      "loss: 0.227069  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399389 \n",
      "\n",
      "Epoch 4764\n",
      "-------------------------------\n",
      "loss: 0.218959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399440 \n",
      "\n",
      "Epoch 4765\n",
      "-------------------------------\n",
      "loss: 0.211017  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.399379 \n",
      "\n",
      "Epoch 4766\n",
      "-------------------------------\n",
      "loss: 0.222766  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398857 \n",
      "\n",
      "Epoch 4767\n",
      "-------------------------------\n",
      "loss: 0.224985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398215 \n",
      "\n",
      "Epoch 4768\n",
      "-------------------------------\n",
      "loss: 0.210313  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398586 \n",
      "\n",
      "Epoch 4769\n",
      "-------------------------------\n",
      "loss: 0.212881  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400374 \n",
      "\n",
      "Epoch 4770\n",
      "-------------------------------\n",
      "loss: 0.224367  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401852 \n",
      "\n",
      "Epoch 4771\n",
      "-------------------------------\n",
      "loss: 0.221551  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402035 \n",
      "\n",
      "Epoch 4772\n",
      "-------------------------------\n",
      "loss: 0.225877  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401940 \n",
      "\n",
      "Epoch 4773\n",
      "-------------------------------\n",
      "loss: 0.213166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401767 \n",
      "\n",
      "Epoch 4774\n",
      "-------------------------------\n",
      "loss: 0.214417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401813 \n",
      "\n",
      "Epoch 4775\n",
      "-------------------------------\n",
      "loss: 0.222726  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402414 \n",
      "\n",
      "Epoch 4776\n",
      "-------------------------------\n",
      "loss: 0.211967  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403716 \n",
      "\n",
      "Epoch 4777\n",
      "-------------------------------\n",
      "loss: 0.212727  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406553 \n",
      "\n",
      "Epoch 4778\n",
      "-------------------------------\n",
      "loss: 0.231020  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.408503 \n",
      "\n",
      "Epoch 4779\n",
      "-------------------------------\n",
      "loss: 0.206115  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.409341 \n",
      "\n",
      "Epoch 4780\n",
      "-------------------------------\n",
      "loss: 0.218794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.407431 \n",
      "\n",
      "Epoch 4781\n",
      "-------------------------------\n",
      "loss: 0.229151  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405265 \n",
      "\n",
      "Epoch 4782\n",
      "-------------------------------\n",
      "loss: 0.209247  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403709 \n",
      "\n",
      "Epoch 4783\n",
      "-------------------------------\n",
      "loss: 0.212708  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403680 \n",
      "\n",
      "Epoch 4784\n",
      "-------------------------------\n",
      "loss: 0.230847  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402650 \n",
      "\n",
      "Epoch 4785\n",
      "-------------------------------\n",
      "loss: 0.224974  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402205 \n",
      "\n",
      "Epoch 4786\n",
      "-------------------------------\n",
      "loss: 0.227832  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402629 \n",
      "\n",
      "Epoch 4787\n",
      "-------------------------------\n",
      "loss: 0.217035  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403816 \n",
      "\n",
      "Epoch 4788\n",
      "-------------------------------\n",
      "loss: 0.229962  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404621 \n",
      "\n",
      "Epoch 4789\n",
      "-------------------------------\n",
      "loss: 0.228468  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404322 \n",
      "\n",
      "Epoch 4790\n",
      "-------------------------------\n",
      "loss: 0.225558  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403947 \n",
      "\n",
      "Epoch 4791\n",
      "-------------------------------\n",
      "loss: 0.228177  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403064 \n",
      "\n",
      "Epoch 4792\n",
      "-------------------------------\n",
      "loss: 0.222301  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401897 \n",
      "\n",
      "Epoch 4793\n",
      "-------------------------------\n",
      "loss: 0.236258  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400742 \n",
      "\n",
      "Epoch 4794\n",
      "-------------------------------\n",
      "loss: 0.222566  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399893 \n",
      "\n",
      "Epoch 4795\n",
      "-------------------------------\n",
      "loss: 0.211264  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400236 \n",
      "\n",
      "Epoch 4796\n",
      "-------------------------------\n",
      "loss: 0.220495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401247 \n",
      "\n",
      "Epoch 4797\n",
      "-------------------------------\n",
      "loss: 0.220266  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401159 \n",
      "\n",
      "Epoch 4798\n",
      "-------------------------------\n",
      "loss: 0.206598  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401085 \n",
      "\n",
      "Epoch 4799\n",
      "-------------------------------\n",
      "loss: 0.207300  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400424 \n",
      "\n",
      "Epoch 4800\n",
      "-------------------------------\n",
      "loss: 0.234092  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398919 \n",
      "\n",
      "Epoch 4801\n",
      "-------------------------------\n",
      "loss: 0.228232  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397265 \n",
      "\n",
      "Epoch 4802\n",
      "-------------------------------\n",
      "loss: 0.216925  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396471 \n",
      "\n",
      "Epoch 4803\n",
      "-------------------------------\n",
      "loss: 0.217102  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395771 \n",
      "\n",
      "Epoch 4804\n",
      "-------------------------------\n",
      "loss: 0.227364  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395426 \n",
      "\n",
      "Epoch 4805\n",
      "-------------------------------\n",
      "loss: 0.218669  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395989 \n",
      "\n",
      "Epoch 4806\n",
      "-------------------------------\n",
      "loss: 0.226368  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398024 \n",
      "\n",
      "Epoch 4807\n",
      "-------------------------------\n",
      "loss: 0.208906  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400565 \n",
      "\n",
      "Epoch 4808\n",
      "-------------------------------\n",
      "loss: 0.238141  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400665 \n",
      "\n",
      "Epoch 4809\n",
      "-------------------------------\n",
      "loss: 0.211992  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399072 \n",
      "\n",
      "Epoch 4810\n",
      "-------------------------------\n",
      "loss: 0.227784  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396547 \n",
      "\n",
      "Epoch 4811\n",
      "-------------------------------\n",
      "loss: 0.209030  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396356 \n",
      "\n",
      "Epoch 4812\n",
      "-------------------------------\n",
      "loss: 0.219165  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397124 \n",
      "\n",
      "Epoch 4813\n",
      "-------------------------------\n",
      "loss: 0.216400  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398398 \n",
      "\n",
      "Epoch 4814\n",
      "-------------------------------\n",
      "loss: 0.211794  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399732 \n",
      "\n",
      "Epoch 4815\n",
      "-------------------------------\n",
      "loss: 0.203940  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400355 \n",
      "\n",
      "Epoch 4816\n",
      "-------------------------------\n",
      "loss: 0.208319  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400830 \n",
      "\n",
      "Epoch 4817\n",
      "-------------------------------\n",
      "loss: 0.207640  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401723 \n",
      "\n",
      "Epoch 4818\n",
      "-------------------------------\n",
      "loss: 0.212828  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403708 \n",
      "\n",
      "Epoch 4819\n",
      "-------------------------------\n",
      "loss: 0.215325  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403911 \n",
      "\n",
      "Epoch 4820\n",
      "-------------------------------\n",
      "loss: 0.213676  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402521 \n",
      "\n",
      "Epoch 4821\n",
      "-------------------------------\n",
      "loss: 0.224478  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401345 \n",
      "\n",
      "Epoch 4822\n",
      "-------------------------------\n",
      "loss: 0.218639  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400919 \n",
      "\n",
      "Epoch 4823\n",
      "-------------------------------\n",
      "loss: 0.209463  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400923 \n",
      "\n",
      "Epoch 4824\n",
      "-------------------------------\n",
      "loss: 0.216728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401124 \n",
      "\n",
      "Epoch 4825\n",
      "-------------------------------\n",
      "loss: 0.214816  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401571 \n",
      "\n",
      "Epoch 4826\n",
      "-------------------------------\n",
      "loss: 0.234071  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402703 \n",
      "\n",
      "Epoch 4827\n",
      "-------------------------------\n",
      "loss: 0.224644  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404968 \n",
      "\n",
      "Epoch 4828\n",
      "-------------------------------\n",
      "loss: 0.214671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405677 \n",
      "\n",
      "Epoch 4829\n",
      "-------------------------------\n",
      "loss: 0.222783  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404034 \n",
      "\n",
      "Epoch 4830\n",
      "-------------------------------\n",
      "loss: 0.212968  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401494 \n",
      "\n",
      "Epoch 4831\n",
      "-------------------------------\n",
      "loss: 0.205870  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400269 \n",
      "\n",
      "Epoch 4832\n",
      "-------------------------------\n",
      "loss: 0.214095  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400646 \n",
      "\n",
      "Epoch 4833\n",
      "-------------------------------\n",
      "loss: 0.207818  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401279 \n",
      "\n",
      "Epoch 4834\n",
      "-------------------------------\n",
      "loss: 0.221934  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401361 \n",
      "\n",
      "Epoch 4835\n",
      "-------------------------------\n",
      "loss: 0.214927  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401645 \n",
      "\n",
      "Epoch 4836\n",
      "-------------------------------\n",
      "loss: 0.224693  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402179 \n",
      "\n",
      "Epoch 4837\n",
      "-------------------------------\n",
      "loss: 0.225984  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401288 \n",
      "\n",
      "Epoch 4838\n",
      "-------------------------------\n",
      "loss: 0.227738  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401509 \n",
      "\n",
      "Epoch 4839\n",
      "-------------------------------\n",
      "loss: 0.211294  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402160 \n",
      "\n",
      "Epoch 4840\n",
      "-------------------------------\n",
      "loss: 0.200926  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404011 \n",
      "\n",
      "Epoch 4841\n",
      "-------------------------------\n",
      "loss: 0.221631  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403764 \n",
      "\n",
      "Epoch 4842\n",
      "-------------------------------\n",
      "loss: 0.260684  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401355 \n",
      "\n",
      "Epoch 4843\n",
      "-------------------------------\n",
      "loss: 0.218776  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399452 \n",
      "\n",
      "Epoch 4844\n",
      "-------------------------------\n",
      "loss: 0.213051  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397819 \n",
      "\n",
      "Epoch 4845\n",
      "-------------------------------\n",
      "loss: 0.236396  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397104 \n",
      "\n",
      "Epoch 4846\n",
      "-------------------------------\n",
      "loss: 0.216939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397284 \n",
      "\n",
      "Epoch 4847\n",
      "-------------------------------\n",
      "loss: 0.209129  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397736 \n",
      "\n",
      "Epoch 4848\n",
      "-------------------------------\n",
      "loss: 0.233451  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398387 \n",
      "\n",
      "Epoch 4849\n",
      "-------------------------------\n",
      "loss: 0.228403  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398809 \n",
      "\n",
      "Epoch 4850\n",
      "-------------------------------\n",
      "loss: 0.218997  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398636 \n",
      "\n",
      "Epoch 4851\n",
      "-------------------------------\n",
      "loss: 0.228200  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398373 \n",
      "\n",
      "Epoch 4852\n",
      "-------------------------------\n",
      "loss: 0.216166  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398522 \n",
      "\n",
      "Epoch 4853\n",
      "-------------------------------\n",
      "loss: 0.216464  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398601 \n",
      "\n",
      "Epoch 4854\n",
      "-------------------------------\n",
      "loss: 0.216734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398976 \n",
      "\n",
      "Epoch 4855\n",
      "-------------------------------\n",
      "loss: 0.210134  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399150 \n",
      "\n",
      "Epoch 4856\n",
      "-------------------------------\n",
      "loss: 0.207557  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399695 \n",
      "\n",
      "Epoch 4857\n",
      "-------------------------------\n",
      "loss: 0.211741  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401274 \n",
      "\n",
      "Epoch 4858\n",
      "-------------------------------\n",
      "loss: 0.208952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402089 \n",
      "\n",
      "Epoch 4859\n",
      "-------------------------------\n",
      "loss: 0.219472  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401340 \n",
      "\n",
      "Epoch 4860\n",
      "-------------------------------\n",
      "loss: 0.229210  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399908 \n",
      "\n",
      "Epoch 4861\n",
      "-------------------------------\n",
      "loss: 0.225510  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399079 \n",
      "\n",
      "Epoch 4862\n",
      "-------------------------------\n",
      "loss: 0.214308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399170 \n",
      "\n",
      "Epoch 4863\n",
      "-------------------------------\n",
      "loss: 0.229843  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399995 \n",
      "\n",
      "Epoch 4864\n",
      "-------------------------------\n",
      "loss: 0.217393  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401264 \n",
      "\n",
      "Epoch 4865\n",
      "-------------------------------\n",
      "loss: 0.223422  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402507 \n",
      "\n",
      "Epoch 4866\n",
      "-------------------------------\n",
      "loss: 0.212048  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403913 \n",
      "\n",
      "Epoch 4867\n",
      "-------------------------------\n",
      "loss: 0.211993  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405564 \n",
      "\n",
      "Epoch 4868\n",
      "-------------------------------\n",
      "loss: 0.223492  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406158 \n",
      "\n",
      "Epoch 4869\n",
      "-------------------------------\n",
      "loss: 0.228734  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406075 \n",
      "\n",
      "Epoch 4870\n",
      "-------------------------------\n",
      "loss: 0.212487  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405036 \n",
      "\n",
      "Epoch 4871\n",
      "-------------------------------\n",
      "loss: 0.212001  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404132 \n",
      "\n",
      "Epoch 4872\n",
      "-------------------------------\n",
      "loss: 0.221369  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403985 \n",
      "\n",
      "Epoch 4873\n",
      "-------------------------------\n",
      "loss: 0.219304  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403681 \n",
      "\n",
      "Epoch 4874\n",
      "-------------------------------\n",
      "loss: 0.222448  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403955 \n",
      "\n",
      "Epoch 4875\n",
      "-------------------------------\n",
      "loss: 0.208853  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405657 \n",
      "\n",
      "Epoch 4876\n",
      "-------------------------------\n",
      "loss: 0.221897  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406542 \n",
      "\n",
      "Epoch 4877\n",
      "-------------------------------\n",
      "loss: 0.213989  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.406963 \n",
      "\n",
      "Epoch 4878\n",
      "-------------------------------\n",
      "loss: 0.205447  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405047 \n",
      "\n",
      "Epoch 4879\n",
      "-------------------------------\n",
      "loss: 0.227293  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402739 \n",
      "\n",
      "Epoch 4880\n",
      "-------------------------------\n",
      "loss: 0.201126  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400882 \n",
      "\n",
      "Epoch 4881\n",
      "-------------------------------\n",
      "loss: 0.215770  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399160 \n",
      "\n",
      "Epoch 4882\n",
      "-------------------------------\n",
      "loss: 0.220930  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397870 \n",
      "\n",
      "Epoch 4883\n",
      "-------------------------------\n",
      "loss: 0.223372  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397097 \n",
      "\n",
      "Epoch 4884\n",
      "-------------------------------\n",
      "loss: 0.222954  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397072 \n",
      "\n",
      "Epoch 4885\n",
      "-------------------------------\n",
      "loss: 0.224806  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397915 \n",
      "\n",
      "Epoch 4886\n",
      "-------------------------------\n",
      "loss: 0.217571  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399675 \n",
      "\n",
      "Epoch 4887\n",
      "-------------------------------\n",
      "loss: 0.207365  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401254 \n",
      "\n",
      "Epoch 4888\n",
      "-------------------------------\n",
      "loss: 0.242985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400656 \n",
      "\n",
      "Epoch 4889\n",
      "-------------------------------\n",
      "loss: 0.205625  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399041 \n",
      "\n",
      "Epoch 4890\n",
      "-------------------------------\n",
      "loss: 0.230420  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398552 \n",
      "\n",
      "Epoch 4891\n",
      "-------------------------------\n",
      "loss: 0.206273  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399025 \n",
      "\n",
      "Epoch 4892\n",
      "-------------------------------\n",
      "loss: 0.239638  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399483 \n",
      "\n",
      "Epoch 4893\n",
      "-------------------------------\n",
      "loss: 0.227308  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399512 \n",
      "\n",
      "Epoch 4894\n",
      "-------------------------------\n",
      "loss: 0.226072  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399448 \n",
      "\n",
      "Epoch 4895\n",
      "-------------------------------\n",
      "loss: 0.209631  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400709 \n",
      "\n",
      "Epoch 4896\n",
      "-------------------------------\n",
      "loss: 0.222905  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403451 \n",
      "\n",
      "Epoch 4897\n",
      "-------------------------------\n",
      "loss: 0.215112  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405317 \n",
      "\n",
      "Epoch 4898\n",
      "-------------------------------\n",
      "loss: 0.229915  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404913 \n",
      "\n",
      "Epoch 4899\n",
      "-------------------------------\n",
      "loss: 0.218031  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402989 \n",
      "\n",
      "Epoch 4900\n",
      "-------------------------------\n",
      "loss: 0.210775  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400789 \n",
      "\n",
      "Epoch 4901\n",
      "-------------------------------\n",
      "loss: 0.227171  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399826 \n",
      "\n",
      "Epoch 4902\n",
      "-------------------------------\n",
      "loss: 0.223307  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400245 \n",
      "\n",
      "Epoch 4903\n",
      "-------------------------------\n",
      "loss: 0.215965  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401642 \n",
      "\n",
      "Epoch 4904\n",
      "-------------------------------\n",
      "loss: 0.223181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403326 \n",
      "\n",
      "Epoch 4905\n",
      "-------------------------------\n",
      "loss: 0.215728  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405144 \n",
      "\n",
      "Epoch 4906\n",
      "-------------------------------\n",
      "loss: 0.216183  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405422 \n",
      "\n",
      "Epoch 4907\n",
      "-------------------------------\n",
      "loss: 0.222055  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404599 \n",
      "\n",
      "Epoch 4908\n",
      "-------------------------------\n",
      "loss: 0.218310  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401885 \n",
      "\n",
      "Epoch 4909\n",
      "-------------------------------\n",
      "loss: 0.217164  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399764 \n",
      "\n",
      "Epoch 4910\n",
      "-------------------------------\n",
      "loss: 0.221322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399510 \n",
      "\n",
      "Epoch 4911\n",
      "-------------------------------\n",
      "loss: 0.214192  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399808 \n",
      "\n",
      "Epoch 4912\n",
      "-------------------------------\n",
      "loss: 0.218733  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400093 \n",
      "\n",
      "Epoch 4913\n",
      "-------------------------------\n",
      "loss: 0.220985  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401417 \n",
      "\n",
      "Epoch 4914\n",
      "-------------------------------\n",
      "loss: 0.213204  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403483 \n",
      "\n",
      "Epoch 4915\n",
      "-------------------------------\n",
      "loss: 0.220404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405021 \n",
      "\n",
      "Epoch 4916\n",
      "-------------------------------\n",
      "loss: 0.222449  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404773 \n",
      "\n",
      "Epoch 4917\n",
      "-------------------------------\n",
      "loss: 0.195523  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.403746 \n",
      "\n",
      "Epoch 4918\n",
      "-------------------------------\n",
      "loss: 0.222714  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401725 \n",
      "\n",
      "Epoch 4919\n",
      "-------------------------------\n",
      "loss: 0.219671  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399258 \n",
      "\n",
      "Epoch 4920\n",
      "-------------------------------\n",
      "loss: 0.218404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398411 \n",
      "\n",
      "Epoch 4921\n",
      "-------------------------------\n",
      "loss: 0.219230  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398043 \n",
      "\n",
      "Epoch 4922\n",
      "-------------------------------\n",
      "loss: 0.217665  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398510 \n",
      "\n",
      "Epoch 4923\n",
      "-------------------------------\n",
      "loss: 0.218933  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399572 \n",
      "\n",
      "Epoch 4924\n",
      "-------------------------------\n",
      "loss: 0.222673  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399752 \n",
      "\n",
      "Epoch 4925\n",
      "-------------------------------\n",
      "loss: 0.202135  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399752 \n",
      "\n",
      "Epoch 4926\n",
      "-------------------------------\n",
      "loss: 0.216996  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400519 \n",
      "\n",
      "Epoch 4927\n",
      "-------------------------------\n",
      "loss: 0.241605  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401237 \n",
      "\n",
      "Epoch 4928\n",
      "-------------------------------\n",
      "loss: 0.223457  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400404 \n",
      "\n",
      "Epoch 4929\n",
      "-------------------------------\n",
      "loss: 0.229037  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399374 \n",
      "\n",
      "Epoch 4930\n",
      "-------------------------------\n",
      "loss: 0.217814  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398624 \n",
      "\n",
      "Epoch 4931\n",
      "-------------------------------\n",
      "loss: 0.206239  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397732 \n",
      "\n",
      "Epoch 4932\n",
      "-------------------------------\n",
      "loss: 0.227995  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396994 \n",
      "\n",
      "Epoch 4933\n",
      "-------------------------------\n",
      "loss: 0.214179  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397116 \n",
      "\n",
      "Epoch 4934\n",
      "-------------------------------\n",
      "loss: 0.217574  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397113 \n",
      "\n",
      "Epoch 4935\n",
      "-------------------------------\n",
      "loss: 0.224004  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397298 \n",
      "\n",
      "Epoch 4936\n",
      "-------------------------------\n",
      "loss: 0.226180  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396770 \n",
      "\n",
      "Epoch 4937\n",
      "-------------------------------\n",
      "loss: 0.210970  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396004 \n",
      "\n",
      "Epoch 4938\n",
      "-------------------------------\n",
      "loss: 0.217890  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394600 \n",
      "\n",
      "Epoch 4939\n",
      "-------------------------------\n",
      "loss: 0.217162  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393723 \n",
      "\n",
      "Epoch 4940\n",
      "-------------------------------\n",
      "loss: 0.213322  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393556 \n",
      "\n",
      "Epoch 4941\n",
      "-------------------------------\n",
      "loss: 0.220323  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393565 \n",
      "\n",
      "Epoch 4942\n",
      "-------------------------------\n",
      "loss: 0.219576  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394122 \n",
      "\n",
      "Epoch 4943\n",
      "-------------------------------\n",
      "loss: 0.227799  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396026 \n",
      "\n",
      "Epoch 4944\n",
      "-------------------------------\n",
      "loss: 0.220539  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397864 \n",
      "\n",
      "Epoch 4945\n",
      "-------------------------------\n",
      "loss: 0.223481  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398135 \n",
      "\n",
      "Epoch 4946\n",
      "-------------------------------\n",
      "loss: 0.232417  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396445 \n",
      "\n",
      "Epoch 4947\n",
      "-------------------------------\n",
      "loss: 0.217353  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395410 \n",
      "\n",
      "Epoch 4948\n",
      "-------------------------------\n",
      "loss: 0.211080  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395201 \n",
      "\n",
      "Epoch 4949\n",
      "-------------------------------\n",
      "loss: 0.226482  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395746 \n",
      "\n",
      "Epoch 4950\n",
      "-------------------------------\n",
      "loss: 0.221981  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397235 \n",
      "\n",
      "Epoch 4951\n",
      "-------------------------------\n",
      "loss: 0.211397  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398094 \n",
      "\n",
      "Epoch 4952\n",
      "-------------------------------\n",
      "loss: 0.206181  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399895 \n",
      "\n",
      "Epoch 4953\n",
      "-------------------------------\n",
      "loss: 0.212330  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401085 \n",
      "\n",
      "Epoch 4954\n",
      "-------------------------------\n",
      "loss: 0.214953  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401579 \n",
      "\n",
      "Epoch 4955\n",
      "-------------------------------\n",
      "loss: 0.224006  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401298 \n",
      "\n",
      "Epoch 4956\n",
      "-------------------------------\n",
      "loss: 0.218429  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400835 \n",
      "\n",
      "Epoch 4957\n",
      "-------------------------------\n",
      "loss: 0.212668  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401270 \n",
      "\n",
      "Epoch 4958\n",
      "-------------------------------\n",
      "loss: 0.200959  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401146 \n",
      "\n",
      "Epoch 4959\n",
      "-------------------------------\n",
      "loss: 0.213952  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401236 \n",
      "\n",
      "Epoch 4960\n",
      "-------------------------------\n",
      "loss: 0.212495  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402718 \n",
      "\n",
      "Epoch 4961\n",
      "-------------------------------\n",
      "loss: 0.211837  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403964 \n",
      "\n",
      "Epoch 4962\n",
      "-------------------------------\n",
      "loss: 0.237600  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402366 \n",
      "\n",
      "Epoch 4963\n",
      "-------------------------------\n",
      "loss: 0.216431  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400399 \n",
      "\n",
      "Epoch 4964\n",
      "-------------------------------\n",
      "loss: 0.216136  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399743 \n",
      "\n",
      "Epoch 4965\n",
      "-------------------------------\n",
      "loss: 0.214276  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400003 \n",
      "\n",
      "Epoch 4966\n",
      "-------------------------------\n",
      "loss: 0.234672  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400665 \n",
      "\n",
      "Epoch 4967\n",
      "-------------------------------\n",
      "loss: 0.223161  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401162 \n",
      "\n",
      "Epoch 4968\n",
      "-------------------------------\n",
      "loss: 0.208296  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.402328 \n",
      "\n",
      "Epoch 4969\n",
      "-------------------------------\n",
      "loss: 0.218260  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.403644 \n",
      "\n",
      "Epoch 4970\n",
      "-------------------------------\n",
      "loss: 0.209860  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404675 \n",
      "\n",
      "Epoch 4971\n",
      "-------------------------------\n",
      "loss: 0.221813  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.405237 \n",
      "\n",
      "Epoch 4972\n",
      "-------------------------------\n",
      "loss: 0.217361  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.404188 \n",
      "\n",
      "Epoch 4973\n",
      "-------------------------------\n",
      "loss: 0.211280  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401871 \n",
      "\n",
      "Epoch 4974\n",
      "-------------------------------\n",
      "loss: 0.220081  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400564 \n",
      "\n",
      "Epoch 4975\n",
      "-------------------------------\n",
      "loss: 0.205195  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399092 \n",
      "\n",
      "Epoch 4976\n",
      "-------------------------------\n",
      "loss: 0.199076  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398508 \n",
      "\n",
      "Epoch 4977\n",
      "-------------------------------\n",
      "loss: 0.222217  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397944 \n",
      "\n",
      "Epoch 4978\n",
      "-------------------------------\n",
      "loss: 0.218939  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.397817 \n",
      "\n",
      "Epoch 4979\n",
      "-------------------------------\n",
      "loss: 0.217651  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398651 \n",
      "\n",
      "Epoch 4980\n",
      "-------------------------------\n",
      "loss: 0.212966  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399176 \n",
      "\n",
      "Epoch 4981\n",
      "-------------------------------\n",
      "loss: 0.222404  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.399356 \n",
      "\n",
      "Epoch 4982\n",
      "-------------------------------\n",
      "loss: 0.214761  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398972 \n",
      "\n",
      "Epoch 4983\n",
      "-------------------------------\n",
      "loss: 0.225653  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.396606 \n",
      "\n",
      "Epoch 4984\n",
      "-------------------------------\n",
      "loss: 0.224442  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394399 \n",
      "\n",
      "Epoch 4985\n",
      "-------------------------------\n",
      "loss: 0.220137  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393330 \n",
      "\n",
      "Epoch 4986\n",
      "-------------------------------\n",
      "loss: 0.213211  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393266 \n",
      "\n",
      "Epoch 4987\n",
      "-------------------------------\n",
      "loss: 0.218701  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393254 \n",
      "\n",
      "Epoch 4988\n",
      "-------------------------------\n",
      "loss: 0.229096  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393310 \n",
      "\n",
      "Epoch 4989\n",
      "-------------------------------\n",
      "loss: 0.213058  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394852 \n",
      "\n",
      "Epoch 4990\n",
      "-------------------------------\n",
      "loss: 0.213917  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398137 \n",
      "\n",
      "Epoch 4991\n",
      "-------------------------------\n",
      "loss: 0.219935  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.400748 \n",
      "\n",
      "Epoch 4992\n",
      "-------------------------------\n",
      "loss: 0.225747  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.401418 \n",
      "\n",
      "Epoch 4993\n",
      "-------------------------------\n",
      "loss: 0.206710  [ 1024/176128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.400788 \n",
      "\n",
      "Epoch 4994\n",
      "-------------------------------\n",
      "loss: 0.208236  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.398488 \n",
      "\n",
      "Epoch 4995\n",
      "-------------------------------\n",
      "loss: 0.216553  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395267 \n",
      "\n",
      "Epoch 4996\n",
      "-------------------------------\n",
      "loss: 0.221131  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393805 \n",
      "\n",
      "Epoch 4997\n",
      "-------------------------------\n",
      "loss: 0.217577  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.393719 \n",
      "\n",
      "Epoch 4998\n",
      "-------------------------------\n",
      "loss: 0.206202  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394280 \n",
      "\n",
      "Epoch 4999\n",
      "-------------------------------\n",
      "loss: 0.213466  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.394685 \n",
      "\n",
      "Epoch 5000\n",
      "-------------------------------\n",
      "loss: 0.216838  [ 1024/176128]\n",
      "Test Error: \n",
      " Avg loss: 0.395661 \n",
      "\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 53 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 53 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://new-ui.neptune.ai/jettinger35/predictScalp/e/PRED-66/metadata\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if optChoice == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "elif optChoice == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "else:\n",
    "    optimizer = None\n",
    "    print('no optimizer chosen...')\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=neptuneProject,\n",
    "    api_token=api_token,  \n",
    "    capture_hardware_metrics=True,\n",
    "    capture_stderr=True,\n",
    "    capture_stdout=True,\n",
    ")\n",
    "\n",
    "PARAMS = {\n",
    "    \"modelID\": modelID,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": learningRate,\n",
    "    \"optimizer\": optChoice,\n",
    "    \"patience\": patience,\n",
    "    \"subsampleFreq\": subsampleFreq,\n",
    "    \"secondsInWindow\": secondsInWindow,\n",
    "    \"nperseg\": nperseg,\n",
    "    \"noverlap\": noverlap,\n",
    "    \"window\": stringify_unsupported(window),\n",
    "    \"loss_fn\": stringify_unsupported(loss_fn),\n",
    "    \"architectureString\": str(model),\n",
    "    \"numParameters\": sdm.count_parameters(model)\n",
    "}\n",
    "run[\"parameters\"] = PARAMS\n",
    "\n",
    "noImprovementCount = 0\n",
    "\n",
    "#epochs = 2\n",
    "\n",
    "try:\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = sdm.train(trainDataLoader, model, loss_fn, optimizer, device)\n",
    "        test_loss = sdm.test(validDataLoader, model, loss_fn, device)\n",
    "\n",
    "        if test_loss < bestTestLoss:\n",
    "            noImprovementCount = 0\n",
    "            bestTestLoss = test_loss\n",
    "            \n",
    "            model_scripted = torch.jit.script(model) \n",
    "            model_scripted.save(modelPath + 'model_%s.pt' % str(modelID))\n",
    "    \n",
    "            run[\"best_test_loss\"] =  bestTestLoss\n",
    "            run[\"best_test_epoch\"] = t\n",
    "            print(\"\\nSaved a new best model!\\n\")\n",
    "        else:\n",
    "            noImprovementCount = noImprovementCount + 1\n",
    "\n",
    "        run[\"train/loss\"].append(train_loss)\n",
    "        run[\"test/loss\"].append(test_loss)\n",
    "\n",
    "        if noImprovementCount >= patience:   \n",
    "            print(\"Early stopping invoked....\")\n",
    "            break\n",
    "\n",
    "    run.stop()\n",
    "    print(\"Done!\")\n",
    "except:\n",
    "    run.stop()\n",
    "    print(\"Training aborted...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3474b",
   "metadata": {},
   "source": [
    "# PLOT RESULTS OF FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a858773f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT PREDICTION VERSUS TRUTH\n",
    "\n",
    "trainPlotFlag = False\n",
    "    \n",
    "if trainPlotFlag:\n",
    "    x = trainXTensor\n",
    "    trainTitle = 'train'\n",
    "else:\n",
    "    x = validXTensor\n",
    "    trainTitle = 'valididation'\n",
    "\n",
    "model.to('cpu')\n",
    "predict = model(x).cpu().detach().numpy()\n",
    "model.to(device)\n",
    "\n",
    "if predict.shape[1] == 1:\n",
    "    yPred = predict[:,0]\n",
    "    if trainPlotFlag:\n",
    "        yTrue = yTrainTimeDomain[:,0]\n",
    "    else:\n",
    "        yTrue = yValidTimeDomain[:,0]\n",
    "else:\n",
    "    _, yPred = realSTFTtoTimeSeries(predict)\n",
    "    if trainPlotFlag:\n",
    "        y = y_trainRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "    else:\n",
    "        y = y_validRTheta\n",
    "        _, yTrue = realSTFTtoTimeSeries(y)\n",
    "        \n",
    "\n",
    "lossTemp = loss_fn(torch.tensor(yPred), torch.tensor(yTrue)).item()\n",
    "title = 'Data: ' + trainTitle + ' (loss: %s)' % str(lossTemp)\n",
    "plt.figure()\n",
    "plt.plot(yPred, label='predict')\n",
    "plt.plot(yTrue, label='true')\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962a7d4",
   "metadata": {},
   "source": [
    "# GET BEST MODEL DATA FROM NEPTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cdade1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/jettinger35/predictScalp/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys/id</th>\n",
       "      <th>best_test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRED-66</td>\n",
       "      <td>0.389803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRED-65</td>\n",
       "      <td>0.677281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRED-64</td>\n",
       "      <td>0.648604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRED-63</td>\n",
       "      <td>0.665345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRED-62</td>\n",
       "      <td>0.676881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRED-61</td>\n",
       "      <td>0.666001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRED-60</td>\n",
       "      <td>0.674732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRED-59</td>\n",
       "      <td>0.391365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRED-54</td>\n",
       "      <td>0.391573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRED-53</td>\n",
       "      <td>0.423721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRED-46</td>\n",
       "      <td>0.405430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRED-43</td>\n",
       "      <td>0.390877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PRED-38</td>\n",
       "      <td>0.398955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRED-35</td>\n",
       "      <td>0.403722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRED-34</td>\n",
       "      <td>0.417772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRED-32</td>\n",
       "      <td>0.408214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRED-31</td>\n",
       "      <td>0.409690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRED-58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRED-57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRED-56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRED-55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sys/id  best_test_loss\n",
       "0   PRED-66        0.389803\n",
       "1   PRED-65        0.677281\n",
       "2   PRED-64        0.648604\n",
       "3   PRED-63        0.665345\n",
       "4   PRED-62        0.676881\n",
       "5   PRED-61        0.666001\n",
       "6   PRED-60        0.674732\n",
       "7   PRED-59        0.391365\n",
       "12  PRED-54        0.391573\n",
       "13  PRED-53        0.423721\n",
       "14  PRED-46        0.405430\n",
       "15  PRED-43        0.390877\n",
       "16  PRED-38        0.398955\n",
       "17  PRED-35        0.403722\n",
       "18  PRED-34        0.417772\n",
       "19  PRED-32        0.408214\n",
       "20  PRED-31        0.409690\n",
       "8   PRED-58             NaN\n",
       "9   PRED-57             NaN\n",
       "10  PRED-56             NaN\n",
       "11  PRED-55             NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdm.neptuneBestRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671c8d3",
   "metadata": {},
   "source": [
    "# SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c14b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram, stft, istft, check_NOLA\n",
    "\n",
    "fs = 1\n",
    "nperseg = 32\n",
    "noverlap = 31\n",
    "#windowType = ('tukey', .25)\n",
    "windowType = np.ones(nperseg)\n",
    "\n",
    "\n",
    "a = np.random.rand(100)\n",
    "f, t, S = stft(a, fs=fs, window=windowType, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "b = torch.stft(torch.tensor(a), \n",
    "               n_fft = nperseg, \n",
    "               hop_length = 1, \n",
    "               return_complex=True, \n",
    "               normalized=False, \n",
    "               onesided=True, \n",
    "               pad_mode='constant').numpy()\n",
    "\n",
    "np.abs(np.divide(b,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d95ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import get_window\n",
    "a = get_window(('tukey', .25), nperseg)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        return loss\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, layerOrderedDict):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(layerOrderedDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# GIVEN A LIST OF LAYER SIZES MAKE AN ORDERED DICTIONARY FOR INITIALIZING A PYTORCH NET\n",
    "\n",
    "def listToOrderedDict(sizeList):\n",
    "    n = len(sizeList)\n",
    "    tupleList = []\n",
    "    for i in range(n - 1):\n",
    "        tupleList.append(('bn%s' % str(i), nn.BatchNorm1d(sizeList[i])))\n",
    "        tupleList.append(('l%s' % str(i), nn.Linear(sizeList[i], sizeList[i+1])))\n",
    "        tupleList.append(('r%s' % str(i), nn.ReLU()))\n",
    "    return OrderedDict(tupleList[:-1])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "'''\n",
    "\n",
    "'''\n",
    "    layerSizeList = [trainXTensor.shape[1]] + hiddenLayerSizes + [trainYTensor.shape[1]]\n",
    "    layerOrderedDict = sdm.listToOrderedDict(layerSizeList)\n",
    "    model = sdm.NeuralNetwork(layerOrderedDict)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.13",
   "language": "python",
   "name": "pytorch-1.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
